#include "_TreeEM_new.h"

//
//  TreeEM.cpp
//  TreeSeg
//
//  Created by Carole Sudre on 08/04/2013.
//  Copyright (c) 2013 Carole Sudre. All rights reserved.
//


TreeEM::TreeEM(){

    this->Parent = NULL;
    this->DataImage=NULL;
    this->Mask = NULL;
    this->Priors = NULL;
    this->PriorsAdapted=NULL;
    this->PartPriorsAdapted=NULL;
    //this->Short_2_Long_Indices = NULL;
    //this->Long_2_Short_Indices;
    this->L2S=NULL;
    this->S2L=NULL;
    this->NormResp=NULL;
    this->NormWeight=1;
    this->IndFactor=0;
    this->NumberMaskedElements=0;
    this->DPChildren=NULL;
    this->FlagDistClassInd=0;
    this->FlagOutliers=0;
    this->FlagCovPriors=0;
    this->FlagMeanPriors=0;
    this->ParametersDistribution=NULL;
    this->SplitCheck=NULL;
    this->MergeCheck=NULL;
    // this->BFBasisFunctions=NULL;
    //    this->BFCorrection=NULL;
    this->DataBFCorrected=NULL;
    this->BFCoeffs=NULL;
    this->HardSeg=NULL;
    this->MRF=NULL;
    this->GMatrix=NULL;

}

//static int numbbins=128;
static int numbbins=256;
static int MaxBaMoSTries=1000;
static bool NormMask=0;
static int BForder=3;
static bool BFFlag=1;
static int BICFP=1;
static int KernelSize=3;
static int NumbMaxLeaves=15;
static int MaxNumbLeavesperClass=15;
static PrecisionTYPE Threshold=1E-5;
static int MaxIteration=50;
static int MinIteration=6;
const char* Mod[]={"Undefined","T1","T2","FLAIR","PD"};
static vector<string> PossibleModalities(Mod,Mod+5);
const float  MahalThreshold[]={0.0027,0.0111,0.0293,0.0611};
vector< vector<int> > NeighborhoodSummary;
vector<vector<int> > OutlierSummary;
int numbClasses;
float GValues[3];
bool ValidGInfo=0;


TreeEM::TreeEM(nifti_image * DataInput){

    this->Parent=NULL;
    this->DataImage=DataInput;
    this->Mask = NULL;
    this->Priors = NULL;
    this->PriorsAdapted=NULL;
    this->PartPriorsAdapted=NULL;
    this->L2S=NULL;
    this->S2L=NULL;
    this->NormResp=NULL;
    this->NormWeight=1;
    this->IndFactor=0;
    this->NumberMaskedElements=0;
    this->DPChildren=NULL;
    this->FlagDistClassInd=0;
    this->FlagOutliers=0;
    this->ParametersDistribution=NULL;
    this->SplitCheck=NULL;
    this->MergeCheck=NULL;
    this->DataBFCorrected=NULL;
    this->BFCoeffs=NULL;
    this->HardSeg=NULL;
    this->MRF=NULL;
    this->GMatrix=NULL;
}

float * TreeEM::LogGaussBlur(float * GaussianBlur,int TotalSize){
    float * LogGaussBlur=new float[TotalSize];
    for(int i=0;i<TotalSize;i++){
        if(GaussianBlur[i]<=0){
            LogGaussBlur[i]=-10E6;
        }
        else{
            LogGaussBlur[i]=logf(GaussianBlur[i]);
        }
    }
    return LogGaussBlur;
}

// To be used to optimise time efficiency dealing with exponentiation
inline float TreeEM::pow_int(const float base,
                             int exp){
    if(exp==0){return 1;}
    float result = base;
    while (--exp){result *= base;}
    return result;
}

// Returns the transposed matrix in a new float array given the matrix and its dimension
float * TreeEM::TransposeMatrix(float * MatrixToTranspose, int SizeM,int SizeN){
    float * TransposedMatrix =new float [SizeN*SizeM];
    for(int n=0;n<SizeN;n++){
        for(int m=0;m<SizeM;m++){
            TransposedMatrix[m*SizeN+n]=MatrixToTranspose[n*SizeM+m];
        }
    }
    return TransposedMatrix;
}

// Returns in a float array newly assigned the product of matrix L and R given their size
float * TreeEM::ProductMatrix(float * MatrixL, float * MatrixR,int * Size){
    if(Size[1]!=Size[2]){
        cout<<"Size incompatibilities in the matrices"<<endl;
        return NULL;
    }
    float * MatrixProduct=new float[Size[0]*Size[3]];
    for(int i=0;i<Size[0]*Size[3];i++){
        MatrixProduct[i]=0;
    }
    for(int i=0;i<Size[0];i++){
        for(int k=0;k<Size[3];k++){
            for(int j=0;j<Size[1];j++){
                MatrixProduct[i+k*Size[0]]+=MatrixL[i+j*Size[0]]*MatrixR[j+k*Size[1]];
//                if (MatrixR[j+k*Size[0]]==1) {
//                    cout<<"value on R "<<j<<" "<<k<<" is 1 and value at L "<<i<<" "<<j <<" is "<<MatrixL[i+j*Size[0]]<<endl;
//                }
            }
        }
    }
    return MatrixProduct;
}

//Returns in a float array newly assigned the product of matrix A elementwise by value M given the size of A
float * TreeEM::ProductMatrix(float *MatrixA, float M, int *Size){
    float * MatrixProd=new float[Size[0]*Size[1]];
    for (int i=0; i<Size[0]*Size[1]; i++) {
        MatrixProd[i]=MatrixA[i]*M;
    }
    return MatrixProd;
}

//Returns in a float array newly assigned the difference elementwise between matrix A and matrix B A-B given the size of A (size of B assumed to be the same)
float * TreeEM::DiffMatrix(float * A, float * B, int* Size){
    float * DiffResult=new float[Size[0]*Size[1]];
    for (int i=0; i<Size[0]*Size[1]; i++) {
        DiffResult[i]=A[i]-B[i];
    }
    return DiffResult;
}

//Returns in a float array newly assigned the addition elementwise between matrix A and matrix B A+B given the size of A (size of B assumed to be the same)
float * TreeEM::AddMatrix(float * A, float * B, int* Size){
    float * DiffResult=new float[Size[0]*Size[1]];
    for (int i=0; i<Size[0]*Size[1]; i++) {
        DiffResult[i]=A[i]+B[i];
    }
    return DiffResult;
}

// Returns the infinite norm of Matrix A given its Size
float TreeEM::NormInfMatrix(float * A, int* Size)
{
    float maxval=0.0;
    float newval=0.0;
    for (int i=0; i < Size[0]; i++)
    {
        for (int j=0; j < Size[1]; j++)
        {
            newval= fabs(A[i+j*Size[0]]);
            maxval = (newval > maxval) ? newval : maxval;
        }
    }
    return maxval;
}

// Return the square root of a matrix
float * TreeEM::MatrixSquareRoot(float * Matrix, int Size)
{
    float * X=new float[Size*Size];
    float * Y=new float[Size*Size];
    int it=0;
    int maxit=10;
    for (int m1=0; m1<Size; m1++) {
        for (int m2=0; m2<Size; m2++) {
            Y[m1+Size*m2]=(float)(m1==m2);
            X[m1+Size*m2]=Matrix[m1+Size*m2];
        }
    }
    double eps=1.0e-7;
//    int * SizeX=new int[2];
    int SizeX[2];
    SizeX[0]=SizeX[1]=Size;
    int SizeX2[4];
//    int * SizeX2=new int[4];
    SizeX2[0]=SizeX2[1]=SizeX2[2]=SizeX2[3]=Size;
    float * Xsq=ProductMatrix(Matrix, Matrix, SizeX2);
    
    float * diffMat = DiffMatrix(Xsq,Matrix,SizeX);
    delete[] Xsq;
    Xsq=NULL;
    while (NormInfMatrix(diffMat, SizeX) > eps)
    {
        delete[] diffMat;
        diffMat=NULL;
        float * delX=InvertMatrix(X, Size);
        float * delY=InvertMatrix(Y, Size);
        float * XdelY=AddMatrix(X, delY, SizeX);
        float * YdelX=AddMatrix(Y, delX, SizeX);
        delete [] X;
        delete [] Y;
        delete [] delX;
        delete [] delY;
        X=NULL;
        Y=NULL;
        delX=NULL;
        delY=NULL;
         X=ProductMatrix(XdelY, 0.5, SizeX2);
         Y=ProductMatrix(YdelX, 0.5, SizeX2);
        delete [] XdelY;
        delete [] YdelX;
        XdelY=NULL;
        YdelX=NULL;
        Xsq=ProductMatrix(X, X, SizeX2);
        diffMat = DiffMatrix(Xsq, Matrix, SizeX);
        delete [] Xsq;
        Xsq=NULL;
        it++;
        if(it > maxit)
            break;
    }
    delete [] Y;
    Y=NULL;
    delete [] diffMat;
    diffMat=NULL;
//    delete [] SizeX;
//    SizeX=NULL;
//    delete[] SizeX2;
//    SizeX2=NULL;
    return X;
}
/* *************************************************************** */
/* *************************************************************** */
/**
 * Compute the matrix exponential according to "Linear combination of transformations", Marc Alex, Volume 21, Issue 3, ACM SIGGRAPH 2002.
 * and from Kelvin's implementation of the code in NifTK
 */
float * TreeEM::ExpMatrix(float * mat, int maxit, int Size)
{
//    int * SizeX=new int[2];
    int SizeX[2];
    SizeX[0]=SizeX[1]=Size;
//    int * SizeX2=new int[4];
    int SizeX2[4];
    SizeX2[0]=SizeX2[1]=SizeX2[2]=SizeX2[3]=Size;
    double j = max(0.0,1+floor(log(NormInfMatrix(mat, SizeX))/log(2.0)));
    
    float * A=ProductMatrix(mat, pow(2.0, -j), SizeX);
//    for(int i=0;i<Size*Size;i++){
//        cout<<" "<<A[i];
//    }
//    cout<<endl;
    float * D=new float[Size*Size];
    float * N=new float[Size*Size];
    float * X=new float[Size*Size];
    for (int m1=0; m1<Size; m1++) {
        for (int m2=0; m2<Size; m2++) {
            D[m1+m2*Size]=(float)(m1==m2);
            X[m1+m2*Size]=(float)(m1==m2);
            N[m1+m2*Size]=(float)(m1==m2);
        }
    }
    float * D1;
    float * X1;

    
    double c = 1.0;
    for(int k=1; k <= maxit; k++)
    {
        c = c * (maxit-k+1.0) / (k*(2*maxit-k+1.0));
        X1=ProductMatrix(A, X, SizeX2);
        delete [] X;
        X=NULL;
        X=X1;
        float * cX=ProductMatrix(X1, c, SizeX);
        float * N1=AddMatrix(N, cX, SizeX);
        delete [] N;
        N=NULL;
        N=N1;
        float * cX1=ProductMatrix(cX, pow(-1.0,k), SizeX);
        delete [] cX;
        cX=NULL;
        cX=cX1;
        D1=AddMatrix(D, cX, SizeX);
        delete [] D;
        D = NULL;
        delete [] cX;
        cX=NULL;
        D=D1;
    }
    delete [] A;
    A=NULL;
    D1=InvertMatrix(D,Size);
    delete [] X;
    X=NULL;
    X=ProductMatrix(D1, N, SizeX2);
    delete [] D1;
    delete [] N;
    N=NULL;
    D1=NULL;
    for(int i=0; i < round(j); i++)
    {
        X1=ProductMatrix(X, X, SizeX2);
        delete [] X;
        X=NULL;
        X=X1;
    }
//    delete [] SizeX;
//    delete [] SizeX2;
//    SizeX=NULL;
//    SizeX2=NULL;
    
    return X;
}
/* *************************************************************** */
/* *************************************************************** */
// Computes the log of a matrix and return the result in a new float array
float * TreeEM::LogMatrix(float * Matrix, int Size)
{
    int k = 0;
    float * I=new float[Size*Size];
    float * A=new float[Size*Size];
    for (int m1=0; m1<Size; m1++) {
        for (int m2=0; m2<Size; m2++) {
            I[m1+m2*Size]=(float)(m1==m2);
            A[m1+m2*Size]=Matrix[m1+m2*Size];
        }
    }
//    int * SizeX=new int[2];
    int SizeX[2];
    SizeX[0]=SizeX[1]=Size;
//    int * SizeX2=new int[4];
    int SizeX2[4];
    SizeX2[0]=SizeX2[1]=SizeX2[2]=SizeX2[3]=Size;
    double eps=1.0e-7;
    float * A_I = DiffMatrix(A, I, SizeX);
    while(NormInfMatrix(A_I, SizeX) > 0.5)
    {
        float * A1=MatrixSquareRoot(A, Size);
        delete [] A;
        A=NULL;
        A=A1;
        delete [] A_I;
        A_I=NULL;
        A_I = DiffMatrix(A, I, SizeX);
        k=k+1;
    }
    delete [] A_I;
    A_I=NULL;
    float * A2 = DiffMatrix(I, A, SizeX);
    delete [] A;
    A=NULL;
    A=A2;
    delete [] I;
    I=NULL;
    
    float * Z=new float[Size*Size];
    float * X= new float[Size * Size];
    for (int i=0; i<Size*Size; i++) {
        Z[i]=A[i];
        X[i]=A[i];
    }
    double i = 1.0;
    while(NormInfMatrix(Z, SizeX) > eps)
    {
        float * Z1 = ProductMatrix(Z, A, SizeX2);
        delete [] Z;
        Z=NULL;
        Z=Z1;
        i += 1.0;
        float * Z_i = ProductMatrix(Z, 1.0/i, SizeX);
        float * X1 = AddMatrix(X, Z_i, SizeX);
        delete [] X;
        X=NULL;
        X=X1;
        delete [] Z_i;
        Z_i=NULL;
    }
    delete [] A;
    A=NULL;
    delete [] Z;
    Z=NULL;
    float * X2=ProductMatrix(X, -1.0, SizeX);
    delete [] X;
    X=NULL;
    X=X2;
    float * X3 = ProductMatrix(X, pow(2.0,k), SizeX);
    delete [] X;
    X=NULL;
//    delete [] SizeX;
//    delete [] SizeX2;
//    SizeX=NULL;
//    SizeX2=NULL;
    return X3;
    
}

// Returns in a float array the log mean of a vector of matrices according to the weights attributed to these matrices and their size (same size assumed for all matrices)
float * TreeEM::WeightedLogMean(vector<float *> MatrixVector, vector<float> WeightVector, int Size){
    int numbMatrices=MatrixVector.size();
    int numbWeights=WeightVector.size();
    if (numbMatrices!=numbWeights) {
        cout<<"Not similar number of weights and matrices for log mean"<<endl;
        return NULL;
    }
    // Normalisation of weights
    float sumWeights=0;
    for (int l=0; l<numbMatrices; l++) {
        sumWeights+=WeightVector[l];
    }
    if (sumWeights>0) {
        for (int l=0; l<numbMatrices; l++) {
            WeightVector[l]/=sumWeights;
        }
    }
    else{
        cout<<"pb in averaging : sum of weights is 0"<<endl;
        return NULL;
    }
//    int * SizeX=new int[2];
    int SizeX[2];
    SizeX[0]=SizeX[1]=Size;
//    int * SizeX2=new int[4];
    int SizeX2[4];
    SizeX2[0]=SizeX2[1]=SizeX2[2]=SizeX2[3]=Size;
    // Initialisation of weighted sum of log matrices
    float * SumWeightedLogMatrices=new float[Size * Size];
    for (int i=0; i<Size*Size; i++) {
        SumWeightedLogMatrices[i]=0;
    }
    // Determination of weighted sum of log matrices
    for (int l=0; l<numbMatrices; l++) {
        float * logMatrix=LogMatrix(MatrixVector[l], Size);
        float * WeightedLogMatrix=ProductMatrix(logMatrix, WeightVector[l], SizeX);
        delete [] logMatrix;
        logMatrix=NULL;
        float * SumWeightedLogMatricesTmp=AddMatrix(SumWeightedLogMatrices, WeightedLogMatrix, SizeX);
        delete [] WeightedLogMatrix;
        WeightedLogMatrix=NULL;
        delete [] SumWeightedLogMatrices;
        SumWeightedLogMatrices=NULL;
        SumWeightedLogMatrices=SumWeightedLogMatricesTmp;
    }
//    for (int i=0; i<Size*Size; i++) {
//        cout<<" "<<SumWeightedLogMatrices[i];
//    }
//    cout<<endl;
    float * LogMeanMatrices=ExpMatrix(SumWeightedLogMatrices, 6, Size);
//    for (int i=0; i<Size*Size; i++) {
//        cout<<" "<<LogMeanMatrices[i];
//    }
//    cout<<endl;
    delete [] SumWeightedLogMatrices;
//    delete [] SizeX;
    SumWeightedLogMatrices=NULL;
//    SizeX=NULL;
    return LogMeanMatrices;

}

// Modify the input matrix in order to give its inverse given its size. The assumption is made that the float array given as input contains size*size elements
void TreeEM::invertMatrix(float * MatrixToInvert, int SizeMatrix)  {
//  if (size!=size2){
//      cout << "Matrix in not square" << endl;
//      return;
//    }
  if (SizeMatrix <= 1) {
      if(MatrixToInvert[0]!=0){
      MatrixToInvert[0]=1.0/MatrixToInvert[0];
      }
      return;
  }
  for (int i=1; i < SizeMatrix; i++) {
      MatrixToInvert[i] /= MatrixToInvert[0]; // normalize row 0
    }
  for (int i=1; i < SizeMatrix; i++)  {
      for (int j=i; j < SizeMatrix; j++)  { // do a column of L
          PrecisionTYPE sum = 0.0;
          for (int k = 0; k < i; k++){
              sum += MatrixToInvert[j*SizeMatrix+k] * MatrixToInvert[k*SizeMatrix+i];
            }
          MatrixToInvert[j*SizeMatrix+i] -= sum;
        }
      if (i == SizeMatrix-1) continue;
      for (int j=i+1; j < SizeMatrix; j++)  {  // do a row of U
          PrecisionTYPE sum = 0.0;
          for (int k = 0; k < i; k++){
              sum +=(PrecisionTYPE) MatrixToInvert[i*SizeMatrix+k]*MatrixToInvert[k*SizeMatrix+j];
            }
          MatrixToInvert[i*SizeMatrix+j] =(MatrixToInvert[i*SizeMatrix+j]-sum) / MatrixToInvert[i*SizeMatrix+i];
        }
    }
  for ( int i = 0; i < SizeMatrix; i++ )  {// invert L
    for ( int j = i; j < SizeMatrix; j++ )  {
        float x = 1.0;
        if ( i != j ) {
            x = 0.0;
            for ( int k = i; k < j; k++ ){
                x -= MatrixToInvert[j*SizeMatrix+k]*MatrixToInvert[k*SizeMatrix+i];
              }
          }
        MatrixToInvert[j*SizeMatrix+i] = x / MatrixToInvert[j*SizeMatrix+j];
      }
  }
  for ( int i = 0; i < SizeMatrix; i++ ) {  // invert U
    for ( int j = i; j < SizeMatrix; j++ )  {
        if ( i == j ){continue;}
        PrecisionTYPE sum = 0.0;
        for ( int k = i; k < j; k++ ){
            sum += (PrecisionTYPE)MatrixToInvert[k*SizeMatrix+j]*( (i==k) ? 1.0 : MatrixToInvert[i*SizeMatrix+k] );
          }
        MatrixToInvert[i*SizeMatrix+j] = -sum;
      }
  }
  for ( int i = 0; i < SizeMatrix; i++ ){   // final inversion
    for ( int j = 0; j < SizeMatrix; j++ )  {
        PrecisionTYPE sum = 0.0;
        for ( int k = ((i>j)?i:j); k < SizeMatrix; k++ ){
            sum +=(PrecisionTYPE) ((j==k)?1.0:MatrixToInvert[j*SizeMatrix+k])*MatrixToInvert[k*SizeMatrix+i];
          }
        MatrixToInvert[j*SizeMatrix+i] = (float)sum;
      }
  }
  return;
}

// Invert the matrix and return the result under newly assigned array
float * TreeEM::InvertMatrix(float * MatrixToInvert, int SizeMatrix)  {
    //  if (size!=size2){
    //      cout << "Matrix in not square" << endl;
    //      return;
    //    }
    float * CopyMatrix=new float[SizeMatrix*SizeMatrix];
    for (int i=0; i<SizeMatrix*SizeMatrix; i++) {
        CopyMatrix[i]=MatrixToInvert[i];
    }
    if (SizeMatrix <= 1) {
        if(CopyMatrix[0]!=0){
            CopyMatrix[0]=1.0/CopyMatrix[0];
        }
        return CopyMatrix;
    }
    for (int i=1; i < SizeMatrix; i++) {
         CopyMatrix[i] /= CopyMatrix[0]; // normalize row 0
    }
    for (int i=1; i < SizeMatrix; i++)  {
        for (int j=i; j < SizeMatrix; j++)  { // do a column of L
            PrecisionTYPE sum = 0.0;
            for (int k = 0; k < i; k++){
                sum += CopyMatrix[j*SizeMatrix+k] * CopyMatrix[k*SizeMatrix+i];
            }
            CopyMatrix[j*SizeMatrix+i] -= sum;
        }
        if (i == SizeMatrix-1) continue;
        for (int j=i+1; j < SizeMatrix; j++)  {  // do a row of U
            PrecisionTYPE sum = 0.0;
            for (int k = 0; k < i; k++){
                sum +=(PrecisionTYPE) CopyMatrix[i*SizeMatrix+k]*CopyMatrix[k*SizeMatrix+j];
            }
            CopyMatrix[i*SizeMatrix+j] =(CopyMatrix[i*SizeMatrix+j]-sum) / CopyMatrix[i*SizeMatrix+i];
        }
    }
    for ( int i = 0; i < SizeMatrix; i++ )  {// invert L
        for ( int j = i; j < SizeMatrix; j++ )  {
            float x = 1.0;
            if ( i != j ) {
                x = 0.0;
                for ( int k = i; k < j; k++ ){
                    x -= CopyMatrix[j*SizeMatrix+k]*CopyMatrix[k*SizeMatrix+i];
                }
            }
            CopyMatrix[j*SizeMatrix+i] = x / CopyMatrix[j*SizeMatrix+j];
        }
    }
    for ( int i = 0; i < SizeMatrix; i++ ) {  // invert U
        for ( int j = i; j < SizeMatrix; j++ )  {
            if ( i == j ){continue;}
            PrecisionTYPE sum = 0.0;
            for ( int k = i; k < j; k++ ){
                sum += (PrecisionTYPE)CopyMatrix[k*SizeMatrix+j]*( (i==k) ? 1.0 : CopyMatrix[i*SizeMatrix+k] );
            }
            CopyMatrix[i*SizeMatrix+j] = -sum;
        }
    }
    for ( int i = 0; i < SizeMatrix; i++ ){   // final inversion
        for ( int j = 0; j < SizeMatrix; j++ )  {
            PrecisionTYPE sum = 0.0;
            for ( int k = ((i>j)?i:j); k < SizeMatrix; k++ ){
                sum +=(PrecisionTYPE) ((j==k)?1.0:CopyMatrix[j*SizeMatrix+k])*CopyMatrix[k*SizeMatrix+i];
            }
            CopyMatrix[j*SizeMatrix+i] = (float)sum;
        }
    }
    return CopyMatrix;
}

//Returns the determinant of the data/ matrix given its size. The same assumption as before is made on the content of the data element
float TreeEM::determinant(float * data, int size){

  int i,j,j1,j2;
  float det = 0;
  float **m = NULL;
//  cout<<"Size is "<<size<<endl;
  if (size < 1) {
return 0;
    } else if (size == 1) { /* Shouldn't get used */
      det = data[0];
    } else if (size == 2) {
      det = data[0+size*0] * data[1+size*1] - data[1+size*0] * data[0+size*1];
    } else {
      det = 0;
      for (j1=0;j1<size;j1++) {
          m = (float **) malloc((size-1)*sizeof(float *));
          for (i=0;i<size-1;i++)
            m[i] = (float *) malloc((size-1)*sizeof(float));
          for (i=1;i<size;i++) {
              j2 = 0;
              for (j=0;j<size;j++) {
                  if (j == j1)
                    continue;
                  m[i-1][j2] = data[i+size*j];
                  j2++;
                }
            }
          det += (PrecisionTYPE)pow(-1.0,1.0+j1+1.0) * data[0+size*j1] * Determinant_lib(m,size-1);
          for (i=0;i<size-1;i++)
            free(m[i]);
          free(m);
        }
    }
  return (float)det;
}

// Recursive function needed to calculate the determinant
float TreeEM::Determinant_lib(float **a,int n)
{
  int i,j,j1,j2;
  float det = 0;
  float **m = NULL;

  if (n < 1) { /* Error */

    } else if (n == 1) { /* Shouldn't get used */
      det = a[0][0];
    } else if (n == 2) {
      det = a[0][0] * a[1][1] - a[1][0] * a[0][1];
    } else {
      det = 0;
      for (j1=0;j1<n;j1++) {
          m = (float **) malloc((n-1)*sizeof(float *));
          for (i=0;i<n-1;i++)
            m[i] = (float *) malloc((n-1)*sizeof(float));
          for (i=1;i<n;i++) {
              j2 = 0;
              for (j=0;j<n;j++) {
                  if (j == j1)
                    continue;
                  m[i-1][j2] = a[i][j];
                  j2++;
                }
            }
          det += (PrecisionTYPE)pow(-1.0,1.0+j1+1.0) * a[0][j1] * Determinant_lib(m,n-1);
          for (i=0;i<n-1;i++)
            free(m[i]);
          free(m);
        }
    }
  return((float)det);
}

// Image to Multiply is multiplied elementwise by ImageFactor and modified thus the void output
void MultiplyNiiByNii(nifti_image * ImageToMultiply, nifti_image * ImageFactor){
    // First check for dimension compatibility of the two images
    if (ImageToMultiply->nx != ImageFactor->nx || ImageToMultiply->ny != ImageFactor->ny || ImageToMultiply->nz !=ImageFactor->nz || ImageToMultiply->nu != ImageFactor->nu || ImageToMultiply->nt!=ImageFactor->nt) {
        cout<<"Dimension incompatibility between multiplicative nifti images"<<endl;
        return;
    }
    else{
        // First make all the data float
        if (ImageToMultiply->datatype!=DT_FLOAT) {
            seg_changeDatatype<float>(ImageToMultiply);
        }
        if (ImageFactor->datatype!=DT_FLOAT) {
            seg_changeDatatype<float>(ImageFactor);
        }
        float * ImM_PTR=static_cast<float *>(ImageToMultiply->data);
        float * ImF_PTR=static_cast<float *>(ImageFactor->data);
        int numel = ImageToMultiply->nvox;
        //Multiplication taking place
        for (int i=0; i<numel; i++, ImM_PTR++,ImF_PTR++) {
            *ImM_PTR*=*ImF_PTR;
        }
        return;
        
    }
}


/************* COPY METHODS ***********************/

// Returns a pointer to a TreeEM element copying all information needed
TreeEM * TreeEM::CopyTree(TreeEM * ParentNew){
    TreeEM * CopiedTree=new TreeEM();

    // Copy all elements in the node according to preestablished copying methods
    CopiedTree->Parent=ParentNew;
    if (this->GetDataDirect()==NULL && ParentNew==NULL) {
        cout<<"Improper beginning of copy"<<endl;
        CopiedTree->DataImage=this->FindRoot()->CopyImage();
        CopiedTree->Mask=this->FindRoot()->CopyMask();
    }
    else{
        //cout<<"Proper beginning of copy"<<endl;
        CopiedTree->DataImage=this->CopyImage();
        CopiedTree->Mask=this->CopyMask();
    }
    CopiedTree->Priors=this->CopyPriors();
    CopiedTree->PriorsAdapted=this->CopyPriorsAdapted();
    CopiedTree->PartPriorsAdapted=this->CopyPartPriorsAdapted();
//    cout<<"Copy until after Priors";
    CopiedTree->L2S=this->CopyL2S();
    CopiedTree->S2L=this->CopyS2L();
    //    CopiedTree->Distribution=this->CopyDistribution();
    //    CopiedTree->NonNormResp=this->CopyNonNormResp();
    CopiedTree->NormResp=this->CopyNormResp();
//    cout<<"...after NormResp";
    CopiedTree->NonNormWeight=this->GetNonNormWeight();
    CopiedTree->NormWeight=this->GetNormWeight();
    CopiedTree->ParametersDistribution=this->CopyParameters();
//    cout<<"...after Parameters...";
    CopiedTree->SplitCheck=this->CopySplitCheck();
    CopiedTree->MergeCheck=this->CopyMergeCheck();
    //    CopiedTree->BFCorrection=this->CopyBFCorrection();
    CopiedTree->DataBFCorrected=this->CopyDataBFCorrected();
//    cout<<"...after DataCorrected";
    CopiedTree->BFCoeffs=this->CopyBFCoeffs();
    CopiedTree->IndFactor=this->CopyIndFactor();
    CopiedTree->DPChildren=this->CopyDPChildren();
    CopiedTree->FlagDistClassInd=this->FlagDistClassInd;
    CopiedTree->FlagOutliers=this->FlagOutliers;
    CopiedTree->FlagUTC=this->FlagUTC;
    CopiedTree->FlagCovPriors=this->FlagCovPriors;
    CopiedTree->NumberMaskedElements=this->NumberMaskedElements;
    CopiedTree->HardSeg=this->CopyHardSeg();
//    cout<<" ...until MRF";
    CopiedTree->MRF=this->CopyMRF();
//    cout<<" ...until after MRF done"<<endl;
    // Copying for all children of this but with the proper parent pointer
    int numbchild=this->GetNumberChildren();
    for (int c=0; c<numbchild; c++) {
//        cout<< "Copy of Child "<<c;
        CopiedTree->Children.push_back((this->GetChild(c))->CopyTree(CopiedTree));
//        cout<<"performed"<<endl;
    }
    //cout<<"Node copied"<<endl;
    return CopiedTree;
}

// Returns a pointer to a nifti_image that is a strict copy from the data image directly obtained in this
nifti_image * TreeEM::CopyImage(){
    if (this->GetDataDirect()==NULL) {// Meaning that it is not the root
        //cout<<"Direct Data is NULL"<<endl;
        return NULL;
    }

    else{ // DataImage is directly available so we have to copy it;
        if(this->GetDataImage()->datatype!=DT_FLOAT){
            this->ConvertDataImageToFloat();
        }
        //cout<<this->GetDataImage()<<" and "<<this->GetDataDirect()<<endl;
        nifti_image * CopiedImage=nifti_copy_nim_info(this->GetDataImage());
        // CopiedImage is at the moment with a NULL pointer to the data. According memory must then be allocated and filled with the values
        int numbvox=this->GetDataImage()->nvox;
        CopiedImage->data=(void *)calloc(this->GetDataImage()->nvox,sizeof(float));
        float * CopiedImageData=static_cast<float *>(CopiedImage->data);
        float * CopiedImageData_PTR=CopiedImageData;
        float * Data_PTR=static_cast<float *>(this->GetDataImage()->data);
        for (int i=0; i<numbvox; i++,Data_PTR++,CopiedImageData_PTR++) {
            *CopiedImageData_PTR=*Data_PTR;
        }
        //cout<<"Image copied"<<endl;
        return CopiedImage;
    }
}

// Returns as a nifti_image binary converted the mask used if a mask is used. Similar to CopyImage since the Mask can only be at the root also
nifti_image * TreeEM::CopyMask(){
    if (this->GetMaskDirect()==NULL) {
        return NULL;
    }
    else{
        if(this->GetMask()->datatype!=DT_BINARY){
            this->MakeMaskBinary();
        }
        nifti_image * CopiedMask=nifti_copy_nim_info(this->GetMask());
        int numbvox=this->GetMask()->nvox;
        CopiedMask->data=(void *)calloc(this->GetMask()->nvox,sizeof(bool));
        bool * CopiedMaskData=static_cast<bool *>(CopiedMask->data);
        bool * CopiedMaskData_PTR=CopiedMaskData;
        bool * Mask_PTR=static_cast<bool *>(this->GetMask()->data);
        for (int i=0; i<numbvox; i++,Mask_PTR++,CopiedMaskData_PTR++) {
            *CopiedMaskData_PTR=*Mask_PTR;
        }
        //cout<<" Mask copied "<<endl;
        return CopiedMask;
    }
}

// Returns a pointer to a nifti_image float converted that is the copy of the priors used.
nifti_image * TreeEM::CopyPriors(){
    if (this->GetPriorsDirect()==NULL) {
        return NULL;
    }
    else{
        if (this->GetPriorsDirect()->datatype!=DT_FLOAT) {
            this->MakePriorsFloat();
        }
        nifti_image * CopiedPriors=nifti_copy_nim_info(this->GetPriorsDirect());
        int numbvox=this->GetPriors()->nvox;
        CopiedPriors->data=(void *)calloc(this->GetPriors()->nvox,sizeof(float));
        float * CopiedPriorsData=static_cast<float *>(CopiedPriors->data);
        float * CopiedPriorsData_PTR=CopiedPriorsData;
        float * Priors_PTR=static_cast<float *>(this->GetPriors()->data);
        for (int i=0; i<numbvox; i++,Priors_PTR++,CopiedPriorsData_PTR++) {
            *CopiedPriorsData_PTR=*Priors_PTR;
        }
        //cout<<" Priors copied"<< endl;
        return CopiedPriors;
    }
}

float * TreeEM::CopyPartPriorsAdapted(){
    if (this->GetPartPriorsAdaptedDirect()==NULL) {
        return NULL;
    }
    else {
        int numelmasked=this->GetNumberMaskedElements();
        float * CopiedPartPriorsAdapted=new float[numelmasked];
        float * CopiedPartPriorsAdapted_PTR=CopiedPartPriorsAdapted;
        float * PartPriorsAdapted_PTR=this->GetPartPriorsAdapted_bis();
        for (int i=0; i<numelmasked; i++,CopiedPartPriorsAdapted_PTR ++,PartPriorsAdapted_PTR++) {
            *CopiedPartPriorsAdapted_PTR=*PartPriorsAdapted_PTR;
        }
        return CopiedPartPriorsAdapted;
    }
}

// Only stored at general classes. If exist makes copy of PriorsAdapted and returns corresponding float pointer
float * TreeEM::CopyPriorsAdapted(){
    if (this->GetPriorsAdaptedDirect()==NULL) {
        return NULL;
    }
    else {
        int numel=this->GetNumberElements();
        float * CopiedPriorsAdapted=new float[numel];
        float * CopiedPriorsAdapted_PTR=CopiedPriorsAdapted;
        float * PriorsAdapted_PTR=this->GetPriorsAdapted();
        for (int i=0; i<numel; i++,CopiedPriorsAdapted_PTR ++,PriorsAdapted_PTR++) {
            *CopiedPriorsAdapted_PTR=*PriorsAdapted_PTR;
        }
        return CopiedPriorsAdapted;
    }
}

// Similar to previous ones since it is only stored at the Root. If exists makes the copy of L2S and returns a int pointer
int * TreeEM::CopyL2S(){
    if (this->GetL2SDirect()==NULL) {
        return NULL;
    }
    else {
        int numel=this->GetNumberElements();
        int * CopiedL2S=new int[numel];
        int * CopiedL2S_PTR=CopiedL2S;
        int * L2S_PTR=this->GetL2S();
        for (int i=0; i<numel; i++,CopiedL2S_PTR ++,L2S_PTR++) {
            *CopiedL2S_PTR=*L2S_PTR;
        }
        return CopiedL2S;
    }
}

// Similar to previous ones since it is only stored at the Root. If exists makes the copy of S2L and returns a int pointer
int * TreeEM::CopyS2L(){
    if (this->GetS2LDirect()==NULL) {
        return NULL;
    }
    else {
        int numelmasked=this->GetNumberMaskedElements();
        int * CopiedS2L=new int[numelmasked];
        int * CopiedS2L_PTR=CopiedS2L;
        int * S2L_PTR=this->GetS2L();
        for (int i=0; i<numelmasked; i++,CopiedS2L_PTR++,S2L_PTR++) {
            *CopiedS2L_PTR=*S2L_PTR;
        }
        return CopiedS2L;
    }
}

// Similar to previous ones since it is only stored at the Root. If exists makes the copy of HardSeg and returns a int pointer
int * TreeEM::CopyHardSeg(){
    if(this->GetHardSegDirect()==NULL){
        return NULL;
    }
    else{
        int numelmasked=this->GetNumberMaskedElements();
        int * CopiedHardSeg=new int[numelmasked];
        int * CopiedHardSeg_PTR=CopiedHardSeg;
        int * HardSeg_PTR=this->GetHardSeg();
        for (int i=0; i<numelmasked; i++,CopiedHardSeg_PTR++,HardSeg_PTR++) {
            *CopiedHardSeg_PTR=*HardSeg_PTR;
        }
        return CopiedHardSeg;
    }
}


// Copy the content of NormResp and returns the newly associated float pointer
float * TreeEM::CopyNormResp(){
    if (this->GetS2L()==NULL) {// If there is no S2L, then there should not be any NormResp and return NULL is natural
        return NULL;
    }
    else { // make the copy, knowing that NormResp contains numelmasked elements
        int numelmasked=this->GetNumberMaskedElements();
        float * CopiedNormResp=new float[numelmasked];
        float * CopiedNormResp_PTR=CopiedNormResp;
        float * NormResp_PTR=this->GetNormResp();
        for (int i=0; i<numelmasked; i++,CopiedNormResp_PTR++,NormResp_PTR++) {
            *CopiedNormResp_PTR=*NormResp_PTR;
        }
        return CopiedNormResp;
    }
}

// Return the value of IndFactor (Independence factor as defined in Groves)
float TreeEM::CopyIndFactor(){
    return this->IndFactor;
}

// Returns in a Parameters structure the copy of the parameters
Parameters * TreeEM::CopyParameters(){
    if (this->GetParameters()==NULL) {
        return NULL;
    }
    else{
        Parameters * CopiedParameters=new Parameters;
        CopiedParameters->DistributionType=this->GetDistributionType();
        CopiedParameters->SizeParameters=this->GetSizeParameters();
        CopiedParameters->PriorsCovFlag=this->GetParameters()->PriorsCovFlag;
        int sizeParams=CopiedParameters->SizeParameters;
        if (sizeParams==0) { // Distinction done if the size of the Parameters is more than 0 or not to allocate proper amount of memory
            CopiedParameters->ValueParameters=NULL;
        }
        else{
            CopiedParameters->ValueParameters=new float[CopiedParameters->SizeParameters];
            float * CopiedValueParameters_PTR=CopiedParameters->ValueParameters;

            float * ValueParameters_PTR=this->GetParametersValue();
            for (int i=0; i<sizeParams; i++,CopiedValueParameters_PTR++,ValueParameters_PTR++) {
                *CopiedValueParameters_PTR=*ValueParameters_PTR;
            }
        }
        bool FlagCovPriors=CopiedParameters->PriorsCovFlag;
        float * CovPriors=this->GetPriorsCovMatrix();
        int numbmodal=this->GetNumberModalities();
        int numbmodalSq=numbmodal*numbmodal;
        if (CovPriors!=NULL && FlagCovPriors) {
            CopiedParameters->PriorsCov=new float[numbmodalSq];
            for (int i=0; i<numbmodalSq; i++) {
                CopiedParameters->PriorsCov[i]=CovPriors[i];
            }
        }
        
        float FlagMeanPriors=this->GetFlagMeanPriors();
        float * MeanPriors=this->GetPriorsMeanMatrix();
        if (MeanPriors!=NULL && FlagMeanPriors>0.01) {
            CopiedParameters->PriorsMean=new float[numbmodal];
            for (int i=0; i<numbmodal; i++) {
                CopiedParameters->PriorsMean[i]=MeanPriors[i];
            }
        }
        return CopiedParameters;
    }
}

bool * TreeEM::CopyMergeCheck(){
    if (this->GetMergeCheck()==NULL) {
        return NULL;
    }
    else{
        int numbDirectLeaves=this->GetNumberDirectLeaves();
        int numbchild=this->GetNumberChildren();
        int numbchildSq=numbchild*numbchild;
        if (numbDirectLeaves==0) {
            return NULL;
        }
        bool * MergeCheck_PTR=this->GetMergeCheck();
//        bool * CopiedMergeCheck=new bool[numbDirectLeaves*numbDirectLeaves];
        bool * CopiedMergeCheck=new bool[numbchildSq];
//        for(int i=0;i<numbDirectLeaves*numbDirectLeaves;i++){
//            CopiedMergeCheck[i]=false;
//        }
        for(int i=0;i<numbchildSq;i++){
            CopiedMergeCheck[i]=false;
        }
        bool * CopiedMergeCheck_PTR=CopiedMergeCheck;
//        for (int i=0; i<numbDirectLeaves*numbDirectLeaves; i++,CopiedMergeCheck_PTR++,MergeCheck_PTR++) {
//            *CopiedMergeCheck_PTR=*MergeCheck_PTR;
//        }
        for (int i=0; i<numbchildSq; i++,CopiedMergeCheck_PTR++,MergeCheck_PTR++) {
            *CopiedMergeCheck_PTR=*MergeCheck_PTR;
        }
        return CopiedMergeCheck;
    }
}

bool * TreeEM::CopySplitCheck(){
    if (this->GetSplitCheck()==NULL) {
        return NULL;
    }
    else{
        int numbDirectLeaves=this->GetNumberDirectLeaves();
        int numbchild=this->GetNumberChildren();
        if (numbDirectLeaves==0) {
            return NULL;
        }
        bool * SplitCheck_PTR=this->GetSplitCheck();
        bool * CopiedSplitCheck=new bool[numbchild];
        for(int i=0;i<numbchild;i++){
            CopiedSplitCheck[i]=false;
        }
        bool * CopiedSplitCheck_PTR=CopiedSplitCheck;
        for (int i=0; i<numbchild; i++,CopiedSplitCheck_PTR++,SplitCheck_PTR++) {
            *CopiedSplitCheck_PTR=*SplitCheck_PTR;
        }
        return CopiedSplitCheck;
    }
}

//// Returns a float pointer to an array where the BFBasisFunctions have been copied
//float * TreeEM::CopyBFCorrection(){
//    // Normally the BF are at the root and only stored there, elsewhere it is a NULL pointer
//    if (this->GetBFCorrectionDirect()==NULL) {
//        return NULL;
//    }
//    else{
//        int numelmasked=this->GetNumberMaskedElements();
//        int numbmodal=this->GetNumberModalities();
//        //int numbBF=((BForder+1)*(BForder+2)*(BForder+3))/6;
//        float * CopiedBFCorrection=new float[numbmodal*numelmasked];//{0};
//        for (int i=0; i<numbmodal*numelmasked; i++) {
//            CopiedBFCorrection[i]=0;
//        }
//        float * CopiedBFCorrection_PTR=CopiedBFCorrection;
//        float * BFCorrection_PTR=this->GetBFCorrectionDirect();
//        for (int i=0; i<numbmodal*numelmasked; i++,CopiedBFCorrection_PTR++,BFCorrection_PTR++) {
//            *CopiedBFCorrection_PTR=*BFCorrection_PTR;
//        }
//        return CopiedBFCorrection;
//    }
//}

// Return in a float array of size numelmasked*numbmodal the Data corrected for bias field
float * TreeEM::CopyDataBFCorrected(){
    // Normally the BF are at the root and only stored there, elsewhere it is a NULL pointer
    if (this->GetDataBFCorrectedDirect()==NULL) {
        return NULL;
    }
    else{
        int numelmasked=this->GetNumberMaskedElements();
        int numbmodal=this->GetNumberModalities();
        //int numbBF=((BForder+1)*(BForder+2)*(BForder+3))/6;
        int SizeDataBFCorrected=numbmodal*numelmasked;
        float * CopiedDataBFCorrected=new float[SizeDataBFCorrected];//{0};
        for (int i=0; i<SizeDataBFCorrected; i++) {
            CopiedDataBFCorrected[i]=0;
        }
        float * CopiedDataBFCorrected_PTR=CopiedDataBFCorrected;
        float * DataBFCorrected_PTR=this->GetDataBFCorrected();
        for (int i=0; i<SizeDataBFCorrected; i++,CopiedDataBFCorrected_PTR++,DataBFCorrected_PTR++) {
            *CopiedDataBFCorrected_PTR=*DataBFCorrected_PTR;
        }
        return CopiedDataBFCorrected;
    }
}

// Returns a vector of pointers to the arrays containing the coefficients corresponding to the different modalities
float * TreeEM::CopyBFCoeffs(){
    //Declaration of the element to return;
    int numbmodal=this->GetNumberModalities();
    int numbBF=((BForder+1)*(BForder+2)*(BForder+3))/6;
    float * BFCoeffsToCopy=this->GetBFCoeffsDirect();


    // 1st case where there is no available coeffs, the size of the vector to copy is 0;
    if (this->GetBFCoeffsDirect()==NULL) {
        return NULL;
    }

    else{
        int sizeCopiedBF=numbmodal*numbBF;
        float * CopiedBFCoeffs=new float[sizeCopiedBF];
        for(int i=0;i<sizeCopiedBF;i++){
            CopiedBFCoeffs[i]=0;
        }
        for(int l=0;l<sizeCopiedBF;l++){
            CopiedBFCoeffs[l]=BFCoeffsToCopy[l];
        }
        return CopiedBFCoeffs;
    }
}

float* TreeEM::CopyDPChildren(){
    float* DPChildrenToCopy=this->GetDPChildrenDirect();
    float* CopiedDPChildren=NULL;
//    int DPsize=DPChildrenToCopy.size();
    if(DPChildrenToCopy==NULL){
        return CopiedDPChildren;
    }
    else{
        int numbchild=this->GetNumberChildren();
        if(this->GetFlagDistClassInd()){

            CopiedDPChildren=new float[MaxSupport*numbchild];
            for(int i=0;i<MaxSupport*numbchild;i++){
                CopiedDPChildren[i]=DPChildrenToCopy[i];
            }
        }
        else{
            int SizeHistogram=(int)pow_int(MaxSupport,numbchild);
            CopiedDPChildren=new float[SizeHistogram];
            for(int i=0;i<SizeHistogram;i++){
                CopiedDPChildren[i]=DPChildrenToCopy[i];
            }
        }
        return CopiedDPChildren;
    }
}

// Deletion function for the class TreeEM
TreeEM::~TreeEM (){
    MakeEmpty ();
}

void TreeEM::MakeEmpty (){
    int numbchild=this->GetNumberChildren();
    for (int c = 0; c < numbchild; c++)
    {
        if(this->GetChild(c)!=NULL){
            delete this->Children [c];
            this->Children[c] = NULL;
        }
    }
    this->Children.clear();
    if (this->GetBFCoeffsDirect()!=NULL) {
        delete[] this->BFCoeffs;
        this->BFCoeffs=NULL;
    }
    //    if (this->GetBFCorrectionDirect()!=NULL) {
    //        delete[] this->BFCorrection;
    //        this->BFCorrection=NULL;
    //    }
    if(this->GetDataBFCorrectedDirect()!=NULL){
        delete [] this->DataBFCorrected;
        this->DataBFCorrected=NULL;
    }
    if(this->GetGMatrixDirect()!=NULL){
        delete [] this->GMatrix;
        this->GMatrix=NULL;
    }
    if (this->GetDataDirect()!=NULL) {
        nifti_image_free(this->GetDataDirect());
        this->DataImage=NULL;
    }
    if (this->GetMaskDirect()!=NULL) {
        nifti_image_free(this->GetMaskDirect());
        this->Mask=NULL;
    }
    if (this->GetL2SDirect()!=NULL) {
        delete [] this->GetL2SDirect();
        this->L2S=NULL;
    }
    if (this->GetS2LDirect()!=NULL) {
        delete [] this->GetS2LDirect();
        this->S2L=NULL;
    }
    if(this->GetHardSegDirect()!=NULL){
        delete [] this->GetHardSegDirect();
        this->HardSeg=NULL;
    }
    if(this->GetMRF()!=NULL){
        delete [] this->GetMRF();
        this->MRF=NULL;
    }
    if(this->GetDPChildrenDirect()!=NULL){
        delete[] this->GetDPChildrenDirect();
        this->DPChildren=NULL;
    }
    if (this->GetPriorsDirect()!=NULL) {
        nifti_image_free(this->GetPriorsDirect());
        this->Priors=NULL;
    }
    if(this->GetPriorsAdaptedDirect()!=NULL){
        delete [] PriorsAdapted;
        this->PriorsAdapted=NULL;
    }
    if (this->GetPartPriorsAdaptedDirect()!=NULL) {
        delete [] this->PartPriorsAdapted;
        this->PartPriorsAdapted=NULL;
    }
    //    if (this->NonNormResp!=NULL){
    //        delete this->NonNormResp;
    //        this->NonNormResp=NULL;
    //    }
    if (this->NormResp!=NULL){
        delete [] this->NormResp;
        this->NormResp=NULL;
    }
    //    if (this->Distribution!=NULL){
    //        delete []this->Distribution;
    //        this->Distribution=NULL;
    //    }
    if (this->ParametersDistribution!=NULL){
        delete this->ParametersDistribution;
        this->ParametersDistribution=NULL;
    }
    if (this->GetSplitCheck()!=NULL) {
        delete [] this->GetSplitCheck();
        this->SplitCheck=NULL;
    }
    if (this->GetMergeCheck()!=NULL) {
        delete [] this->GetMergeCheck();
        this->MergeCheck=NULL;
    }

    this->Parent=NULL;
    return;
}

/************************* GET FUNCTIONS ************************************/
TreeEM * TreeEM::GetParent(){
    return this->Parent;
}

// Return vector of children for a node
vector<TreeEM *> TreeEM::GetChildren(){
    return this->Children;
}

// Returns the number of children
int TreeEM::GetNumberChildren(){
    return this->GetChildren().size();
}

// Returns the number of anatomical classes : rules for anatomical classes, if without outlier class, number of children of the root if with outliers, supposed to be at second level under first child
int TreeEM::GetNumberGeneralClasses(){
    int OutlierType = this->GetFlagOutliers();
    switch(OutlierType){
    case 0:{ // case no outlier model
      return this->GetNumberChildren();
      break;
    }
    case 1:{ // case outlier model in three level
      return this->GetChild(0)->GetNumberChildren();
      break;
    }
    case 2:{ // case outlier model in horizontal model
      return this->GetNumberChildren()-1;
      break;
    }
        case 3:{ // case outlier model with 1 inlier and 1 outlier node. General anatomical classes at second level of inlier node
            return this->GetChild(0)->GetNumberChildren();
        }
            break;
        case 5:{
            return this->GetChild(0)->GetNumberChildren();
        }
        case 6:{
            return this->GetChild(0)->GetNumberChildren();
        }
        case 8:{
            return this->GetChild(0)->GetNumberChildren();
        }
            break;
    default :{ // no outlier model;
        return this->GetNumberChildren();
        break;
    }
    }
}

// Gets the child of index c after checking that we have at least c+1 children
TreeEM * TreeEM::GetChild(int c){
    if (c>=this->GetNumberChildren()) {
        cout<<"Getting over bounds of number of children"<<endl;
        cout<<"c and the address of the parent are "<<c<<" "<<this<<endl;
        return NULL;
    }
    else {
        return this->GetChildren()[c];
    }
}

// Gets the Data directly : NULL if not the node where it is stored
nifti_image * TreeEM::GetDataDirect(){
    return this->DataImage;
}

// Same as for Data previously but for the Mask
nifti_image * TreeEM::GetMaskDirect(){
    return this->Mask;
}

// Retrieves the pointer to the Mask
nifti_image * TreeEM::GetMask(){
    if (this->GetMaskDirect()!=NULL) {
        //cout<<"Has direct Mask reference"<<endl;
        return this->GetMaskDirect();
    }
    else if (this->GetParent()==NULL){ // Means it is a root or an initial node
        //cout<<"Root or IN"<<endl;
        return NULL;
    }
    else {
        return this->GetParent()->GetMask();
    }
}

// Get the pointer to the Priors as soon as they appear : closest in upper hierarchy
nifti_image * TreeEM::GetPriors(){
    if (this->Priors !=NULL){
        return this->Priors;
    }
    else if(this->GetParent()==NULL){// Means it is a root or an initial node
        return NULL;
    }
    else {
        return this->GetParent()->GetPriors();
    }
}

float * TreeEM::GetPartPriorsAdapted_bis(){
    if(this->PartPriorsAdapted!=NULL){
        return this->PartPriorsAdapted;
    }
    else if(this->GetParent()==NULL){// Means it is a root or an initial node
        return NULL;
    }
    else {
        return this->GetParent()->GetPartPriorsAdapted_bis();
    }
}

// Get the pointer to the adapted priors closest in the upper hierarchy
float * TreeEM::GetPriorsAdapted(){
    if(this->PriorsAdapted!=NULL){
        return this->PriorsAdapted;
    }
    else if(this->GetParent()==NULL){// Means it is a root or an initial node
        return NULL;
    }
    else {
        return this->GetParent()->GetPriorsAdapted();
    }
}

// Gets pointer to priors NULL if no priors stored at this node
nifti_image * TreeEM::GetPriorsDirect(){
    return this->Priors;
}

// Same as before but for PriorsAdapted
float * TreeEM::GetPriorsAdaptedDirect(){
    return this->PriorsAdapted;
}

float * TreeEM::GetPartPriorsAdaptedDirect(){
    return this->PartPriorsAdapted;
}
//float * TreeEM::GetNonNormResp(){
//    return this->NonNormResp;
//}

// Returns pointer to NormResp
float * TreeEM::GetNormResp(){
    return this->NormResp;
}


float TreeEM::GetNonNormWeight(){
    return this->NonNormWeight;
}

float TreeEM::GetNormWeight(){
    return this->NormWeight;
}

// Returns value of the partial normalised weight, that is the overall weight over the whole model in contrast to the relative weight with respect to the closest upper node, that is given by NormWeight.
float TreeEM::GetPartNormWeight(){
    if (this->Parent==NULL || this->GetParent()->GetPriorsDirect()!=NULL) {
        return this->GetNormWeight();
    }
    else return this->GetNormWeight()*(this->GetParent())->GetPartNormWeight();
}

// Returns the Value of the relative weight with respect to the inlier/outlier part of the model
float TreeEM::GetPartWeightLevel2(){
//    if (this->Parent==NULL || this->GetLevel()==1 || ((this->GetFlagOutliers()==3 || this->GetFlagOutliers()>=5) && this->GetLevel()==2)) {
//        return 1;
//    }
    if(this->GetParent()==NULL || (this->GetLevel()==1 && (this->GetFlagOutliers()==3 || this->GetFlagOutliers()>=5))){
        return 1;
    }
    else return this->GetNormWeight()*(this->GetParent()->GetPartWeightLevel2());
}

// Returns the value of the relative weight with respect to the anatomical class and the inlier/ outlier part of the model
float TreeEM::GetPartWeightLevel3(){
    if (this->Parent==NULL || this->GetLevel()<=2 || (this->GetFlagOutliers()==7  && this->GetLevel()==3)) {
        return 1;
    }
    else return this->GetNormWeight()*(this->GetParent()->GetPartWeightLevel3());
}

float TreeEM::GetPartWeightLevel(int Level){
    if (this->GetParent()==NULL || this->GetLevel()==Level-1) {
        return 1;
    }
    else return this->GetNormWeight()*this->GetParent()->GetPartWeightLevel(Level);
}

// Returns partial weight above the priors if no priors set above certain nodes
float TreeEM::GetPartNormWeightAbovePriors(){
    TreeEM* NodePrior=this->FindGeneralClassPriors();
    if(NodePrior==NULL){
        return 1;
    }
    else return NodePrior->GetParent()->GetPartNormWeight();
}

// Returns partial weight on node above the first priors setting
float TreeEM::GetPartNormWeightAboveTopPriors(){
    if (this->GetPriors()==NULL) {
        return this->GetPartNormWeight();
    }
    else{
        return this->GetParent()->GetPartNormWeightAbovePriors();
    }
}

float TreeEM::GetCompleteWeight(){
    if (this->IsRoot()) {
        return 1;
    }
    else{
        return this->GetNormWeight()*this->GetParent()->GetCompleteWeight();
    }
}

float * TreeEM::GetPartPriorsAdaptedMasked(){
    int numelmasked=this->GetNumberMaskedElements();
    float * PartPriorsAdapted=new float[numelmasked];
    for (int i=0;i<numelmasked; i++) {
        PartPriorsAdapted[i]=1;
    }
    if (this->GetParent()==NULL) {
        return PartPriorsAdapted;
    }
    else if (this->GetPriorsAdaptedDirect()!=NULL && this->GetParent()!=NULL) {
//        int * L2S_PTR=this->GetL2S();
        int * S2L_PTR=this->GetS2L();
        float * ParentPriorsPart=this->GetParent()->GetPartPriorsAdaptedMasked();
        float * PriorsAdaptedDirect=this->GetPriorsAdaptedDirect();
        for (int i=0; i<numelmasked; i++) {
            PartPriorsAdapted[i]=PriorsAdaptedDirect[S2L_PTR[i]]*ParentPriorsPart[i];
        }
        //        this->SaveTmpResult(ParentPriorsPart, "/Users/Carole/Documents/PhD/Test.nii.gz");
        //        this->SaveTmpResult(PartPriorsAdapted, "/Users/Carole/Documents/PhD/Test.nii.gz");
        delete [] ParentPriorsPart;
        ParentPriorsPart=NULL;
        return PartPriorsAdapted;
    }
    else{
        float * ParentPriorsPart=this->GetParent()->GetPartPriorsAdaptedMasked();
        for (int i=0; i<numelmasked; i++) {
            PartPriorsAdapted[i]=ParentPriorsPart[i];
        }
        delete [] ParentPriorsPart;
        ParentPriorsPart=NULL;
        return PartPriorsAdapted;
    }
}

// Returns in a pointed float array the relative adapted priors : obtained by multiplying all priors adapted from that level upwards.
float * TreeEM::GetPartPriorsAdapted(){
    int numel=this->GetNumberElements();
        float * PartPriorsAdapted=new float[numel];
        for (int i=0;i<numel; i++) {
            PartPriorsAdapted[i]=1;
        }
    if (this->GetParent()==NULL) {
        return PartPriorsAdapted;
    }
    else if (this->GetPriorsAdaptedDirect()!=NULL && this->GetParent()!=NULL) {
        float * ParentPriorsPart=this->GetParent()->GetPartPriorsAdapted();
        float * PriorsAdaptedDirect=this->GetPriorsAdaptedDirect();
        for (int i=0; i<numel; i++) {
            PartPriorsAdapted[i]=PriorsAdaptedDirect[i]*ParentPriorsPart[i];
        }
//        this->SaveTmpResult(ParentPriorsPart, "/Users/Carole/Documents/PhD/Test.nii.gz");
//        this->SaveTmpResult(PartPriorsAdapted, "/Users/Carole/Documents/PhD/Test.nii.gz");
        delete [] ParentPriorsPart;
        ParentPriorsPart=NULL;
        return PartPriorsAdapted;
    }
    else{
        float * ParentPriorsPart=this->GetParent()->GetPartPriorsAdapted();
        for (int i=0; i<numel; i++) {
            PartPriorsAdapted[i]=ParentPriorsPart[i];
        }
        delete [] ParentPriorsPart;
        ParentPriorsPart=NULL;
        return PartPriorsAdapted;
    }

}

Parameters * TreeEM::GetParameters(){
    return this->ParametersDistribution;
}

int TreeEM::GetDistributionType(){
    return this->GetParameters()->DistributionType;
}

bool TreeEM::GetPriorsCovFlag(){
    return this->GetParameters()->PriorsCovFlag;
}

int TreeEM::GetFlagCovPriors(){
    return this->FindRoot()->FlagCovPriors;
}

float TreeEM::GetFlagMeanPriors(){
    return this->FindRoot()->FlagMeanPriors;
}

float* TreeEM::GetPriorsCovMatrix(){
    return this->GetParameters()->PriorsCov;
}

float* TreeEM::GetPriorsMeanMatrix(){
    return this->GetParameters()->PriorsMean;
}

float * TreeEM::GetPriorsCovMatrixTotal(){
    if (!this->GetFlagCovPriors()) {
        return NULL;
    }
    else if(this->GetFlagCovPriors()==1){
        return this->GetPriorsCovMatrix();
    }
    else{
        return this->GetPriorsCovMatrixGeneral();
    }
}

float * TreeEM::GetPriorsMeanTotal(){
    if (this->GetFlagMeanPriors()<0.01) {
        return NULL;
    }
    else {
        return this->GetPriorsMeanMatrix();
    }

}

float * TreeEM::GetPriorsCovMatrixGeneral(){
    
    if (this->GetFlagCovPriors() <2) {
        cout<<"no general priors on covariance if CovPriorsType is not above 2"<<endl;
        return NULL;
    }
    if(this->FindRoot()->GetPriorsCovMatrix()==NULL){
        if(this->GetFlagCovPriors()>=8){
            float * GeneralPriorCov=this->FindRoot()->CreateCovPriorsForInverseWishart();
            this->FindRoot()->SetCovPriorsMatrix(GeneralPriorCov);
            if (GeneralPriorCov!=NULL){
            delete [] GeneralPriorCov;
            GeneralPriorCov=NULL;
            }
        }
        else if (this->GetFlagCovPriors()>=4) {
            int numbmodal=this->GetNumberModalities();
            int numbmodalSq=numbmodal*numbmodal;
            TreeEM * MiniVarTree=this->GetMiniVariance();
            float * MiniVarTest=MiniVarTree->GetVariance();
            float * MiniVarToSet=NULL;
            if (MiniVarTest==NULL || MiniVarTest[0]==0) {
                MiniVarToSet=MiniVarTree->GetVarianceDirect();
            }
            else{
                MiniVarToSet=new float[numbmodalSq];
                for (int m=0; m<numbmodalSq; m++) {
                    MiniVarToSet[m]=MiniVarTest[m];
                }
            }
//            float * MiniVarToSet=MiniVarTree->GetVarianceDirect();
//            int numbmodal=this->GetNumberModalities();
            float * ScalingVariance=MiniVarTree->MakeScalingVariance();
            if (this->GetFlagCovPriors()==4) {
                for (int m=0; m<numbmodal; m++) {
                    ScalingVariance[m+m*numbmodal]=1;
                }
            }
//            int * Size= new int[4];
            int Size[4];
            Size[0]=Size[1]=Size[2]=Size[3]=numbmodal;
            float * VarianceToSet1=ProductMatrix(MiniVarToSet, ScalingVariance, Size );
            float * VarianceToSet=ProductMatrix(ScalingVariance, VarianceToSet1, Size);
            int numelmasked=this->GetNumberMaskedElements();
            for (int m=0; m<numbmodalSq; m++) {
                VarianceToSet[m]*=(numelmasked+numbmodal+1);
            }
            this->FindRoot()->SetCovPriorsMatrix(VarianceToSet);
            delete [] VarianceToSet1;
            VarianceToSet1=NULL;
            delete [] MiniVarToSet;
            MiniVarToSet=NULL;
            delete[] ScalingVariance;
            ScalingVariance=NULL;
            delete [] VarianceToSet;
            VarianceToSet=NULL;
        }
        else{
        float * GeneralPriorCov=this->FindRoot()->CreateCovPriorsFromExistingCovMatrices();
        this->FindRoot()->SetCovPriorsMatrix(GeneralPriorCov);
        delete [] GeneralPriorCov;
        GeneralPriorCov=NULL;
        }
//        float * Test=this->FindRoot()->GetPriorsCovMatrix();
        return this->FindRoot()->GetPriorsCovMatrix();
    }
    return this->FindRoot()->GetPriorsCovMatrix();
}

//float * TreeEM::GetDistribution(){
//    return this->Distribution;
//}

int * TreeEM::GetL2SDirect(){
    return this->L2S;
}

int * TreeEM::GetS2LDirect(){
    return this->S2L;
}

int * TreeEM::GetHardSegDirect(){
    return this->HardSeg;
}

bool * TreeEM::GetSplitCheck(){
    return this->SplitCheck;
}

bool * TreeEM::GetMergeCheck(){
    return this->MergeCheck;
}

/*Returns the number of bins used for the histogram. Has to be the same for each member. Therefore only stored at the root and put to 0 everywhere else*/
int TreeEM::GetNumbbins(){
    return (int)(numbbins/pow_int(2, (this->GetNumberModalities()-1)));
}

// Returns the pointer to the beginning of the values for the means in the parameters values
/* WARNING : do not create a copy of the mean values in another array*/
float * TreeEM::GetMean(){
    if (this->GetNumberChildren()!=0) {
        return NULL;
    }
    else {
        return this->GetParameters()->ValueParameters;
    }
}

//// Creates the PrecisionTYPE array and returns the pointer to it which will hold the mean for the considered NormResp given the values (no need for the considered tree to be a leaf)
//float * TreeEM::GetMeanDirect(){
//    int numbmodal=this->GetNumberModalities();
//    int numel=this->GetNumberElements();
//    float * MeanResult=new float[numbmodal];//{0};
//    for (int i=0; i<numbmodal; i++) {
//        MeanResult[i]=0;
//    }
//    float * Data=static_cast<float*>(this->GetDataImage()->data);
//    float * Data_PTR=Data;
//    int * L2S_PTR=this->GetL2S();
//
//    for (int m=0; m<numbmodal; m++) {
//        Data_PTR=&Data[m*numel];
//        PrecisionTYPE MeanResult_tmp=0;
//        L2S_PTR=this->GetL2S();
//        float * NormResp_PTR=this->GetNormResp();
//        PrecisionTYPE SumNormResp=0;
//        for (int i=0; i<numel; i++,Data_PTR++,L2S_PTR++) {
//            if (*L2S_PTR>=0) {
//                MeanResult_tmp+=(PrecisionTYPE)*Data_PTR*(*NormResp_PTR);
//                SumNormResp+=(PrecisionTYPE)*NormResp_PTR;
//                NormResp_PTR++;
//            }
//        }
//        MeanResult[m]=(float)MeanResult_tmp/SumNormResp;
//    }
//    return MeanResult;
//}


// Creates the PrecisionTYPE array and returns the pointer to it which will hold the mean for the considered NormResp given the values (no need for the considered tree to be a leaf)
void TreeEM::GetMeanDirect_bis(float * MeanResult){
    int numbmodal=this->GetNumberModalities();
    int numelmasked=this->GetNumberMaskedElements();
    //    PrecisionTYPE SumNormResp=0;
    //float * PointerToDataBegin = static_cast<float *>(this->GetDataImage()->data);
    //    float * PointerToDataBegin=this->MakeDataBFCorrected();
    float * PointerToDataBegin=this->GetDataBFCorrected();
    float * PointerToDataBegin_PTR=PointerToDataBegin;
    float * NormalisedResponsabilities_PTR=this->GetNormResp();
    // Initialisation of the results
//    float * MeanResult=new float[numbmodal];
    
    for (int m=0; m<numbmodal; m++) {
        MeanResult[m]=0;
    }
    if (this->GetFlagOutliers()==4) { // Special case of the VL implementation where mean calculation depends on the typicality
        for (int m=0; m<numbmodal; m++) {
            PointerToDataBegin_PTR=&PointerToDataBegin[m*numelmasked];
            float * Typicality_PTR=&this->GetNormResp()[numelmasked];
            PrecisionTYPE MeanResult_tmp=0;
            PrecisionTYPE SumNormResp=0;
            NormalisedResponsabilities_PTR=this->GetNormResp();
            for (int i=0; i<numelmasked; i++,PointerToDataBegin_PTR++,NormalisedResponsabilities_PTR++,Typicality_PTR++) {
                MeanResult_tmp+=(PrecisionTYPE)(*NormalisedResponsabilities_PTR)*(*Typicality_PTR)*(*PointerToDataBegin_PTR);
                SumNormResp+=(PrecisionTYPE)(*NormalisedResponsabilities_PTR)*(*Typicality_PTR);
            }
            MeanResult[m]=(float)MeanResult_tmp/SumNormResp;
        }
    }
    else{ // Normal calculation of the mean
        for (int m=0; m<numbmodal; m++) {
            PointerToDataBegin_PTR=&PointerToDataBegin[m*numelmasked];
            PrecisionTYPE MeanResult_tmp=0;
            PrecisionTYPE SumNormResp=0;
            NormalisedResponsabilities_PTR=this->GetNormResp();
            for (int i=0; i<numelmasked; i++,PointerToDataBegin_PTR++,NormalisedResponsabilities_PTR++) {
                MeanResult_tmp+=(PrecisionTYPE)(*NormalisedResponsabilities_PTR)*(*PointerToDataBegin_PTR);
                SumNormResp+=(PrecisionTYPE)(*NormalisedResponsabilities_PTR);
            }
            MeanResult[m]=(float)MeanResult_tmp/SumNormResp;
        }
    }
    return;
}

// Creates the PrecisionTYPE array and returns the pointer to it which will hold the mean for the considered NormResp given the values (no need for the considered tree to be a leaf)
float * TreeEM::GetMeanDirect(){
    int numbmodal=this->GetNumberModalities();
    int numelmasked=this->GetNumberMaskedElements();
//    PrecisionTYPE SumNormResp=0;
    //float * PointerToDataBegin = static_cast<float *>(this->GetDataImage()->data);
    //    float * PointerToDataBegin=this->MakeDataBFCorrected();
    float * PointerToDataBegin=this->GetDataBFCorrected();
    float * PointerToDataBegin_PTR=PointerToDataBegin;
    float * NormalisedResponsabilities_PTR=this->GetNormResp();
    // Initialisation of the results
    float * MeanResult=new float[numbmodal];

        for (int m=0; m<numbmodal; m++) {
            MeanResult[m]=0;
        }
    if (this->GetFlagOutliers()==4) { // Special case of the VL implementation where mean calculation depends on the typicality
        for (int m=0; m<numbmodal; m++) {
            PointerToDataBegin_PTR=&PointerToDataBegin[m*numelmasked];
            float * Typicality_PTR=&this->GetNormResp()[numelmasked];
            PrecisionTYPE MeanResult_tmp=0;
            PrecisionTYPE SumNormResp=0;
            NormalisedResponsabilities_PTR=this->GetNormResp();
            for (int i=0; i<numelmasked; i++,PointerToDataBegin_PTR++,NormalisedResponsabilities_PTR++,Typicality_PTR++) {
                MeanResult_tmp+=(PrecisionTYPE)(*NormalisedResponsabilities_PTR)*(*Typicality_PTR)*(*PointerToDataBegin_PTR);
                SumNormResp+=(PrecisionTYPE)(*NormalisedResponsabilities_PTR)*(*Typicality_PTR);
            }
            MeanResult[m]=(float)MeanResult_tmp/SumNormResp;
        }
    }
    else{ // Normal calculation of the mean
    for (int m=0; m<numbmodal; m++) {
        PointerToDataBegin_PTR=&PointerToDataBegin[m*numelmasked];
        PrecisionTYPE MeanResult_tmp=0;
        PrecisionTYPE SumNormResp=0;
        NormalisedResponsabilities_PTR=this->GetNormResp();
        for (int i=0; i<numelmasked; i++,PointerToDataBegin_PTR++,NormalisedResponsabilities_PTR++) {
            MeanResult_tmp+=(PrecisionTYPE)(*NormalisedResponsabilities_PTR)*(*PointerToDataBegin_PTR);
            SumNormResp+=(PrecisionTYPE)(*NormalisedResponsabilities_PTR);
        }
            MeanResult[m]=(float)MeanResult_tmp/SumNormResp;
    }
    }
    return MeanResult;
}

// Returns in a float array of size numbmodal*numbmodal the euclidean mean of the covariance matrices of the general anatomical classes
float * TreeEM::GetMeanVarianceGeneralClasses(){
    vector<TreeEM *> GeneralClassesVector=this->GetGeneralClassesVector();
    vector<float *> GeneralClassesVariance;
    vector<float> GeneralClassesWeight;
    float SumWeight=0;
    int numbgen=GeneralClassesVector.size();
    for (int g=0; g<numbgen; g++) {
        GeneralClassesVariance.push_back(GeneralClassesVector[g]->GetVarianceDirect());
        GeneralClassesWeight.push_back(GeneralClassesVector[g]->GetNormWeight());
        SumWeight+=GeneralClassesVector[g]->GetNormWeight();
    }
    if (SumWeight>0) {
        for (int g=0; g<numbgen; g++) {
            GeneralClassesWeight[g]/=SumWeight;
        }
    }

    int numbmodal=this->GetNumberModalities();
    int numbmodalSq=numbmodal*numbmodal;
    if (numbgen==0) {
        return NULL;
    }
    float * MeanGenVariance=new float [numbmodalSq];
    for (int m=0; m<numbmodalSq; m++) {
        MeanGenVariance[m]=0;
    }
    for(int g=0;g<numbgen;g++ ){
        for (int m=0; m<numbmodalSq; m++) {
            MeanGenVariance[m]+=GeneralClassesWeight[g]*GeneralClassesVariance[g][m];
        }
    }
    for (int g=0; g<numbgen; g++) {
        delete [] GeneralClassesVariance[g];
        GeneralClassesVariance[g]=NULL;
    }
    return MeanGenVariance;
}

// Returns in a float array of size numbmodal * numbmodal the covariance matrix of a specific node given the data and the corresponding NormResp array.
float * TreeEM::GetVarianceDirect(){
    //    int numel=this->GetNumberElements();
        int numbmodal=this->GetNumberModalities();
        int numbmodalSq=numbmodal*numbmodal;
        int numelmasked=this->GetNumberMaskedElements();
        PrecisionTYPE sumResp=0; // Initialisation of the denominator
        //float * PointerToDataBegin = static_cast<float *>(this->GetDataImage()->data);
        //    float * PointerToDataBegin=this->MakeDataBFCorrected();
        float * PointerToDataBegin=this->GetDataBFCorrected();
        float * PointerToDataBegin_PTR1=PointerToDataBegin;
        float * PointerToDataBegin_PTR2=PointerToDataBegin;
        float * NormalisedResponsabilities_PTR=this->GetNormResp();
        //    int * L2S_PTR=this->GetL2S();



        float * VarianceDirect=new float[numbmodalSq];
//        float * MeanDirect=this->GetMeanDirect();
    float MeanDirect[MaxNumbModal];
    for (int m=0; m<MaxNumbModal; m++) {
        MeanDirect[m]=0;
    }
    this->GetMeanDirect_bis(MeanDirect);
        for(int m1=0;m1<numbmodal;m1++){
            for(int m2=0;m2<numbmodal;m2++){
                    VarianceDirect[m1+m2*numbmodal]=0;
            }
        }
    
    if (this->GetFlagOutliers()==4) {
        float * Typicality_PTR=&this->GetNormResp()[numelmasked];
        // Calculation of the denominator (sum over the active voxels of the normalised responsabilities)
        for (int i=0; i<numelmasked; i++,NormalisedResponsabilities_PTR++,Typicality_PTR++) {
            sumResp+=(PrecisionTYPE)(*NormalisedResponsabilities_PTR)*(*Typicality_PTR);
        }
        for(int m1=0;m1<numbmodal;m1++){
            float Mean1=MeanDirect[m1];
            // First data pointer to the beginning of the modality m1 considered
            for(int m2=0;m2<numbmodal;m2++){
                float Mean2=MeanDirect[m2];
                PointerToDataBegin_PTR1=&PointerToDataBegin[m1*numelmasked];
                PointerToDataBegin_PTR2=&PointerToDataBegin[m2*numelmasked]; // Second Data pointer to the beginning of the modality m2 considered
                NormalisedResponsabilities_PTR=this->GetNormResp(); // Reinitialisation of the responsabilities pointer to the beginning
                Typicality_PTR=&this->GetNormResp()[numelmasked];
                PrecisionTYPE VarianceToUpdate_tmp=0;
                for(int i=0;i<numelmasked;i++,PointerToDataBegin_PTR1++,PointerToDataBegin_PTR2++,NormalisedResponsabilities_PTR++,Typicality_PTR++){
                    // Update of the numerator of the Variance Calculation only if in the case of an active voxel
//                    VarianceToUpdate_tmp+=(PrecisionTYPE)(*NormalisedResponsabilities_PTR)*(*Typicality_PTR)*((*PointerToDataBegin_PTR1)-MeanDirect[m1])*((*PointerToDataBegin_PTR2)-MeanDirect[m2]);
                    VarianceToUpdate_tmp+=(PrecisionTYPE)(*NormalisedResponsabilities_PTR)*(*Typicality_PTR)*((*PointerToDataBegin_PTR1)-Mean1)*((*PointerToDataBegin_PTR2)-Mean2);
                }
                if (sumResp !=0) {
                    VarianceDirect[m1+m2*numbmodal]=(float)VarianceToUpdate_tmp/sumResp;
                    if (m1==m2) {
                        VarianceDirect[m1+m2*numbmodal]=VarianceDirect[m1+m2*numbmodal]<=1E-6?1E-6:VarianceDirect[m1+m2*numbmodal]; // in order to avoid going to 0 if too sharp distribution but not changing non diagonal of variance
                    }
                    
                    
                }
                else{
                    VarianceDirect[m1+m2*numbmodal]=VarianceToUpdate_tmp/numelmasked;// this->GetNumberMaskedElements();
                }
                // Use of the symmetry property of the Variance matrix
                VarianceDirect[m2+m1*numbmodal]=VarianceDirect[m1+m2*numbmodal];
            }
        }

    }

    else{
        // Calculation of the denominator (sum over the active voxels of the normalised responsabilities)
        for (int i=0; i<numelmasked; i++,NormalisedResponsabilities_PTR++) {
            sumResp+=(PrecisionTYPE)(*NormalisedResponsabilities_PTR);
        }
        for(int m1=0;m1<numbmodal;m1++){
            float Mean1=MeanDirect[m1];
            // First data pointer to the beginning of the modality m1 considered
            for(int m2=m1;m2<numbmodal;m2++){
                float Mean2=MeanDirect[m2];
                PointerToDataBegin_PTR1=&PointerToDataBegin[m1*numelmasked];
                PointerToDataBegin_PTR2=&PointerToDataBegin[m2*numelmasked]; // Second Data pointer to the beginning of the modality m2 considered
                NormalisedResponsabilities_PTR=this->GetNormResp(); // Reinitialisation of the responsabilities pointer to the beginning
                PrecisionTYPE VarianceToUpdate_tmp=0;
                for(int i=0;i<numelmasked;i++,PointerToDataBegin_PTR1++,PointerToDataBegin_PTR2++,NormalisedResponsabilities_PTR++){
                    // Update of the numerator of the Variance Calculation only if in the case of an active voxel
//                    VarianceToUpdate_tmp+=(PrecisionTYPE)(*NormalisedResponsabilities_PTR)*((*PointerToDataBegin_PTR1)-MeanDirect[m1])*((*PointerToDataBegin_PTR2)-MeanDirect[m2]);
                    VarianceToUpdate_tmp+=(PrecisionTYPE)(*NormalisedResponsabilities_PTR)*((*PointerToDataBegin_PTR1)-Mean1)*((*PointerToDataBegin_PTR2)-Mean2);
                }
                if (sumResp !=0) {
                    VarianceDirect[m1+m2*numbmodal]=(float)VarianceToUpdate_tmp/sumResp;
                    if (m1==m2) {
                        VarianceDirect[m1+m2*numbmodal]=VarianceDirect[m1+m2*numbmodal]<=1E-6?1E-6:VarianceDirect[m1+m2*numbmodal]; // in order to avoid going to 0 if too sharp distribution but not changing non diagonal of variance
                    }


                }
                else{
                    VarianceDirect[m1+m2*numbmodal]=VarianceToUpdate_tmp/numelmasked;// this->GetNumberMaskedElements();
                }
                // Use of the symmetry property of the Variance matrix
                VarianceDirect[m2+m1*numbmodal]=VarianceDirect[m1+m2*numbmodal];
            }
        }
    }
        // Clearing memory
//        delete [] MeanDirect;
//        MeanDirect=NULL;
        return VarianceDirect;
}

// Returns in a float array of size numbmodal * numbmodal the covariance matrix of a specific node given the data and the corresponding NormResp array.
float * TreeEM::GetVarianceDirect(float * MeanDirect){
    //    int numel=this->GetNumberElements();
    int numbmodal=this->GetNumberModalities();
    int numbmodalSq=numbmodal*numbmodal;
    int numelmasked=this->GetNumberMaskedElements();
    PrecisionTYPE sumResp=0; // Initialisation of the denominator
    //float * PointerToDataBegin = static_cast<float *>(this->GetDataImage()->data);
    //    float * PointerToDataBegin=this->MakeDataBFCorrected();
    float * PointerToDataBegin=this->GetDataBFCorrected();
    float * PointerToDataBegin_PTR1=PointerToDataBegin;
    float * PointerToDataBegin_PTR2=PointerToDataBegin;
    float * NormalisedResponsabilities_PTR=this->GetNormResp();
    //    int * L2S_PTR=this->GetL2S();
    
    
    
    float * VarianceDirect=new float[numbmodalSq];
    //        float * MeanDirect=this->GetMeanDirect();
//    float MeanDirect[MaxNumbModal];
//    for (int m=0; m<MaxNumbModal; m++) {
//        MeanDirect[m]=0;
//    }
//    this->GetMeanDirect_bis(MeanDirect);
    for(int m1=0;m1<numbmodal;m1++){
        for(int m2=0;m2<numbmodal;m2++){
            VarianceDirect[m1+m2*numbmodal]=0;
        }
    }
    
    if (this->GetFlagOutliers()==4) {
        float * Typicality_PTR=&this->GetNormResp()[numelmasked];
        // Calculation of the denominator (sum over the active voxels of the normalised responsabilities)
        for (int i=0; i<numelmasked; i++,NormalisedResponsabilities_PTR++,Typicality_PTR++) {
            sumResp+=(PrecisionTYPE)(*NormalisedResponsabilities_PTR)*(*Typicality_PTR);
        }
        for(int m1=0;m1<numbmodal;m1++){
            // First data pointer to the beginning of the modality m1 considered
            for(int m2=0;m2<numbmodal;m2++){
                PointerToDataBegin_PTR1=&PointerToDataBegin[m1*numelmasked];
                PointerToDataBegin_PTR2=&PointerToDataBegin[m2*numelmasked]; // Second Data pointer to the beginning of the modality m2 considered
                NormalisedResponsabilities_PTR=this->GetNormResp(); // Reinitialisation of the responsabilities pointer to the beginning
                Typicality_PTR=&this->GetNormResp()[numelmasked];
                PrecisionTYPE VarianceToUpdate_tmp=0;
                for(int i=0;i<numelmasked;i++,PointerToDataBegin_PTR1++,PointerToDataBegin_PTR2++,NormalisedResponsabilities_PTR++,Typicality_PTR++){
                    // Update of the numerator of the Variance Calculation only if in the case of an active voxel
                    VarianceToUpdate_tmp+=(PrecisionTYPE)(*NormalisedResponsabilities_PTR)*(*Typicality_PTR)*((*PointerToDataBegin_PTR1)-MeanDirect[m1])*((*PointerToDataBegin_PTR2)-MeanDirect[m2]);
                }
                if (sumResp !=0) {
                    VarianceDirect[m1+m2*numbmodal]=(float)VarianceToUpdate_tmp/sumResp;
                    if (m1==m2) {
                        VarianceDirect[m1+m2*numbmodal]=VarianceDirect[m1+m2*numbmodal]<=1E-6?1E-6:VarianceDirect[m1+m2*numbmodal]; // in order to avoid going to 0 if too sharp distribution but not changing non diagonal of variance
                    }
                    
                    
                }
                else{
                    VarianceDirect[m1+m2*numbmodal]=VarianceToUpdate_tmp/numelmasked;// this->GetNumberMaskedElements();
                }
                // Use of the symmetry property of the Variance matrix
                VarianceDirect[m2+m1*numbmodal]=VarianceDirect[m1+m2*numbmodal];
            }
        }
        
    }
    
    else{
        // Calculation of the denominator (sum over the active voxels of the normalised responsabilities)
        for (int i=0; i<numelmasked; i++,NormalisedResponsabilities_PTR++) {
            sumResp+=(PrecisionTYPE)(*NormalisedResponsabilities_PTR);
        }
        for(int m1=0;m1<numbmodal;m1++){
            // First data pointer to the beginning of the modality m1 considered
            for(int m2=m1;m2<numbmodal;m2++){
                PointerToDataBegin_PTR1=&PointerToDataBegin[m1*numelmasked];
                PointerToDataBegin_PTR2=&PointerToDataBegin[m2*numelmasked]; // Second Data pointer to the beginning of the modality m2 considered
                NormalisedResponsabilities_PTR=this->GetNormResp(); // Reinitialisation of the responsabilities pointer to the beginning
                PrecisionTYPE VarianceToUpdate_tmp=0;
                for(int i=0;i<numelmasked;i++,PointerToDataBegin_PTR1++,PointerToDataBegin_PTR2++,NormalisedResponsabilities_PTR++){
                    // Update of the numerator of the Variance Calculation only if in the case of an active voxel
                    VarianceToUpdate_tmp+=(PrecisionTYPE)(*NormalisedResponsabilities_PTR)*((*PointerToDataBegin_PTR1)-MeanDirect[m1])*((*PointerToDataBegin_PTR2)-MeanDirect[m2]);
                }
                if (sumResp !=0) {
                    VarianceDirect[m1+m2*numbmodal]=(float)VarianceToUpdate_tmp/sumResp;
                    if (m1==m2) {
                        VarianceDirect[m1+m2*numbmodal]=VarianceDirect[m1+m2*numbmodal]<=1E-6?1E-6:VarianceDirect[m1+m2*numbmodal]; // in order to avoid going to 0 if too sharp distribution but not changing non diagonal of variance
                    }
                    
                    
                }
                else{
                    VarianceDirect[m1+m2*numbmodal]=VarianceToUpdate_tmp/numelmasked;// this->GetNumberMaskedElements();
                }
                // Use of the symmetry property of the Variance matrix
                VarianceDirect[m2+m1*numbmodal]=VarianceDirect[m1+m2*numbmodal];
            }
        }
    }
    // Clearing memory
    //        delete [] MeanDirect;
    //        MeanDirect=NULL;
    return VarianceDirect;
}


// Returns in a array of float array the
float ** TreeEM::GetMeanDirectLabel(int * Label, int numbLabels){
    int numbmodal=this->GetNumberModalities();
    int numelmasked=this->GetNumberMaskedElements();
    //float * PointerToDataBegin = static_cast<float *>(this->GetDataImage()->data);
    //    float * PointerToDataBegin=this->MakeDataBFCorrected();
    float * PointerToDataBegin=this->GetDataBFCorrected();
    float * PointerToDataBegin_PTR=PointerToDataBegin;
    float * NormalisedResponsabilities_PTR=this->GetNormResp();
    int * Label_PTR=Label;
    // Initialisation of the results
    float ** MeanResult=new float*[numbLabels];
    for (int l=0; l<numbLabels; l++) {
        MeanResult[l]=new float[numbmodal];
        for (int m=0; m<numbmodal; m++) {
            MeanResult[l][m]=0;
        }
    }
    for (int m=0; m<numbmodal; m++) {
        PointerToDataBegin_PTR=&PointerToDataBegin[m*numelmasked];
        PrecisionTYPE * MeanResult_tmp=new PrecisionTYPE[numbLabels];
        PrecisionTYPE * SumNormResp=new PrecisionTYPE[numbLabels];
        for (int l=0; l<numbLabels; l++) {
            MeanResult_tmp[l]=0;
            SumNormResp[l]=0;
        }
        Label_PTR=Label;
        NormalisedResponsabilities_PTR=this->GetNormResp();
        for (int i=0; i<numelmasked; i++,PointerToDataBegin_PTR++,NormalisedResponsabilities_PTR++,Label_PTR++) {
            MeanResult_tmp[*Label_PTR]+=(PrecisionTYPE)*NormalisedResponsabilities_PTR*(*PointerToDataBegin_PTR);
                SumNormResp[*Label_PTR]+=(PrecisionTYPE)*NormalisedResponsabilities_PTR;
        }
        for (int l=0; l<numbLabels; l++) {
             MeanResult[l][m]=(float)MeanResult_tmp[l]/SumNormResp[l];
        }
        delete [] MeanResult_tmp;
        MeanResult_tmp=NULL;
        delete [] SumNormResp;
        SumNormResp=NULL;
    }
    return MeanResult;
}

float ** TreeEM::GetVarianceDirectLabel(int * Label,int numbLabels){
    //    int numel=this->GetNumberElements();
    int numbmodal=this->GetNumberModalities();
    int numbmodalSq=numbmodal*numbmodal;
    int numelmasked=this->GetNumberMaskedElements();
    PrecisionTYPE * sumResp=new PrecisionTYPE[numbLabels]; // Initialisation of the denominators
    for (int l=0; l<numbLabels; l++) {
        sumResp[l]=0;
    }
    //float * PointerToDataBegin = static_cast<float *>(this->GetDataImage()->data);
    //    float * PointerToDataBegin=this->MakeDataBFCorrected();
    float * PointerToDataBegin=this->GetDataBFCorrected();
    float * PointerToDataBegin_PTR1=PointerToDataBegin;
    float * PointerToDataBegin_PTR2=PointerToDataBegin;
    float * NormalisedResponsabilities_PTR=this->GetNormResp();
    int * Label_PTR=Label;
    //    int * L2S_PTR=this->GetL2S();
    
    // Calculation of the denominator (sum over the active voxels of the normalised responsabilities)
    for (int i=0; i<numelmasked; i++,NormalisedResponsabilities_PTR++,Label_PTR++) {
        sumResp[*Label_PTR]+=(PrecisionTYPE)(*NormalisedResponsabilities_PTR);
    }
    // Initialisation of mean and variance
    float ** VarianceDirect =new float*[numbLabels];
    for (int l=0; l<numbLabels; l++) {
        VarianceDirect[l]=new float[numbmodalSq];
        for (int m=0; m<numbmodalSq; m++) {
            VarianceDirect[l][m]=0;
        }
    }
    float ** MeanDirect=this->GetMeanDirectLabel(Label,numbLabels);
    
    for(int m1=0;m1<numbmodal;m1++){
        // First data pointer to the beginning of the modality m1 considered
        for(int m2=0;m2<numbmodal;m2++){
            PointerToDataBegin_PTR1=&PointerToDataBegin[m1*numelmasked];
            PointerToDataBegin_PTR2=&PointerToDataBegin[m2*numelmasked]; // Second Data pointer to the beginning of the modality m2 considered
            NormalisedResponsabilities_PTR=this->GetNormResp(); // Reinitialisation of the responsabilities pointer to the beginning
            Label_PTR=Label; // Reinitialisation of the labels to the beginning
            PrecisionTYPE * VarianceToUpdate_tmp= new PrecisionTYPE[numbLabels];
            for (int l=0; l<numbLabels; l++) {
                VarianceToUpdate_tmp[l]=0;
            }
            for(int i=0;i<numelmasked;i++,PointerToDataBegin_PTR1++,PointerToDataBegin_PTR2++,NormalisedResponsabilities_PTR++,Label_PTR++){
                // Update of the numerator of the Variance Calculation only if in the case of an active voxel
                VarianceToUpdate_tmp[*Label_PTR]+=(PrecisionTYPE)(*NormalisedResponsabilities_PTR)*((*PointerToDataBegin_PTR1)-MeanDirect[*Label_PTR][m1])*((*PointerToDataBegin_PTR2)-MeanDirect[*Label_PTR][m2]);
            }
            for (int l=0; l<numbLabels; l++) {
                if (sumResp[l] !=0) {
                    VarianceDirect[l][m1+m2*numbmodal]=(float)VarianceToUpdate_tmp[l]/sumResp[l];
                    if (m1==m2) {
                        VarianceDirect[l][m1+m2*numbmodal]=VarianceDirect[l][m1+m2*numbmodal]<=1E-6?1E-6:VarianceDirect[l][m1+m2*numbmodal]; // in order to avoid going to 0 if too sharp distribution but not changing non diagonal of variance
                    }
                    
                    
                }
                else{
                    VarianceDirect[l][m1+m2*numbmodal]=VarianceToUpdate_tmp[l]/numelmasked;// this->GetNumberMaskedElements();
                }
                // Use of the symmetry property of the Variance matrix
                VarianceDirect[l][m2+m1*numbmodal]=VarianceDirect[l][m1+m2*numbmodal];
            }
            delete [] VarianceToUpdate_tmp;
            VarianceToUpdate_tmp=NULL;
        }
    }
    // Clearing memory
    for (int l=0; l<numbLabels; l++) {
        delete [] MeanDirect[l];
        MeanDirect[l]=NULL;
    }
    delete [] MeanDirect;
    MeanDirect=NULL;
    delete [] sumResp;
    sumResp=NULL;
    return VarianceDirect;
}

// Returns in a float array of size numbmodal the diagonal values of the covariance matrix for a given node
float * TreeEM::GetDiagVarianceDirect(){
    int numbmodal=this->GetNumberModalities();
    int numel=this->GetNumberElements();
    float * MeanUsedB=this->GetMeanDirect();
    float MeanUsed[MaxNumbModal];
    for(int m=0;m<MaxNumbModal;m++){
        if(m<numbmodal){
            MeanUsed[m]=MeanUsedB[m];
        }
        else{
            MeanUsed[m]=0;
        }
    }
    delete [] MeanUsedB;
    float * Data=static_cast<float *>(this->GetDataImage()->data);
    float * Data_PTR=Data;
    int * L2S_PTR=this->GetL2S();
    float * NormResp_PTR=this->GetNormResp();
    float * DiagVarianceResult=new float[numbmodal];//{0};
    for (int i=0; i<numbmodal; i++) {
        DiagVarianceResult[i]=0;
    }
    PrecisionTYPE SumNormResp=0;
    PrecisionTYPE DiagVarianceResult_tmp=0;
    for (int m=0; m<numbmodal; m++) {
        Data_PTR=&Data[m*numel];
        L2S_PTR=this->GetL2S();
        NormResp_PTR=this->GetNormResp();
        SumNormResp=0;
        DiagVarianceResult_tmp=0;
        for (int i=0; i<numel; i++,Data_PTR++,L2S_PTR++) {
            if (*L2S_PTR>=0) {
//                DiagVarianceResult_tmp+=(PrecisionTYPE)*NormResp_PTR*pow_int((*Data_PTR-MeanUsed[m]), 2);
                DiagVarianceResult_tmp+=(PrecisionTYPE)*NormResp_PTR*((*Data_PTR-MeanUsed[m])*(*Data_PTR-MeanUsed[m]));
                SumNormResp+=(PrecisionTYPE)*NormResp_PTR;
                NormResp_PTR++;
            }
        }
        DiagVarianceResult[m]=(float)DiagVarianceResult_tmp/SumNormResp;
    }

    return DiagVarianceResult;
}

float * TreeEM::GetDiagVarianceDirect_corr(){
    //    int numel=this->GetNumberElements();
    int numbmodal=this->GetNumberModalities();
    int numelmasked=this->GetNumberMaskedElements();
    PrecisionTYPE sumResp=0; // Initialisation of the denominator
    //float * PointerToDataBegin = static_cast<float *>(this->GetDataImage()->data);
    //    float * PointerToDataBegin=this->MakeDataBFCorrected();
    float * PointerToDataBegin=this->GetDataBFCorrected();
    float * PointerToDataBegin_PTR1=PointerToDataBegin;
    float * NormalisedResponsabilities_PTR=this->GetNormResp();
    //    int * L2S_PTR=this->GetL2S();
    
    
    
    float * DiagVarianceDirect=new float[numbmodal];
    float MeanDirect[10];
    for (int d=0; d<10; d++) {
        MeanDirect[d]=0;
    }
//    float * MeanDirect=this->GetMeanDirect();
    this->GetMeanDirect_bis(MeanDirect);
    for(int m=0;m<numbmodal;m++){
            DiagVarianceDirect[m]=0;
        }
    
    if (this->GetFlagOutliers()==4) {
        float * Typicality_PTR=&this->GetNormResp()[numelmasked];
        // Calculation of the denominator (sum over the active voxels of the normalised responsabilities)
        for (int i=0; i<numelmasked; i++,NormalisedResponsabilities_PTR++,Typicality_PTR++) {
            sumResp+=(PrecisionTYPE)(*NormalisedResponsabilities_PTR)*(*Typicality_PTR);
        }
        for(int m=0;m<numbmodal;m++){
                PointerToDataBegin_PTR1=&PointerToDataBegin[m*numelmasked];
                NormalisedResponsabilities_PTR=this->GetNormResp(); // Reinitialisation of the responsabilities pointer to the beginning
                Typicality_PTR=&this->GetNormResp()[numelmasked];
                PrecisionTYPE VarianceToUpdate_tmp=0;
                for(int i=0;i<numelmasked;i++,PointerToDataBegin_PTR1++,NormalisedResponsabilities_PTR++,Typicality_PTR++){
                    // Update of the numerator of the Variance Calculation only if in the case of an active voxel
                    VarianceToUpdate_tmp+=(PrecisionTYPE)(*NormalisedResponsabilities_PTR)*(*Typicality_PTR)*((*PointerToDataBegin_PTR1)-MeanDirect[m])*((*PointerToDataBegin_PTR1)-MeanDirect[m]);
//                    pow_int((*PointerToDataBegin_PTR1)-MeanDirect[m],2);
                }
                if (sumResp !=0) {
                    DiagVarianceDirect[m]=(float)VarianceToUpdate_tmp/sumResp;
                }
                else{
                    DiagVarianceDirect[m]=VarianceToUpdate_tmp/numelmasked;// this->GetNumberMaskedElements();
                }

            }
        }

    
    else{
        // Calculation of the denominator (sum over the active voxels of the normalised responsabilities)
        for (int i=0; i<numelmasked; i++,NormalisedResponsabilities_PTR++) {
            sumResp+=(PrecisionTYPE)(*NormalisedResponsabilities_PTR);
        }
        for(int m=0;m<numbmodal;m++){
            // First data pointer to the beginning of the modality m1 considered
                PointerToDataBegin_PTR1=&PointerToDataBegin[m*numelmasked];
                NormalisedResponsabilities_PTR=this->GetNormResp(); // Reinitialisation of the responsabilities pointer to the beginning
                PrecisionTYPE VarianceToUpdate_tmp=0;
                for(int i=0;i<numelmasked;i++,PointerToDataBegin_PTR1++,NormalisedResponsabilities_PTR++){
                    // Update of the numerator of the Variance Calculation only if in the case of an active voxel
//                    VarianceToUpdate_tmp+=(PrecisionTYPE)(*NormalisedResponsabilities_PTR)*pow_int((*PointerToDataBegin_PTR1)-MeanDirect[m],2);
                    VarianceToUpdate_tmp+=(PrecisionTYPE)(*NormalisedResponsabilities_PTR)*((*PointerToDataBegin_PTR1)-MeanDirect[m])*((*PointerToDataBegin_PTR1)-MeanDirect[m]);
                }
                if (sumResp !=0) {
                    DiagVarianceDirect[m]=(float)VarianceToUpdate_tmp/sumResp;
                    
                }
                else{
                    DiagVarianceDirect[m]=VarianceToUpdate_tmp/numelmasked;// this->GetNumberMaskedElements();
                }
            }
        }
    // Clearing memory
//    delete [] MeanDirect;
//    MeanDirect=NULL;
    return DiagVarianceDirect;
}

// Returns the pointer to the beginning of the parameters values concerned by the variance
/*WARNING : do not create a copy of the values pointed as belonging to the variance matrix*/
float * TreeEM::GetVariance(){
    if (this->GetNumberChildren()!=0) { /* If the considered element is not a leaf, there is no parameters since the distribution is of mixture type*/
        return NULL;
    }
    else {
        switch (this->GetDistributionType()) { /* For the moment only Gaussian distribution = default case might change in the future*/
            case 2:{ // Case of a uniform distribution
                return NULL;
            }
        default:
            return this->GetParameters()->ValueParameters+this->GetNumberModalities();
            break;
        }
    }
}

// Return the size of the parameters value
int TreeEM::GetSizeParameters(){
    if (this->GetDistributionType()==1 && this->GetParameters()->SizeParameters==(int)((this->GetNumberModalities()+1)*this->GetNumberModalities())) {
        return this->GetParameters()->SizeParameters;
    }
    //cout<<"Not Gaussian or not appropriate size of parameters"<< this->GetDistributionType()<< endl;

    return this->GetParameters()->SizeParameters;
}

float * TreeEM::GetParametersValue(){
    return this->GetParameters()->ValueParameters;
}

//// Returns in a vector of pointers to nifti_images the Priors of the children
//vector<nifti_image *> TreeEM::GetPriorsVector(){
//    vector<nifti_image *> PriorsVector;
//    int numbchild=this->GetNumberChildren();
//    for(int c=0;c<numbchild;c++){
//        PriorsVector.push_back(this->GetChild(c)->GetPriors());
//        //cout<<PriorsVector[c];
//    }
//    return PriorsVector;
//}

// Return for the given node all priors under it in a vector but does not consider priors at this level if exist
vector<nifti_image*> TreeEM::GetPriorsVector(){
    vector<nifti_image*> PriorsVector;
//    if(this->GetPriorsDirect()!=NULL){
//        PriorsVector.push_back(this->GetPriorsDirect());
//    }
    int numbchild=this->GetNumberChildren();
    for (int c=0; c<numbchild; c++) {
        if (this->GetChild(c)->GetPriorsDirect()!=NULL) {
            PriorsVector.push_back(this->GetChild(c)->GetPriorsDirect());
        }
        else{
            vector<nifti_image*> PriorsVectorChild=this->GetChild(c)->GetPriorsVector();
            int numbPVChild=PriorsVectorChild.size();
            for(int i=0;i<numbPVChild;i++){
                PriorsVector.push_back(PriorsVectorChild[i]);
            }
        }
    }
    return PriorsVector;
//    else{
//        int numbchild=this->GetNumberChildren();
//        for(int c=0;c<numbchild;c++){
//            vector<nifti_image*> PriorsVectorChild=this->GetChild(c)->GetPriorsVector();
//            for(int i=0;i<PriorsVectorChild.size();i++){
//                PriorsVector.push_back(PriorsVectorChild[i]);
//            }
//        }
//    }
//    return PriorsVector;
}


// Return the vector of nodes in which the statistical atlases are stored (may not be first level if outlier model is chosen)
vector<TreeEM*> TreeEM::GetPriorsNodeVector(){
    vector<TreeEM*> PriorsNodeVector;
    //    if(this->GetPriorsDirect()!=NULL){
    //        PriorsVector.push_back(this->GetPriorsDirect());
    //    }
    int numbchild=this->GetNumberChildren();
    if ((this->GetFlagOutliers()!=1 && this->GetFlagOutliers()!=3 && this->GetFlagOutliers()!=5 && this->GetFlagOutliers()!=6) || !this->IsRoot()) { // case where model bilayered or not considered from root
        for (int c=0; c<numbchild; c++) {
            if (this->GetChild(c)->GetPriorsDirect()!=NULL) {
                PriorsNodeVector.push_back(this->GetChild(c));
            }
            else{
                vector<TreeEM*> PriorsVectorChild=this->GetChild(c)->GetPriorsNodeVector();
                int numbPVChild=PriorsVectorChild.size();
                for(int i=0;i<numbPVChild;i++){
                    PriorsNodeVector.push_back(PriorsVectorChild[i]);
                }
            }
        }
    }
    else{ // case where we consider trilayered model and begin at root
        int numbchild0=this->GetChild(0)->GetNumberChildren();
        int numbchild1=this->GetChild(1)->GetNumberChildren();
        
        for (int c=0; c<numbchild0; c++) {
            if (this->GetChild(0)->GetChild(c)->GetPriorsDirect()!=NULL) {
                PriorsNodeVector.push_back(this->GetChild(0)->GetChild(c));
            }
            else{
                vector<TreeEM*> PriorsVectorChild=this->GetChild(0)->GetChild(c)->GetPriorsNodeVector();
                int numbPVChild=PriorsVectorChild.size();
                for(int i=0;i<numbPVChild;i++){
                    PriorsNodeVector.push_back(PriorsVectorChild[i]);
                }
            }
        }
        if (numbchild1==0) { // corresponding to no leaf to outliers node in second level
            if (this->GetChild(1)->GetPriorsDirect()!=NULL) {
                PriorsNodeVector.push_back(this->GetChild(1));
            }
        }
        else{
        for (int c=0; c<numbchild1; c++) {
            if (this->GetChild(1)->GetChild(c)->GetPriorsDirect()!=NULL) {
                PriorsNodeVector.push_back(this->GetChild(1)->GetChild(c));
            }
            else{
                vector<TreeEM*> PriorsVectorChild=this->GetChild(1)->GetChild(c)->GetPriorsNodeVector();
                int numbPVChild=PriorsVectorChild.size();
                for(int i=0;i<numbPVChild;i++){
                    PriorsNodeVector.push_back(PriorsVectorChild[i]);
                }
            }
        }
        }
        
    }

    return PriorsNodeVector;
}

// Returns in a vector the direct children nodes that have a direct prior statistical atlas.
vector<TreeEM *> TreeEM::GetAllPriorsNodeVectorParent(){
    vector<TreeEM*> PriorsNodeVector;
    //    if(this->GetPriorsDirect()!=NULL){
    //        PriorsVector.push_back(this->GetPriorsDirect());
    //    }
//    int numbchild=this->GetNumberChildren();
        for (int c=0; c<this->GetNumberChildren(); c++) {
            if (this->GetChild(c)->GetPriorsDirect()!=NULL) {
                PriorsNodeVector.push_back(this->GetChild(c));
            }
}
    return PriorsNodeVector;
}

// Changes PriorNodeVector to add all nodes that contain statistical priors stored in them
void TreeEM::GetAllPriorsNodeVector(vector<TreeEM *> & PriorNodeVector){
    int numbchild=this->GetNumberChildren();
    if (this->GetPriorsDirect()!=NULL) {
        PriorNodeVector.push_back(this);
    }
    for (int c=0; c<numbchild; c++) {
        this->GetChild(c)->GetAllPriorsNodeVector( PriorNodeVector);
    }
}

// Returns the vector of the inlier main general classes
vector<TreeEM*> TreeEM::GetGeneralClassesVector(){
    vector<TreeEM*> GeneralClassesVector;
    TreeEM * Root=this->FindRoot();
    switch(this->GetFlagOutliers()){
    case 0:{ // no outlier model considered
        GeneralClassesVector= Root->GetChildren();
        break;
    }
    case 1:{
        GeneralClassesVector=Root->GetChild(0)->GetChildren();
        break;
    }
    case 2:{
        int numbchild=Root->GetNumberChildren();
        for(int c=0;c<numbchild-1;c++){
            GeneralClassesVector.push_back(Root->GetChild(c));
        }
        break;
    }
    case 3:{
            GeneralClassesVector=Root->GetChild(0)->GetChildren();
        }
            break;
    case 5:{
            GeneralClassesVector=Root->GetChild(0)->GetChildren();
        }
            break;
        case 6:{
            GeneralClassesVector=Root->GetChild(0)->GetChildren();
        }
            break;
            case 7:{
                GeneralClassesVector=Root->GetChild(0)->GetAllTreesFromLevel(2);
                break;
            }
    default:{
        GeneralClassesVector= Root->GetChildren();
        break;
    }
    }
    return GeneralClassesVector;
}

// Returns the vector of trees with the main general classes and the outlier node
vector<TreeEM*> TreeEM::GetMainNodesVector(){
    if(this->GetFlagOutliers()!=1 && this->GetFlagOutliers()!=3 && this->GetFlagOutliers()<5){ // no outlier class or outlier class at same level with evolving priors
        return this->FindRoot()->GetChildren();
    }
    else{// priors at level 2 + Node outlier
        vector<TreeEM *> GeneralClassesVector=this->FindRoot()->GetChild(0)->GetChildren();
        GeneralClassesVector.push_back(this->GetNodeOutlier());
        return GeneralClassesVector;
    }
}

// Return the pointer to the node from which the outlier classes will be derived
TreeEM* TreeEM::GetNodeOutlier(){
    if(!this->GetFlagOutliers()){
        return NULL;
    }
    else{ // the outlier node is the last of the children from the root Rule
        TreeEM* Root=this->FindRoot();
        int numbchild=Root->GetNumberChildren();
        return Root->GetChild(numbchild-1);
    }
}

//Return the pointer to the node from which the Inlier classes will be derived : Corresponds only to certain value of FlagOutliers
TreeEM * TreeEM::GetNodeInlier(){
    if (this->GetFlagOutliers()!=3 && this->GetFlagOutliers()<5) {
        return NULL;
    }
    else{
        TreeEM * Root=this->FindRoot();
        if (Root->GetNumberChildren()==0) {
            return NULL;
        }
        return Root->GetChild(0);
    }
}

// In case of uniform splitting 5, return the vectors of nodes related to different classes of outliers.
vector<TreeEM *> TreeEM::GetOutliersMainNodesVector(){
    vector<TreeEM *> OutliersMainNodesVector;
    if (this->GetFlagOutliers()==0) {
        return OutliersMainNodesVector;
    }
    else if (this->GetFlagUTC()!=5 && this->GetFlagOutliers()!=3 && this->GetFlagOutliers()<5){
        OutliersMainNodesVector.push_back(this->FindRoot()->GetNodeOutlier());
        return OutliersMainNodesVector;
    }
    else {
//        OutliersMainNodesVector=this->FindRoot()->GetOutliersMainNodesVectorChangeableAtlases(segment_param);
//        if (OutliersMainNodesVector.size()==0) {
//            OutliersMainNodesVector=this->FindRoot()->GetNodeOutlier()->GetPriorsNodeVector();
//        }
        OutliersMainNodesVector=this->FindRoot()->GetNodeOutlier()->GetDeepestPriorNodeVector();
        return OutliersMainNodesVector;
    }
    
}

vector<TreeEM *> TreeEM::GetOutliersMainNodesVectorChangeableAtlases(SEG_PARAMETERS * segment_param){
    vector<TreeEM*> OutliersNodeVectorFin;
    if (segment_param->uniformTypeChange!=5) { // Only available with UTC=5
        return OutliersNodeVectorFin;
    }
    switch (this->GetFlagOutliers()) {
        case 0:
            return OutliersNodeVectorFin;
            break;
        case 2:
            OutliersNodeVectorFin=this->FindRoot()->GetNodeOutlier()->GetPriorsNodeVector();
            break;
        case 3:{
            TreeEM * NodeOutlier=this->FindRoot()->GetNodeOutlier();
            int numbchildOutliers=NodeOutlier->GetNumberChildren();
            for (int c=0; c<numbchildOutliers; c++) {
                vector<TreeEM *> OutliersNodeVectorFinTmp=NodeOutlier->GetChild(c)->GetPriorsNodeVector();
                int numbOutNodes=OutliersNodeVectorFinTmp.size();
                for (int l=0; l<numbOutNodes; l++) {
                    OutliersNodeVectorFin.push_back(OutliersNodeVectorFinTmp[l]);
                }
            }
        }
            break;
        case 5:{
            TreeEM * NodeOutlier=this->FindRoot()->GetNodeOutlier();
            int numbchildOutliers=NodeOutlier->GetNumberChildren();
            for (int c=0; c<numbchildOutliers; c++) {
                vector<TreeEM *> OutliersNodeVectorFinTmp=NodeOutlier->GetChild(c)->GetPriorsNodeVector();
                int numbOutNodes=OutliersNodeVectorFinTmp.size();
                for (int l=0; l<numbOutNodes; l++) {
                    OutliersNodeVectorFin.push_back(OutliersNodeVectorFinTmp[l]);
                }
            }
        }
            break;
        case 6:{
            TreeEM * NodeOutlier=this->FindRoot()->GetNodeOutlier();
            int numbchildOutliers=NodeOutlier->GetNumberChildren();
            for (int c=0; c<numbchildOutliers; c++) {
                vector<TreeEM *> OutliersNodeVectorFinTmp=NodeOutlier->GetChild(c)->GetPriorsNodeVector();
                int numbOutNodes=OutliersNodeVectorFinTmp.size();
                for (int l=0; l<numbOutNodes; l++) {
                    OutliersNodeVectorFin.push_back(OutliersNodeVectorFinTmp[l]);
                }
            }
        }
            break;
        default:
            break;
    }
    return OutliersNodeVectorFin;
}

// Returns the vector of nodes that correspond to the deepest node in the hierarchy that store statistical priors
vector<TreeEM *> TreeEM::GetDeepestPriorNodeVector(){
    vector<TreeEM *> DeepestPriorNodeVector;
                int numbchild=this->GetNumberChildren();
        if (this->GetPriorsDirect()!=NULL && this->GetNumberChildren()==0) { // leaf and has priors
            DeepestPriorNodeVector.push_back(this);
        }
        else if(this->GetPriorsDirect()!=NULL){ // Not at deepest but has priors

            vector<TreeEM *>TmpDeepestPriorNodeVector=this->GetChild(0)->GetDeepestPriorNodeVector();
            if (TmpDeepestPriorNodeVector.size()==0) { // No priors further deep on first
                DeepestPriorNodeVector.push_back(this);
            }
            else{ // Partial recursivity
            for (int c=0; c<numbchild; c++) {
                TmpDeepestPriorNodeVector=this->GetChild(c)->GetDeepestPriorNodeVector();
                int numbDeepest=TmpDeepestPriorNodeVector.size();
                for (int l=0; l<numbDeepest; l++) {
                    DeepestPriorNodeVector.push_back(TmpDeepestPriorNodeVector[l]);
                }
            }


        }
    }
        else{// case where there is no prior on the considered node ; need to be seeked further down
            for (int c=0; c<numbchild; c++) { // finalisation of recursivity
                vector<TreeEM *> ChildDeepestPriorNodeVector=this->GetChild(c)->GetDeepestPriorNodeVector();
                int numbChildDeepest=ChildDeepestPriorNodeVector.size();
                for (int l=0; l<numbChildDeepest; l++) {
                    DeepestPriorNodeVector.push_back(ChildDeepestPriorNodeVector[l]);
                }
            }
            
        }
    return DeepestPriorNodeVector;

}

//// Return in a vector of pointers to float arrays the PriorsAdapted of the children
//vector<float *> TreeEM::GetPriorsAdaptedVector(){
//    vector<float *> PriorsAdaptedVector;
//    int numbchild=this->GetNumberChildren();
//    for(int c=0;c<numbchild;c++){
//        PriorsAdaptedVector.push_back(this->GetChild(c)->GetPriorsAdapted());
//        //cout<<PriorsVector[c];
//    }
//    return PriorsAdaptedVector;
//}

// Returns in a vector the PriorsAdapted that are stored under the considered node
vector<float*> TreeEM::GetPriorsAdaptedVector(){
    vector<float*> PriorsAdaptedVector;
    vector<TreeEM*> NodePriorVector=this->GetPriorsNodeVector();
//    vector<TreeEM *> NodePriorVector=this->GetAllPriorsNodeVectorParent();
    int numbclasses=NodePriorVector.size();
    for(int c=0;c<numbclasses;c++){
        PriorsAdaptedVector.push_back(NodePriorVector[c]->GetPriorsAdapted());
    }
    return PriorsAdaptedVector;
}

vector<float *> TreeEM::GetPartPriorsAdaptedVector(){
    vector<float*> PartPriorsAdaptedVector;
    vector<TreeEM*> NodePriorVector=this->GetPriorsNodeVector();
    //    vector<TreeEM *> NodePriorVector=this->GetAllPriorsNodeVectorParent();
    int numbclasses=NodePriorVector.size();
    for(int c=0;c<numbclasses;c++){
        PartPriorsAdaptedVector.push_back(NodePriorVector[c]->GetPartPriorsAdapted_bis());
    }
    return PartPriorsAdaptedVector;
}

// Returns the Priors Adapted under the parent of the considered node.
vector<float *> TreeEM::GetPriorsAdaptedVectorParent(){
    vector<float*> PriorsAdaptedVector;
    vector<TreeEM*> NodePriorVector=this->GetAllPriorsNodeVectorParent();
    int numbclasses=NodePriorVector.size();
    for(int c=0;c<numbclasses;c++){
        PriorsAdaptedVector.push_back(NodePriorVector[c]->GetPriorsAdapted());
    }
    return PriorsAdaptedVector;
}

vector<float *> TreeEM::GetPartPriorsAdaptedVectorParent(){
    vector<float*> PartPriorsAdaptedVector;
    vector<TreeEM*> NodePriorVector=this->GetAllPriorsNodeVectorParent();
    int numbclasses=NodePriorVector.size();
    for(int c=0;c<numbclasses;c++){
        PartPriorsAdaptedVector.push_back(NodePriorVector[c]->GetPartPriorsAdapted_bis());
    }
    return PartPriorsAdaptedVector;
}

// Returns the vector of all priors adapted used in the node and under it
vector<float *> TreeEM::GetAllPriorsAdaptedVector(){
    vector<float*> AllPriorsAdaptedVector;
    vector<TreeEM*> NodeAllPriorVector;
    this->GetAllPriorsNodeVector(NodeAllPriorVector);
    int numbclasses=NodeAllPriorVector.size();
    for(int c=0;c<numbclasses;c++){
        AllPriorsAdaptedVector.push_back(NodeAllPriorVector[c]->GetPriorsAdapted());
    }
    return AllPriorsAdaptedVector;
}

vector<float *> TreeEM::GetAllPartPriorsAdaptedVector(){
    vector<float*> AllPartPriorsAdaptedVector;
    vector<TreeEM*> NodeAllPriorVector;
    this->GetAllPriorsNodeVector(NodeAllPriorVector);
    int numbclasses=NodeAllPriorVector.size();
    for(int c=0;c<numbclasses;c++){
        AllPartPriorsAdaptedVector.push_back(NodeAllPriorVector[c]->GetPartPriorsAdapted());
    }
    return AllPartPriorsAdaptedVector;
}

// Returns the pointer to the image used for the segmentation
nifti_image * TreeEM::GetDataImage(){
    //if (this->WhatTypeOfTreeComponent()==ROOT || this->WhatTypeOfTreeComponent()==INITIALNODE){
    if(this->GetParent()==NULL){ // The image is only stored at root
        //cout<< "The considered tree is a root or an initial node"<<endl;
        if( this->DataImage==NULL) {
            cout<<"This tree is not valid : no input image is given !"<<endl;

            return NULL;
        }
        else{
            return this->DataImage;
        }
    }
    else{
        return this->GetParent()->GetDataImage();
    }
}

// Returns the max of modality m in data image after checking it can be found
float TreeEM::GetMaxDataModal(int m){
    float MaxResult=-1E18;
    if (this->GetDataImage()==NULL) { // no data image attributed in the tree
        cout<< "No data attributed to the tree, tree not valid"<< endl;
        return MaxResult;
    }
    else{
        // Check if modality wanted is compatible with Data
        if (m>=this->GetNumberModalities()){// modality wanted is out of bounds
            cout<< "Modality wanted is out of bounds"<<endl;
            return MaxResult;
        }
        // Everything has been checked so we look for the maximum
        float * Data_PTR=static_cast<float *>(this->GetDataImage()->data);
        int numel=this->GetNumberElements();
        float * Data_PTRm=&Data_PTR[m*numel];

        for (int i=0; i<numel; i++,Data_PTRm++) {
            if((*Data_PTRm)>MaxResult){ // update of the maximum
                MaxResult=(*Data_PTRm);
            }
        }
        //cout << "the max is "<<MaxResult<<endl;
        return MaxResult;
    }
}

// Returns the min of modality m in data image after checking it can be found
float TreeEM::GetMinDataModal(int m){
    float MinResult=1E18;
    if (this->GetDataImage()==NULL) { // no data image attributed in the tree
        cout<< "No data attributed to the tree, tree not valid"<< endl;
        return MinResult;
    }
    else{
        // Check if modality wanted is compatible with Data
        if (m>=this->GetNumberModalities()){// modality wanted is out of bounds
            cout<< "Modality wanted is out of bounds"<<endl;
            return MinResult;
        }
        // Everything has been checked so we look for the maximum
        float * Data_PTR=static_cast<float *>(this->GetDataImage()->data);
        int numel=this->GetNumberElements();
        float * Data_PTRm=&Data_PTR[m*numel];

        for (int i=0; i<numel; i++,Data_PTRm++) {
            if((*Data_PTRm)<MinResult){ // update of the maximum
                MinResult=(*Data_PTRm);
            }
        }
        //cout<<"the min is "<<MinResult<<endl;
        return MinResult;
    }
}

// Returns the max of modality m in data image after checking it can be found
float TreeEM::GetMaxDataMaskedModal(int m){
    float MaxResult=-1E18;
    if (this->GetDataImage()==NULL) { // no data image attributed in the tree
        cout<< "No data attributed to the tree, tree not valid"<< endl;
        return MaxResult;
    }
    if (this->GetMask()==NULL) {
        cout <<"No mask to apply the normalisation on the masked data"<<endl;
        return this->GetMaxDataModal(m);
    }
    else{
        // Check if modality wanted is compatible with Data
        if (m>=this->GetNumberModalities()){// modality wanted is out of bounds
            cout<< "Modality wanted is out of bounds"<<endl;
            return MaxResult;
        }
        // Everything has been checked so we look for the maximum
        float * Data_PTR=static_cast<float *>(this->GetDataImage()->data);
        bool * Mask_PTR=static_cast<bool *>(this->GetMask()->data);
        int numel=this->GetNumberElements();
        float * Data_PTRm=&Data_PTR[m*numel];
        
        for (int i=0; i<numel; i++,Data_PTRm++,Mask_PTR++) {
            if((*Data_PTRm)>MaxResult && *Mask_PTR>0){ // update of the maximum
                MaxResult=(*Data_PTRm);
            }
        }
        //cout << "the max is "<<MaxResult<<endl;
        return MaxResult;
    }
}

// Returns the min of modality m in data image after checking it can be found
float TreeEM::GetMinDataMaskedModal(int m){
    float MinResult=1E18;
    if (this->GetDataImage()==NULL) { // no data image attributed in the tree
        cout<< "No data attributed to the tree, tree not valid"<< endl;
        return MinResult;
    }
    if (this->GetMask()==NULL) {
        cout <<"No mask to apply the normalisation on the masked data"<<endl;
        return this->GetMaxDataModal(m);
    }
    else{
        // Check if modality wanted is compatible with Data
        if (m>=this->GetNumberModalities()){// modality wanted is out of bounds
            cout<< "Modality wanted is out of bounds"<<endl;
            return MinResult;
        }
        // Everything has been checked so we look for the maximum
        float * Data_PTR=static_cast<float *>(this->GetDataImage()->data);
        bool * Mask_PTR=static_cast<bool *>(this->GetMask()->data);
        int numel=this->GetNumberElements();
        float * Data_PTRm=&Data_PTR[m*numel];
        
        for (int i=0; i<numel; i++,Data_PTRm++,Mask_PTR++) {
            if((*Data_PTRm)<MinResult && *Mask_PTR>0){ // update of the maximum
                MinResult=(*Data_PTRm);
            }
        }
        //cout<<"the min is "<<MinResult<<endl;
        return MinResult;
    }
}




// According to value in NormResp, give the extremum in the corresponding data relative to threshold of classification
float * TreeEM::GetExtremaDataSeg(int ExtremumType, float threshold){
    // by default the threshold to consider for the classification is 0.5. Might be lowered.
    int numbmodal=this->GetNumberModalities();
    float * NormRespToCheck_PTR=this->GetNormResp();
    float * DataCorrectedToConsider=this->GetDataBFCorrected();
    int numelmasked=this->GetNumberMaskedElements();
    // initialisation of the result float array
    float * ExtremaResult=new float [numbmodal];
    float tmpExtr=0;
    switch (ExtremumType) {
        case 1: {// Looking at maximum
            for (int m=0; m<numbmodal; m++) {
                tmpExtr=-1E18;
                float * DataCorrectedToConsider_PTR=&DataCorrectedToConsider[m*numelmasked];
                NormRespToCheck_PTR=this->GetNormResp();
                for (int i=0; i<numelmasked; i++,NormRespToCheck_PTR++,DataCorrectedToConsider_PTR++) {
                    if(*NormRespToCheck_PTR>0.5){
                        tmpExtr=*DataCorrectedToConsider_PTR>tmpExtr?*DataCorrectedToConsider_PTR:tmpExtr;
                    }
                }
                ExtremaResult[m]=tmpExtr;
            }
        }
            break;
        case -1 : {// finding minimum
            for (int m=0; m<numbmodal; m++) {
                tmpExtr=1E18;
                float * DataCorrectedToConsider_PTR=&DataCorrectedToConsider[m*numelmasked];
                NormRespToCheck_PTR=this->GetNormResp();
                for (int i=0; i<numelmasked; i++,NormRespToCheck_PTR++,DataCorrectedToConsider_PTR++) {
                    if(*NormRespToCheck_PTR>0.5){
                        tmpExtr=*DataCorrectedToConsider_PTR<tmpExtr?*DataCorrectedToConsider_PTR:tmpExtr;
                    }
                }
                ExtremaResult[m]=tmpExtr;
            }
        }
            break;
        default:
            break;
    }
    
    return ExtremaResult;
}

// Copy the data of modality m according to the mask in a float array and returns the pointer to the beginning
float * TreeEM::GetDataModalMasked(int m){
    if (this->GetDataImage()==NULL) { // no data image attributed in the tree
        cout<< "No data attributed to the tree, tree not valid"<< endl;
        return NULL;
    }
    else{
        // Check if modality wanted is compatible with Data
        if (m>=this->GetNumberModalities()){// modality wanted is out of bounds
            cout<< "Modality wanted is out of bounds"<<endl;
            return NULL;
        }
        int numel=this->GetNumberElements();
        float * Data_PTR=static_cast<float *>(this->GetDataImage()->data);
        float * Data_PTRm=&Data_PTR[m*numel];
        float * DataMaskedModal=new float[numel];//{0};
        for (int i=0; i<numel; i++) {
            DataMaskedModal[i]=0;
        }
        float * DataMaskedModal_PTR=DataMaskedModal;
        int * L2S_PTR=this->GetL2S();
        for (int i=0; i<numel; i++,L2S_PTR++,Data_PTRm++,DataMaskedModal_PTR++) {
            if (*L2S_PTR>=0) {
                *DataMaskedModal_PTR=*Data_PTRm;
            }
        }
        return DataMaskedModal;
    }
}

// Return the number of 3D voxels considered in the image (no nvox since a 4D image is used in case of multimodality)
int TreeEM::GetNumberElements(){
    if (this->GetDataImage()==NULL){
        cout<<"No image to look at"<<endl;
        return 0;
    }
    //cout<< this->GetDataImage()->nx<<endl;
    return this->GetDataImage()->nx*this->GetDataImage()->ny*this->GetDataImage()->nz;
}

// Returns the number of channels used in data image
int TreeEM::GetNumberModalities(){
    if (this->GetDataImage()==NULL){
        cout<<"No image to look at"<<endl;
        return 0;
    }
    return this->GetDataImage()->nu*this->GetDataImage()->nt;
}

// Returns the number of elements considered as active under the mask;
int TreeEM::GetNumberMaskedElements(){
    if(this->GetParent()==NULL){
        if(this->NumberMaskedElements==0){
            this->SetNumberMaskedElements(this->MakeNumberMaskedElements());
        }
        return this->NumberMaskedElements;
    }
    else{
        return this->GetParent()->GetNumberMaskedElements();
    }
}

// Calculate and return the number of active/masked elements in the process
int TreeEM::MakeNumberMaskedElements(){
    int numel=this->GetDataImage()->nx*this->GetDataImage()->ny*this->GetDataImage()->nz;
    if(this->GetMask()==NULL || this->GetMask()->datatype!=DT_BINARY){
        //cout<<"Mask is NULL or not Binary "<<this->GetNumberElements()<<endl;
        if (this->GetMask()!=NULL && this->GetMask()->datatype!=DT_BINARY) {
            cout<<"Mask is not binary "<< this->GetMask()<<endl;
        }
        return this->GetNumberElements();
    }
    else{

        //cout<<"Mask is correct and binary"<<endl;
        int CountMaskedVoxels=0;
        bool * MaskPointer=static_cast<bool *>(this->GetMask()->data);
        for (int i=0; i<numel; i++) {
            if (MaskPointer[i]>0) {
                CountMaskedVoxels++;
            }
        }
        return CountMaskedVoxels;
    }
}

int * TreeEM::GetL2S(){
    if(this->GetMask()==this->GetMaskDirect()){
        if (this->L2S==NULL) {
            this->MakeL2S();
        }
        return this->L2S;
    }
    else{ // we are at a place where L2S should be NULL and we get it from the parent
        //cout<<"It must be a child"<<endl;
        if (this->L2S!=NULL) {
            delete [] this->L2S;
            this->L2S=NULL;
        }
        return this->GetParent()->GetL2S();
    }
}

// Create and set in the Tree the L2S integer pointer that makes the correspondance between the index in the image and the index in the restricted masked array considered
void TreeEM::MakeL2S(){
    if(this->GetMask()==this->GetMaskDirect()){
//        cout<<"we are at the basis level"<<endl;
        if (this->L2S!=NULL) {
            delete [] this->L2S;
        }
        int numel=this->GetNumberElements();
        this->L2S= new int [numel];
        if(this->GetMask()!=NULL && this->GetMask()->datatype==DT_BINARY){
            /* The compatibility between the dimensions of DataImage and MaskImage has to be checked when setting the MaskImage pointer beforehand*/
            bool * Maskptr = static_cast<bool *> (this->GetMask()->data);
            bool * Maskptrtmp = Maskptr;
            int * L2S_PTR = this->GetL2S();
            Maskptrtmp = Maskptr;
            int tempindex=0;


            for (int i=0; i<numel; i++,Maskptrtmp++,L2S_PTR++) {
                if ((*Maskptrtmp)>0) {
                    (*L2S_PTR)=tempindex;
                    tempindex++;

                }
                else{
                    (*L2S_PTR)=-1;
                }
            }
        }
        else {
            if(this->GetMask()==NULL){
                cout<< "No mask used : all active"<<endl;
            }
            else{
                cout<< "Mask not binary : all active" << endl;
            }
            int * L2S_PTR = this->L2S;
            int numel=this->GetNumberElements();
            for (int i=0; i<numel; i++,L2S_PTR++) {

                (*L2S_PTR)=i;
            }
        }
    }
    else{
        if(this->L2S!=NULL){
            delete [] this->L2S;
            this->L2S=NULL;
        }
    }
}

// Returns the pointer to the stored integer array that converts the masked indices to the global image ones.
int * TreeEM::GetS2L(){
    if (this->GetMask()==this->GetMaskDirect()) { // we are at the level where S2L must be calculated
        // if the pointer to the Mask is NULL, it means that the mask is the image itself and the full image must be considered
        if (this->S2L==NULL) {
            this->MakeS2L();
        }
        return this->S2L;

    }
    else{// S2L must be NULL and we get S2L from the parent
        if (this->S2L!=NULL) {
            delete [] S2L;
            this->S2L=NULL;
        }
        return this->GetParent()->GetS2L();
    }
}

// Determines and set at the root the ShortToLong indices correspond. Of size numelmasked it gives the corresponding 3D global image index
void TreeEM::MakeS2L(){
    if (this->GetMask()==this->GetMaskDirect()) { // we are at the level where S2L must be calculated
        // if the pointer to the Mask is NULL, it means that the mask is the image itself and the full image must be considered
        if(this->GetMask()!=NULL && this->GetMask()->datatype==DT_BINARY){
            bool * Maskptr = static_cast<bool *> (this->GetMask()->data);
            bool * Maskptrtmp = Maskptr;
            int numelmasked=this->GetNumberMaskedElements();

            // reinitialise S2L
            if(this->S2L!=NULL){
                delete [] this->S2L;
            }
            this->S2L= new int[numelmasked];
            int * S2L_PTR = (int *)(this->S2L);
            Maskptrtmp = Maskptr;
            int tempindex=0;
            int numel=this->GetNumberElements();
            for (int i=0; i<numel; i++) {
                if ((*Maskptrtmp)>0) {
                    S2L_PTR[tempindex]=i;
                    tempindex++;
                }
                Maskptrtmp++;
            }
        }
        else {
            printf("the datatype is not binary, all the voxels are considered as active");
            // reinitialise S2L
            if(this->S2L!=NULL){
                delete [] this->S2L;
            }
            int numelmasked=this->GetNumberMaskedElements();
            this->S2L= new int[numelmasked];
            int * S2L_PTR=this->S2L;
            int numel=this->GetNumberElements();
            for(int i=0;i<numel;i++, S2L_PTR++){
                (*S2L_PTR)=i;
            }
        }
    }
    else{
        if(this->S2L!=NULL){
            delete [] this->S2L;
            this->S2L=NULL;
        }
    }
}

// Returns the pointer to the Hard segmentation as established in MakeHardSeg and stored at root
int * TreeEM::GetHardSeg(){
    if (this->GetMask()==this->GetMaskDirect() && this->IsRoot()) { // we are at the level where HardSeg must be calculated
        // if the pointer to the Mask is NULL, it means that the mask is the image itself and the full image must be considered
        if (this->HardSeg==NULL) {
            this->MakeHardSeg();
        }
        return this->HardSeg;

    }
    else{// HardSeg must be NULL and we get HardSeg from the parent
        if (this->HardSeg!=NULL) {
            delete [] HardSeg;
            this->HardSeg=NULL;
        }
        return this->GetParent()->GetHardSeg();
    }
}

int * TreeEM::MakeHardSegCombined(){
    int * HardSegCombinedResult=NULL;
    if (this->GetMask()==this->GetMaskDirect() && this->IsRoot()) { // we are at the level where HardSeg can be calculated
        // if the pointer to the Mask is NULL, it means that the mask is the image itself and the full image must be considered
        int numelmasked=this->GetNumberMaskedElements();
        HardSegCombinedResult=new int[numelmasked];
        int * HardSeg_PTR=HardSegCombinedResult;
        vector<float*> NormRespChildrenVector;
//        float * NormRespOutliers=NULL;
        int numbchild=0;
//        int FlagOutliersToUse=this->GetFlagOutliers();
        if (this->GetFlagOutliers()<3){
            numbchild=this->GetNumberChildren();
            for(int c=0;c<numbchild;c++){
                NormRespChildrenVector.push_back(this->GetChild(c)->GetNormResp());
            }
        }
        else if (this->GetFlagOutliers()==3){
            numbchild=this->GetNumberGeneralClasses();
            for(int c=0;c<numbchild;c++){
                NormRespChildrenVector.push_back(this->GetNodeInlier()->GetChild(c)->GetNormResp());
                NormRespChildrenVector.push_back(this->GetNodeOutlier()->GetChild(c)->GetNormResp());
            }
        }
        
        // find for each active voxel index of max NormResp and put it in result of HardSeg;
        int sizeNormRespVector=NormRespChildrenVector.size();
        for(int i=0;i<numelmasked;i++,HardSeg_PTR++){
            int maxInd=0;
            float maxNormResp=0;
            for(int c=0;c<numbchild;c++){
                if (sizeNormRespVector==numbchild) {
                    if (NormRespChildrenVector[c][i]>maxNormResp){
                        maxInd=c;
                        maxNormResp=NormRespChildrenVector[c][i];
                    }
                }
                else if (sizeNormRespVector==2*numbchild) {
                    float SumTest=NormRespChildrenVector[2*c][i]+NormRespChildrenVector[2*c+1][i];
                    if (SumTest>maxNormResp){
                        maxInd=c;
                        maxNormResp=SumTest;
                    }
                }

            }
            *HardSeg_PTR=maxInd;
        }
    }
        else{
            HardSegCombinedResult=this->GetParent()->MakeHardSegCombined();
        }

        return HardSegCombinedResult;
}


// Calculates and set the Hard segmentation at root. Gives the hard segmentation of the first separating level
void TreeEM::MakeHardSeg(){
    if (this->GetMask()==this->GetMaskDirect() && this->IsRoot()) { // we are at the level where HardSeg must be calculated
        // if the pointer to the Mask is NULL, it means that the mask is the image itself and the full image must be considered
            int numelmasked=this->GetNumberMaskedElements();

            // reinitialise HardSeg
            if(this->HardSeg!=NULL){
                delete [] this->HardSeg;
            }
            this->HardSeg= new int[numelmasked];
            int * HardSeg_PTR = (int *)(this->HardSeg);
           vector<float*> NormRespChildrenVector;
        float * NormRespOutliers=NULL;
        int numbchild=0;
        int FlagOutliersToUse=this->GetFlagOutliers();
        if (this->GetFlagOutliers()<3){
           numbchild=this->GetNumberChildren();
            for(int c=0;c<numbchild;c++){
                NormRespChildrenVector.push_back(this->GetChild(c)->GetNormResp());
            }
        }
        else if (this->GetFlagOutliers()==3){
            numbchild=this->GetNumberGeneralClasses();
            for(int c=0;c<numbchild;c++){
                NormRespChildrenVector.push_back(this->GetNodeInlier()->GetChild(c)->GetNormResp());
                NormRespOutliers=this->GetNodeOutlier()->GetNormResp();
            }
        }

           // find for each active voxel index of max NormResp and put it in result of HardSeg;
           for(int i=0;i<numelmasked;i++,HardSeg_PTR++){
               int maxInd=0;
               float maxNormResp=0;
               for(int c=0;c<numbchild;c++){
                   if (NormRespChildrenVector[c][i]>maxNormResp){
                       maxInd=c;
                       maxNormResp=NormRespChildrenVector[c][i];
                   }
               }
               if(FlagOutliersToUse<3){
               *HardSeg_PTR=maxInd;
               }
               else{ // Comparison with outlier segmentation. Classify as outlier if overall outlier NormSeg superior to MaxNormResp of inliers
                   if(NormRespOutliers[i]<maxNormResp){
                       *HardSeg_PTR=maxInd;
                   }
                   else{
                       *HardSeg_PTR=numbchild;
                   }
               }
           }
    }
    else{
        if(this->HardSeg!=NULL){
            delete [] this->HardSeg;
            this->HardSeg=NULL;
        }
    }
}

// Add to the leaves vector the leaves under the considered node or the node itself if it is a leaf.
void TreeEM::GetLeaves(vector<TreeEM*> & LeavesVector){
    if (this->GetNumberChildren()==0) {
        LeavesVector.push_back(this);
    }
    else{
        int numbchild=this->GetNumberChildren();
        for (int c=0; c<numbchild; c++) {
            this->GetChild(c)->GetLeaves(LeavesVector);
        }
    }
}

// Returns the vector of leaves corresponding to an anatomical class inlier and outlier at the same time
vector<TreeEM *> TreeEM::GetAllLeavesAnatomicalClass(int anatClass){
    vector<TreeEM *> LeavesAnatClassVector;
    if (anatClass>=this->GetNumberGeneralClasses()) {
        cout<< "anatomical class asked for does not exist"<<endl;
        return LeavesAnatClassVector;
    }
    vector<TreeEM *> AnatClasses=this->GetGeneralClassesVector();
    LeavesAnatClassVector=AnatClasses[anatClass]->GetAllLeaves();
    return LeavesAnatClassVector;
}

// Return the vector of nodes corresponding to Gaussian leaves of specific anatomical classes inlier and outliers
vector<TreeEM *> TreeEM::GetAllGaussianLeavesAnatomicalClass(int anatClass){
    vector<TreeEM *> LeavesGenGaussClassVector=GetAllLeavesAnatomicalClass(anatClass);
    vector<TreeEM *> LeavesOutGaussClassVector;
    if (this->GetFlagOutliers()==3 || this->GetFlagOutliers()==8) {
        LeavesOutGaussClassVector=this->GetNodeOutlier()->GetChild(anatClass)->GetAllGaussianLeaves();
    }
    int numboutGauss=LeavesOutGaussClassVector.size();
    for(int l=0;l<numboutGauss;l++){
        LeavesGenGaussClassVector.push_back(LeavesOutGaussClassVector[l]);
    }
    return LeavesGenGaussClassVector;
}

// Return the vector of all nodes that are leaves
vector<TreeEM *> TreeEM::GetAllLeaves(){
    vector<TreeEM *> LeavesVector;
    if(this->GetNumberChildren()==0){
        return LeavesVector;
    }
    else{
        int numbchild=this->GetNumberChildren();
        for (int c=0; c<numbchild; c++) {
            if (this->GetChild(c)->GetNumberChildren()==0) {
                LeavesVector.push_back(this->GetChild(c));
            }
            else {
                vector<TreeEM *> ChildLeaveVector=this->GetChild(c)->GetAllLeaves();
                int numbChildLeaves=ChildLeaveVector.size();
                for (int i=0; i<numbChildLeaves; i++) {
                    LeavesVector.push_back(ChildLeaveVector[i]);
                }
            }
        }
    }
    return LeavesVector;
}

// Return the vector of all nodes that are leaves
vector<TreeEM *> TreeEM::GetAllNodes(){
    vector<TreeEM *> NodesVector;
    if(this->GetNumberChildren()==0){
        return NodesVector;
    }
    else{
        int numbchild=this->GetNumberChildren();
        for (int c=0; c<numbchild; c++) {
            NodesVector.push_back(this->GetChild(c));
                vector<TreeEM *> ChildNodesVector=this->GetChild(c)->GetAllNodes();
            int numbChildNodes=ChildNodesVector.size();
                for (int i=0; i<numbChildNodes; i++) {
                    NodesVector.push_back(ChildNodesVector[i]);
                }
            }
        }
    return NodesVector;
}

// Return the vector of all leaves that follow a Gaussian distribution
vector<TreeEM *> TreeEM::GetAllGaussianLeaves(){
    vector<TreeEM *> LeavesVector;
    if(this->GetNumberChildren()==0){
        return LeavesVector;
    }
    else{
        int numbchild=this->GetNumberChildren();
        for (int c=0; c<numbchild; c++) {
            if (this->GetChild(c)->GetNumberChildren()==0 && this->GetChild(c)->GetDistributionType()==1) {
                LeavesVector.push_back(this->GetChild(c));
            }
            else {
                vector<TreeEM *> ChildLeaveVector=this->GetChild(c)->GetAllGaussianLeaves();
                int numbChildLeaves=ChildLeaveVector.size();
                for (int i=0; i<numbChildLeaves; i++) {
                    LeavesVector.push_back(ChildLeaveVector[i]);
                }
            }
        }
    }
    return LeavesVector;
}

// Return the number of leaves under a certain node. 0 if itself a leave
int TreeEM::GetNumberAllLeaves(){
    int numbAllLeaves=0;
    if (this->GetNumberChildren()==0) {
        numbAllLeaves=0;
        return numbAllLeaves;
    }
    else{
        int numbchild=this->GetNumberChildren();
        for (int c=0; c<numbchild; c++) {
            if (this->GetChild(c)->GetNumberChildren()==0) {
                numbAllLeaves+=1;
            }
            else {
                numbAllLeaves=numbAllLeaves+this->GetChild(c)->GetNumberAllLeaves();
            }
        }
    }
    return numbAllLeaves;
}

// Return the number of free parameters in the model
int TreeEM::GetNumberFreeParameters(){
    int numbFreeParameters=0;
    int numbmodal=this->GetNumberModalities();
    if (this->GetNumberChildren()==0) {
        switch (this->GetDistributionType()) {
        case 0: // Should not be possible that a leaf is considered as a mixture but taken care of anyway
            return numbFreeParameters;
            break;
        case 2: // case uniform is considered, then numbFreeParameters =0
                return numbFreeParameters;
                break;

        default: // Gaussian case is default for leaves
            numbFreeParameters=(int)numbmodal+((numbmodal+1)*numbmodal)/2;
            break;
        }
    }
    else{
        int numbchild=this->GetNumberChildren();
        for (int c=0; c<numbchild; c++) {
            numbFreeParameters=numbFreeParameters+this->GetChild(c)->GetNumberFreeParameters(); // Recursive part
        }
    }
    return numbFreeParameters;
}

////Returns the value of log priors on covariance matrix
//float TreeEM::MakeInverseWishart()

//Returns the value of the loglikelihood for the considered model
float TreeEM::GetLogLikelihood(){
    int numelmasked=this->GetNumberMaskedElements();
    PrecisionTYPE LL=0;
    float * Distribution=new float[numelmasked];
    float * Distribution_PTR=Distribution;
    for(int i=0;i<numelmasked;i++){
        Distribution[i]=0;
    }
    this->MakeWeightedDist(Distribution);
    int CountNeedChangeValue=0;


    for (int i=0; i<numelmasked; i++,Distribution_PTR++) {
        if (*Distribution_PTR>=1E-6) {
            LL+=(PrecisionTYPE)log(*Distribution_PTR);
        }
        else {
            CountNeedChangeValue++;
            if (this->GetFlagOutliers()!=4) {
                LL+=(PrecisionTYPE)log(1E-6);
            }
            
        }
    }
    if(Distribution!=NULL){
        delete [] Distribution;
        Distribution = NULL;
    }
    return (float)LL;
}

float TreeEM::GetLogLikelihoodCEM(int c){
    int numelmasked=this->GetNumberMaskedElements();
    PrecisionTYPE LL=0;
    float * Distribution=new float[numelmasked];
    float * Distribution_PTR=Distribution;
    for(int i=0;i<numelmasked;i++){
        Distribution[i]=0;
    }
    this->MakeWeightedDist(Distribution);
    int CountNeedChangeValue=0;
    int * HardSeg_PTR=this->GetHardSeg();

    for (int i=0; i<numelmasked; i++,Distribution_PTR++,HardSeg_PTR++) {
        if (*Distribution_PTR>=1E-6 && *HardSeg_PTR==c) {
            LL+=(PrecisionTYPE)log(*Distribution_PTR);
        }
        else if(*HardSeg_PTR==c) {
            CountNeedChangeValue++;
            LL+=(PrecisionTYPE)logf(1E-6);
        }
    }
    if(Distribution!=NULL){
        delete [] Distribution;
        Distribution = NULL;
    }
    return (float)LL;
}

// Return the vector of nodes that are leaves directly under considered node
vector<TreeEM *> TreeEM::GetAllDirectLeaves(){
    vector<TreeEM *> DirectLeavesVector;
    int numbchild=this->GetNumberChildren();
    for (int c=0; c<numbchild; c++) {
        if (this->GetChild(c)->GetNumberChildren()==0) {
            DirectLeavesVector.push_back(this->GetChild(c));
        }
    }
    return DirectLeavesVector;
}

// Return the number of children that are leaves
int TreeEM::GetNumberDirectLeaves(){
    int numbDirectLeaves=0;
    int numbchild=this->GetNumberChildren();
    for (int c=0; c<numbchild; c++) {
        if (this->GetChild(c)->GetNumberChildren()==0) {
            numbDirectLeaves++;
        }
    }
    return numbDirectLeaves;
}

// Modify numbLeaves to assess the number of leaves under specific node. This time if itself a leave, number is set to 1.
void TreeEM::GetNumberLeaves(int & numbleaves){

    if (this->GetNumberChildren()==0) {
        numbleaves++;
    }
    else{
        int numbchild=this->GetNumberChildren();
        for (int c=0; c<numbchild; c++) {
            this->GetChild(c)->GetNumberLeaves(numbleaves);
        }
    }
}

// Returns in a PrecisionTYPE array the shifted values according to the dimension of the shift and its direction
float * TreeEM::GetDataShifted(int dim,int dir){
    // First make sure that the input values are ok or change them accordingly
    dir=dir>0?1:-1;
    dim=dim>2?2:dim;
    dim=dim<0?0:dim;

    // Initialisation of the needed values
//    int * Dimensions=new int[3];
//    int Dimensions[3];
//    Dimensions[0]=this->GetDataImage()->nx;
//    Dimensions[1]=this->GetDataImage()->ny;
//    Dimensions[2]=this->GetDataImage()->nz;
//    int * Shift=new int[3];
    int Shift[3];
    Shift[0]=1;
    Shift[1]=this->GetDataImage()->nx;
    Shift[2]=this->GetDataImage()->nx*this->GetDataImage()->ny;
    int numbx=this->GetDataImage()->nx;
    int numby=this->GetDataImage()->ny;
    int numbz=this->GetDataImage()->nz;
    int indexShift=Shift[dim]*dir;
    int numbmodal=this->GetNumberModalities();
    int numel=this->GetNumberElements();
    int nvox=this->GetDataImage()->nvox;
    int newIndex=0;
    int oldIndex=0;
    // Allocation of memory for shifted matrix
    float * DataShifted= new float[nvox];//{0};
    for (int i=0; i<nvox; i++) {
        DataShifted[i]=0;
    }
    float * DataPointed= static_cast<float*>(this->GetDataImage()->data);
    for (int m=0; m<numbmodal; m++) {
        for (int i=0; i<numbx; i++) {
            for (int j=0; j<numby; j++) {
                for (int k=0; k<numbz; k++) {
                    newIndex=i+j*Shift[1]+k*Shift[2]+indexShift;
                    oldIndex=i+j*Shift[1]+k*Shift[2];
                    if (newIndex>0 && newIndex<numel) {
                        DataShifted[m*numel+newIndex]=DataPointed[m*numel+oldIndex];
                    }
                }
            }
        }
    }
    // Memory cleaning
//    delete [] Dimensions;
//    Dimensions=NULL;
//    delete [] Shift;
//    Shift=NULL;
    return DataShifted;
}

// Returns in a float array of size nvox = numel * numbmodal the corrected data when considered shifted along dim and according to dir. Needs to take into account that DataBFCorrected is stored in a space related to numel masked...
float * TreeEM::GetDataShiftedCorrected(int dim, int dir){
    // First make sure that the input values are ok or change them accordingly
    if(dir!=0){
    dir=dir>0?1:-1;
    }
    dim=dim>2?2:dim;
    dim=dim<0?0:dim;

    // Initialisation of the needed values
//    int Dimensions[3];
//    Dimensions[0]=this->GetDataImage()->nx;
//    Dimensions[1]=this->GetDataImage()->ny;
//    Dimensions[2]=this->GetDataImage()->nz;
    int Shift[3];
    Shift[0]=1;
    Shift[1]=this->GetDataImage()->nx;
    Shift[2]=this->GetDataImage()->nx*this->GetDataImage()->ny;
    int numbx=this->GetDataImage()->nx;
    int numby=this->GetDataImage()->ny;
    int numbz=this->GetDataImage()->nz;
    int indexShift=Shift[dim]*dir;
    int numbmodal=this->GetNumberModalities();
    int numel=this->GetNumberElements();
    int nvox=this->GetDataImage()->nvox;
    int numelmasked=this->GetNumberMaskedElements();
    int newIndex=0;
    int oldIndex=0;
    // Allocation of memory for shifted matrix
    float * DataShifted= new float[nvox];//{0};
    int * L2S_PTR=this->GetL2S();
    float * DataPointedNC=this->GetDataBFCorrected();
    float * DataPointed = new float[numel*numbmodal];
    for(int m=0;m<numbmodal;m++){
        L2S_PTR=this->GetL2S();
        float * DataPointedNC_PTR = &DataPointedNC[m*numelmasked];
        for (int i=0; i<numel; i++,L2S_PTR++) {

                DataPointed[i+m*numel]=0;
                if(*L2S_PTR>=0){
                    DataPointed[i+m*numel]=*DataPointedNC_PTR;
                    DataPointedNC_PTR++;
                }
                DataShifted[i+m*numel]=0;
        }
    }

//    nifti_image * Shift0=SavePartialResult(DataPointed, this->GetDataImage(), "/Users/Carole/Documents/PhD/TestShift0");
//    nifti_image_write(Shift0);
//    nifti_image_free(Shift0);
//    Shift0=NULL;


//    float * DataPointed= static_cast<float*>(this->GetDataImage()->data);
    for (int m=0; m<numbmodal; m++) {
        for (int i=0; i<numbx; i++) {
            for (int j=0; j<numby; j++) {
                for (int k=0; k<numbz; k++) {
                    newIndex=i+j*Shift[1]+k*Shift[2]+indexShift;
                    oldIndex=i+j*Shift[1]+k*Shift[2];
                    if (newIndex>0 && newIndex<numel) {
                        DataShifted[m*numel+newIndex]=DataPointed[m*numel+oldIndex];
                    }
                }
            }
        }
    }
//    delete [] Dimensions;
//    Dimensions=NULL;
//    delete [] Shift;
//    Shift = NULL;
    delete [] DataPointed;
    DataPointed=NULL;
    return DataShifted;
}

// Returns in a float array, of size numbmodal, the Correlation of the data according to a certain dimension calculated as the mean of the correlations when shifted by 1 voxel in both + and - directions. The data corrected is used for that purpose
float * TreeEM::GetDataCorrelation(int dim){
    int numbmodal=this->GetNumberModalities();
    int numel=this->GetNumberElements();
    float * CorrelationResult=new float[numbmodal];//{0};
    for (int i=0; i<numbmodal; i++) {
        CorrelationResult[i]=0;
    }
    PrecisionTYPE Mean[MaxNumbModal];//{0};
    for (int i=0; i<MaxNumbModal; i++) {
        Mean[i]=0;
    }
    PrecisionTYPE Var[MaxNumbModal];//{0};
    for (int i=0; i<MaxNumbModal; i++) {
        Var[i]=0;
    }
    PrecisionTYPE MeanShifted[MaxNumbModal];//{0};
    for (int i=0; i<MaxNumbModal; i++) {
        MeanShifted[i]=0;
    }
    PrecisionTYPE VarShifted[MaxNumbModal];//{0};
    for (int i=0; i<MaxNumbModal; i++) {
        VarShifted[i]=0;
    }
    dim=dim<0?0:dim;
    dim=dim>2?2:dim;
    int numelmasked=this->GetNumberMaskedElements();

    // Handling the + part same afterwards for the - part
//    float * DataShifted=this->GetDataShifted(dim, 1);
    float * DataShifted=this->GetDataShiftedCorrected(dim,1);
//    nifti_image * ShiftPlus=SavePartialResult(DataShifted, this->GetDataImage(), "/Users/Carole/Documents/PhD/TestShiftPlus");
//    nifti_image_write(ShiftPlus);
//    nifti_image_free(ShiftPlus);
//    ShiftPlus=NULL;
    float * Data=this->GetDataBFCorrected();
//    float * Data=static_cast<float*>(this->GetDataImage()->data);
    float * DataShifted_PTR=DataShifted;
    float * Data_PTR=Data;
    int* L2S_PTR=this->GetL2S();


    // First calculate the mean and the standard deviation for shifted and not shifted
    for (int m=0; m<numbmodal; m++) {
        DataShifted_PTR=&DataShifted[m*numel];
        Data_PTR=&Data[m*numelmasked];
        L2S_PTR=this->GetL2S();
        float tmpMeanShifted=0;
        float tmpMean=0;
        float tmpStd=0;
        float tmpStdShifted=0;
        for (int i=0; i<numel; i++,DataShifted_PTR++,L2S_PTR++) {
            if (*L2S_PTR>=0) {
                tmpMeanShifted+=*DataShifted_PTR;
                tmpMean+=*Data_PTR;
                tmpStdShifted+=*DataShifted_PTR*(*DataShifted_PTR);
                tmpStd+=*Data_PTR*(*Data_PTR);
                Data_PTR++;
            }
        }
        MeanShifted[m]=tmpMeanShifted/numelmasked;
        Mean[m]=tmpMean/numelmasked;
//        Var[m]=powf(tmpStd/numelmasked-Mean[m]*Mean[m],0.5);
//        Var[m]=powf(tmpStd/(numelmasked-1)-(float)(numelmasked+1)/(float)(numelmasked-1)*Mean[m]*Mean[m], 0.5);
        Var[m]=tmpStd/numelmasked-Mean[m]*Mean[m];
//        VarShifted[m]=powf(tmpStdShifted/numelmasked-MeanShifted[m]*MeanShifted[m], 0.5);
//        VarShifted[m]=powf(tmpStdShifted/(numelmasked-1)-(float)(numelmasked+1)/(float)(numelmasked-1)*MeanShifted[m]*MeanShifted[m], 0.5);
        VarShifted[m]=tmpStdShifted/numelmasked-MeanShifted[m]*MeanShifted[m];
    }

    // Then calculate the correlation

    for (int m=0; m<numbmodal; m++) {
        L2S_PTR=this->GetL2S();
        DataShifted_PTR=&DataShifted[m*numel];
        Data_PTR=&Data[m*numelmasked];
        float tmpCorrelation=0;
        for (int i=0; i<numel; i++,DataShifted_PTR++,L2S_PTR++) {
            if (*L2S_PTR>=0) {
//                tmpCorrelation+=((*Data_PTR)-Mean[m])*((*DataShifted_PTR)-MeanShifted[m]);
                tmpCorrelation+=*Data_PTR*(*DataShifted_PTR);
                Data_PTR++;
            }
        }
//        CorrelationResult[m]=tmpCorrelation/(StdShifted[m]*Std[m]);
        tmpCorrelation=tmpCorrelation-numelmasked*Mean[m]*MeanShifted[m];
        CorrelationResult[m]=tmpCorrelation/sqrt(fabs(VarShifted[m])*fabs(Var[m]));
    }

    delete [] DataShifted;
    DataShifted=NULL;
    DataShifted_PTR=NULL;

//    float * DataShiftedMoins=this->GetDataShifted(dim, -1);
    float * DataShiftedMoins=this->GetDataShiftedCorrected(dim,-1);
    L2S_PTR=this->GetL2S();
//    nifti_image * ShiftMoins=SavePartialResult(DataShiftedMoins, this->GetDataImage(), "/Users/Carole/Documents/PhD/TestShiftMoins");
//    nifti_image_write(ShiftMoins);
//    nifti_image_free(ShiftMoins);
//    ShiftMoins=NULL;
    float * DataShiftedMoins_PTR=DataShiftedMoins;

    // Then calculate the mean and the standard deviation for shifted in other direction
    for (int m=0; m<numbmodal; m++) {
        DataShiftedMoins_PTR=&DataShiftedMoins[m*numel];
        L2S_PTR=this->GetL2S();
        float tmpMeanShiftedMoins=0;
        float tmpStdShiftedMoins=0;
        int CountActive=0;
        for (int i=0; i<numel; i++,DataShiftedMoins_PTR++,L2S_PTR++) {
            if (*L2S_PTR>=0) {
                tmpMeanShiftedMoins+=*DataShiftedMoins_PTR;
                CountActive++;
                tmpStdShiftedMoins+=*DataShiftedMoins_PTR*(*DataShiftedMoins_PTR);
            }
        }
//        cout<< "Numelmasked is "<<CountActive<<endl;
        MeanShifted[m]=tmpMeanShiftedMoins/(float)numelmasked;
//        StdShifted[m]=powf(tmpStdShifted/numelmasked-MeanShifted[m]*MeanShifted[m], 0.5);
//        VarShifted[m]=powf(tmpStdShifted/(numelmasked-1)-(float)(numelmasked+1)/(float)(numelmasked-1)*MeanShifted[m]*MeanShifted[m], 0.5);
        VarShifted[m]=tmpStdShiftedMoins/(float)numelmasked-MeanShifted[m]*MeanShifted[m];
    }
//float test=0;
//float test2=0;
    // Then calculate the correlation
    for (int m=0; m<numbmodal; m++) {
        DataShiftedMoins_PTR=&DataShiftedMoins[m*numel];
        Data_PTR=&Data[m*numelmasked];
        L2S_PTR=this->GetL2S();
        float tmpCorrelationMoins=0;
//        float tmpCorrelationtest=0;
        for (int i=0; i<numel; i++,DataShiftedMoins_PTR++,L2S_PTR++) {
            if (*L2S_PTR>=0) {
//                tmpCorrelationMoins+=((*Data_PTR)-Mean[m])*((*DataShiftedMoins_PTR)-MeanShifted[m]);
                tmpCorrelationMoins+=*Data_PTR*(*DataShiftedMoins_PTR);
                Data_PTR++;
            }
        }
//        CorrelationResult[m]=(float)(CorrelationResult[m]+tmpCorrelation/(VarShifted[m]*Var[m]))/(2*(numelmasked-1));
//        CorrelationResult[m]=(float)(CorrelationResult[m]+tmpCorrelation/(VarShifted[m]*Var[m]))/(2*(numelmasked));
//        test=tmpCorrelationMoins/sqrt(Var[m]*VarShifted[m]);
        tmpCorrelationMoins=tmpCorrelationMoins-numelmasked*Mean[m]*MeanShifted[m];
//        test2=test2/sqrt(VarShifted[m]*Var[m]);
        CorrelationResult[m]=(float)(CorrelationResult[m]+tmpCorrelationMoins/sqrt(fabs(VarShifted[m])*fabs(Var[m])))/(2.0*(float)numelmasked);
    }
    delete [] DataShiftedMoins;
    DataShiftedMoins=NULL;
    DataShiftedMoins_PTR=NULL;
    for(int m=0;m<numbmodal;m++){
        if(fabs(CorrelationResult[m])>1){
            cout<<"Pb with the calculation of the correlation in dim "<<dim<<endl;
        }
    }
    return CorrelationResult;
}

// Return the data correlation in one dimension between two modalities defined in modalchoice. If the two modalities are the same, gives the correlation in the + direction. If modalities are different, no need to shift the data corrected, the correlation is simply calculated between the two modalities
float TreeEM::GetDataCorrelationMod(int dim,int * modalChoice){
    int numbmodal=this->GetNumberModalities();
//    cout<< modalChoice[0]<<modalChoice[1];
    // Check if the choice of modalities are available
    for(int i =0;i<2;i++){
        if(modalChoice[i]>=numbmodal || modalChoice[i]<0){
            cout<<"Pb in the modalities to correlate with "<<modalChoice[0]<<" and "<<modalChoice[1]<<endl;
            return 0;
        }
    }

    int numel=this->GetNumberElements();
    float CorrelationResult=0;
    float Mean=0;
    float Var=0;
    float MeanShifted=0;
    float VarShifted=0;

    dim=dim<0?0:dim;
    dim=dim>2?2:dim;
    int numelmasked=this->GetNumberMaskedElements();

    // Handling the + part same afterwards for the - part
//    float * DataShifted=this->GetDataShifted(dim, 1);
    float * DataShifted;
    if(modalChoice[0]==modalChoice[1]){ // Case where a shifted correlation is performed since same modality is used.
     DataShifted=this->GetDataShiftedCorrected(dim,1);
    }
    else{
         DataShifted=this->GetDataShiftedCorrected(dim,0);
    }
    float * Data=this->GetDataBFCorrected();
//    float * Data=static_cast<float*>(this->GetDataImage()->data);
    float * DataShifted_PTR=DataShifted;
    float * Data_PTR=Data;
    int* L2S_PTR=this->GetL2S();


    // First calculate the mean and the standard deviation for shifted and not shifted
        DataShifted_PTR=&DataShifted[modalChoice[1]*numel];
        Data_PTR=&Data[modalChoice[0]*numelmasked];
        L2S_PTR=this->GetL2S();
        float tmpMeanShifted=0;
        float tmpMean=0;
        float tmpStd=0;
        float tmpStdShifted=0;
        for (int i=0; i<numel; i++,DataShifted_PTR++,L2S_PTR++) {
            if (*L2S_PTR>=0) {
                tmpMeanShifted+=*DataShifted_PTR;
                tmpMean+=*Data_PTR;
                tmpStdShifted+=*DataShifted_PTR*(*DataShifted_PTR);
                tmpStd+=*Data_PTR*(*Data_PTR);
                Data_PTR++;
            }
        }
        MeanShifted=tmpMeanShifted/numelmasked;
        Mean=tmpMean/numelmasked;
//        Var[m]=powf(tmpStd/numelmasked-Mean[m]*Mean[m],0.5);
//        Var[m]=powf(tmpStd/(numelmasked-1)-(float)(numelmasked+1)/(float)(numelmasked-1)*Mean[m]*Mean[m], 0.5);
        Var=tmpStd/numelmasked-Mean*Mean;
//        VarShifted[m]=powf(tmpStdShifted/numelmasked-MeanShifted[m]*MeanShifted[m], 0.5);
//        VarShifted[m]=powf(tmpStdShifted/(numelmasked-1)-(float)(numelmasked+1)/(float)(numelmasked-1)*MeanShifted[m]*MeanShifted[m], 0.5);
        VarShifted=tmpStdShifted/numelmasked-MeanShifted*MeanShifted;


    // Then calculate the correlation


        L2S_PTR=this->GetL2S();
        DataShifted_PTR=&DataShifted[modalChoice[1]*numel];
        Data_PTR=&Data[modalChoice[0]*numelmasked];
        float tmpCorrelation=0;
        for (int i=0; i<numel; i++,DataShifted_PTR++,L2S_PTR++) {
            if (*L2S_PTR>=0) {
//                tmpCorrelation+=((*Data_PTR)-Mean[m])*((*DataShifted_PTR)-MeanShifted[m]);
                tmpCorrelation+=*Data_PTR*(*DataShifted_PTR);
                Data_PTR++;
            }
        }
//        CorrelationResult[m]=tmpCorrelation/(StdShifted[m]*Std[m]);
        tmpCorrelation=tmpCorrelation-numelmasked*Mean*MeanShifted;
        CorrelationResult=tmpCorrelation/sqrt(VarShifted*Var);


    delete [] DataShifted;
    DataShifted=NULL;
    DataShifted_PTR=NULL;

//    float * DataShiftedMoins=this->GetDataShifted(dim, -1);
    float * DataShiftedMoins;
    if(modalChoice[0]==modalChoice[1]){
     DataShiftedMoins=this->GetDataShiftedCorrected(dim,-1);
    }
    else{
         DataShiftedMoins=this->GetDataShiftedCorrected(dim,0);
    }
    L2S_PTR=this->GetL2S();
    float * DataShiftedMoins_PTR=DataShiftedMoins;

    // Then calculate the mean and the standard deviation for shifted in other direction
        DataShiftedMoins_PTR=&DataShiftedMoins[modalChoice[1]*numel];
        L2S_PTR=this->GetL2S();
        float tmpMeanShiftedMoins=0;
        float tmpStdShiftedMoins=0;
        int CountActive=0;
        for (int i=0; i<numel; i++,DataShiftedMoins_PTR++,L2S_PTR++) {
            if (*L2S_PTR>=0) {
                tmpMeanShiftedMoins+=*DataShiftedMoins_PTR;
                CountActive++;
                tmpStdShiftedMoins+=*DataShiftedMoins_PTR*(*DataShiftedMoins_PTR);
            }
        }
//        cout<< "Numelmasked is "<<CountActive<<endl;
        MeanShifted=tmpMeanShiftedMoins/(float)numelmasked;
//        StdShifted[m]=powf(tmpStdShifted/numelmasked-MeanShifted[m]*MeanShifted[m], 0.5);
//        VarShifted[m]=powf(tmpStdShifted/(numelmasked-1)-(float)(numelmasked+1)/(float)(numelmasked-1)*MeanShifted[m]*MeanShifted[m], 0.5);
        VarShifted=tmpStdShiftedMoins/(float)numelmasked-MeanShifted*MeanShifted;
//float test=0;
//float test2=0;
    // Then calculate the correlation
        DataShiftedMoins_PTR=&DataShiftedMoins[modalChoice[1]*numel];
        Data_PTR=&Data[modalChoice[0]*numelmasked];
        L2S_PTR=this->GetL2S();
        float tmpCorrelationMoins=0;
//        float tmpCorrelationtest=0;
        for (int i=0; i<numel; i++,DataShiftedMoins_PTR++,L2S_PTR++) {
            if (*L2S_PTR>=0) {
//                tmpCorrelationMoins+=((*Data_PTR)-Mean[m])*((*DataShiftedMoins_PTR)-MeanShifted[m]);
                tmpCorrelationMoins+=*Data_PTR*(*DataShiftedMoins_PTR);
                Data_PTR++;
            }
        }

//        CorrelationResult[m]=(float)(CorrelationResult[m]+tmpCorrelation/(VarShifted[m]*Var[m]))/(2*(numelmasked-1));
//        CorrelationResult[m]=(float)(CorrelationResult[m]+tmpCorrelation/(VarShifted[m]*Var[m]))/(2*(numelmasked));
//        test=tmpCorrelationMoins/sqrt(Var[m]*VarShifted[m]);
        tmpCorrelationMoins=tmpCorrelationMoins-numelmasked*Mean*MeanShifted;
//        test2=test2/sqrt(VarShifted[m]*Var[m]);
        CorrelationResult=(float)(CorrelationResult+tmpCorrelationMoins/sqrt(VarShifted*Var))/(2.0*(float)numelmasked);

    delete [] DataShiftedMoins;
    DataShiftedMoins=NULL;
    DataShiftedMoins_PTR=NULL;
        if(fabs(CorrelationResult)>1){
            cout<<"Pb with the calculation of the correlation in dim "<<dim<<" "<<CorrelationResult<<endl;
        }
    return CorrelationResult;
}

// Returns the independence factor for dimension dim;
float TreeEM::MakeIndFactor(int dim){
    dim=dim>2?2:dim;
    dim=dim<0?0:dim;
    int numbmodal=this->GetNumberModalities();
    float * CorrelationDim=this->GetDataCorrelation(dim);
    float CorrMean=0;
    for (int m=0; m<numbmodal; m++) {
        CorrMean+=CorrelationDim[m];
    }
    CorrMean/=numbmodal;
//    cout<< CorrMean <<"corr mean for dim "<<dim<<endl;
//    float IndFactorDim_pre=0.9394/powf(-2*logf(2)/logf(CorrMean), 0.5);
    float IndFactorDim=powf(-logf(fabs(CorrMean))*2/M_PI, 0.5);
    delete [] CorrelationDim;
    CorrelationDim=NULL;
    return IndFactorDim;
}

// Returns the value of the indFactor using the determinant of the correlation matrix between modalities according to the dimension specified in dim
float TreeEM::MakeIndFactorMod(int dim){
    dim=dim>2?2:dim;
    dim=dim<0?0:dim;
    int numbModal=this->GetNumberModalities();
    int numbmodalSq=numbModal*numbModal;
    // Initialisation of the corr matrix
    float * CorrMatrix=new float[numbmodalSq];
    for(int i=0;i<numbModal;i++){
        for(int j=0;j<numbModal;j++){
            if(i==j){
                CorrMatrix[i+j*numbModal]=1;
            }
            else{
                CorrMatrix[i+j*numbModal]=0;
            }
        }
    }
//    int * modalChoice=new int[2];
    int modalChoice[2];
    for(int m1=0;m1<numbModal;m1++){
        for(int m2=m1;m2<numbModal;m2++){
            modalChoice[0]=m1;
            modalChoice[1]=m2;
//            cout<< modalChoice[0]<<modalChoice[1];
            CorrMatrix[m1+m2*numbModal]=this->GetDataCorrelationMod(dim,modalChoice);
            CorrMatrix[m2+m1*numbModal]=CorrMatrix[m1+m2*numbModal];
        }
    }
//    delete [] modalChoice;
//    modalChoice=NULL;
    float DetCorr= determinant(CorrMatrix,numbModal);
    DetCorr=1;
    for(int m=0;m<numbModal;m++){
        DetCorr*=CorrMatrix[m+m*numbModal];
    }
//    cout<< DetCorr << "det for dimension "<<dim<<endl;
    float IndFactorDim=0.9394/powf(-2*logf(2)/logf(fabs(DetCorr)), 0.5);
    return IndFactorDim;

}

// Return the global IndFactorTotMod as product of the partial dimensional IndFactorMod
float TreeEM::MakeIndFactorTotMod(){
    float IF0=this->MakeIndFactorMod(0);
    float IF1=this->MakeIndFactorMod(1);
    float IF2=this->MakeIndFactorMod(2);
    cout<<"the partial IF are "<< IF0<<" "<<IF1<<" "<<IF2<<endl;
    return IF0*IF1*IF2;
//    return this->MakeIndFactorMod(0)*this->MakeIndFactorMod(1)*MakeIndFactorMod(2);
}

// Return the global independence factor as the product of the partial dimensional independence factor as described in Groves
float TreeEM::MakeIndFactorTot(){
    float IF0=this->MakeIndFactor(0);
    float IF1=this->MakeIndFactor(1);
    float IF2=this->MakeIndFactor(2);
    cout<<"the partial IF are "<< IF0<<" "<<IF1<<" "<<IF2<<endl;
    return IF0*IF1*IF2;
//    return this->MakeIndFactor(0)*this->MakeIndFactor(1)*MakeIndFactor(2);
}

// Return the independence factor stored at root or determines and set it if not available.
float TreeEM::GetIndFactor(){
    if(this->GetParent()==NULL){
        if(this->IndFactor<=0){
            this->SetIndFactor(this->MakeIndFactorTot());
            return this->IndFactor;
        }
        else return this->IndFactor;
    }
    else{
        return this->GetParent()->GetIndFactor();
    }
}

float * TreeEM::GetDPChildren(){
    if(!this->IsRoot()){
        return this->GetParent()->GetDPChildren();
    }
    else{
        return this->DPChildren;
    }
}

float * TreeEM::GetDPChildrenDirect(){
    return this->DPChildren;
}

bool TreeEM::GetFlagDistClassInd(){
    if(!this->IsRoot()){
       return this->GetParent()->GetFlagDistClassInd();
    }
    else{
        return this->FlagDistClassInd;
    }
}

// Returns the type of outlier model used and stored at the root
int TreeEM::GetFlagOutliers(){
    if(!this->IsRoot()){
        return this->GetParent()->GetFlagOutliers();
    }
    else{
        return this->FlagOutliers;
    }
}

// Return the time of uniform type changing stored at root and set according to segment_param
int TreeEM::GetFlagUTC(){
    if(!this->IsRoot()){
        return this->GetParent()->GetFlagUTC();
    }
    else{
        return this->FlagUTC;
    }
}

// Returns a float array of size the number of elements in the image (in order to save it as a nifti image afterwards) with the needed values
float * TreeEM::GetPartialResult(PartialResultType ResultType, SEG_PARAMETERS * segment_param){
    if (!this->IsTreeStructureValid()) {
        cout<<"Tree not valid : will not get any partial result"<<endl;
        return NULL;
    }
    if (ResultType>5 || ResultType<0) {
        cout<<"Not proper result type wanted"<<endl;
        return NULL;
    }
    int numel=this->GetNumberElements();
    int numelmasked=this->GetNumberMaskedElements();
    float * PartialResult=new float[numel];//{0};
    for (int i=0; i<numel; i++) {
        PartialResult[i]=0;
    }
    float * PartialResult_PTR=PartialResult;
    float * tmp=new float[numelmasked];
    float * tmp_PTR=tmp;
    for(int i=0;i<numelmasked;i++){
        tmp[i]=0;
    }
    int * L2S_PTR=this->GetL2S();
    float * tmp2;

    // Get the pointer to the data to put in the PartialResult array;
    switch (ResultType) {
    case DISTRIBUTION:
        this->MakeWeightedDist(tmp);
        break;
    case NONNORMRESP:
        this->MakeNonNormWeightedSum(tmp,segment_param);
        break;
    case NORMRESP:
        tmp2=this->GetNormResp();
        for(int i=0;i<numelmasked;i++,tmp2++){
            tmp[i]=*tmp2;
        }
        break;
    default:
        tmp2=static_cast<float *>(this->GetDataImage()->data);
        for(int i=0;i<numel;i++,tmp2++,L2S_PTR++){
            if(*L2S_PTR>=0){
                *tmp_PTR=*tmp2;
                tmp_PTR++;
            }
        }
        tmp_PTR=tmp;
        break;
    }
    L2S_PTR=this->GetL2S();
    // Copying the corresponding data at the correct position in the PartialResult array
    for (int i=0; i<numel; i++,PartialResult_PTR++,L2S_PTR++) {
        if (*L2S_PTR>=0) {
            *PartialResult_PTR=*tmp_PTR;
            tmp_PTR++;
        }
    }
    if(tmp!=NULL){
        delete [] tmp;
        tmp=NULL;
    }
    return PartialResult;
}

//float * TreeEM::GetBFCorrectionDirect(){
//    return this->BFCorrection;
//}

// Returns the direct pointer to the bias field coefficient : NULL if node considered is not the root.
float * TreeEM::GetBFCoeffsDirect(){
    return this->BFCoeffs;
}

// Idem as before but for the corrected data
float * TreeEM::GetDataBFCorrectedDirect(){
    return this->DataBFCorrected;
}

//float * TreeEM::GetBFCorrection(){
//    if (this->WhatTypeOfTreeComponent()!=ROOT && this->GetBFCorrectionDirect()==NULL) {
//        return this->GetParent()->GetBFCorrection();
//    }
//    else{
//        // if not yet calculated when needed, then create the right Basis Functions
//        if (BFFlag && this->BFCorrection==NULL) {
//            this->BFCorrection=this->MakeBFCorrection();
//        }
//        return this->BFCorrection;
//    }
//}

// Returns the pointer to the data corrected stored at root
float * TreeEM::GetDataBFCorrected(){
    if (this->WhatTypeOfTreeComponent()!=ROOT && this->GetDataBFCorrectedDirect()==NULL) {
        return this->GetParent()->GetDataBFCorrected();
    }
    else{
        // if not yet calculated when needed, then create the right Basis Functions
        if (this->DataBFCorrected==NULL) {
            float * DataCorrectedToSet=this->MakeDataBFCorrected();
            this->SetDataBFCorrected(DataCorrectedToSet);
            if(DataCorrectedToSet!=NULL){
                delete [] DataCorrectedToSet;
                DataCorrectedToSet=NULL;
            }
        }
        return this->DataBFCorrected;
    }
}

// Returns the pointer to the bias coefficients stored at the root
float * TreeEM::GetBFCoeffs(){
    if ((this->WhatTypeOfTreeComponent()!=ROOT && this->WhatTypeOfTreeComponent()!=INITIALNODE) && !this->AreBFCoeffsDirectUseable()) {
        return this->GetParent()->GetBFCoeffs();
    }
    else {
        //        if (BFFlag && !this->AreBFCoeffsDirectUseable()) {
        ////            if (this->GetBFCorrection()==NULL) {
        ////                this->BFCorrection=this->MakeBFCorrection();
        ////            }
        //            this->BFCoeffs=this->MakeFinalBFCoeffsChildren();
        //        }
        return this->BFCoeffs;
    }
}

/************** SET FUNCTIONS WITH NEEDED CHECKS *********************/

// Setting the parent and resetting everything else afterwards
void TreeEM::SetParent(TreeEM *ParentInput){
    // First check if the ParentInput is a valid tree (Method to write, not done so far)
    // then change the pointer of parent
    this->Parent=ParentInput;
    // Reinitialise memory allocation and set everything back to zero
    this->ReinitialiseTree();
}


void TreeEM::ReinitialiseTree(){
    this->SetMask(this->GetMask());
    int numbchild=this->GetNumberChildren();
    for (int c=0; c<numbchild; c++) {
        this->GetChild(c)->ReinitialiseTree();
    }
}

// Setting of children when given a vector of nodes
void TreeEM::SetChildren(vector<TreeEM *> ChildrenInput){
    // First check if everything is right with each of the offered tree in the vector
    int numbInput=ChildrenInput.size();
    for (int c=0; c<numbInput; c++) { /*if valid, each in ChildrenInput is added to the Children vector of this
                                                  WARNING : here the previous possible existing children are not suppressed see */
        if (ChildrenInput[c]->IsTreeValid(1) && ChildrenInput[c]->GetParent()==this) {
            this->Children.push_back(ChildrenInput[c]);
        }
    }
    if (numbInput==0) { // if there is no children as input, be sure that this is still in mode simple distribution
        if (this->GetNumberChildren()==0) {
            this->CreateAllocateAndInitializeParameters(1);
        }
    }
    else{
        this->MakeParametersMixture();
    }
}

// Add Child if valid to current vector of Children
void TreeEM::AddChild(TreeEM * ChildAdded){
    if (ChildAdded->GetParent()==this) { // check that the Child added is set for the right parent
        this->Children.push_back(ChildAdded);
        if (!this->IsNumbChildOKWithDistType()) {
            this->MakeParametersMixture();
        }
    }
    else{
        cout<<"The added child does not correspond to the right parent"<<endl;
    }
}

void TreeEM::ChangeData(nifti_image * DataInput){
    if (this->WhatTypeOfTreeComponent()!=ROOT&&this->WhatTypeOfTreeComponent()!=INITIALNODE) {
        cout<< "Data image can only be modified at root level and pointer is only stored there"<<endl;
        return;
    }
    else{ // the data can be modified since we are at Root level;
        if (this->GetDataDirect()!=NULL) {
            nifti_image_free(this->DataImage);
        }
        this->DataImage=DataInput;
        if(!IsDataFloat()){
            this->ConvertDataImageToFloat();
        }
    }
}

// Setting of data image to segment (Contains all modalities used)
void TreeEM::SetData(nifti_image * DataInput){
    // Check if the considered Tree on which applied is of type Root otherwise data cannot be changed nor modified
    if (this->WhatTypeOfTreeComponent()!=ROOT&&this->WhatTypeOfTreeComponent()!=INITIALNODE) {
        cout<< "Data image can only be modified at root level and pointer is only stored there"<<endl;
        return;
    }
    else{ // the data can be modified since we are at Root level;
        if (this->GetDataDirect()!=NULL) {
            nifti_image_free(this->DataImage);
        }
        this->DataImage=DataInput;
        if(!IsDataFloat()){
            this->ConvertDataImageToFloat();
        }
//        cout<< "Re give data input"<<endl;
//        if (!this->IsDataImageNormalised()) {
//            cout<< "We have to normalise Image"<<endl;
//            this->NormaliseDataImage();
//        }
//        cout<< "Image is already normalised" << endl;
        // if there was previously a mask, check if we can keep it
        if(this->GetMask()!=NULL){ // check on the dimensions
            if (this->GetMask()->nx!=DataInput->nx || this->GetMask()->ny!=DataInput->ny || this->GetMask()->nz!=DataInput->nz){ // Mask reput to NULL as default and so everything is reallocated as needed
                this->SetMask(NULL);
                this->ReinitialiseTree();
            }
            else { // in case of existing Mask, need to reinitialise the tree : needed mostly for the parameters structure in case the number of modalities has changed. Allows for keeping a similar structure but reinitialising and reallocating memory
                this->ReinitialiseTree();
            }
        }
    }
}

// Perform the normalisation of the image by first converting to float, then finding max and min according to if using only masked data or whole image, normalisation so that after log of the data, stays between 0 and 1.
void TreeEM::NormaliseDataImage(){
    if (this->GetDataImage()==NULL){
        cout<<"WARNING : there is no data to segment !"<<endl;
        return;
    }
    if (!this->IsDataFloat()) {
        this->ConvertDataImageToFloat();
    }
    int numbmodal=this->GetNumberModalities();
    int numel=this->GetNumberElements();
//    cout<<"Data type image"<<this->GetDataImage()->datatype<< endl;
    float * Data_PTR=static_cast<float *>(this->GetDataImage()->data);
    float * Data_PTRtmp=Data_PTR;
    for (int m=0; m<numbmodal; m++) {
        Data_PTRtmp=&Data_PTR[m*numel];
        float maxRes=1E18;
        float minRes=-1E18;
        if (NormMask) {
            maxRes=this->GetMaxDataMaskedModal(m);
            minRes=this->GetMinDataMaskedModal(m);
        }
        else{
            maxRes=this->GetMaxDataModal(m);
            minRes=this->GetMinDataModal(m);
        }
        if (maxRes==minRes) { // Case where all the values are equal in the image
            for (int i=0; i<numel; i++,Data_PTRtmp++) {
                (*Data_PTRtmp)=0;
            }
        }
        else{
            float MultiplicativeFactor=(expf(1.0f)-1.0f)/(maxRes-minRes);
            float AdditiveFactor=1.0f-MultiplicativeFactor*minRes;
            //cout<< MultiplicativeFactor << "and " <<AdditiveFactor << endl;
            int numel=this->GetNumberElements();
            for (int i=0; i<numel; i++,Data_PTRtmp++) {
                (*Data_PTRtmp)=MultiplicativeFactor*(*Data_PTRtmp)+AdditiveFactor;
                (*Data_PTRtmp)=logf((*Data_PTRtmp)); // Normally then between 0 and 1;
            }
        }
    }
    //cout<<this->GetMinDataModal(0)<<"and "<<this->GetMaxDataModal(0);
    return;
}


void TreeEM::NormaliseDataImageNonLog(){
    if (this->GetDataImage()==NULL){
        cout<<"WARNING : there is no data to segment !"<<endl;
        return;
    }
    if (!this->IsDataFloat()) {
        this->ConvertDataImageToFloat();
    }
    int numbmodal=this->GetNumberModalities();
    int numel=this->GetNumberElements();
    //    cout<<"Data type image"<<this->GetDataImage()->datatype<< endl;
    float * Data_PTR=static_cast<float *>(this->GetDataImage()->data);
    float * Data_PTRtmp=Data_PTR;
    for (int m=0; m<numbmodal; m++) {
        Data_PTRtmp=&Data_PTR[m*numel];
        float maxRes=1E18;
        float minRes=-1E186;
        if (NormMask) {
            maxRes=this->GetMaxDataMaskedModal(m);
            minRes=this->GetMinDataMaskedModal(m);
        }
        else{
            maxRes=this->GetMaxDataModal(m);
            minRes=this->GetMinDataModal(m);
        }
        if (maxRes==minRes) { // Case where all the values are equal in the image
            for (int i=0; i<numel; i++,Data_PTRtmp++) {
                (*Data_PTRtmp)=0;
            }
        }
        else{
            float MultiplicativeFactor=1.0/(maxRes-minRes);
            float AdditiveFactor=0.0-MultiplicativeFactor*minRes;
            //cout<< MultiplicativeFactor << "and " <<AdditiveFactor << endl;
            int numel=this->GetNumberElements();
            for (int i=0; i<numel; i++,Data_PTRtmp++) {
                (*Data_PTRtmp)=MultiplicativeFactor*(*Data_PTRtmp)+AdditiveFactor;
//                (*Data_PTRtmp)=logf((*Data_PTRtmp)); // Normally then between 0 and 1;
            }
        }
    }
    //cout<<this->GetMinDataModal(0)<<"and "<<this->GetMaxDataModal(0);
    return;
}


void TreeEM::NormaliseDataImageMasked(){
    if (this->GetDataImage()==NULL){
        cout<<"WARNING : there is no data to segment !"<<endl;
        return;
    }
    if (!this->IsDataFloat()) {
        this->ConvertDataImageToFloat();
    }
    if (this->GetMask()==NULL) {
        this->NormaliseDataImage();
        return;
    }
    int numbmodal=this->GetNumberModalities();
    int numel=this->GetNumberElements();
    //    cout<<"Data type image"<<this->GetDataImage()->datatype<< endl;
    float * Data_PTR=static_cast<float *>(this->GetDataImage()->data);
    float * Data_PTRtmp=Data_PTR;
    for (int m=0; m<numbmodal; m++) {
        Data_PTRtmp=&Data_PTR[m*numel];
        float maxRes=this->GetMaxDataMaskedModal(m);
        float minRes=this->GetMinDataMaskedModal(m);
        if (maxRes==minRes) { // Case where all the values are equal in the image
            for (int i=0; i<numel; i++,Data_PTRtmp++) {
                (*Data_PTRtmp)=0;
            }
        }
        else{
            float MultiplicativeFactor=(expf(1.0f)-1.0f)/(maxRes-minRes);
            float AdditiveFactor=1.0f-MultiplicativeFactor*minRes;
            //cout<< MultiplicativeFactor << "and " <<AdditiveFactor << endl;
            int numel=this->GetNumberElements();
            for (int i=0; i<numel; i++,Data_PTRtmp++) {
                (*Data_PTRtmp)=MultiplicativeFactor*(*Data_PTRtmp)+AdditiveFactor;
                (*Data_PTRtmp)=logf((*Data_PTRtmp)); // Normally then between 0 and 1;
            }
        }
    }
    //cout<<this->GetMinDataModal(0)<<"and "<<this->GetMaxDataModal(0);
    return;
}

// Modify the data so that the outliers according to a percentage threshold defined in quantMin and quantMax are set to the border value.
void TreeEM::QuantilizeDataImage(SEG_PARAMETERS * segment_param){
    // Check if there is Data to modify
    if(this->GetDataImage()==NULL){
        cout<<"No data to take care of"<<endl;
    }
    // Make image properly float
    if(!this->IsDataFloat()){
        this->ConvertDataImageToFloat();
    }
    // Look at values of the quantiles to choose as outliers limits
    float quantMin=segment_param->quantMin;
    float quantMax=segment_param->quantMax;
    quantMin=quantMin<=0?0:quantMin;
    quantMax=quantMax>=1?1:quantMax;
    if(quantMax<=quantMin){
        cout<<"quantiles not in right order therefore nothing done"<<endl;
        return;
    }
    // Copy Data image values to define quantiles values for each modality;
    int numbmodal=this->GetNumberModalities();
    int numel = this->GetNumberElements();
    int numelmasked=this->GetNumberMaskedElements();
    int IndQuantMin=(int)round(quantMin*numelmasked);
    IndQuantMin=IndQuantMin<=0?0:IndQuantMin;
    int IndQuantMax=(int)round(quantMax*numelmasked);
    IndQuantMax=IndQuantMax>=numelmasked-1?(numelmasked-1):IndQuantMax;

    for(int m=0;m<numbmodal;m++){
        float * DataToCopy=&static_cast<float*>(this->GetDataImage()->data)[m*numel];
        float * DataToCopy_PTR=DataToCopy;
        float * tmpCopyData=new float[numelmasked];
        float * tmpCopyData_PTR=tmpCopyData;
        int * L2S_PTR=this->GetL2S();
        for(int i=0;i<numel;i++,L2S_PTR++){
            if(*L2S_PTR>=0){
                *tmpCopyData_PTR=*DataToCopy_PTR;
                tmpCopyData_PTR++;
                DataToCopy_PTR++;
            }
        }
        // Sorting of the values in the image to consider
        if(IndQuantMin >0 || IndQuantMax < numelmasked -1){
//        quickSort(tmpCopyData,numelmasked);
            HeapSort(tmpCopyData, numelmasked-1);
        float ValueQuantMin=tmpCopyData[IndQuantMin];
        float ValueQuantMax=tmpCopyData[IndQuantMax];
        // Putting all values according to the quantiles chosen.
        L2S_PTR=this->GetL2S();
        for(int i=0;i<numel;i++,L2S_PTR++,DataToCopy++){
            if(*L2S_PTR>=0){
                *DataToCopy=*DataToCopy<=ValueQuantMin?ValueQuantMin:*DataToCopy;
                *DataToCopy=*DataToCopy>=ValueQuantMax?ValueQuantMax:*DataToCopy;
            }
        }
        }
        delete [] tmpCopyData;
        tmpCopyData=NULL;

    }


}

// Changing the data nifti image and converting it to floats
void TreeEM::ConvertDataImageToFloat(){
    if (this->GetDataImage()==NULL) {
        cout<<"WARNING : there is no data to convert !"<<endl;
        return;
    }
    if (this->IsDataFloat()) {
        cout<<"Data already of type float no need to change"<<endl;
        return;
    }


    cout<<"Image has to be converted"<<endl;
//    // First changing the values to have only 0 and 1
//    float * Data_PTR=static_cast<float *>(this->GetDataImage()->data); // consider that then data is float
//    int numbvox=this->GetDataImage()->nvox;

//    // Then changing datatype
//    this->GetDataImage()->datatype=DT_FLOAT;

//    // the initial array is saved and freeed
//    float *initialValue = new float[this->GetDataImage()->nvox];
//    float * initialValue_PTR=initialValue;
//    for (int i=0; i<numbvox; i++,initialValue_PTR++,Data_PTR++) {
//        *initialValue_PTR=(float)(*Data_PTR);
//    }

//    float *initialValue_tmp=initialValue;
//    //cout<<initialValue<<endl;
//    // the new array is allocated and then filled

//    free(this->GetDataImage()->data);
//    this->GetDataImage()->nbyper = sizeof(float);
//    this->GetDataImage()->data = (void *)calloc(this->GetDataImage()->nvox,sizeof(float));
//    float *dataPtr = static_cast<float *>(this->GetDataImage()->data);
//    for (int i=0; i<numbvox; i++, dataPtr++,initialValue_tmp++) {
//        (*dataPtr)=(float)(*initialValue_tmp);
//    }
//    delete [] initialValue;
    seg_changeDatatype<float>(this->GetDataImage());
//    float * TestImage=static_cast<float*>(this->GetDataImage()->data);
//    SaveTmpResult(TestImage,"/Users/Carole/Documents/PhD/TestImage3.nii.gz");
//    nifti_set_filenames(this->GetDataImage(),"/Users/Carole/Documents/PhD/TestImage2.nii.gz",0,0);
//    nifti_image_write(this->GetDataImage());
    //cout<<this->GetDataImage()->datatype<<endl;
}


void TreeEM::AdaptParametersToAffineTransform(float * LinearWeight, float *ConstWeight){
    if (LinearWeight !=NULL && ConstWeight!=NULL) {
    if (this->GetParameters()!=NULL) {
        if (this->GetDistributionType()!=2) {
            int numbchild=this->GetNumberChildren();
            for (int c=0; c<numbchild; c++) {
                this->GetChild(c)->AdaptParametersToAffineTransform(LinearWeight, ConstWeight);
            }
        }
        else{
            
//            Preparation of Parameters to adapt
            float * ParametersToAdapt=this->GetParametersValue();
            int SizeParameters=this->GetSizeParameters();
            int numbmodal=(int)(-1+sqrt(1+4*SizeParameters))/2;
            float * MeanAdapted=new float[numbmodal];
            float * VarianceAdapted=new float[numbmodal*numbmodal];
            for (int m1=0; m1<numbmodal; m1++) {
                MeanAdapted[m1]=ParametersToAdapt[m1];
                for(int m2=m1;m2<numbmodal;m2++){
                    VarianceAdapted[m1+m2*numbmodal]=ParametersToAdapt[numbmodal+m2];
                    VarianceAdapted[m2+m1*numbmodal]=VarianceAdapted[m1+m2*numbmodal];
                }
            }
////            Preparation of LinearWeight and ConstWeight if not already done by adding 0 at the end if not of good size;
//            int LWsize=LinearWeight.size();
//            int CWsize=ConstWeight.size();
//            for (int i=LWsize; i<numbmodal; i++) {
//                LinearWeight.push_back(0);
//            }
//            for (int i=CWsize; i<numbmodal; i++) {
//                ConstWeight.push_back(0);
//            }
//            float * LWArray=new float[numbmodal];
//            float * CWArray=new float[numbmodal];
//            for (int m=0; m<numbmodal; m++) {
//                LWArray[m]=LinearWeight[m];
//                CWArray[m]=ConstWeight[m];
//            }
//            Creation of final MeanAdapted and VarianceAdapted by ways of products
            for (int m=0; m<numbmodal; m++) {
                MeanAdapted[m]=ConstWeight[m]+MeanAdapted[m]*LinearWeight[m];
                VarianceAdapted[m+m*numbmodal]=LinearWeight[m]*LinearWeight[m]*VarianceAdapted[m+m*numbmodal];
            }
//            Setting the new value parameters in the parameters
            for (int m1=0; m1<numbmodal; m1++) {
                ParametersToAdapt[m1]=MeanAdapted[m1];
                for (int m2=0; m2<numbmodal; m2++) {
                    ParametersToAdapt[m1+m1+m2*numbmodal]=VarianceAdapted[m1+m2*numbmodal];
                }
            }
//            Clearing memory not needed
            if (MeanAdapted!=NULL) {
                delete [] MeanAdapted;
                MeanAdapted=NULL;
            }
            if (VarianceAdapted!=NULL) {
                delete [] VarianceAdapted;
                VarianceAdapted=NULL;
            }
//            if (LWArray!=NULL) {
//                delete [] LWArray;
//                LWArray=NULL;
//            }
//            if (CWArray!=NULL) {
//                delete [] CWArray;
//                CWArray=NULL;
//            }
        }
    }
    }
    return;
}


// After checking set the parameters to ParametersSet
void TreeEM::SetParameters(Parameters * ParametersToSet){

    // Check for compatibility between the Distribution Type and the Parameters and between the image and the Parameters
    if(!CheckForValidityOfParametersStructure(ParametersToSet)||!CheckForSizeParametersValidity( ParametersToSet)){
        cout<< "The structure of the parameters to set is not valid or the sizes are not compatible therefore creation and allocation of valid ones"<<endl;
        int DistType=0;
        if(ParametersToSet !=NULL){
            DistType=ParametersToSet->DistributionType;
            delete ParametersToSet;
            ParametersToSet=NULL;
        }
        int TypeTreeComponent=this->WhatTypeOfTreeComponent();
        ParametersToSet=new Parameters();
        switch (TypeTreeComponent) {
        case 0: // Case of a root
            this->CreateAllocateAndInitializeParameters(0);
            break;
            case 1: {// Case of a branch
                if (this->GetNumberChildren()<=1) { // case used when setting parameters on collapsing tree
                    if (DistType>0 && DistType<3) {
                        this->CreateAllocateAndInitializeParameters(DistType);
                    }
                    else{
                        this->CreateAllocateAndInitializeParameters(1);
                    }
                }
                else{
            this->CreateAllocateAndInitializeParameters(0);
                }
            }
            break;
                
            default: {// Case of a leaf;
                if (DistType>0 && DistType<3) {
                    this->CreateAllocateAndInitializeParameters(DistType);
                }
                else{
                    this->CreateAllocateAndInitializeParameters(1);
                }
            }
            break;
        }
    }
    else{
        // All checks are ok : Delete previous one and set new one instead;
        if(this->ParametersDistribution!=NULL){
            delete this->ParametersDistribution;
        }
        this->ParametersDistribution=new Parameters();
        this->ParametersDistribution->DistributionType=ParametersToSet->DistributionType;
        this->ParametersDistribution->SizeParameters=ParametersToSet->SizeParameters;
        if (ParametersToSet->SizeParameters==0) {
            this->ParametersDistribution->ValueParameters=NULL;
        }
        else{
        this->ParametersDistribution->ValueParameters=new float [this->ParametersDistribution->SizeParameters];//{0};
            int SizeParametersToUse=this->ParametersDistribution->SizeParameters;
        for (int i=0; i<SizeParametersToUse; i++) {
            this->ParametersDistribution->ValueParameters[i]=0;
        }
        int SP=this->ParametersDistribution->SizeParameters;
        for (int sp=0; sp<SP; sp++) {
            this->ParametersDistribution->ValueParameters[sp]=ParametersToSet->ValueParameters[sp];
        }
        }
        this->ParametersDistribution->PriorsCovFlag=ParametersToSet->PriorsCovFlag;
        if (ParametersToSet->PriorsCovFlag==1) { // Needed special PriorsCov if linked directly to diagonal
            int numbmodal=this->GetNumberModalities();
            int numbmodalSq=numbmodal*numbmodal;
            if (ParametersToSet->PriorsCov!=NULL) {
                this->ParametersDistribution->PriorsCov=new float[numbmodalSq];
                for (int i=0; i<numbmodalSq; i++) {
                    this->ParametersDistribution->PriorsCov[i]=ParametersToSet->PriorsCov[i];
                }
            }
        }
        if (ParametersToSet->PriorsMean!=NULL) {
            int numbmodal=this->GetNumberModalities();
            this->ParametersDistribution->PriorsMean=new float[numbmodal];
            for(int m=0;m<numbmodal;m++){
                this->ParametersDistribution->PriorsMean[m]=ParametersToSet->PriorsMean[m];
            }
        }
    }
    return;
}

// Transform the Tree to make it basic again Needed when beginning BF on new added modality for BuildTreeWithAddedModality
void TreeEM::MakeTreeBasic(){
    vector<TreeEM *> GeneralClasses=this->GetGeneralClassesVector();
    vector<TreeEM *> OutliersClasses=this->GetOutliersMainNodesVector();
    int numbgc=GeneralClasses.size();
    int numboc=OutliersClasses.size();
    for (int gc=0; gc<numbgc; gc++) {
        int numbchild=GeneralClasses[gc]->GetNumberChildren();
        for (int c=numbchild-1; c>=0; c--) { // delete all children of the corresponding General class
            delete GeneralClasses[gc]->GetChild(c);
            GeneralClasses[gc]->Children[c]=NULL;
        }
        GeneralClasses[gc]->Children.clear();
        // Modify Parameters to Gaussian distribution
        GeneralClasses[gc]->CreateAllocateAndInitializeParameters(1);
    }
    for (int oc=0; oc<numboc; oc++) {
        int numbchild=OutliersClasses[oc]->GetNumberChildren();
        for (int c=numbchild-1; c>=0; c--) { // delete all children of the corresponding General class
            delete OutliersClasses[oc]->GetChild(c);
            OutliersClasses[oc]->Children[c]=NULL;
        }
        OutliersClasses[oc]->Children.clear();
        // Modify Parameters to Gaussian distribution
        OutliersClasses[oc]->CreateAllocateAndInitializeParameters(2);
    }
    cout <<"Tree is now "<< this->IsBasicTree()<<endl;
}


// Transforms the Parameters into a mixture (needed when creating child for a leaf becoming a branch)
void TreeEM::MakeParametersMixture(){
    if (CheckForValidityOfParametersStructure()&& this->GetDistributionType()==0) {
        return;
    }
    if(this->ParametersDistribution!=NULL){
        if (this->GetParametersValue()!=NULL) {
            delete [] this->GetParametersValue();
            this->ParametersDistribution->ValueParameters=NULL;
        }
        if (this->GetPriorsCovMatrix()!=NULL) {
            delete [] this->GetPriorsCovMatrix();
            this->ParametersDistribution->PriorsCov=NULL;
        }
        if (this->GetPriorsMeanMatrix()!=NULL) {
            delete [] this->GetPriorsMeanMatrix();
            this->ParametersDistribution->PriorsMean=NULL;
        }
        this->ParametersDistribution->PriorsCovFlag=0;
        delete this->ParametersDistribution;
        this->ParametersDistribution=NULL;
    }
    this->CreateAllocateAndInitializeParameters(0);
}

// Setting the independence factor at root and determining it if needed.
void TreeEM::SetIndFactor(float IndFactorInput){
    if(this->GetParent()!=NULL){
        cout<<"Cannot change ind factor if not at root"<<endl;
        return;
    }
    if(IndFactorInput<=0){
        cout<<"IndFactor cannot be negative"<<endl;
        return;
    }
    else{
        this->IndFactor=IndFactorInput;
    }
}

// Set Mask to MaskImage after checking. For the moment : Mask can only be introduced at the root level and nowhere else
void TreeEM::SetMask(nifti_image *MaskImage){
    // First check if trying to set a mask at root or somewhere else
    if (this->GetParent()==NULL){
        cout<<"It is a root or an initial node"<<endl;
        // Then check for the dimension validity
        if (MaskImage!=NULL && (MaskImage->nx!=this->GetDataImage()->nx || MaskImage->ny!=this->GetDataImage()->ny ||MaskImage->nz!=this->GetDataImage()->nz) ) {
            cout<< "The dimensions between Mask and Image are not compatible"<<endl;
            this->SetMask(NULL);
            return;
        }

        // Set the pointer to Mask to MaskImage
        this->Mask=MaskImage;
        if (MaskImage!=NULL && this->GetMask()->datatype!=DT_BINARY) {
//            nifti_set_filenames(this->GetMask(),"/Users/Carole/Documents/PhD/Masktest.nii.gz",0,0);
//            nifti_image_write(this->GetMask());
            this->MakeMaskBinary();
//            nifti_set_filenames(this->GetMask(),"/Users/Carole/Documents/PhD/Masktest.nii.gz",0,0);
//            nifti_image_write(this->GetMask());
//            bool * MaskTest=static_cast<bool*>(this->GetMask()->data);
//            float * MaskToSave=new float[this->GetMask()->nvox];
//            int numel=this->GetMask()->nvox;
//            for(int i=0;i<numel;i++){
//                MaskToSave[i]=(float)MaskTest[i];
//            }
//            SaveTmpResult(MaskToSave,"/Users/Carole/Documents/PhD/Masktest2.nii.gz");

            cout<<"Binarisation performed "<<endl;
        }
        // Calculate S2L and L2S
        if (this->L2S!=NULL) {
            delete [] this->L2S;
            this->L2S=NULL;
        }
        this->MakeL2S();
        if(this->S2L!=NULL){
            delete [] this->S2L;
            this->S2L=NULL;
        }
        this->MakeS2L();
        this->SetNumberMaskedElements(this->MakeNumberMaskedElements());
        int numelmasked=this->GetNumberMaskedElements();
        //cout<< "the number of masked elements is "<<this->GetNumberMaskedElements()<<endl;
        // Allocate right amount of memory to Distribution, NonNormResp, NormResp
        //        if(this->GetDistribution()!=NULL){
        //            delete this->Distribution;
        //        }
        //        this->Distribution=new float[numelmasked];//{0};
        //        for (int i=0; i<numelmasked; i++) {
        //                    this->Distribution[i]=0;
        //                }
        //        if(this->NonNormResp!=NULL){
        //            delete this->NonNormResp;
        //        }
        //        this->NonNormResp=new float[numelmasked];//{0};
        //        for (int i=0; i<numelmasked; i++) {
        //                    this->NonNormResp[i]=0;
        //                }
        if(this->NormResp!=NULL){
            delete this->NormResp;
            this->NormResp=NULL;
        }
        if (this->GetFlagOutliers()==4) {
            this->NormResp=new float[2*numelmasked];//{0};
            for (int i=0; i<numelmasked; i++) {
                this->NormResp[i]=0;
                this->NormResp[i+numelmasked]=1;
            }
            
        }
        else{
        this->NormResp=new float[numelmasked];//{0};
        for (int i=0; i<numelmasked; i++) {
            this->NormResp[i]=0;
        }
        }
//        if(this->HardSeg!=NULL){
//            delete [] this->HardSeg;
//            this->HardSeg=NULL;
//        }
//        this->HardSeg=new int[numelmasked];
//        for(int i=0;i<numelmasked;i++){
//            this->HardSeg[i]=0;
//        }
        // Propagate Mask to children
        int numbchild=this->GetNumberChildren();
        for(int c=0;c<numbchild;c++){
            this->GetChild(c)->SetMask(MaskImage);
        }
        return;
    }
    else {
        //cout<<"Parent Not NULL and address Mask is"<< this->GetMask()<<endl;
        //        this->SetNumberMaskedElements(this->MakeNumberMaskedElements());
        int numelmasked=this->GetNumberMaskedElements();
        //cout<< "the number of masked elements is "<<this->GetNumberMaskedElements()<<endl;
        // Allocate right amount of memory to Distribution, NonNormResp, NormResp
        //        if(this->GetDistribution()!=NULL){
        //            delete this->Distribution;
        //        }
        //        this->Distribution=new float[numelmasked];//{0};
        //        for (int i=0; i<numelmasked; i++) {
        //                    this->Distribution[i]=0;
        //                }
        //        if(this->NonNormResp!=NULL){
        //            delete this->NonNormResp;
        //        }
        //        this->NonNormResp=new float[numelmasked];//{0};
        //        for (int i=0; i<numelmasked; i++) {
        //                    this->NonNormResp[i]=0;
        //                }
        if(this->NormResp!=NULL){
            delete [] this->NormResp;
        }
        this->NormResp=new float[numelmasked];//{0};
        for (int i=0; i<numelmasked; i++) {
            this->NormResp[i]=0;
        }

        // Ensuring that pointer to L2S and S2L and HardSeg are NULL if we are not at the node where the pointer to the Mask is stored
        if (this->L2S!=NULL) {
            delete [] this->L2S;
            this->L2S=NULL;
        }

        if(this->S2L!=NULL){
            delete [] this->S2L;
            this->S2L=NULL;
        }
//        if(this->HardSeg!=NULL){
//            delete [] this->HardSeg;
//            this->HardSeg=NULL;
//        }

        // Propagate memory allocation to children
        int numbchild=this->GetNumberChildren();
        for(int c=0;c<numbchild;c++){
            this->GetChild(c)->SetMask(MaskImage);
        }
    }
    return;
}

void TreeEM::SetNumberMaskedElements(int NumberMaskedElementsInput){
    if(this->GetParent()!=NULL){
        //        cout<<"Cannot set the number of masked elements at any other place than root"<<endl;
        return;
    }
    if(NumberMaskedElementsInput!=this->MakeNumberMaskedElements()){
        cout<<"Not appropriate Input for number masked elements"<<endl;
        return;
    }
    this->NumberMaskedElements=NumberMaskedElementsInput;
    return;
}

// change nifti_image of Mask so that it becomes binary
void TreeEM::MakeMaskBinary(){
    if (this->GetMask()==NULL){
        cout<< "No mask so nothing to binarise"<<endl;
        return;
    }
    if(this->GetMask()->datatype==DT_BINARY){
        cout<< "Already binarised"<<endl;
        return;
    }
    else{
        cout<<"Mask has to be binarised"<<endl;
//        // First changing the values to have only 0 and 1
//        float * Mask_PTR=static_cast<float *>(this->GetMask()->data); // consider that then data is float
//        float * Mask_PTRtmp=Mask_PTR;
//        int numel=this->GetNumberElements();
//        // if set as mask then it has been checked before that dimensions with dataimage are compatible
//        bool *initialValue = new bool[this->GetMask()->nvox];
//        bool *initialValue_PTR=initialValue;
//        for (int i=0; i<numel; i++,Mask_PTRtmp++,initialValue_PTR++) {
//            (*Mask_PTRtmp)=(*Mask_PTRtmp)>0?1:0;// Set to 1 if strictly positive, 0 otherwise
//            (*initialValue_PTR)=(bool)(*Mask_PTRtmp);

//        }
//        // Then changing datatype
//        this->GetMask()->datatype=DT_BINARY;

//        // the initial array is saved and freeed

//        initialValue_PTR=initialValue;
//        free(this->GetMask()->data);
//        this->GetMask()->nbyper = sizeof(bool);
//        this->GetMask()->data = (void *)calloc(this->GetMask()->nvox,sizeof(bool));
//        bool *dataPtr = static_cast<bool *>(this->GetMask()->data);
//        for (int i=0; i<numel; i++, dataPtr++,initialValue_PTR++) {
//            (*dataPtr)=(bool)(*initialValue_PTR);
//        }
//        delete [] initialValue;
//        cout<<this->GetMask()->datatype<<endl;
        seg_convert2binary(this->GetMask(),0.1);
    }

}

// Setting the Priors to PriorsInput first checking the validity of the dimension and datatype, deleting any previous set of the priors and making sure then they are of probability type
void TreeEM::SetPriors(nifti_image *PriorsInput){
    if (PriorsInput == NULL) {
        this->Priors=NULL;
        return;
    }
    else{
        bool ValidityPriors=(PriorsInput->nx==this->GetDataImage()->nx)&&(PriorsInput->ny==this->GetDataImage()->ny)&&(PriorsInput->nz==this->GetDataImage()->nz);
        if(ValidityPriors){
            if(this->Priors!=NULL){
//                delete [] this->Priors;
                nifti_image_free(this->Priors);
                this->Priors=NULL;
            }
            this->Priors=PriorsInput;
//            this->SaveTmpResult(static_cast<float *>(this->GetPriorsDirect()->data), "/Users/Carole/Documents/PhD/ISBI/TestStrange/SetPriors0.nii.gz");
            if((PriorsInput->datatype!=DT_FLOAT32)){
                this->MakePriorsFloat();
            }
//            this->SaveTmpResult(static_cast<float *>(this->GetPriorsDirect()->data), "/Users/Carole/Documents/PhD/ISBI/TestStrange/SetPriors1.nii.gz");
            this->MakePriorsProbabilityType();
        }
//        this->SaveTmpResult(static_cast<float *>(this->GetPriorsDirect()->data), "/Users/Carole/Documents/PhD/ISBI/TestStrange/SetPriors.nii.gz");
        return;
    }
}

// Setting the priors adapted, allocating the proper float array (size numel) and copying the values given in the input.
void TreeEM::SetPriorsAdapted(float * PriorsAdaptedInput){
    if (PriorsAdaptedInput == NULL) {
        this->PriorsAdapted=NULL;
        return;
    }
    else{
        int numel =this->GetNumberElements();
        if(this->GetPriorsAdapted()!=NULL){
            delete [] this->PriorsAdapted;
            this->PriorsAdapted=NULL;
        }
        this->PriorsAdapted=new float[numel];
        for(int i=0;i<numel;i++){
            this->PriorsAdapted[i]=PriorsAdaptedInput[i];
        }
        return;
    }
}

void TreeEM::SetPartPriorsAdapted(float * PartPriorsAdaptedInput){
    if (PartPriorsAdaptedInput == NULL) {
        if (this->GetPartPriorsAdaptedDirect()!=NULL) {
            delete [] this->PartPriorsAdapted;
            this->PartPriorsAdapted=NULL;
        }
        this->PartPriorsAdapted=NULL;
        return;
    }
    else{
        int numelmasked =this->GetNumberMaskedElements();
        if(this->GetPartPriorsAdaptedDirect()!=NULL){
            delete [] this->PartPriorsAdapted;
            this->PartPriorsAdapted=NULL;
        }
        this->PartPriorsAdapted=new float[numelmasked];
        for(int i=0;i<numelmasked;i++){
            this->PartPriorsAdapted[i]=PartPriorsAdaptedInput[i];
        }
        return;
    }
}

// Change the priors referred so that we only handle float datatype
void TreeEM::MakePriorsFloat(){
    if (this->GetPriors()==NULL) {
        cout<<"WARNING : there is no data to convert !"<<endl;
        return;
    }
    if (this->IsPriorsFloat()) {
        cout<<"Priors already of type float no need to change"<<endl;
        return;
    }


    cout<<"Priors has to be converted"<<endl;
//    // First changing the values to have only 0 and 1
//    float * Priors_PTR=static_cast<float *>(this->GetPriors()->data); // consider that then data is float
//    int numbvox=this->GetPriors()->nvox;

//    // Then changing datatype
//    this->GetPriors()->datatype=DT_FLOAT;

//    // the initial array is saved and freeed
//    float *initialValue = new float[numbvox];
//    float * initialValue_PTR=initialValue;
//    float maxValue=0;
//    for (int i=0; i<numbvox; i++,initialValue_PTR++,Priors_PTR++) {

//        *initialValue_PTR=(float)(*Priors_PTR);
////        cout<<*initialValue_PTR<<"  ";
//        if (*initialValue_PTR>maxValue){
//            maxValue=*initialValue_PTR;
//        }
//    }
//    float *initialValue_tmp=initialValue;
//    if(maxValue>0){
//    for(int i=0;i<numbvox;i++,initialValue_tmp++)
//        *initialValue_tmp/=maxValue;
//    }

//    initialValue_tmp=initialValue;
//    //cout<<initialValue<<endl;
//    // the new array is allocated and then filled

//    free(this->GetPriors()->data);
//    this->GetPriors()->nbyper = sizeof(float);
//    this->GetPriors()->data = (void *)calloc(this->GetPriors()->nvox,sizeof(float));
//    float *priorsPtr = static_cast<float *>(this->GetPriors()->data);
//    for (int i=0; i<numbvox; i++, priorsPtr++,initialValue_tmp++) {
//        (*priorsPtr)=(float)(*initialValue_tmp);
//    }
//    delete [] initialValue;
    seg_changeDatatype<float>(this->GetPriors());
    return;
//    string filenameOut="/Users/Carole/Documents/PhD/Phantom/PriorsModified";
//    nifti_set_filenames(this->GetPriors(), filenameOut.c_str(), 0, 0);
//    nifti_image_write(this->GetPriors());
    //cout<<this->GetPriors()->datatype<<endl;
}

// Replaces the values in Priors so that they are between 0 and 1 and can be used as probabilities by rescaling the dispersion of the values
void TreeEM::MakePriorsAdaptedProbabilityType(){
    if (this->GetPriorsAdapted()==NULL) {
        return;
    }
    float * Priors_PTR=this->GetPriorsAdapted();
    float * Priors_PTRtmp=Priors_PTR;
    // Initialisation of the maximal and minimal values
    float maxPriors=-1E32;
    float minPriors=1E32;
    int numel=this->GetNumberElements();
    // Determination of the value of the maximum and the minimum
    for (int i=0; i<numel; i++,Priors_PTRtmp++) {
        if ((*Priors_PTRtmp)>maxPriors) { // update of the maximum value
            maxPriors=(*Priors_PTRtmp);
        }
        if((*Priors_PTRtmp)<minPriors){ // update of the minimum value
            minPriors=(*Priors_PTRtmp);
        }
    }

    // reinitialisation of the pointer to the beginning of the Priors
    Priors_PTRtmp=Priors_PTR;
    // modification of the values
    if (minPriors==maxPriors) { // case (strange) where all the values are equal, then we put them all to 1
        for (int i=0; i<numel; i++,Priors_PTRtmp++) {
            (*Priors_PTRtmp)=1;
        }
    }
    else {// rescaling of the values
        if (minPriors<0) {
            minPriors=0;
        }
        // no rescaling if max priors below 1. Rescaling only if above
        if (maxPriors<1) {
            maxPriors=1;
        }
        for (int i=0;i<numel;i++,Priors_PTRtmp++){ // Putting all the values between 0 and 1
            if (*Priors_PTRtmp<0) {
                *Priors_PTRtmp=0;
            }
            (*Priors_PTRtmp)=(*Priors_PTRtmp-minPriors)/(maxPriors-minPriors);
        }
    }
//    string filenameOut="/Users/Carole/Documents/PhD/Phantom/PriorsModified";
//    nifti_set_filenames(this->GetPriors(), filenameOut.c_str(), 0, 0);
//    nifti_image_write(this->GetPriors());
}


// Replaces the values in Priors so that they are between 0 and 1 and can be used as probabilities by rescaling the dispersion of the values
void TreeEM::MakePriorsProbabilityType(){
    if (this->GetPriors()==NULL) {
        return;
    }
    float * Priors_PTR=static_cast<float *>(this->GetPriors()->data);
    float * Priors_PTRtmp=Priors_PTR;
    // Initialisation of the maximal and minimal values
    float maxPriors=-1E32;
    float minPriors=1E32;
    int numel=this->GetNumberElements();
    // Determination of the value of the maximum and the minimum
    for (int i=0; i<numel; i++,Priors_PTRtmp++) {
        if ((*Priors_PTRtmp)>maxPriors) { // update of the maximum value
            maxPriors=(*Priors_PTRtmp);
        }
        if((*Priors_PTRtmp)<minPriors){ // update of the minimum value
            minPriors=(*Priors_PTRtmp);
        }
    }


    // reinitialisation of the pointer to the beginning of the Priors
    Priors_PTRtmp=Priors_PTR;
    // modification of the values
    if (minPriors==maxPriors) { // case (strange) where all the values are equal, then we put them all to 1 NO !!! Can correspond to weight spatially constant put to be afterwards adapted !!!
//        for (int i=0; i<numel; i++,Priors_PTRtmp++) {
//            (*Priors_PTRtmp)=1;
//        }
    }
    else if(minPriors>0 && maxPriors<1){ // if the range is ok even if not completely occupied
        return;
    }
    else {// rescaling of the values
        //Change at 14 04 2014. Force threshold of 0 before considering scaling
        if (minPriors<0) {
            minPriors=0;
        }
        // no rescaling if max priors below 1. Rescaling only if above
        if (maxPriors<1 && maxPriors>0) {
            maxPriors=1;
        }
        for (int i=0;i<numel;i++,Priors_PTRtmp++){ // Putting all the values between 0 and 1
            if (*Priors_PTRtmp<0) {
                *Priors_PTRtmp=0;
            }

            (*Priors_PTRtmp)=(*Priors_PTRtmp-minPriors)/(maxPriors-minPriors);
            if (*Priors_PTRtmp<1E-6) {
                *Priors_PTRtmp=0;
            }
        }
    }
//    string filenameOut="/Users/Carole/Documents/PhD/Phantom/PriorsModified";
//    nifti_set_filenames(this->GetPriors(), filenameOut.c_str(), 0, 0);
//    nifti_image_write(this->GetPriors());
}

// Copies the content of NonNormRespInput into the NonNormResp of the tree on which it is applied
//void TreeEM::SetNonNormResp(float *NonNormRespInput){
//    int numelmasked=this->GetNumberMaskedElements();
//    if (NonNormRespInput==NULL) {
//        if (this->GetNonNormResp()!=NULL) {
//            delete []this->GetNonNormResp();
//        }
//        this->NonNormResp=NULL;
//        return;
//    }
//    if (this->GetNonNormResp()==NULL) {
//        this->NonNormResp=new float[this->GetNumberMaskedElements()];//{0};
//        for (int i=0; i<numelmasked; i++) {
//                    this->NonNormResp[i]=0;
//                }
//    }
//    float * NonNormResp_PTR=this->GetNonNormResp();
//    float * NonNormRespInput_PTR=NonNormRespInput;
//    for (int i=0; i<numelmasked; i++,NonNormResp_PTR++,NonNormRespInput_PTR++) {
//        *NonNormResp_PTR=*NonNormRespInput_PTR;
//    }
//    return;
//}

// Copies the content of NormRespInput into NormResp of the tree on which it is applied
void TreeEM::SetNormResp(float * NormRespInput){
    int numelmasked=this->GetNumberMaskedElements();
    if (NormRespInput==NULL) {
        if (this->GetNormResp()!=NULL) {
            delete []this->GetNormResp();
        }
        this->NormResp=NULL;
        return;
    }
    if (this->GetNormResp()==NULL) {
        if (this->GetFlagOutliers()==4) {//VL implementation
            this->NormResp=new float[2*numelmasked];//{0};
            for (int i=0; i<numelmasked; i++) {
                this->NormResp[i]=0;
                this->NormResp[i+numelmasked]=1;
            }
        }
        else{
        this->NormResp=new float[this->GetNumberMaskedElements()];//{0};
        for (int i=0; i<numelmasked; i++) {
            this->NormResp[i]=0;
        }
        }
    }
    float * NormResp_PTR=this->NormResp;
    float * NormRespInput_PTR=NormRespInput;
    
    for (int i=0; i<numelmasked; i++,NormResp_PTR++,NormRespInput_PTR++) {
        *NormResp_PTR=*NormRespInput_PTR;
    }
    return;
}

// Set the Hard segmentation contained in HardSegInput as the Hard Seg field saved at root
void TreeEM::SetHardSeg(int * HardSegInput){
    int numelmasked=this->GetNumberMaskedElements();
    if(!this->IsRoot()){
        cout<<"HardSeg only modified at root"<<endl;
        return;
    }
    if(HardSegInput==NULL){
        if(this->GetHardSegDirect()!=NULL){
            delete [] this->HardSeg;
        }
        this->HardSeg=NULL;
        return;
    }
    if(this->GetHardSegDirect()==NULL){
        this->HardSeg=new int[numelmasked];
        for(int i=0;i<numelmasked;i++){
            this->HardSeg[i]=0;
        }
    }
    int * HardSeg_PTR=this->HardSeg;
    int * HardSegInput_PTR=HardSegInput;
    for(int i=0;i<numelmasked;i++,HardSegInput_PTR++,HardSeg_PTR++){
        *HardSeg_PTR=*HardSegInput_PTR;
    }
    return;
}

void TreeEM::SetCovPriorsMatrix(float * NewCovMatrix){
    // First check that it is a leaf following gaussian distribution
    if (this->GetDistributionType()!=1 && !this->IsRoot()) { // allow also possibility to store cov priors on root (useful with covPriorsType 2)
        cout<< "No setting of covariance matrix priors if not gaussian distribution"<<endl;
        return;
    }
    if (!this->GetFlagCovPriors() && !this->IsRoot()) { //// allow also possibility to store cov priors on root (useful with covPriorsType 2)
        cout<<"No setting of covariance matrix priors if no priors flag up"<<endl;
        return;
    }
    else{
        int numbmodal=this->GetNumberModalities();
        int numbmodalSq=numbmodal*numbmodal;
        float * PreCovMatrix=this->GetPriorsCovMatrix();
        if (PreCovMatrix!=NULL) {
            delete [] PreCovMatrix;
            PreCovMatrix=NULL;
        }
        if(NewCovMatrix!=NULL){
            this->ParametersDistribution->PriorsCov=new float[numbmodalSq];
            for (int i=0; i<numbmodalSq; i++) {
                this->ParametersDistribution->PriorsCov[i]=NewCovMatrix[i];
            }
        }
        else{
            this->ParametersDistribution->PriorsCov=NULL;
        }

    }
}


void TreeEM::SetMeanPriorsMatrix(float * NewMeanMatrix){
    // First check that it is a leaf following gaussian distribution
    if (this->GetDistributionType()!=1 && !this->IsRoot()) { // allow also possibility to store cov priors on root (useful with covPriorsType 2)
        cout<< "No setting of covariance matrix priors if not gaussian distribution"<<endl;
        return;
    }
    if (this->GetFlagMeanPriors()<0.01 && !this->IsRoot()) { //// allow also possibility to store cov priors on root (useful with covPriorsType 2)
        cout<<"No setting of covariance matrix priors if no priors flag up"<<endl;
        return;
    }
    else{
        int numbmodal=this->GetNumberModalities();
        float * PreMeanMatrix=this->GetPriorsMeanMatrix();
        if (PreMeanMatrix!=NULL) {
            delete [] PreMeanMatrix;
            PreMeanMatrix=NULL;
        }
        if(NewMeanMatrix!=NULL){
            this->ParametersDistribution->PriorsMean=new float[numbmodal];
            for (int i=0; i<numbmodal; i++) {
                this->ParametersDistribution->PriorsMean[i]=NewMeanMatrix[i];
            }
        }
        
    }
}

// At this specific level of the tree reinitialisation of the NormResp with the values of the priors after making them usable in a probabilistic manner
void TreeEM::InitialiseNormRespWithPriors(){
    float * NormResp_PTR=this->GetNormResp();
    int numelmasked=this->GetNumberMaskedElements();
    if (this->GetFlagOutliers()==4) {
        if (NormResp_PTR==NULL) {
            float * NormRespToSet=new float[2*numelmasked];
            for (int i=0; i<numelmasked; i++) {
                NormRespToSet[i]=0;
                NormRespToSet[i+numelmasked]=1;
            }
            this->SetNormResp( NormRespToSet);//{0});
        }
    }
    else{
    if (NormResp_PTR==NULL) {
        float * NormRespToSet=new float[numelmasked];
        for (int i=0; i<numelmasked; i++) {
            NormRespToSet[i]=0;
        }
        this->SetNormResp( NormRespToSet);//{0});
    }
}

    if(!this->IsPriorsProbabilityType()){ // Conversion into probabilities if needed
        this->MakePriorsProbabilityType();
    }
    if(!this->ArePriorsNormalised()){
        this->NormalisePriors();
    }
    float * PriorsData_PTR=static_cast<float*>(this->GetPriors()->data);
    int * L2S_PTR=this->GetL2S();
    int numel=this->GetNumberElements();
    for (int i=0; i<numel; i++,PriorsData_PTR++,L2S_PTR++) {
        if ((*L2S_PTR)>=0) {
            (*NormResp_PTR)=(*PriorsData_PTR);
            NormResp_PTR++;
        }
    }
}
// Sets NonNormWeight of the tree on which it is applied to NonNormWeightInput
void TreeEM::SetNonNormWeight(float NonNormWeightInput){
    this->NonNormWeight=NonNormWeightInput;
}

// Sets NormWeight of the tree on which it is applied to NormWeightInput after checking that the value is between 0 and 1
void TreeEM::SetNormWeight(float NormWeightInput){
    if (NormWeightInput>=0&&NormWeightInput<=1) {
        this->NormWeight=NormWeightInput;
    }
    else{
        cout<<"the input value is not valid"<<endl;
    }
}

//void TreeEM::SetDistribution(float * DistributionInput){
//    int numelmasked=this->GetNumberMaskedElements();
//    if (DistributionInput==NULL) {
//        if (this->GetDistribution()!=NULL) {
//            delete []this->GetDistribution();
//        }
//        this->Distribution=NULL;
//        return;
//    }
//    if (this->GetDistribution()==NULL) {
//        this->Distribution=new float[this->GetNumberMaskedElements()];//{0};
//        for(int i=0;i<numelmasked;i++){
//            this->Distribution[i]=0;
//        }
//    }
//    float * Distribution_PTR=this->GetDistribution();
//    float * DistributionInput_PTR=DistributionInput;

//    //cout<<"Addresses distribution"<< Distribution_PTR << " "<< DistributionInput_PTR;
//    for (int i=0; i<numelmasked; i++,Distribution_PTR++,DistributionInput_PTR++) {
//        *Distribution_PTR=*DistributionInput_PTR;
//    }
//    return;

//}

// To be used in case BF Coeffs already known for one or more modality or that not same order achieved for each of them. Especially needed when adding new modality into model and need for progressive BF correction for the added modality. We assume that the float array BFCoeffs considered is of the proper size
void TreeEM::SetBFCoeffsSeparated(float * BFCoeffsInput, vector<int> BFOrderPerModality){
    int numbmodal=this->GetNumberModalities();
    
    // Clearing current space for BFCoeffs if allocated
    // Given the order per modality, determines the appropriate number of BFCoeffs to consider in total
    int numbTotBF=0;
    for (int m=0; m<numbmodal; m++) {
        numbTotBF+=((BFOrderPerModality[m]+1)*(BFOrderPerModality[m]+2)*(BFOrderPerModality[m]+3))/6;
    }
    float * BFCoeffsToChange=this->GetBFCoeffs();
    if(this->GetParent()!=NULL){ // if it is not a root we do not change the BF coeffs
        cout<<"BF coeffs only set at the root"<<endl;
        return;
    }
    
    // Fill with BF CoeffsInput
    if(BFCoeffsInput!=NULL) { // it is only in the case we are at the root (checked before)
        if (BFCoeffsToChange!=NULL) {
            delete [] BFCoeffsToChange;
            BFCoeffsToChange=NULL;
        }
        if(BFCoeffsToChange==NULL){
//            cout<<"Memory allocated for BF"<<endl;
            this->BFCoeffs=new float[numbTotBF];
        }
        BFCoeffsToChange=this->BFCoeffs;
        for (int l=0; l<numbTotBF;l++) {
            BFCoeffsToChange[l]=BFCoeffsInput[l];
        }
    }
}

// After checking the validity of such an update change the BF coeffs
void TreeEM::SetBFCoeffs(float * BFCoeffsInput){
    int numbmodal=this->GetNumberModalities();

    // Clearing current space for BFCoeffs if allocated
    int numbBF=((BForder+1)*(BForder+2)*(BForder+3))/6;
    float * BFCoeffsToChange=this->GetBFCoeffs();
    if(this->GetParent()!=NULL){ // if it is not a root we do not change the BF coeffs
        cout<<"BF coeffs only set at the root"<<endl;
        return;
    }

    // Fill with BF CoeffsInput
    if(BFCoeffsInput!=NULL) { // it is only in the case we are at the root (checked before)
        int sizeBFCoeffs=numbmodal*numbBF;
        if (BFCoeffsToChange!=NULL) {
            delete [] BFCoeffsToChange;
            BFCoeffsToChange=NULL;
        }
        if(BFCoeffsToChange==NULL){
//            cout<<"Memory allocated for BF"<<endl;
            this->BFCoeffs=new float[sizeBFCoeffs];
        }
        BFCoeffsToChange=this->BFCoeffs;
        for (int l=0; l<sizeBFCoeffs;l++) {
            BFCoeffsToChange[l]=BFCoeffsInput[l];
        }
    }
    
    // If want to set NULL Coeffs, need to delete the one there if there are some
    if(BFCoeffsInput==NULL){
        if(BFCoeffsToChange!=NULL){
            delete [] BFCoeffsToChange;
            this->BFCoeffs=NULL;
        }
    }

}

//void TreeEM::SetBFCorrection(float * BFCorrectionInput){
//    int numbmodal=this->GetNumberModalities();
//    int numelmasked=this->GetNumberMaskedElements();
////    int numbBF=((BForder+1)*(BForder+2)*(BForder+3))/6;
//    // Clearing current space for BFCoeffs if allocated

//    float * BFCorrectionToChange=this->BFCorrection;
//    if(this->GetParent()!=NULL){ // if it is not a root we do not change the BF coeffs
//        cout<<"BF correction only set at the root"<<endl;
//        return;
//    }

//    // Fill with BF CoeffsInput
//    if(BFCorrectionInput!=NULL) {
//        if(BFCorrectionToChange==NULL){
//        this->BFCorrection=new float[numelmasked*numbmodal];
//            BFCorrectionToChange=this->BFCorrection;
//        }
//        for (int i=0; i<numelmasked*numbmodal;i++) {
//            BFCorrectionToChange[i]=BFCorrectionInput[i];
//        }
//    }
//}

// Setting the bias field corrected data given DataBFCorrectedInput. Size is numelmasked for the attributed input
void TreeEM::SetDataBFCorrected(float * DataBFCorrectedInput){
    int numbmodal=this->GetNumberModalities();
    int numelmasked=this->GetNumberMaskedElements();
    int sizeDataBFCorrected=numbmodal*numelmasked;
    // Clearing current space for BFCoeffs if allocated

    float * DataBFCorrectedToChange=this->DataBFCorrected;

    if(this->GetParent()!=NULL){ // if it is not a root we do not change the BF coeffs
        cout<<"Data correction only set at the root"<<endl;
        return;
    }
    // Fill with DataBFCorrectedInput
    if(DataBFCorrectedInput!=NULL) {
        // Clearing space for DataBFCorrectedInput if has to
        if (DataBFCorrectedToChange!=NULL) {
            delete [] DataBFCorrectedToChange;
            DataBFCorrectedToChange=NULL;
        }
        if(DataBFCorrectedToChange==NULL){
            this->DataBFCorrected=new float[sizeDataBFCorrected];
            DataBFCorrectedToChange=this->DataBFCorrected;
        }
        for (int i=0; i<sizeDataBFCorrected;i++) {
            DataBFCorrectedToChange[i]=DataBFCorrectedInput[i];
        }
    }
}

void TreeEM::SetDPChildren(float* DPChildrenInput){
    if(!this->IsRoot()){
        cout<<"DP children only set at root"<<endl;
        return;
    }
    int numbchild=this->GetNumberChildren();
//    if(numbchild!=DPChildrenInput.size()){
//        cout<<"Incompatibility in size for DP"<<endl;
//        if(numbchild>DPChildrenInput.size()){
//            for(int i=DPChildrenInput.size();i<numbchild;i++){
//                DPChildrenInput.push_back(NULL);
//            }
//        }

//    }
    float * DPChildrenInitial=this->GetDPChildrenDirect();
    if(DPChildrenInitial!=NULL){
        delete [] DPChildrenInitial;
        DPChildrenInitial=NULL;
    }
    if(this->GetFlagDistClassInd()){
    float * DPChildrenToInput=new float[MaxSupport*numbchild];
    for(int c=0;c<numbchild;c++){
        for(int i=0;i<MaxSupport;i++){
            DPChildrenToInput[i+c*MaxSupport]=DPChildrenInput[i+c*MaxSupport];
        }
    }
    this->DPChildren=DPChildrenToInput;
    }
    else{
        int SizeHistogram=(int)pow_int(MaxSupport,numbchild);
        float *DPChildrenToInput=new float[SizeHistogram];
        for(int i=0;i<SizeHistogram;i++){
            DPChildrenToInput[i]=DPChildrenInput[i];
        }
        this->DPChildren=DPChildrenToInput;
    }



//        int DPsize=this->GetDPChildrenDirect().size();
//        vector<float *> DPChildrenInitial=this->GetDPChildrenDirect();
//        if(DPsize!=0){
//            for(int c=0;c<DPsize;c++){
//                if(DPChildrenInitial[c]!=NULL){
//                    delete [] DPChildrenInitial[c];
//                    DPChildrenInitial[c]=NULL;
//                }
//            }
//            DPChildrenInitial.clear();
//        }
//        this->DPChildren=DPChildrenInput;
}

void TreeEM::SetFlagDistClassInd(bool flag_DistClassInd){
    if(!this->IsRoot()){
        this->GetParent()->SetFlagDistClassInd(flag_DistClassInd);
    }
    else{
        this->FlagDistClassInd=flag_DistClassInd;
    }
}

void TreeEM::SetFlagOutliers(int flag_Outliers){
    if(!this->IsRoot()){
        this->GetParent()->SetFlagOutliers(flag_Outliers);
    }
    else{
        this->FlagOutliers=flag_Outliers;
    }
}

void TreeEM::SetFlagUTC(int flag_UTC){
    if(!this->IsRoot()){
        this->GetParent()->SetFlagUTC(flag_UTC);
    }
    else{
        this->FlagUTC=flag_UTC;
    }
}

void TreeEM::SetFlagCovPriorsParameters(bool flag_CovPriors){
    if(this->GetDistributionType()!=1){
        this->ParametersDistribution->PriorsCovFlag=0;
    }
    else{
        this->ParametersDistribution->PriorsCovFlag=flag_CovPriors;
    }
}

void TreeEM::SetFlagCovPriors(int flag_CovPriors){
    if(!this->IsRoot()){
        this->GetParent()->SetFlagCovPriors(flag_CovPriors);
    }
    else{
        this->FlagCovPriors=flag_CovPriors;
    }
}


void TreeEM::SetFlagMeanPriors(float flag_MeanPriors){
    if(!this->IsRoot()){
        this->GetParent()->SetFlagMeanPriors(flag_MeanPriors);
    }
    else{
        this->FlagMeanPriors=flag_MeanPriors;
    }
}

/********************* EM RELATED METHODS ***************************/

// Update all the parameters of the model in a recursive way
void TreeEM::UpdateParameters(){
    int TypeTreeComponent=this->WhatTypeOfTreeComponent();
    if(TypeTreeComponent==LEAF){// Means it is a leaf
        /* For the moment only Gaussian distribution as simple distribution so no other case than the default one in the switch*/
        switch (this->GetDistributionType()) {
        case 2: // case of uniform distribution with outliers : no updating
            break;
        case 0:{
            cout<<"Leaf should not have 0 distribution"<<endl;
            }
            break;
        default:
            this->UpdateGaussianParameters();
            //cout<<"Gaussian parameters updated";
            break;
        }
    }
    else{ // Recursive part
        int numbchild=this->GetNumberChildren();
        for (int c=0; c<numbchild; c++) {
            //cout<<"Updating parameters of child "<<c<<endl;
            this->GetChild(c)->UpdateParameters();
        }
    }
    return;
}

// Update Gaussian parameters if node considered as governed by gaussian distribution
void TreeEM::UpdateGaussianParameters(){
    if (this->GetDistributionType()!=1){
        cout<<"It is not a Gaussian distribution"<<endl;
        return;
    }
    this->UpdateGaussianMean();
    //this->UpdateGaussianVariance();
    this->UpdateGaussianVariancePriors();
    if(this->FindRoot()->FlagMeanPriors){
    this->UpdateGaussianMeanPriors();
    }
    return;
}

void TreeEM::UpdatePartPriorsAdapted(){
    int numelmasked=this->GetNumberMaskedElements();
    if (this->IsRoot()) {
        float * PartPriorsRoot=new float[numelmasked];
        for (int i=0; i<numelmasked; i++) {
            PartPriorsRoot[i]=1;
        }
        this->SetPartPriorsAdapted(PartPriorsRoot);
        delete [] PartPriorsRoot;
        PartPriorsRoot=NULL;
    }
    else if (this->GetPriorsDirect()==NULL) {
        this->SetPartPriorsAdapted(NULL);
    }
    else if(this->GetPriorsDirect()!=NULL){
        float * PartPriorsAdaptedToSet=this->GetPartPriorsAdaptedMasked();
        this->SetPartPriorsAdapted(PartPriorsAdaptedToSet);
        delete [] PartPriorsAdaptedToSet;
        PartPriorsAdaptedToSet=NULL;
    }
    int numbchild=this->GetNumberChildren();
    for (int c=0; c<numbchild; c++) {
        this->GetChild(c)->UpdatePartPriorsAdapted();
    }
}

// Update the Adapted Priors : only needed on nodes that have direct priors and if AtlasWeight is non zero
void TreeEM::UpdatePriorsAdapted(SEG_PARAMETERS *segment_param){
    if (segment_param->AtlasWeight.size()==0) {
        return;
    }
    if (segment_param->AtlasWeight.size()>1) {
        this->FindRoot()->AdaptPriorsOM3PK8(segment_param);
        return;
    }
    else {
    float Weight=segment_param->AtlasWeight[0];
    if(Weight==0){
        return;
    }
    if (segment_param->PriorsKept==7 && !this->IsRoot()) {
        return;
    }
    if (segment_param->PriorsKept==5 && this->GetFlagOutliers()==7) {
        this->FindRoot()->AdaptPriorsOM7PK5(segment_param);
        return;
    }
    if (segment_param->PriorsKept==5 && this->GetFlagOutliers()==3) {
       // this->FindRoot()->AdaptPriorsAllLevelsOM3PK5(segment_param);
        this->FindRoot()->AdaptPriorsOM3PK8(segment_param);
        return;
    }
    if (segment_param->PriorsKept==8 && (this->GetFlagOutliers()==3 || this->GetFlagOutliers()>=5)) {
        this->FindRoot()->AdaptPriorsOM3PK8(segment_param);
        return;
    }
//    int numbchild=this->GetNumberChildren();
    vector<TreeEM*> NodePriorsVector=this->GetPriorsNodeVector();
    int numbclasses=NodePriorsVector.size();
    if(numbclasses >0){
        for(int c=0;c<numbclasses;c++){
            float * PriorsAdaptedToUpdate=NodePriorsVector[c]->CopyPriorsAdapted();
            float * UpdatedPriors = NodePriorsVector[c]->AdaptPriors(segment_param);
            NodePriorsVector[c]->SetPriorsAdapted(UpdatedPriors);
            delete [] PriorsAdaptedToUpdate;
            PriorsAdaptedToUpdate=NULL;
            delete [] UpdatedPriors;
            UpdatedPriors=NULL;

//                // Check for number of zero values in PriorsAdapted :
//                float * PriorsAdapted_PTR=this->GetChild(c)->GetPriorsAdapted();
//                int * L2S_PTR=this->GetL2S();
//                int numel = this->GetNumberElements();
//                int CountPriorsAdaptedZero=0;
//                for(int i=0;i<numel;i++,L2S_PTR++,PriorsAdapted_PTR++){
//                    if(*L2S_PTR>=0){
//                        if(*PriorsAdapted_PTR==0){
//                            CountPriorsAdaptedZero++;
//                        }
//                    }
//                }
//                cout<<"Number of zero values in new priors masked is "<<CountPriorsAdaptedZero<<" for child "<<c<<endl;
        }
        this->NormalisePriorsAdapted();

    }
    int numbchild=this->GetNumberChildren();
    for(int c=0;c<numbchild;c++){ // recursivity of Priors adaptation
        this->GetChild(c)->UpdatePriorsAdapted(segment_param);
    }
    }
}
//    }
//    if(numbchild >0){
//        if(this->GetChild(0)->GetPriorsAdaptedDirect()!=NULL){
//            for(int c=0;c<numbchild;c++){
//                float * PriorsAdaptedToUpdate=this->GetChild(c)->CopyPriorsAdapted();
//                float * UpdatedPriors = this->GetChild(c)->AdaptPriors(segment_param);
//                this->GetChild(c)->SetPriorsAdapted(UpdatedPriors);
//                delete [] PriorsAdaptedToUpdate;
//                PriorsAdaptedToUpdate=NULL;
//                delete [] UpdatedPriors;
//                UpdatedPriors=NULL;

////                // Check for number of zero values in PriorsAdapted :
////                float * PriorsAdapted_PTR=this->GetChild(c)->GetPriorsAdapted();
////                int * L2S_PTR=this->GetL2S();
////                int numel = this->GetNumberElements();
////                int CountPriorsAdaptedZero=0;
////                for(int i=0;i<numel;i++,L2S_PTR++,PriorsAdapted_PTR++){
////                    if(*L2S_PTR>=0){
////                        if(*PriorsAdapted_PTR==0){
////                            CountPriorsAdaptedZero++;
////                        }
////                    }
////                }
////                cout<<"Number of zero values in new priors masked is "<<CountPriorsAdaptedZero<<" for child "<<c<<endl;
//            }
//            this->NormalisePriorsAdapted();

//        }
//    }

//    // RecursivePart
//    for(int c=0;c<numbchild;c++){
//        this->GetChild(c)->UpdatePriorsAdapted(segment_param);
//    }
//}

// Part of the update of the Gaussian parameters, UpdateGaussianMean updates the mean and the covariance of the considered gaussian node
void TreeEM::UpdateGaussianMean(){
//    int numel=this->GetNumberElements(); // number of elements in the image
    int numelmasked=this->GetNumberMaskedElements();
    int numbmodal=this->GetNumberModalities(); // number of modalities to consider
    //float * PointerToDataBegin=static_cast<float *>(this->GetDataImage()->data);
    //    float * PointerToDataBegin=this->MakeDataBFCorrected();
    float * PointerToDataBegin=this->GetDataBFCorrected();
    
    //Keep old parameters in memory
    Parameters * OldParam=this->CopyParameters();
    
    for (int m=0;m<numbmodal;m++){
        float * PointerToImageBegin_PTR=&PointerToDataBegin[m*numelmasked]; // Points the data to the beginning of each modality image
        float * PointerToNormRespBegin_PTR=this->GetNormResp(); // Points to the beginning of the NormalizedResponsabilities
        double meantmp=0; // Initialisation of the numerator in the update of the mean
        double sumResp=0; // Initialisation of the denominator in the update of the mean
//        float meantmpMarc=0.f; // Initialisation of the numerator in the update of the mean
//        float sumRespMarc=0.f; // Initialisation of the denominator in the update of the mean
        //        int * L2S_PTR=this->GetL2S();
        int CountMoreThanOne=0;
        
        if (this->GetFlagOutliers()==4) { // VLImplementation
            float * PointerToTypicality_PTR=&this->GetNormResp()[numelmasked];
            for(int i=0;i<numelmasked;i++,PointerToImageBegin_PTR++,PointerToNormRespBegin_PTR++,PointerToTypicality_PTR++){
                /* Each time the considered voxel is active (<=> L2S contains an index), update the numerator and the denominator*/
                meantmp+=(double)(*PointerToImageBegin_PTR)*(*PointerToNormRespBegin_PTR)*(*PointerToTypicality_PTR);
//                meantmpMarc+=(*PointerToImageBegin_PTR)*(*PointerToNormRespBegin_PTR);
                if (*PointerToImageBegin_PTR>1) {
                    CountMoreThanOne++;
                    //                    cout<<"Pb in normalisation image";
                }
                sumResp+=(double)(*PointerToNormRespBegin_PTR)*(*PointerToTypicality_PTR);
//                sumRespMarc+=(*PointerToNormRespBegin_PTR);
            }
            if(CountMoreThanOne>0){
                //            cout<<"Transformed values more than one is "<<CountMoreThanOne<<endl;
            }
            if (sumResp!=0) {
                this->GetMean()[m]=meantmp/sumResp;
            }
            else{
                this->GetMean()[m]=meantmp/this->GetNumberMaskedElements();
            }
        }
        
        else{ // Normal implementation without VL typicalities weights
        for(int i=0;i<numelmasked;i++,PointerToImageBegin_PTR++,PointerToNormRespBegin_PTR++){
            /* Each time the considered voxel is active (<=> L2S contains an index), update the numerator and the denominator*/
            meantmp+=(double)(*PointerToImageBegin_PTR)*(*PointerToNormRespBegin_PTR);
//            meantmpMarc+=(*PointerToImageBegin_PTR)*(*PointerToNormRespBegin_PTR);
            if (*PointerToImageBegin_PTR>1) {
                CountMoreThanOne++;
                //                    cout<<"Pb in normalisation image";
            }
            sumResp+=(double)(*PointerToNormRespBegin_PTR);
//            sumRespMarc+=(*PointerToNormRespBegin_PTR);
        }
        if(CountMoreThanOne>0){
            //            cout<<"Transformed values more than one is "<<CountMoreThanOne<<endl;
        }
        if (sumResp!=0) {
            this->GetMean()[m]=meantmp/sumResp;
        }
        else{
            this->GetMean()[m]=meantmp/this->GetNumberMaskedElements();
        }
         
            //checking if subsequent variance will be ok
//            float * VarianceUpdate=this->GetVarianceDirect();
            float * MeanDirect=this->GetMean();
            float * VarianceUpdate=this->GetVarianceDirect(MeanDirect);
            float DeterminantTest=determinant(VarianceUpdate, numbmodal);
            if (DeterminantTest!=DeterminantTest) {
                cout<<"Pb NaN Determinant test"<<endl;
            }
            if (DeterminantTest<1E-15 || DeterminantTest!=DeterminantTest) {
                cout << "Close to singular with determinant "<<DeterminantTest;
                cout << " therefore no update of the parameters "<<endl;
                for (int m=0; m<numbmodal; m++) {
                    this->GetMean()[m]=OldParam->ValueParameters[m];
                    this->GetVariance()[m+numbmodal*m]+=10E-6;
                }
                
                    
            }
            else{
//                cout << "Updating variance";
                float * VarianceUpdated=this->GetVariance();
                for (int m1=0; m1<numbmodal; m1++) {
                    for (int m2=0; m2<numbmodal; m2++) {
                        VarianceUpdated[m1*numbmodal+m2]=VarianceUpdate[m1*numbmodal+m2];
                    }
                }
            }
            
            delete [] VarianceUpdate;
            VarianceUpdate=NULL;

//        printf("HERE We are float %f / %f = %f\n", meantmpMarc, sumRespMarc,meantmpMarc/sumRespMarc);
//        printf("HERE We are double %g / %g = %g\n", meantmp, sumResp,meantmp/sumResp);
//        exit(1);

        //cout<<"Mean is now "<< this->GetMean()[m];
    }
    // Clearing memory
    //    if (PointerToDataBegin!=NULL) {
    //        delete [] PointerToDataBegin;
    //        PointerToDataBegin=NULL;
    //    }
    }
    delete OldParam;
    OldParam=NULL;
    return;
}

// Was used to update Gaussian covariance parameter (now included in UpdateGaussianMean)
void TreeEM::UpdateGaussianVariance(){
//    int numel=this->GetNumberElements();
    int numbmodal=this->GetNumberModalities();
    int numelmasked=this->GetNumberMaskedElements();
    PrecisionTYPE sumResp=0; // Initialisation of the denominator
    //float * PointerToDataBegin = static_cast<float *>(this->GetDataImage()->data);
    //    float * PointerToDataBegin=this->MakeDataBFCorrected();
    float * PointerToDataBegin=this->GetDataBFCorrected();
    float * PointerToDataBegin_PTR1=PointerToDataBegin;
    float * PointerToDataBegin_PTR2=PointerToDataBegin;
    float * NormalisedResponsabilities_PTR=this->GetNormResp();
    //    int * L2S_PTR=this->GetL2S();



    float * VarianceToUpdateB=this->GetVariance();
    float VarianceToUpdate[MaxNumbModal*MaxNumbModal];
    for(int m1=0;m1<MaxNumbModal;m1++){
        for(int m2=0;m2<MaxNumbModal;m2++){
            if(m1<numbmodal&&m2<numbmodal){
                VarianceToUpdate[m1+m2*MaxNumbModal]=VarianceToUpdateB[m1+m2*numbmodal];
            }
            else{
                VarianceToUpdate[m1+m2*MaxNumbModal]=0;
            }
        }
    }
    float * MeanToUseB=this->GetMean();
    float MeanToUse[MaxNumbModal];
    for(int m=0;m<MaxNumbModal;m++){
        if(m<numbmodal){
            MeanToUse[m]=MeanToUseB[m];
        }
    }
    if (this->GetFlagOutliers()==4) { // VL implementation
        float * TypicalityResponsabilities_PTR=&this->GetNormResp()[numelmasked];
        // Calculation of the denominator (sum over the active voxels of the normalised responsabilities)
        for (int i=0; i<numelmasked; i++,NormalisedResponsabilities_PTR++,TypicalityResponsabilities_PTR++) {
            sumResp+=(PrecisionTYPE)(*NormalisedResponsabilities_PTR)*(*TypicalityResponsabilities_PTR);
        }
    for(int m1=0;m1<numbmodal;m1++){
        // First data pointer to the beginning of the modality m1 considered
        for(int m2=0;m2<numbmodal;m2++){
            PointerToDataBegin_PTR1=&PointerToDataBegin[m1*numelmasked];
            PointerToDataBegin_PTR2=&PointerToDataBegin[m2*numelmasked]; // Second Data pointer to the beginning of the modality m2 considered
            NormalisedResponsabilities_PTR=this->GetNormResp(); // Reinitialisation of the responsabilities pointer to the beginning
            TypicalityResponsabilities_PTR=&this->GetNormResp()[numelmasked];
            VarianceToUpdate[m1+m2*MaxNumbModal]=0;
            PrecisionTYPE VarianceToUpdate_tmp=0;
            for(int i=0;i<numelmasked;i++,PointerToDataBegin_PTR1++,PointerToDataBegin_PTR2++,NormalisedResponsabilities_PTR++,TypicalityResponsabilities_PTR++){
                // Update of the numerator of the Variance Calculation only if in the case of an active voxel
                VarianceToUpdate_tmp+=(PrecisionTYPE)(*NormalisedResponsabilities_PTR)*(*TypicalityResponsabilities_PTR)*((*PointerToDataBegin_PTR1)-MeanToUse[m1])*((*PointerToDataBegin_PTR2)-MeanToUse[m2]);
            }
            if (sumResp !=0) {
                VarianceToUpdate[m1+m2*MaxNumbModal]=(float)VarianceToUpdate_tmp/sumResp;
                if (m1==m2) {
                    VarianceToUpdate[m1+m2*MaxNumbModal]=VarianceToUpdate[m1+m2*MaxNumbModal]<=1E-6?1E-6:VarianceToUpdate[m1+m2*MaxNumbModal]; // in order to avoid going to 0 if too sharp distribution but not changing non diagonal of variance
                }


            }
            else{
                VarianceToUpdate[m1+m2*MaxNumbModal]=VarianceToUpdate_tmp/numelmasked;// this->GetNumberMaskedElements();
            }
            // Use of the symmetry property of the Variance matrix
            VarianceToUpdate[m2+m1*MaxNumbModal]=VarianceToUpdate[m1+m2*MaxNumbModal];
        }
    }
}

    else{
        // Calculation of the denominator (sum over the active voxels of the normalised responsabilities)
        for (int i=0; i<numelmasked; i++,NormalisedResponsabilities_PTR++) {
            sumResp+=(PrecisionTYPE)(*NormalisedResponsabilities_PTR);
        }
    for(int m1=0;m1<numbmodal;m1++){
        // First data pointer to the beginning of the modality m1 considered
        for(int m2=0;m2<numbmodal;m2++){
            PointerToDataBegin_PTR1=&PointerToDataBegin[m1*numelmasked];
            PointerToDataBegin_PTR2=&PointerToDataBegin[m2*numelmasked]; // Second Data pointer to the beginning of the modality m2 considered
            NormalisedResponsabilities_PTR=this->GetNormResp(); // Reinitialisation of the responsabilities pointer to the beginning
            VarianceToUpdate[m1+m2*MaxNumbModal]=0;
            PrecisionTYPE VarianceToUpdate_tmp=0;
            for(int i=0;i<numelmasked;i++,PointerToDataBegin_PTR1++,PointerToDataBegin_PTR2++,NormalisedResponsabilities_PTR++){
                // Update of the numerator of the Variance Calculation only if in the case of an active voxel
                VarianceToUpdate_tmp+=(PrecisionTYPE)(*NormalisedResponsabilities_PTR)*((*PointerToDataBegin_PTR1)-MeanToUse[m1])*((*PointerToDataBegin_PTR2)-MeanToUse[m2]);
            }
            if (sumResp !=0) {
                VarianceToUpdate[m1+m2*MaxNumbModal]=(float)VarianceToUpdate_tmp/sumResp;
                if (m1==m2) {
                    VarianceToUpdate[m1+m2*MaxNumbModal]=VarianceToUpdate[m1+m2*MaxNumbModal]<=1E-6?1E-6:VarianceToUpdate[m1+m2*MaxNumbModal]; // in order to avoid going to 0 if too sharp distribution but not changing non diagonal of variance
                }
                
                
            }
            else{
                VarianceToUpdate[m1+m2*MaxNumbModal]=VarianceToUpdate_tmp/numelmasked;// this->GetNumberMaskedElements();
            }
            // Use of the symmetry property of the Variance matrix
            VarianceToUpdate[m2+m1*MaxNumbModal]=VarianceToUpdate[m1+m2*MaxNumbModal];
        }
    }
}

    
    
    
    for(int m1=0;m1<numbmodal;m1++){
        for(int m2=0;m2<numbmodal;m2++){
            VarianceToUpdateB[m1+m2*numbmodal]=VarianceToUpdate[m1+m2*MaxNumbModal];
        }
    }
    // Clearing memory
    //    if (PointerToDataBegin!=NULL) {
    //        delete []  PointerToDataBegin;
    //        PointerToDataBegin=NULL;
    //    }
    return;
}

// Update of the prior over the covariance matrix
void TreeEM::UpdateCovPriors(SEG_PARAMETERS * segment_param){
    if ( (segment_param->CovPriorsType!=2 && segment_param->CovPriorsType!=4 && segment_param->CovPriorsType<8)|| segment_param->flag_CovPriors==0 || this->GetFlagCovPriors()==0) { // should correspond to the case when the covariance priors are not put in a general way
        return;
    }
    else{ // meaning that there is a general covariance matrix to update at each iteration
        float * CovPriorsUpdate=NULL;
        if (this->GetFlagCovPriors()==2) {
            CovPriorsUpdate=this->FindRoot()->CreateCovPriorsFromExistingCovMatrices();
            this->FindRoot()->SetCovPriorsMatrix(CovPriorsUpdate);

        }
        else if( this->GetFlagCovPriors()>=8){
            CovPriorsUpdate=this->FindRoot()->CreateCovPriorsForInverseWishart();
            this->FindRoot()->SetCovPriorsMatrix(CovPriorsUpdate);
        }
        else {
            TreeEM * MiniVarTree=this->FindRoot()->GetMiniVariance();
            int numbmodal=this->GetNumberModalities();
            int numbmodalSq=numbmodal*numbmodal;
            float * CovPriorsTest=MiniVarTree->GetVariance();
            if (CovPriorsTest==NULL || CovPriorsTest[0]==0) {
                CovPriorsUpdate=MiniVarTree->GetVarianceDirect();
            }
            else {
                CovPriorsUpdate=new float [numbmodalSq];
                for (int m=0; m<numbmodalSq; m++) {
                    CovPriorsUpdate[m]=CovPriorsTest[m];
                }
            }
//            CovPriorsUpdate=MiniVarTree->GetVarianceDirect();
//            int numbmodal=this->GetNumberModalities();
            int numelmasked=this->GetNumberMaskedElements();
            for (int m=0; m<numbmodalSq; m++) {
                CovPriorsUpdate[m]*=(numelmasked+numbmodal+1);
            }
            this->FindRoot()->SetCovPriorsMatrix(CovPriorsUpdate);
        }
        delete [] CovPriorsUpdate;
        CovPriorsUpdate=NULL;
        this->FindRoot()->ModifyCovPriors(segment_param);

    }
}

// Modify the covariance matrix update in order to follow a prior on the covariance matrix
void TreeEM::UpdateGaussianVariancePriors(){
    // Normally has been checked before that it is a gaussian leaf
    // then check if the flag for the priors is up
    if (!this->GetFlagCovPriors()) {
        return;
    }
    else{
        // check that there is a priors covariance matrix available otherwise no change with a warning message
        if (this->GetPriorsCovMatrixTotal()==NULL) {
            cout<< "Warning : Cov priors flag up but no available prior matrix"<<endl;
            return;
        }
        else{ // only case when an adaptation of the covariance matrix is possible
            int numbmodal=this->GetNumberModalities();
            int numelmasked=this->GetNumberMaskedElements();
            PrecisionTYPE sumResp=0;
            float * NormResp_PTR=this->GetNormResp();
            for (int i=0; i<numelmasked; i++,NormResp_PTR++) {
                sumResp+=*NormResp_PTR;
            }
            if (sumResp<=0) {
                cout<<"Warning pb in cov priors due to zero sumResp"<<endl;
                return;
            }
            if (sumResp<=10E-8){
                cout << "Too small to do any covariance constraint"<<endl;
                return;
            }
            Parameters * OldParam=this->CopyParameters();
            float * VarianceToModify=&this->GetParametersValue()[numbmodal];
//            float * PriorsCov=this->GetPriorsCovMatrix();
            float *PriorsCov=NULL;
            switch (this->GetFlagCovPriors()) {
                case 1:
                    PriorsCov=this->GetPriorsCovMatrix();
                    break;
//                case 2:
//                    PriorsCov=this->GetPriorsCovMatrix();
//                    break;
                case 6:
                    PriorsCov=this->GetPriorsCovMatrix();
                    break;
                case 7:
                    PriorsCov=this->GetPriorsCovMatrix();
                    break;
                default:
                    PriorsCov=this->GetPriorsCovMatrixGeneral();
                    break;
            }
//            float * PriorsCov=this->GetPriorsCovMatrixGeneral();
//            float NormalisationFactor=1+(numelmasked+(numbmodal*(numbmodal-1))/2.0)/(2*sumResp);
            float NormalisationFactor=1.0+(numelmasked+numbmodal+1)/(2*sumResp);
            if (this->GetFlagCovPriors()>=7) {
                NormalisationFactor=1.0+(numelmasked+numbmodal+1.0)/sumResp;
            }
            float * ScalingVariance=this->MakeScalingVariance();
            if (this->GetFlagCovPriors()==4 || this->GetFlagCovPriors()==6 || this->GetFlagCovPriors()==7) { // Scaling by mean fixed in case 6 and not done in case 4
                for (int m=0; m<numbmodal; m++) {
                    ScalingVariance[m+m*numbmodal]=1;
                }
            }
            for (int m1=0; m1<numbmodal; m1++) {
                for (int m2=0; m2<numbmodal; m2++) {
                    if (this->GetFlagCovPriors()>6) {
//                        VarianceToModify[m1+numbmodal*m2]+=PriorsCov[m1+m2*numbmodal]/(sumResp*(ScalingVariance[m1+m1*numbmodal])*(ScalingVariance[m2+m2*numbmodal]));
                        // Correction adopted on 24/09/2014 with exp instead of mu and S-1 instead of S
//                        VarianceToModify[m1+numbmodal*m2]+=PriorsCov[m1+m2*numbmodal]/(sumResp)*expf(ScalingVariance[m1+m1*numbmodal])*expf(ScalingVariance[m2+m2*numbmodal]);
//                        Correction on 26/09/2014
                        VarianceToModify[m1+numbmodal*m2]+=PriorsCov[m1+m2*numbmodal]/(sumResp)*expf(-(ScalingVariance[m1+m1*numbmodal]+ScalingVariance[m2+m2*numbmodal]));
//                         VarianceToModify[m1+numbmodal*m2]+=PriorsCov[m1+m2*numbmodal]/(numelmasked)*expf(-(ScalingVariance[m1+m1*numbmodal]+ScalingVariance[m2+m2*numbmodal]));
                    }
                    else{
                    VarianceToModify[m1+numbmodal*m2]+=0.5*PriorsCov[m1+m2*numbmodal]/(sumResp*(ScalingVariance[m1+m1*numbmodal])*(ScalingVariance[m2+m2*numbmodal]));
                    }
//                    cout<<(ScalingVariance[m1+m1*numbmodal])*(ScalingVariance[m2+m2*numbmodal])<<" ";
//                    cout<<PriorsCov[m1+m2*numbmodal]<<" ";
                    VarianceToModify[m1+numbmodal*m2]/=NormalisationFactor;
                }
//                cout<<endl;
            }
            delete [] ScalingVariance;
            ScalingVariance=NULL;
            
            float TestDeterminant=determinant(VarianceToModify, numbmodal);
            if (TestDeterminant<1E-15 || TestDeterminant!=TestDeterminant) {
                cout << "Pb when updating variance with covariance constraint with determinant "<<TestDeterminant<<endl;
                if(VarianceToModify[0]!=VarianceToModify[0]){ // case we have NaN
                    cout<< "NaN Variance To modify"<<endl;
                    for(int m1=0;m1<numbmodal;m1++){
                        for(int m2=0;m2<numbmodal;m2++){
                            VarianceToModify[m1+numbmodal*m2]=0;
                            if(m1==m2){
                                VarianceToModify[m1+m1*numbmodal]=10E-6;
                            }
                        }
                    }
                }
                else{
                for (int m1=0; m1<numbmodal; m1++) {
                    for (int m2=0; m2<numbmodal; m2++) {
                        VarianceToModify[m1*numbmodal+m2]=OldParam->ValueParameters[numbmodal+m1*numbmodal+m2];
                    }
                }
                for (int m=0; m<numbmodal; m++) { // Regularisation of covariance matrix
                    VarianceToModify[m+m*numbmodal]+=10E-6;
                }
                }

            }
            delete OldParam;
            OldParam=NULL;
//            cout << "Variance update..."<<endl;
//            for(int m1=0;m1<numbmodal;m1++){
//                for(int m2=0;m2<numbmodal;m2++){
//                    cout<<VarianceToModify[m1+m2*numbmodal]<<" ";
//                }
//                cout<<endl;
//            }
            
        }
    }
}



// Modify the mean update in order to follow a prior on the mean (normal priors)
void TreeEM::UpdateGaussianMeanPriors(){
    // Normally has been checked before that it is a gaussian leaf
    // then check if the flag for the priors is up
    if (!this->GetFlagMeanPriors()) {
        return;
    }
    else{
        // check that there is a priors covariance matrix available otherwise no change with a warning message
        if (this->GetPriorsMeanTotal()==NULL) {
            cout<< "Warning : Mean priors flag up but no available prior matrix"<<endl;
            return;
        }
        else{ // only case when an adaptation / constraint of the mean is possible
            int numbmodal=this->GetNumberModalities();
            int numelmasked=this->GetNumberMaskedElements();
            PrecisionTYPE sumResp=0;
            float * NormResp_PTR=this->GetNormResp();
            for (int i=0; i<numelmasked; i++,NormResp_PTR++) {
                sumResp+=*NormResp_PTR;
            }
            if (sumResp<=0) {
                cout<<"Warning pb in mean priors due to zero sumResp"<<endl;
                return;
            }
            if (sumResp<=10E-8){
                cout << "Too small to do any mean constraint"<<endl;
                return;
            }
//            Parameters * OldParam=this->CopyParameters();
            float * MeanToModify=this->GetParametersValue();
            float * PriorsCov=this->GetPriorsCovMatrix();
            float *PriorsMean=NULL;
            PriorsMean=this->GetPriorsMeanMatrix();
            float Lambda=this->GetFlagMeanPriors();
            float MultiplicationFactor;
            if (PriorsMean !=NULL) {
                for (int m=0; m<numbmodal; m++) {
                    if(PriorsCov!=NULL){
                        MultiplicationFactor=1.0/PriorsCov[m+numbmodal*m];
                    }
                    else{
                        MultiplicationFactor=Lambda;
                    }
                    if (PriorsMean[m]<0) {
                        PriorsMean[m]=0;
                    }
                    cout<<"Mean was "<<MeanToModify[m];
                    float InverseCovFactor=1.0/MeanToModify[numbmodal+m+numbmodal*m];
                    MeanToModify[m]=(sumResp*MeanToModify[m]*InverseCovFactor+MultiplicationFactor*PriorsMean[m])/(MultiplicationFactor+sumResp*InverseCovFactor);
                    cout<<" and now is "<<MeanToModify[m]<<endl;
                }
            }
        }
    }
}





// Returns the float array of size numbmodal*numbmodal that will be used as scaling when using the constraint over the covariance in mode 8
float * TreeEM::MakeScalingVariance(){
    int numbmodal=this->GetNumberModalities();
    float * ScalingVariance=new float[numbmodal*numbmodal];
    float MeanDirect[MaxNumbModal];
    if (this->GetDistributionType()==2) {
        this->GetMeanDirect_bis(MeanDirect);
    }
    else{
        float * MeanFromDirect=this->GetMean();
        for (int m=0; m<numbmodal; m++) {
            MeanDirect[m]=MeanFromDirect[m];
        }
        for (int m=numbmodal; m<MaxNumbModal; m++) {
            MeanDirect[m]=0;
        }
    }
//    float * MeanDirect=this->GetMeanDirect();
    for (int m1=0; m1<numbmodal; m1++) {
        for (int m2=0; m2<numbmodal; m2++) {
            if (m1!=m2) {
                ScalingVariance[m1+m2*numbmodal]=0;
            }
            else{
//                ScalingVariance[m1+m2*numbmodal]=(MeanDirect[m1]*MeanDirect[m1]);
                ScalingVariance[m1+m2*numbmodal]=(MeanDirect[m1]);
            }
        }
    }
//    delete [] MeanDirect;
//    MeanDirect=NULL;
    return ScalingVariance;
 }

// Returns the pointer to the node with the smallest variance in terms of determinant
TreeEM * TreeEM::GetMiniVariance(){
    vector<TreeEM *> LeavesVector=this->FindRoot()->GetAllLeaves();
    int numbmodal=this->GetNumberModalities();
    int numbmodalSq=numbmodal*numbmodal;
    int numbLeaves=LeavesVector.size();
    TreeEM * LeaveMiniVariance=NULL;
    float DetMiniVariance=1E32;
    for (int l=0; l<numbLeaves; l++) {
        float * VarianceLeave=NULL;
        float * VarianceTest=LeavesVector[l]->GetVariance();
        if (VarianceTest==NULL || VarianceTest[0]==0) {
            VarianceLeave=LeavesVector[l]->GetVarianceDirect();
        }
        else{
            VarianceLeave=new float[numbmodalSq];
            for (int m=0; m<numbmodalSq; m++) {
                VarianceLeave[m]=VarianceTest[m];
            }
        }
//        float * VarianceLeave=LeavesVector[l]->GetVarianceDirect();
        float * ScalingVariance=LeavesVector[l]->MakeScalingVariance();
        if (this->GetFlagCovPriors()==4 ) {
            for (int m=0; m<numbmodal; m++) {
                ScalingVariance[m+m*numbmodal]=1;
            }
        }
//        int * Size= new int[4];
        int Size[4];
        Size[0]=Size[1]=Size[2]=Size[3]=numbmodal;
        float * VarianceToTest1=ProductMatrix(VarianceLeave, ScalingVariance, Size );
        float * VarianceToTest=ProductMatrix(ScalingVariance, VarianceToTest1, Size);
//        float DetLeave=determinant(VarianceLeave, numbmodal);
        float DetLeave=determinant(VarianceToTest, numbmodal);
        if (DetLeave<DetMiniVariance && LeavesVector[l]->GetNormWeight()>0.001) {
            DetMiniVariance=DetLeave;
            LeaveMiniVariance=LeavesVector[l];
        }
//        delete [] Size;
//        Size=NULL;
        delete [] VarianceToTest1;
        VarianceToTest1=NULL;
        delete [] ScalingVariance;
        ScalingVariance=NULL;
        delete [] VarianceToTest;
        VarianceToTest=NULL;
        delete [] VarianceLeave;
        VarianceLeave=NULL;
    }
    return LeaveMiniVariance;
}

void TreeEM::ModifyCovPriors(SEG_PARAMETERS * segment_param){
    // Only used when segment_param->flag_CovPriors is up no need to recheck it
    // First get all leaves of the tree susceptible to follow a covariance prior
    vector<TreeEM *> LeavesVector=this->GetAllLeaves();
    int numbLeaves=LeavesVector.size();
    int numbmodal=this->GetNumberModalities();
    int numbmodalSq=numbmodal*numbmodal;
    int numelmasked=this->GetNumberMaskedElements();
    for (int l=0; l<numbLeaves; l++) {
        if (LeavesVector[l]->GetDistributionType()==1) { // check that leaf follows Gaussian distribution
            switch (segment_param->CovPriorsType) {
                case 0:{
                    break;
                }
                case 1: {// case when using first strategy using directly diagonal
//                    float * PriorsCovMatrix=LeavesVector[l]->GetPriorsCovMatrix();
                    float * NewCovMatrix=new float [numbmodalSq];
                    float * VarianceLeave=LeavesVector[l]->GetVariance();
                    float * NormRespLeave=LeavesVector[l]->GetNormResp();
                    PrecisionTYPE sumResp=0;
                    for (int i=0; i<numelmasked; i++,NormRespLeave++) {
                        sumResp+=*NormRespLeave;
                    }
                    for (int m1=0; m1<numbmodal; m1++) {
                        for (int m2=0; m2<numbmodal; m2++) {
                            if (m1==m2) {
                                NewCovMatrix[m1+m2*numbmodal]=VarianceLeave[m1+m2*numbmodal]*sumResp;
                            }
                            else{
                                NewCovMatrix[m1+m2*numbmodal]=0;
                            }
                        }
                    }
                    LeavesVector[l]->SetCovPriorsMatrix(NewCovMatrix);
                    delete [] NewCovMatrix;
                    NewCovMatrix=NULL;
                }

                    break;
//                case 2: { // case when using strategy of logmean covariance matrix to enforce the covariance matrix
//                    float * CovPriors=this->GetPriorsCovMatrixGeneral(segment_param);
//                    float * NormRespLeave=LeavesVector[l]->GetNormResp();
//                    float * NewCovMatrix=new float[numbmodal*numbmodal];
//                    PrecisionTYPE sumResp=0;
//                    for (int i=0; i<numelmasked; i++) {
//                        sumResp+=(PrecisionTYPE)*NormRespLeave;
//                    }
//                    for (int m1=0; m1<numbmodal; m1++) {
//                        for (int m2=0; m2<numbmodal; m2++) {
//                            NewCovMatrix[m1+m2*numbmodal]=CovPriors[m1+m2*numbmodal]*sumResp;
//                        }
//                    }
//                    LeavesVector[l]->SetCovPriorsMatrix(NewCovMatrix);
//                    delete [] NewCovMatrix;
//                    NewCovMatrix=NULL;
//                }
//                    break;
                case 6:{
                    TreeEM * MiniPriorsVarianceTree=this->GetMiniVariance();
                    float * VarianceMiniTest=MiniPriorsVarianceTree->GetVariance();
                    float * VarianceMiniToSet=NULL;
                    if (VarianceMiniTest==NULL || VarianceMiniTest[0]==0) {
                        VarianceMiniToSet=MiniPriorsVarianceTree->GetVarianceDirect();
                    }
                    else{
                        VarianceMiniToSet=new float[numbmodalSq];
                        for (int m=0; m<numbmodalSq; m++) {
                            VarianceMiniToSet[m]=VarianceMiniTest[m];
                        }
                    }
                    //                    float * VarianceMiniToSet=MiniPriorsVarianceTree->GetVarianceDirect();
                    //                    int numbmodal=this->GetNumberModalities();
                    float * ScalingVariance=MiniPriorsVarianceTree->MakeScalingVariance();
                    float * ScalingVariance2=LeavesVector[l]->MakeScalingVariance();
                    float * ScalingInverted=InvertMatrix(ScalingVariance2, numbmodal);
                    
//                    int * Size= new int[4];
                    int Size[4];
                    Size[0]=Size[1]=Size[2]=Size[3]=numbmodal;
                    float * ScalingTot=ProductMatrix(ScalingVariance, ScalingInverted, Size);
                    float * VarianceToSet1=ProductMatrix(VarianceMiniToSet, ScalingTot, Size );
                    float * VarianceToSet=ProductMatrix(ScalingTot, VarianceToSet1, Size);
                    int numelmasked=this->GetNumberMaskedElements();
                    for (int m=0; m<numbmodalSq; m++) {
                        VarianceToSet[m]*=(numelmasked+numbmodal+1);
                    }
                    LeavesVector[l]->SetCovPriorsMatrix(VarianceToSet);
                    delete [] ScalingInverted;
                    ScalingInverted=NULL;
                    delete [] ScalingVariance2;
                    ScalingVariance2=NULL;
                    delete [] ScalingTot;
                    ScalingTot=NULL;
                    delete[] VarianceToSet1;
                    VarianceToSet1=NULL;
                    delete [] VarianceMiniToSet;
                    VarianceMiniToSet=NULL;
                    delete [] VarianceToSet;
                    VarianceToSet=NULL;
                    delete [] ScalingVariance;
                    ScalingVariance=NULL;
                }
                    break;
                case 7:{
                    TreeEM * MiniPriorsVarianceTree=this->GetMiniVariance();
                    float * VarianceMiniTest=MiniPriorsVarianceTree->GetVariance();
                    float * VarianceMiniToSet=NULL;
                    if (VarianceMiniTest==NULL || VarianceMiniTest[0]==0) {
                        VarianceMiniToSet=MiniPriorsVarianceTree->GetVarianceDirect();
                    }
                    else{
                        VarianceMiniToSet=new float[numbmodalSq];
                        for (int m=0; m<numbmodalSq; m++) {
                            VarianceMiniToSet[m]=VarianceMiniTest[m];
                        }
                    }
                    float * MiniNormResp=MiniPriorsVarianceTree->GetNormResp();
                    float sumRespMiniVar=0;
                    for (int i=0; i<numelmasked; i++) {
                        sumRespMiniVar+=MiniNormResp[i];
                    }
                    //                    float * VarianceMiniToSet=MiniPriorsVarianceTree->GetVarianceDirect();
                    //                    int numbmodal=this->GetNumberModalities();
                    float * ScalingVariance=MiniPriorsVarianceTree->MakeScalingVariance();
                    float * ScalingVariance2=LeavesVector[l]->MakeScalingVariance();
                    float * ScalingInverted=InvertMatrix(ScalingVariance2, numbmodal);
                    
//                    int * Size= new int[4];
                    int Size[4];
                    Size[0]=Size[1]=Size[2]=Size[3]=numbmodal;
                    float * ScalingTot=ProductMatrix(ScalingVariance, ScalingInverted, Size);
                    float * VarianceToSet1=ProductMatrix(VarianceMiniToSet, ScalingTot, Size );
                    float * VarianceToSet=ProductMatrix(ScalingTot, VarianceToSet1, Size);
//                    int numelmasked=this->GetNumberMaskedElements();
                    for (int m=0; m<numbmodalSq; m++) {
                        VarianceToSet[m]*=(sumRespMiniVar+numbmodal+1);
                    }
                    LeavesVector[l]->SetCovPriorsMatrix(VarianceToSet);
                    delete [] ScalingInverted;
                    ScalingInverted=NULL;
                    delete [] ScalingVariance2;
                    ScalingVariance2=NULL;
                    delete [] ScalingTot;
                    ScalingTot=NULL;
                    delete[] VarianceToSet1;
                    VarianceToSet1=NULL;
                    delete [] VarianceMiniToSet;
                    VarianceMiniToSet=NULL;
                    delete [] VarianceToSet;
                    VarianceToSet=NULL;
                    delete [] ScalingVariance;
                    ScalingVariance=NULL;
                }
                    break;
                case 8:{ // Using function optimising for Wishart, no need for any change (everything already scaled in the right way)
                    if (this->GetPriorsCovMatrixGeneral()==NULL || this->GetPriorsCovMatrixGeneral()[0]==0) {
                        this->UpdateCovPriors(segment_param);
                    }
                }
                    break;
                    case 9:{ // Using function optimising for Wishart, no need for any change (everything already scaled in the right way)
                        if (this->GetPriorsCovMatrixGeneral()==NULL || this->GetPriorsCovMatrixGeneral()[0]==0) {
                            this->UpdateCovPriors(segment_param);
                        }
                    }
                    break;
                default: {// Case where we adapt to the covariance matrix of the inlier with smallest determinant
                    TreeEM * MiniPriorsVarianceTree=this->GetMiniVariance();
                    float * VarianceMiniTest=MiniPriorsVarianceTree->GetVariance();
                    float * VarianceMiniToSet=NULL;
                    if (VarianceMiniTest==NULL || VarianceMiniTest[0]==0) {
                         VarianceMiniToSet=MiniPriorsVarianceTree->GetVarianceDirect();
                    }
                    else{
                        VarianceMiniToSet=new float[numbmodalSq];
                        for (int m=0; m<numbmodalSq; m++) {
                            VarianceMiniToSet[m]=VarianceMiniTest[m];
                        }
                    }
//                    float * VarianceMiniToSet=MiniPriorsVarianceTree->GetVarianceDirect();
//                    int numbmodal=this->GetNumberModalities();
                    float * ScalingVariance=MiniPriorsVarianceTree->MakeScalingVariance();
                    if (this->GetFlagCovPriors()==4) {
                        for (int m=0; m<numbmodal; m++) {
                            ScalingVariance[m+m*numbmodal]=1;
                        }
                    }
//                    int * Size= new int[4];
                    int Size[4];
                    Size[0]=Size[1]=Size[2]=Size[3]=numbmodal;
                    float * VarianceToSet1=ProductMatrix(VarianceMiniToSet, ScalingVariance, Size );
                    float * VarianceToSet=ProductMatrix(ScalingVariance, VarianceToSet1, Size);
                    int numelmasked=this->GetNumberMaskedElements();
                    for (int m=0; m<numbmodalSq; m++) {
                        VarianceToSet[m]*=(numelmasked+numbmodal+1);
                    }
                    this->FindRoot()->SetCovPriorsMatrix(VarianceToSet);
                    delete[] VarianceToSet1;
                    VarianceToSet1=NULL;
                    delete [] VarianceMiniToSet;
                    VarianceMiniToSet=NULL;
                    delete [] VarianceToSet;
                    VarianceToSet=NULL;
                    delete [] ScalingVariance;
                    ScalingVariance=NULL;
                }
                    break;
//                default:
//                    break;
            }
        }
    }

}

float * TreeEM::CreateCovPriorsFromExistingCovMatrices(){
    vector<TreeEM *> LeavesVector;
    if(this->GetFlagOutliers()!=3 && this->GetFlagOutliers()<5){
        LeavesVector=this->FindRoot()->GetAllLeaves();
    }
    else{
        LeavesVector=this->FindRoot()->GetChild(0)->GetAllLeaves();
    }
    int numbleaves=LeavesVector.size();
    vector<float *> CovarianceVector;
    vector<float> WeightVector;
    for (int l=0; l<numbleaves; l++) {
        if (LeavesVector[l]->GetDistributionType()!=2) {
            CovarianceVector.push_back(LeavesVector[l]->GetVariance());
            WeightVector.push_back(LeavesVector[l]->GetCompleteWeight());
        }
    }
    int numbmodal=this->GetNumberModalities();
    float * CovPriors=WeightedLogMean(CovarianceVector, WeightVector, numbmodal);
    return CovPriors;
}


// Returns in a float array the optimised parameters to use in the wishart distribution
float * TreeEM::CreateCovPriorsForInverseWishart(){
    vector<TreeEM*> LeavesVector=this->FindRoot()->GetAllLeaves();
    int numelmasked=this->GetNumberMaskedElements();
    int numbmodal=this->GetNumberModalities();
    int numbmodalSq=numbmodal*numbmodal;
    int numbleaves=LeavesVector.size();
    float * InvertedWishart=new float[numbmodalSq];
    for (int m1=0; m1<numbmodal; m1++) {
        for (int m2=0; m2<numbmodal; m2++) {
            InvertedWishart[m1+m2*numbmodal]=0;
        }
    }
    int numbGaussian=0;
    
    int CountGaussian=0;
    for (int l=0; l<numbleaves; l++) {
        if (LeavesVector[l]->GetDistributionType()==1) {
            numbGaussian++;
        float * MeanToUse=NULL;
            float * VarianceToUse=NULL;
        if (LeavesVector[l]->GetMean()!=NULL && LeavesVector[l]->GetMean()[0]!=0) {
            MeanToUse=new float [numbmodal];
            float * MeanTmp=LeavesVector[l]->GetMean();
            for (int m=0; m<numbmodal; m++) {
                MeanToUse[m]=MeanTmp[m];
            }
        }
        else{
            MeanToUse=LeavesVector[l]->GetMeanDirect();
        }
            if (LeavesVector[l]->GetVariance()!=NULL && LeavesVector[l]->GetVariance()[0]!=0) {
                VarianceToUse=new float [numbmodalSq];
                float * VarianceTmp=LeavesVector[l]->GetVariance();
                for (int m=0; m<numbmodalSq; m++) {
                    VarianceToUse[m]=VarianceTmp[m];
                }
            }
            else{
                VarianceToUse=LeavesVector[l]->GetVarianceDirect();
            }
        float * InvertedVariance=InvertMatrix(VarianceToUse, numbmodal);
//            Condition over minimum weight of Leaf
            if (LeavesVector[l]->GetNormWeight()>0.001) {
                CountGaussian++;
        for (int m1=0; m1<numbmodal; m1++) {
            for (int m2=0; m2<numbmodal; m2++) {
//                InvertedWishart[m1+m2*numbmodal]+=InvertedVariance[m1+m2*numbmodal]/(MeanToUse[m1]*MeanToUse[m2]);
//                Correction adopted on 24/09/2014
                InvertedWishart[m1+m2*numbmodal]+=InvertedVariance[m1+m2*numbmodal]*1/(expf(MeanToUse[m1]+MeanToUse[m2]));
                
            }
        }
            }
        delete [] InvertedVariance;
        InvertedVariance=NULL;
            delete [] VarianceToUse;
            VarianceToUse=NULL;
            delete [] MeanToUse;
            MeanToUse=NULL;
    }
}

    for(int m1=0;m1<numbmodal;m1++){
        for (int m2=0; m2<numbmodal;m2++) {
            InvertedWishart[m1+m2*numbmodal]/=(numelmasked*CountGaussian);
        }
    }

    float * WishartCovariance = InvertMatrix(InvertedWishart, numbmodal);
    
    delete [] InvertedWishart;
    InvertedWishart=NULL;
    if(this->GetFlagCovPriors()==8){
        return WishartCovariance;
    }
    
//    MAYBE TO ADD FOR INVERSE WISHART
    TreeEM * PotentialMiniVarianceTree=this->FindRoot()->GetMiniVariance();
    float * PotentialMiniVariance=PotentialMiniVarianceTree->GetVarianceDirect();
    float * MeanPotMin=PotentialMiniVarianceTree->GetMeanDirect();
    for(int m=0;m<numbmodal*numbmodal;m++){
        PotentialMiniVariance[m]*=numelmasked;
    }
    for (int m1=0; m1<numbmodal; m1++) {
        for (int m2=0; m2<numbmodal; m2++) {
            //                InvertedWishart[m1+m2*numbmodal]+=InvertedVariance[m1+m2*numbmodal]/(MeanToUse[m1]*MeanToUse[m2]);
            //                Correction adopted on 24/09/2014
            PotentialMiniVariance[m1+m2*numbmodal]*=(expf(MeanPotMin[m1]+MeanPotMin[m2]));
            
        }
    }
    delete [] MeanPotMin;
    float DetWC=determinant(WishartCovariance, numbmodal);
    float DetMini=determinant(PotentialMiniVariance, numbmodal);
    if(DetMini<DetWC){
        cout << "Mini Cov instead of WC"<<endl;
        delete [] WishartCovariance;
        delete [] PotentialMiniVariance;
        PotentialMiniVariance=NULL;
        this->SetFlagCovPriors(0);
        return NULL;
//        return PotentialMiniVariance;
    }
    else{
        cout<<"WC instead of mini cov"<<endl;
        delete [] PotentialMiniVariance;
        return WishartCovariance;

    }
    
}


// Update all the parameters of the model in a recursive way
void TreeEM::UpdateParametersCEM(int Child){
    int TypeTreeComponent=this->WhatTypeOfTreeComponent();
    if(TypeTreeComponent==LEAF){// Means it is a leaf
        /* For the moment only Gaussian distribution as simple distribution so no other case than the default one in the switch*/
        switch (this->GetDistributionType()) {
        default:
            this->UpdateGaussianParametersCEM(Child);
            //cout<<"Gaussian parameters updated";
            break;
        }
    }
    else{ // Recursive part
        int numbchild=this->GetNumberChildren();
        for (int c=0; c<numbchild; c++) {
            //cout<<"Updating parameters of child "<<c<<endl;
            this->GetChild(c)->UpdateParametersCEM(Child);
        }
    }
    return;
}

void TreeEM::UpdateGaussianParametersCEM(int c){
    if (this->GetDistributionType()!=1){
        cout<<"It is not a Gaussian distribution"<<endl;
        return;
    }
    this->UpdateGaussianMeanCEM(c);
    this->UpdateGaussianVarianceCEM(c);
    return;
}


void TreeEM::UpdateGaussianMeanCEM(int c){
//    int numel=this->GetNumberElements(); // number of elements in the image
    int numelmasked=this->GetNumberMaskedElements();
    int numbmodal=this->GetNumberModalities(); // number of modalities to consider
    //float * PointerToDataBegin=static_cast<float *>(this->GetDataImage()->data);
    //    float * PointerToDataBegin=this->MakeDataBFCorrected();
    float * PointerToDataBegin=this->GetDataBFCorrected();
//    int * HardSegUsed=this->GetHardSeg();
    for (int m=0;m<numbmodal;m++){
        float * PointerToImageBegin_PTR=&PointerToDataBegin[m*numelmasked]; // Points the data to the beginning of each modality image
        float * PointerToNormRespBegin_PTR=this->GetNormResp(); // Points to the beginning of the NormalizedResponsabilities
        int * HardSeg_PTR=this->GetHardSeg();
        double meantmp=0; // Initialisation of the numerator in the update of the mean
        double sumResp=0; // Initialisation of the denominator in the update of the mean
        float meantmpMarc=0.f; // Initialisation of the numerator in the update of the mean
        float sumRespMarc=0.f; // Initialisation of the denominator in the update of the mean
        //        int * L2S_PTR=this->GetL2S();
        int CountMoreThanOne=0;
        for(int i=0;i<numelmasked;i++,PointerToImageBegin_PTR++,PointerToNormRespBegin_PTR++,HardSeg_PTR++){
            /* Each time the considered voxel is active (<=> L2S contains an index), update the numerator and the denominator*/
            if(*HardSeg_PTR==c){
            meantmp+=(double)(*PointerToImageBegin_PTR)*(*PointerToNormRespBegin_PTR);
            meantmpMarc+=(*PointerToImageBegin_PTR)*(*PointerToNormRespBegin_PTR);
            if (*PointerToImageBegin_PTR>1) {
                CountMoreThanOne++;
                //                    cout<<"Pb in normalisation image";
            }
            sumResp+=(double)(*PointerToNormRespBegin_PTR);
            sumRespMarc+=(*PointerToNormRespBegin_PTR);
            }
        }
        if(CountMoreThanOne>0){
            //            cout<<"Transformed values more than one is "<<CountMoreThanOne<<endl;
        }
        if (sumResp!=0) {
            this->GetMean()[m]=meantmp/sumResp;
        }
        else{
            this->GetMean()[m]=meantmp/this->GetNumberMaskedElements();
        }
//        printf("HERE We are float %f / %f = %f\n", meantmpMarc, sumRespMarc,meantmpMarc/sumRespMarc);
//        printf("HERE We are double %g / %g = %g\n", meantmp, sumResp,meantmp/sumResp);
//        exit(1);

        //cout<<"Mean is now "<< this->GetMean()[m];
    }
    // Clearing memory
    //    if (PointerToDataBegin!=NULL) {
    //        delete [] PointerToDataBegin;
    //        PointerToDataBegin=NULL;
    //    }
    return;
}

void TreeEM::UpdateGaussianVarianceCEM(int c){

//    int numel=this->GetNumberElements();
    int numbmodal=this->GetNumberModalities();
    int numelmasked=this->GetNumberMaskedElements();
    PrecisionTYPE sumResp=0; // Initialisation of the denominator
    //float * PointerToDataBegin = static_cast<float *>(this->GetDataImage()->data);
    //    float * PointerToDataBegin=this->MakeDataBFCorrected();
    float * PointerToDataBegin=this->GetDataBFCorrected();
    float * PointerToDataBegin_PTR1=PointerToDataBegin;
    float * PointerToDataBegin_PTR2=PointerToDataBegin;
    float * NormalisedResponsabilities_PTR=this->GetNormResp();
    int * HardSeg_PTR=this->GetHardSeg();
    //    int * L2S_PTR=this->GetL2S();

    // Calculation of the denominator (sum over the active voxels of the normalised responsabilities)
    for (int i=0; i<numelmasked; i++,NormalisedResponsabilities_PTR++,HardSeg_PTR++) {
        if(*HardSeg_PTR==c){
        sumResp+=(PrecisionTYPE)(*NormalisedResponsabilities_PTR);
        }
    }

    float * VarianceToUpdateB=this->GetVariance();
    float VarianceToUpdate[MaxNumbModal*MaxNumbModal];
    for(int m1=0;m1<MaxNumbModal;m1++){
        for(int m2=0;m2<MaxNumbModal;m2++){
            if(m1<numbmodal&&m2<numbmodal){
                VarianceToUpdate[m1+m2*MaxNumbModal]=VarianceToUpdateB[m1+m2*numbmodal];
            }
            else{
                VarianceToUpdate[m1+m2*MaxNumbModal]=0;
            }
        }
    }
    float * MeanToUseB=this->GetMean();
    float MeanToUse[MaxNumbModal];
    for(int m=0;m<MaxNumbModal;m++){
        if(m<numbmodal){
            MeanToUse[m]=MeanToUseB[m];
        }
    }
    for(int m1=0;m1<numbmodal;m1++){
        // First data pointer to the beginning of the modality m1 considered
        for(int m2=0;m2<numbmodal;m2++){
            PointerToDataBegin_PTR1=&PointerToDataBegin[m1*numelmasked];
            PointerToDataBegin_PTR2=&PointerToDataBegin[m2*numelmasked]; // Second Data pointer to the beginning of the modality m2 considered
            NormalisedResponsabilities_PTR=this->GetNormResp(); // Reinitialisation of the responsabilities pointer to the beginning
            HardSeg_PTR=this->GetHardSeg();
            VarianceToUpdate[m1+m2*MaxNumbModal]=0;
            PrecisionTYPE VarianceToUpdate_tmp=0;
            for(int i=0;i<numelmasked;i++,PointerToDataBegin_PTR1++,PointerToDataBegin_PTR2++,NormalisedResponsabilities_PTR++,HardSeg_PTR++){
                // Update of the numerator of the Variance Calculation only if in the case of an active voxel
                if(*HardSeg_PTR==c){
                VarianceToUpdate_tmp+=(PrecisionTYPE)(*NormalisedResponsabilities_PTR)*((*PointerToDataBegin_PTR1)-MeanToUse[m1])*((*PointerToDataBegin_PTR2)-MeanToUse[m2]);
                }
            }
            if (sumResp !=0) {
                VarianceToUpdate[m1+m2*MaxNumbModal]=(float)VarianceToUpdate_tmp/sumResp;
                if (m1==m2) {
                    VarianceToUpdate[m1+m2*MaxNumbModal]=VarianceToUpdate[m1+m2*MaxNumbModal]<=1E-6?1E-6:VarianceToUpdate[m1+m2*MaxNumbModal]; // in order to avoid going to 0 if too sharp distribution but not changing non diagonal of variance
                }


            }
            else{
                VarianceToUpdate[m1+m2*MaxNumbModal]=VarianceToUpdate_tmp/numelmasked;// this->GetNumberMaskedElements();
            }
            // Use of the symmetry property of the Variance matrix
            VarianceToUpdate[m2+m1*MaxNumbModal]=VarianceToUpdate[m1+m2*MaxNumbModal];
        }
    }
    for(int m1=0;m1<numbmodal;m1++){
        for(int m2=0;m2<numbmodal;m2++){
            VarianceToUpdateB[m1+m2*numbmodal]=VarianceToUpdate[m1+m2*MaxNumbModal];
        }
    }
    // Clearing memory
    //    if (PointerToDataBegin!=NULL) {
    //        delete []  PointerToDataBegin;
    //        PointerToDataBegin=NULL;
    //    }
    return;
}




// Update the obtention of the bias field coefficients
void TreeEM::UpdateBFCoeffs(){
    //    float * BFCoeffsToUpdate=this->MakeFinalBFCoeffsChildren();
    float * BFCoeffsToUpdate=this->MakeBFCoeffsDirect();
    this->SetBFCoeffs(BFCoeffsToUpdate);
    // Clearing memory not needed anymore.
    if (BFCoeffsToUpdate!=NULL) {
        delete [] BFCoeffsToUpdate;
        BFCoeffsToUpdate=NULL;
    }
}

// Update the obtention of the bias field coefficients with separated BF
void TreeEM::UpdateBFCoeffsSeparated(vector<int> BFOrderperModality, int IndexModalitiesBFTogether){
    //    float * BFCoeffsToUpdate=this->MakeFinalBFCoeffsChildren();
    float * BFCoeffsToUpdate=this->MakeBFCoeffsSeparated(BFOrderperModality, IndexModalitiesBFTogether);
    this->SetBFCoeffsSeparated(BFCoeffsToUpdate, BFOrderperModality);
    // Clearing memory not needed anymore.
    if (BFCoeffsToUpdate!=NULL) {
        delete [] BFCoeffsToUpdate;
        BFCoeffsToUpdate=NULL;
    }
}
//// Update the Bias Field Correction
//void TreeEM::UpdateBFCorrection(){
//    float * BFCorrectionToUpdate=this->MakeBFCorrection();
//    this->SetBFCorrection(BFCorrectionToUpdate);
//    // Clearing memory not needed anymore
//    if(BFCorrectionToUpdate!=NULL){
//        delete [] BFCorrectionToUpdate;
//        BFCorrectionToUpdate=NULL;
//    }
//}

// Update the corrected Data
void TreeEM::UpdateDataBFCorrected(){
    float * DataBFCorrectedToUpdate=this->MakeDataBFCorrected();
    this->SetDataBFCorrected(DataBFCorrectedToUpdate);
    
    // Clearing memory not needed anymore
    if(DataBFCorrectedToUpdate!=NULL){
        delete [] DataBFCorrectedToUpdate;
        DataBFCorrectedToUpdate=NULL;
    }
}

// Update the corrected Data
void TreeEM::UpdateDataBFCorrectedSeparated(vector<int> BFOrderperModality){
    float * DataBFCorrectedToUpdate=this->MakeDataBFCorrectedSeparated(BFOrderperModality);
    this->SetDataBFCorrected(DataBFCorrectedToUpdate);
    
    // Clearing memory not needed anymore
    if(DataBFCorrectedToUpdate!=NULL){
        delete [] DataBFCorrectedToUpdate;
        DataBFCorrectedToUpdate=NULL;
    }
}


// Recursively obtain the NonNormWeight (sum over the voxels for one class of the normalised responsabilities)
void TreeEM::UpdateNonNormWeights(){
    int numelmasked=this->GetNumberMaskedElements();
    int numbchild=this->GetNumberChildren();
    this->SetNonNormWeight(0);
    float * NormResp_PTR=this->GetNormResp();
    float NonNormWeightToSet=0;
    for (int i=0; i<numelmasked; i++, NormResp_PTR++) {
        NonNormWeightToSet+=*NormResp_PTR;
    }
    this->SetNonNormWeight(NonNormWeightToSet);
//    for(int i=0;i<numelmasked;i++,NormResp_PTR++){
//        this->SetNonNormWeight((PrecisionTYPE)this->GetNonNormWeight()+(*NormResp_PTR));
//    }
    for(int c=0;c<numbchild;c++){
        this->GetChild(c)->UpdateNonNormWeights();
    }
    return;
}

// Recursively obtain the NonNormWeight (sum over the voxels for one class of the normalised responsabilities)
void TreeEM::UpdateNonNormWeightsCEM(int c){
    int numelmasked=this->GetNumberMaskedElements();
    int numbchild=this->GetNumberChildren();
    this->SetNonNormWeight(0);
    float * NormResp_PTR=this->GetNormResp();
    int * HardSeg_PTR=this->GetHardSeg();
    for(int i=0;i<numelmasked;i++,NormResp_PTR++,HardSeg_PTR++){
        if(*HardSeg_PTR==c){
        this->SetNonNormWeight((PrecisionTYPE)this->GetNonNormWeight()+(*NormResp_PTR));
        }
    }
    for(int c=0;c<numbchild;c++){
        this->GetChild(c)->UpdateNonNormWeights();
    }
    return;
}


// Recursively Update the normalised weights when the non normalised ones are obtained
void TreeEM::UpdateNormWeights(){
    // First determination of the normalisation factor for the children
    PrecisionTYPE SumNonNormWeights=0;
    int numbchild=this->GetNumberChildren();
    for (int c=0;c<numbchild; c++) {
        SumNonNormWeights+=(PrecisionTYPE)this->GetChild(c)->GetNonNormWeight();
    }
    // Then normalisation of the not normalised weights for the children
    for (int c=0; c<numbchild; c++) {
        if (SumNonNormWeights>0) {
            this->GetChild(c)->SetNormWeight((PrecisionTYPE)this->GetChild(c)->GetNonNormWeight()/SumNonNormWeights);
        }
        else{// in case sum of the weights is 0
            this->GetChild(c)->SetNormWeight(1.0/this->GetNumberChildren());
        }
        //cout<< "Norm weight of child "<<c<<" is of value "<<this->GetChild(c)->GetNormWeight()<<endl;
        this->GetChild(c)->UpdateNormWeights(); // Recursive part
    }

    return;
}

// Modify NonNormSum using weights, needed Gaussian distributions, Atlases and MRF values
void TreeEM::MakeNonNormWeightedSum(float * NonNormSum, SEG_PARAMETERS * segment_param){
    int numbchild=this->GetNumberChildren();
    int numelmasked=this->GetNumberMaskedElements();
//    int numel=this->GetNumberElements();
    if(numbchild==0){// case where it is a leaf
        float* DistSum_tmp=NULL;
        float * DistSum_tmp_PTR=NULL;
        switch (this->GetDistributionType()){
        case 2:{
             DistSum_tmp=this->MakeUniformDistribution();
             DistSum_tmp_PTR=DistSum_tmp;
            if(this->GetPriorsDirect()==NULL){
            float NormWeightUsed=this->GetPartNormWeight();
                TreeEM* NodePriors=this->FindGeneralClassPriors();
                if(NodePriors!=NULL && this->FindRoot()->GetFlagOutliers()!=3){ // case where there are some priors in the tree but not at the first level (outliers model used there) // ADDITION OF SECOND CONDITION ON APRIL 2016 6th
                    float ComplementNormWeightUsed=NodePriors->GetPartNormWeight();
                    NormWeightUsed*=ComplementNormWeightUsed;
                }

            for(int i=0;i<numelmasked;i++,DistSum_tmp_PTR++){
                (*DistSum_tmp_PTR)*=NormWeightUsed;
            }
            }
            break;
        }

        default : {
            int CountZeroValuesNonNorm=0;
             DistSum_tmp=this->MakeGaussianDistribution();
             DistSum_tmp_PTR=DistSum_tmp;
            if(this->GetPriorsDirect()==NULL){// case we have to multiply by the normalised weight until
                float NormWeightUsed=this->GetPartNormWeight();
                TreeEM* NodePriors=this->FindGeneralClassPriors();
                if(NodePriors!=NULL && this->FindRoot()->GetFlagOutliers()!=3){ // case where there are some priors in the tree but not at the first level (outliers model used there) // ADDITION OF SECOND CONDITION ON APRIL 2016 6th
                float ComplementNormWeightUsed=NodePriors->GetPartNormWeight();
                NormWeightUsed*=ComplementNormWeightUsed;
                }
                for(int i=0;i<numelmasked;i++,DistSum_tmp_PTR++){
                    (*DistSum_tmp_PTR)*=NormWeightUsed;
                    if(*DistSum_tmp_PTR==0){
                        CountZeroValuesNonNorm++;
                    }
                }
//                cout<< "Zero values after weighting is "<< CountZeroValuesNonNorm<<endl;
            }
        break;
        }
        }

            if(this->GetPriors()!=NULL){// case where we are using atlases
//                int CountZeroValuesNonNorm=0;
                DistSum_tmp_PTR=DistSum_tmp;
//                int *L2S_PTR=this->GetL2S();
//                float *Priors_PTR=new float[numel];
//                this->AdaptPriors(segment_param,Priors_PTR);
//                float * Priors_PTR=this->GetPartPriorsAdapted();
//                float * Priors_PTR=this->GetPartPriorsAdaptedMasked();
                float * Priors_PTR=this->GetPartPriorsAdapted_bis();
                for (int i=0; i<numelmasked; i++) {
                    DistSum_tmp_PTR[i]*=Priors_PTR[i];
                }
//                CountZeroValuesNonNorm=0;
////                float * Priors_PTR=static_cast<float*>(this->GetPriors()->data);
//                for(int i=0;i<numel;i++,L2S_PTR++){
//                    if(*L2S_PTR>=0){
//                        (*DistSum_tmp_PTR)*=Priors_PTR[i];
//                        if(*DistSum_tmp_PTR==0){
//                            CountZeroValuesNonNorm++;
//                        }
//                        DistSum_tmp_PTR++;
//                    }
//                }
//                cout<< "Zero Values after priors is "<< CountZeroValuesNonNorm<<endl;
//                delete[] Priors_PTR;
//                Priors_PTR=NULL;
            }

            if(this->GetMRF()!=NULL && !this->IsMRFZero()){ // Case where we have an MRF to apply
                DistSum_tmp_PTR=DistSum_tmp;
                float * MRFToUse=this->GetMRF();
                int CountZeroValuesNonNorm=0;
                for(int i=0;i<numelmasked;i++,DistSum_tmp_PTR++){
                    (*DistSum_tmp_PTR)*=MRFToUse[i];
                    if(*DistSum_tmp_PTR==0){
                        CountZeroValuesNonNorm++;
                    }
                }
//                cout<< "Zero value after MRF is "<<CountZeroValuesNonNorm<<endl;
            }
//            SaveTmpResultMasked(DistSum_tmp,"/Users/Carole/Documents/PhD/NormRespMRFTest.nii.gz");
            // Copying the final result in the destined float array
            float * NonNormSum_PTR=NonNormSum;
            DistSum_tmp_PTR=DistSum_tmp;
            int CountZeroValuesNonNorm=0;
            for(int i=0;i<numelmasked;i++,NonNormSum_PTR++,DistSum_tmp_PTR++){
                *NonNormSum_PTR=*DistSum_tmp_PTR;
                if(*NonNormSum_PTR==0){
                    CountZeroValuesNonNorm++;
                }
            }
//            cout<< "NonNorm zero values are : "<<CountZeroValuesNonNorm<<endl;
//            SaveTmpResultMasked(NonNormSum,"/Users/Carole/Documents/PhD/NormRespMRFTest.nii.gz");
            // Clearing memory not needed anymore
            delete[] DistSum_tmp;

            DistSum_tmp=NULL;

    }

    else {
        for(int c=0;c<numbchild;c++){
            // Initialisation of temporary result
            float * DistSum_tmp=new float[numelmasked];
            for(int i=0;i<numelmasked;i++){
                DistSum_tmp[i]=0;
            }
            this->GetChild(c)->MakeNonNormWeightedSum(DistSum_tmp,segment_param); // recursive part
            float * NonNormSum_PTR=NonNormSum;
            float * DistSum_tmp_PTR=DistSum_tmp;
            float NormWeightUsed=1;
            //            if(!this->GetChild(c)->IsLeaf()&&this->GetChild(c)->GetPriorsDirect()==NULL){
            //                NormWeightUsed=this->GetChild(c)->GetNormWeight();
            //            }
            for(int i=0;i<numelmasked;i++,NonNormSum_PTR++,DistSum_tmp_PTR++){
                (*NonNormSum_PTR)+=*DistSum_tmp_PTR*NormWeightUsed;
            }
            delete [] DistSum_tmp;
            DistSum_tmp=NULL;
        }

    }

    return;
}

// Initialise NormResp with existing priors values
void TreeEM::InitialiseNormResp(){
    int numelmasked=this->GetNumberMaskedElements();
    int numel=this->GetNumberElements();
    float * NormRespInit=NULL;
    float * NormRespInit_PTR=NULL;
    if(this->IsLeaf()){ // Copying Easily the priors into NormResp if leaf
//        NormRespInit=this->GetNormResp();
//        if(NormRespInit!=NULL){
//            delete [] NormRespInit;
//            NormRespInit=NULL;
//        }
        if (this->GetFlagOutliers()==4) {
            NormRespInit=new float[2*numelmasked];
            for(int i=0;i<numelmasked;i++){
                NormRespInit[i]=0;
                NormRespInit[i+numelmasked]=1;
            }
        }
        else{
            NormRespInit=new float[numelmasked];
            for(int i=0;i<numelmasked;i++){
                NormRespInit[i]=0;
            }
        }
            NormRespInit_PTR=NormRespInit;
            if(this->GetPriorsAdaptedDirect()!=NULL){//case where there are some priors to put as initial values for the normalised responsabilities
//                this->SaveTmpResult(this->GetParent()->GetPriorsAdaptedDirect(), "/Users/Carole/Documents/PhD/Test.nii.gz");
//                this->SaveTmpResult(this->GetPriorsAdaptedDirect(), "/Users/Carole/Documents/PhD/Test.nii.gz");
                float * PriorsPart=this->GetPartPriorsAdapted();
                float * Priors_PTR=PriorsPart;
//                this->SaveTmpResult(Priors_PTR, "/Users/Carole/Documents/PhD/TestPriorsAdapted.nii.gz");
                int * L2S_PTR=this->GetL2S();
                for(int i=0;i<numel;i++,Priors_PTR++,L2S_PTR++){
                    if(*L2S_PTR>=0){
                    *NormRespInit_PTR=*Priors_PTR;
                        NormRespInit_PTR++;
                    }
                }
                delete [] PriorsPart;
                PriorsPart=NULL;
        }
            else{
                float NormWeightUsed=this->GetNormWeight();
                for(int i=0;i<numelmasked;i++){
                    NormRespInit[i]=NormWeightUsed;
                }
            }
            float NormWeightNormalisation=this->GetPartNormWeightAboveTopPriors();
            for(int i=0;i<numelmasked;i++){
                NormRespInit[i]*=NormWeightNormalisation;
            }
            this->SetNormResp(NormRespInit);
            delete[] NormRespInit;
            NormRespInit=NULL;
    }
    else{ // Warning What to put in NormResp at beginning if not leaf
        int numbchild=this->GetNumberChildren();
//        NormRespInit=this->GetNormResp();
//        if(NormRespInit!=NULL){
//            delete [] NormRespInit;
//            NormRespInit=NULL;
//        }
        if (this->GetFlagOutliers()==4) {
            NormRespInit=new float[2*numelmasked];
            for(int i=0;i<numelmasked;i++){
                NormRespInit[i]=0;
                NormRespInit[i+numelmasked]=1;
            }
        }
        else{
            NormRespInit=new float[numelmasked];
            for(int i=0;i<numelmasked;i++){
                NormRespInit[i]=0;
            }
        }
        for(int c=0;c<numbchild;c++){
            this->GetChild(c)->InitialiseNormResp(); // Recursive part
            float * NormRespToAdd_PTR=this->GetChild(c)->GetNormResp();
            for(int i=0;i<numelmasked;i++,NormRespToAdd_PTR++){
                NormRespInit[i]+=*NormRespToAdd_PTR;
            }
        }
        
//        float NormWeightToUse=this->GetNormWeight();
//        for(int i=0;i<numelmasked;i++){
//            NormRespInit[i]*=NormWeightToUse;
//        }
        this->SetNormResp(NormRespInit);
        delete [] NormRespInit;
        NormRespInit=NULL;
    }
    return;
}

void TreeEM::MakeNonNormWeightedSumCEM(float * NonNormSum){
    int numbchild=this->GetNumberChildren();
    int numelmasked=this->GetNumberMaskedElements();
//    int numel=this->GetNumberElements();
    if(numbchild==0){// case where it is a leaf
        switch (this->GetDistributionType()){
        default : {
            float * DistSum_tmp=this->MakeGaussianDistribution();
            float * DistSum_tmp_PTR=DistSum_tmp;
            if(this->GetPriorsDirect()==NULL){// case we have to multiply by the normalised weight
                float NormWeightUsed=this->GetPartNormWeight();
                for(int i=0;i<numelmasked;i++,DistSum_tmp_PTR++){
                    (*DistSum_tmp_PTR)*=NormWeightUsed;
                }
            }
//            if(this->GetPriors()!=NULL){// case where we are using atlases
//                DistSum_tmp_PTR=DistSum_tmp;
//                int *L2S_PTR=this->GetL2S();
//                float * Priors_PTR=static_cast<float*>(this->GetPriors()->data);
//                for(int i=0;i<numel;i++,L2S_PTR++,Priors_PTR++){
//                    if(*L2S_PTR>=0){
//                        (*DistSum_tmp_PTR)*=*Priors_PTR;
//                        DistSum_tmp_PTR++;
//                    }
//                }
//            }
            // Copying the final result in the destined float array
            float * NonNormSum_PTR=NonNormSum;
            DistSum_tmp_PTR=DistSum_tmp;
            for(int i=0;i<numelmasked;i++,NonNormSum_PTR++,DistSum_tmp_PTR++){
                *NonNormSum_PTR=*DistSum_tmp_PTR;
            }
            // Clearing memory not needed anymore
            delete[] DistSum_tmp;
            DistSum_tmp=NULL;

        }
        }
    }

    else {
        for(int c=0;c<numbchild;c++){
            // Initialisation of temporary result
            float * DistSum_tmp=new float[numelmasked];
            for(int i=0;i<numelmasked;i++){
                DistSum_tmp[i]=0;
            }
            this->GetChild(c)->MakeNonNormWeightedSumCEM(DistSum_tmp); // recursive part
            float * NonNormSum_PTR=NonNormSum;
            float * DistSum_tmp_PTR=DistSum_tmp;
            float NormWeightUsed=1;
            //            if(!this->GetChild(c)->IsLeaf()&&this->GetChild(c)->GetPriorsDirect()==NULL){
            //                NormWeightUsed=this->GetChild(c)->GetNormWeight();
            //            }
            for(int i=0;i<numelmasked;i++,NonNormSum_PTR++,DistSum_tmp_PTR++){
                (*NonNormSum_PTR)+=*DistSum_tmp_PTR*NormWeightUsed;
            }
            delete [] DistSum_tmp;
            DistSum_tmp=NULL;
        }

    }

    return;
}

// Modify WeightedDist to give the weighted dist of the children or itself if it is a leaf
void TreeEM::MakeWeightedDist(float * WeightedDist){
    int numbchild=this->GetNumberChildren();
    int numelmasked=this->GetNumberMaskedElements();
    //    int numel=this->GetNumberElements();
    if(numbchild==0){// case where it is a leaf
        switch (this->GetDistributionType()){
        case 2: {// case of uniform distribution : appears when outlier model is used
            float * DistSum_tmp=this->MakeUniformDistribution();
            float * WeightedDist_PTR=WeightedDist;
            float * DistSum_tmp_PTR=DistSum_tmp;
            for(int i=0;i<numelmasked;i++,WeightedDist_PTR++,DistSum_tmp_PTR++){
                *WeightedDist_PTR=*DistSum_tmp_PTR;
            }
            // Clearing memory not needed anymore
            delete[] DistSum_tmp;
            DistSum_tmp=NULL;
            break;
            }

        default : {
            float * DistSum_tmp=this->MakeGaussianDistribution();
            float * DistSum_tmp_PTR=DistSum_tmp;

            // Copying the final result in the destined float array
            float * WeightedDist_PTR=WeightedDist;
//            DistSum_tmp_PTR=DistSum_tmp;
            for(int i=0;i<numelmasked;i++,WeightedDist_PTR++,DistSum_tmp_PTR++){
                *WeightedDist_PTR=*DistSum_tmp_PTR;
                if (*DistSum_tmp_PTR>1E32) {
                    vector<int> HierarchyVector=this->GetHierarchyVector();
                    cout<< "Pb at index "<<i<<" for weighted distribution, risk to infinity"<<endl;
                }
            }
            // Clearing memory not needed anymore
            delete[] DistSum_tmp;
            DistSum_tmp=NULL;
            break;
        }

        }
    }
    else { // when no a leaf, weighted sum of the children distributions according to their normalised weight
        for(int c=0;c<numbchild;c++){
            // Initialisation of temporary result
            float * DistSum_tmp=new float[numelmasked];
            for(int i=0;i<numelmasked;i++){
                DistSum_tmp[i]=0;
            }
            this->GetChild(c)->MakeWeightedDist(DistSum_tmp); // recursive part

            float * WeightedDist_PTR=WeightedDist;
            float * DistSum_tmp_PTR=DistSum_tmp;
            float NormWeightUsed=this->GetChild(c)->GetNormWeight();
            if(NormWeightUsed>10E-6){
            for(int i=0;i<numelmasked;i++,WeightedDist_PTR++,DistSum_tmp_PTR++){
                (*WeightedDist_PTR)+=NormWeightUsed*(*DistSum_tmp_PTR);
            }
        }
            else{
                if(this->GetChild(c)->GetDistributionType()!=2){
                cout<<"Weight of class is 0 or close to 0"<<endl;
                }
            }
            delete [] DistSum_tmp;
            DistSum_tmp=NULL;
        }
    }
    return;
}

void TreeEM::MakeWeightedDistPriors(float * WeightedDist){
    int numbchild=this->GetNumberChildren();
    int numelmasked=this->GetNumberMaskedElements();
    //    int numel=this->GetNumberElements();
    if(numbchild==0){// case where it is a leaf
        switch (this->GetDistributionType()){
            case 2: {// case of uniform distribution : appears when outlier model is used
                float * DistSum_tmp=this->MakeUniformDistribution();
                float * WeightedDist_PTR=WeightedDist;
                float * DistSum_tmp_PTR=DistSum_tmp;
                for(int i=0;i<numelmasked;i++,WeightedDist_PTR++,DistSum_tmp_PTR++){
                    *WeightedDist_PTR=*DistSum_tmp_PTR;
                }
                // Clearing memory not needed anymore
                delete[] DistSum_tmp;
                DistSum_tmp=NULL;
                break;
            }
                
            default : {
                float * DistSum_tmp=this->MakeGaussianDistribution();
                float * DistSum_tmp_PTR=DistSum_tmp;
                
                // Copying the final result in the destined float array
                float * WeightedDist_PTR=WeightedDist;
                //            DistSum_tmp_PTR=DistSum_tmp;
                for(int i=0;i<numelmasked;i++,WeightedDist_PTR++,DistSum_tmp_PTR++){
                    *WeightedDist_PTR=*DistSum_tmp_PTR;
                    if (*DistSum_tmp_PTR>1E32) {
                        vector<int> HierarchyVector=this->GetHierarchyVector();
                        cout<< "Pb at index "<<i<<" for weighted distribution, risk to infinity"<<endl;
                    }
                }
                // Clearing memory not needed anymore
                delete[] DistSum_tmp;
                DistSum_tmp=NULL;
                break;
            }
                
        }
    }
    else {
        for(int c=0;c<numbchild;c++){
            // Initialisation of temporary result
            float * DistSum_tmp=new float[numelmasked];
            for(int i=0;i<numelmasked;i++){
                DistSum_tmp[i]=0;
            }
            this->GetChild(c)->MakeWeightedDist(DistSum_tmp); // recursive part
            
            float * WeightedDist_PTR=WeightedDist;
            float * DistSum_tmp_PTR=DistSum_tmp;
            if(this->GetChild(c)->GetPriorsAdaptedDirect()==NULL){
            float NormWeightUsed=this->GetChild(c)->GetNormWeight();
            for(int i=0;i<numelmasked;i++,WeightedDist_PTR++,DistSum_tmp_PTR++){
                (*WeightedDist_PTR)+=NormWeightUsed*(*DistSum_tmp_PTR);
            }
            }
            else{
                float * WeightToUse_PTR=this->GetChild(c)->GetPriorsAdaptedDirect();
                int * L2S_PTR=this->GetL2S();
                int numel=this->GetNumberElements();
                for(int i=0;i<numel;i++,L2S_PTR++,WeightToUse_PTR++){
                    if (*L2S_PTR>=0) {
                        (*WeightedDist_PTR)+=*WeightToUse_PTR*(*DistSum_tmp_PTR);
                        WeightedDist_PTR++;
                        DistSum_tmp_PTR++;
                    }
                }
            }
            delete [] DistSum_tmp;
            DistSum_tmp=NULL;
        }
    }
    return;
}

void TreeEM::UpdateNonNormResp(SEG_PARAMETERS * segment_param){
    int numbchild = this->GetNumberChildren();
    int numelmasked=this->GetNumberMaskedElements();
    // Allocation and initialisation of the needed float array
    float * NonNormRespUpdate=new float[numelmasked];
    for(int i=0;i<numelmasked;i++){
        NonNormRespUpdate[i]=0;
    }
    this->MakeNonNormWeightedSum(NonNormRespUpdate, segment_param);
    // SetNormResp
    if (this->GetFlagOutliers()==4) {
        float * NonNormRespBisToUpdate=new float [2*numelmasked];
        for (int i=0; i<numelmasked; i++) {
            NonNormRespBisToUpdate[i]=NonNormRespUpdate[i];
            NonNormRespBisToUpdate[i+numelmasked]=1;
        }
        this->SetNormResp(NonNormRespBisToUpdate);
        delete [] NonNormRespBisToUpdate;
        NonNormRespBisToUpdate=NULL;
    }
    else{
    this->SetNormResp(NonNormRespUpdate);
    }
    // Clearing Memory
    if(NonNormRespUpdate!=NULL){
        delete [] NonNormRespUpdate;
        NonNormRespUpdate=NULL;
    }
    // Recursivity
    for(int c=0;c<numbchild;c++){
        this->GetChild(c)->UpdateNonNormResp(segment_param);
    }
    return;
}

void TreeEM::UpdateNonNormRespCEM(){
    int numbchild = this->GetNumberChildren();
    int numelmasked=this->GetNumberMaskedElements();
    // Allocation and initialisation of the needed float array
    float * NonNormRespUpdate=new float[numelmasked];
    for(int i=0;i<numelmasked;i++){
        NonNormRespUpdate[i]=0;
    }
    this->MakeNonNormWeightedSumCEM(NonNormRespUpdate);
    // SetNormResp
    this->SetNormResp(NonNormRespUpdate);
    // Clearing Memory
    if(NonNormRespUpdate!=NULL){
        delete [] NonNormRespUpdate;
        NonNormRespUpdate=NULL;
    }
    // Recursivity
    for(int c=0;c<numbchild;c++){
        this->GetChild(c)->UpdateNonNormRespCEM();
    }
    return;
}

void TreeEM::UpdateNormResp(){
    int CountNormRespUpdatePb=0;
    int numbchild = this->GetNumberChildren();
    int numelmasked=this->GetNumberMaskedElements();
    if(this->GetParent()!=NULL){
        float * RootNonNormResp=this->FindRoot()->GetNormResp();
        float * NonNormRespToNormalise=this->GetNormResp();
        // Initialisation of the needed pointers for the normalisation
        float * RootNonNormResp_PTR=RootNonNormResp;
        float * NonNormRespToNormalise_PTR=NonNormRespToNormalise;
        // Normalisation if not root
        float MaxDifferenceToOne=0;
        int CountPbZero=0;
        int CountNeg=0;
        for(int i=0;i<numelmasked;i++,RootNonNormResp_PTR++,NonNormRespToNormalise_PTR++){
            if(*RootNonNormResp_PTR>-1E-6){
                if(*RootNonNormResp_PTR<*NonNormRespToNormalise_PTR){
                    //                cout<<"Possible problem at index "<<i<<endl;
                }
                if(*RootNonNormResp_PTR==0){
                    CountPbZero++;
//                    cout<<"RootNonNormResp is equal to 0 at index "<<i<<endl;
                    *NonNormRespToNormalise_PTR=0;
                    *NonNormRespToNormalise_PTR=1E-6;
                    if (this->GetFlagOutliers()==4) {
                        *NonNormRespToNormalise_PTR=this->GetNormWeight();
                    }
                }
                else{
                *NonNormRespToNormalise_PTR=(*NonNormRespToNormalise_PTR)/(*RootNonNormResp_PTR);
                }
                if(*NonNormRespToNormalise_PTR>1+1E-6){
                    CountNormRespUpdatePb++;
                    if(*NonNormRespToNormalise_PTR-1>MaxDifferenceToOne){
                        MaxDifferenceToOne=*NonNormRespToNormalise_PTR-1;
                    }
                }
            }
            else{
                CountNeg++;
                *NonNormRespToNormalise_PTR=1.0;
//                cout<<"RootNonNormResp is negative at index "<<i<<endl;
            }
        }
        if(CountPbZero>0){
//        cout<< "CountZeroPb at root is "<<CountPbZero;
        }
        if(CountNeg>0){
            cout<<"CountNeg is "<<CountNeg<<endl;
        }
        if(CountNormRespUpdatePb>0){
            cout<<"CountNormRespPb is "<<CountNormRespUpdatePb<<" and the max difference is "<<MaxDifferenceToOne<<endl;
        }
    }
    else{
        //        cout<<"We do not change the norm resp of the root at first"<<endl;
    }

    // Recursivity
    for(int c=0;c<numbchild;c++){
        this->GetChild(c)->UpdateNormResp();
    }
    return;
}

void TreeEM::UpdateTypicality(SEG_PARAMETERS * segment_param){
    if (this->GetFlagOutliers()!=4 ) {
        return;
    }
    else{
        int numbchild=this->GetNumberChildren();
        int numelmasked=this->GetNumberMaskedElements();
        if (this->IsLeaf()) {
            float * NormRespTyp=&this->GetNormResp()[numelmasked];
            float * Typicality=this->MakeTypicalityWeight(segment_param);
            string FilenameMSOutliers=nifti_makebasename(segment_param->filename_out[0].c_str());
            FilenameMSOutliers+="_EMVL_MSOut.nii.gz";
//            this->SaveTmpResultMasked(Typicality, FilenameMSOutliers);
            for (int i=0; i<numelmasked; i++) {
                NormRespTyp[i]=Typicality[i];
            }
            delete [] Typicality;
            string FilenameNormResp=nifti_makebasename(segment_param->filename_out[0].c_str());
            FilenameNormResp+="_EMVL_NormResp.nii.gz";
//            this->SaveTmpResultMasked(this->GetNormResp(), FilenameNormResp);
        }
        else{
            for (int c=0; c<numbchild; c++) {
                this->GetChild(c)->UpdateTypicality(segment_param);
            }
        }
        
    }
}

void TreeEM::UpdateHardSeg(){
    if(!this->IsRoot()){
        return this->GetParent()->UpdateHardSeg();
    }
    else{
        this->MakeHardSeg();
    }
}

void TreeEM::UpdateNormRespRoot(){
    int numelmasked=this->GetNumberMaskedElements();
    float * RootNonNormResp=this->FindRoot()->GetNormResp();
    float * RootNonNormResp_PTR=RootNonNormResp;
    for(int i=0;i<numelmasked;i++,RootNonNormResp_PTR++){
        if(*RootNonNormResp_PTR>0){
            *RootNonNormResp_PTR/=*RootNonNormResp_PTR;
        }
        else{
            *RootNonNormResp_PTR=1;
        }
    }
}

//// Avoiding 0 in RespRoot if possible
//void TreeEM::ZeroNormRespRootToUniform(){
////    Only possible for case in which there is an outlier model and where there is at least one uniform class.
//}

//void TreeEM::UpdateNormResp(){
//    int CountNormRespUpdatePb=0;
//    int numbchild = this->GetNumberChildren();
//    int numelmasked=this->GetNumberMaskedElements();
//    // Allocation and initialisation of the needed float array
//    float * RootNonNormResp=new float [numelmasked];
//    float * NonNormRespToNormalise=new float[numelmasked];
//    float * NormRespUpdate=new float[numelmasked];
//    for(int i=0;i<numelmasked;i++){
//        RootNonNormResp[i]=0;
//        NonNormRespToNormalise[i]=0;
//        NormRespUpdate[i]=0;
//    }
//    this->FindRoot()->MakeNonNormWeightedSum(RootNonNormResp);
//    this->MakeNonNormWeightedSum(NonNormRespToNormalise);
//    // Initialisation of the needed pointers for the normalisation
//    float * RootNonNormResp_PTR=RootNonNormResp;
//    float * NonNormRespToNormalise_PTR=NonNormRespToNormalise;
//    float * NormRespUpdate_PTR=NormRespUpdate;
//    // Normalisation
//    for(int i=0;i<numelmasked;i++,NormRespUpdate_PTR++,RootNonNormResp_PTR++,NonNormRespToNormalise_PTR++){
//        if(*RootNonNormResp_PTR>0){
//            *NormRespUpdate_PTR=(*NonNormRespToNormalise_PTR)/(*RootNonNormResp_PTR);
//            if(*NormRespUpdate_PTR>1+1E-6){
//                CountNormRespUpdatePb++;
//            }
//        }
//        else{
//            *NormRespUpdate_PTR=1.0;
//        }
//    }
////    cout<<"CountNormRespUpdatePb is "<<CountNormRespUpdatePb<<endl;
//    // SetNormResp
//    this->SetNormResp(NormRespUpdate);
//    // Clearing Memory
//    if(RootNonNormResp!=NULL){
//        delete [] RootNonNormResp;
//        RootNonNormResp=NULL;
//    }
//    if(NonNormRespToNormalise!=NULL){
//        delete [] NonNormRespToNormalise;
//        NonNormRespToNormalise=NULL;
//    }
//    if(NormRespUpdate!=NULL){
//        delete [] NormRespUpdate;
//        NormRespUpdate=NULL;
//    }
//    // Recursivity
//    for(int c=0;c<numbchild;c++){
//        this->GetChild(c)->UpdateNormResp();
//    }
//return;
//}

// Return a pointer to a float array of size numelmasked representing a uniform distribution
float * TreeEM::MakeUniformDistribution(){
    if(this->GetDistributionType()!=2){
        cout<<"This is not a leaf with uniform distribution : cannot be made uniform"<<endl;
        return NULL;
    }
    int numelmasked=this->GetNumberMaskedElements();
    float * UniformDistOutput=new float[numelmasked];
    for(int i=0;i<numelmasked;i++){
        UniformDistOutput[i]=1;
    }
    return UniformDistOutput;
}

// Returns in a float array of size numelmasked, the value of the gaussian density function when using the Gaussian parameters of the current leaf and the corrected data.
float* TreeEM::MakeGaussianDistribution(){
    //cout<<"Updating Gaussian Distribution"<<endl;
    if (this->GetDistributionType()!=1) {
        cout<<"This is not a leaf with Gaussian distribution : cannot be updated as wanted"<<endl;
        vector<int> HierarchyVector=this->GetHierarchyVector();
        cout<<"Leaf with problem for Gaussian distribution updated is ";
        int sizeHierarch=HierarchyVector.size();
        for (int h=0; h<sizeHierarch; h++) {
            cout<<" "<<HierarchyVector[h];
        }
        cout<<endl;
        return NULL;
    }
    // Distribution put back to zero every where
    //    this->ReputDistributionToZero();
//    int numel=this->GetNumberElements();
    int numelmasked=this->GetNumberMaskedElements();
    int numbmodal=this->GetNumberModalities();
    int numbmodalSq=numbmodal*numbmodal;
    float * GaussianDistOutput=new float[numelmasked];
    for(int i=0;i<numelmasked;i++){
        GaussianDistOutput[i]=0;
    }
    //    float * DataPointer=this->MakeDataBFCorrected();
    float * DataPointer=this->GetDataBFCorrected();
//    matrix<float> VarianceMatrix=matrix<float>(numbmodal);
    float * VarianceBis=this->GetVariance();
//    float VarianceToUse[MaxNumbModal*MaxNumbModal];
//    for(int m1=0;m1<MaxNumbModal;m1++){
//        for(int m2=0;m2<MaxNumbModal;m2++){
//            if(m1<numbmodal&&m2<numbmodal){
//                VarianceToUse[m1+m2*MaxNumbModal]=VarianceBis[m1+m2*numbmodal];
//            }
//            else{
//                VarianceToUse[m1+m2*MaxNumbModal]=0;
//            }
//        }
//    }
    float * VarianceToUseTest=new float[numbmodalSq];
    for(int i=0;i<numbmodalSq;i++){
        VarianceToUseTest[i]=VarianceBis[i];
    }
    float * MeanBis=this->GetMean();
    float MeanToUse[MaxNumbModal];
    for(int i=0;i<MaxNumbModal;i++){
        if(i<numbmodal){
            MeanToUse[i]=MeanBis[i];
        }
        else{
            MeanToUse[i]=0;
        }

    }
    //    for(int m1=0;m1<MaxNumbModal;m1++){
    //        for(int m2=0;m2<MaxNumbModal;m2++){
    //            VarianceMatrix.setvalue(m1,m2,m1==m2?1:0);
    //        }
    //    }
//    for (int m1=0; m1<numbmodal; m1++) {
//        for (int m2=0; m2<numbmodal; m2++) {
//            VarianceMatrix.setvalue(m1, m2, VarianceToUse[m1+m2*MaxNumbModal]);

//        }
//    }

    // Calculation of the factor in front of the exponential
//    float DeterminantVariance=VarianceMatrix.determinant();
    float DeterminantVariance=determinant(VarianceToUseTest,numbmodal);
    
    //cout<<"the Variance determinant is "<<DeterminantVariance<<endl;
    float NormalisationFactor=1.0/(float)(powf(2*M_PI , (float)((float)numbmodal/2.0))*powf(DeterminantVariance, 0.5));
    //cout <<"The normalisation factor is "<<NormalisationFactor<<endl;
    //Initialisation of the needed element to calculate the inside of the exponential
    float * Distribution_PTR=GaussianDistOutput;
    int SizeMaxModalSq=MaxNumbModal*MaxNumbModal;
    float InvertedVariance[MaxNumbModal*MaxNumbModal];
    for(int i=0;i<SizeMaxModalSq;i++){
        InvertedVariance[i]=0;
    }
    if (numbmodal>1) {
//        VarianceMatrix.invert();

//        float DetTest=determinant(VarianceToUseTest,numbmodal);
        invertMatrix(VarianceToUseTest,numbmodal);

//        bool success;
        for(int m1=0;m1<numbmodal;m1++){
            for (int m2=0; m2<numbmodal; m2++) {
                InvertedVariance[m1+m2*MaxNumbModal]=VarianceToUseTest[m1+m2*numbmodal];
//                VarianceMatrix.getvalue(m1, m2, InvertedVariance[m1+m2*MaxNumbModal], success);
            }
        }
        delete[] VarianceToUseTest;
        VarianceToUseTest=NULL;

    }
    else{
//        bool success;
//        VarianceMatrix.getvalue(0, 0, InvertedVariance[0], success);
        *InvertedVariance=1.0/(*VarianceToUseTest);
        delete[] VarianceToUseTest;
        VarianceToUseTest=NULL;
    }
    PrecisionTYPE temp;
    vector<float *> DataPointerVec;
    for (int m=0; m<numbmodal; m++) {
        DataPointerVec.push_back(&DataPointer[m*numelmasked]);
    }

    // Calculation of the inside of the exponential
    //cout<<InvertedVariance[0]<<endl;
    //        int * L2S_PTR=this->GetL2S();
    for (int i=0; i<numelmasked; i++,Distribution_PTR++) {
        for (int m1=0; m1<numbmodal; m1++) {
            temp=0;
            int ShiftIndexInvertToReach=m1*MaxNumbModal;
            for (int m2=0; m2<numbmodal; m2++) {
//                temp+=(PrecisionTYPE)(DataPointer[i+m2*numelmasked]-MeanToUse[m2])*InvertedVariance[m2+m1*MaxNumbModal];
//                temp+=(PrecisionTYPE)(DataPointerVec[m2][i]-MeanToUse[m2])*InvertedVariance[m2+m1*MaxNumbModal];
                 temp+=(PrecisionTYPE)(DataPointerVec[m2][i]-MeanToUse[m2])*InvertedVariance[m2+ShiftIndexInvertToReach];
            }
//            *Distribution_PTR=(*Distribution_PTR)+temp*(DataPointer[i+m1*numelmasked]-MeanToUse[m1]);
            *Distribution_PTR=(*Distribution_PTR)+temp*(DataPointerVec[m1][i]-MeanToUse[m1]);
        }
    }
    
    

    // Filling the distribution array with the value
    Distribution_PTR=GaussianDistOutput;
    if (NormalisationFactor>1E32) {
        cout<<"Risk of infinity in normalisation factor"<<endl;
        cout<<DeterminantVariance<<"for subcomponent ";
        vector<int > HierarchyVector=this->GetHierarchyVector();
        int HierarchySize=HierarchyVector.size();
        for (int h=0; h<HierarchySize; h++) {
            cout<<HierarchyVector[h]<<" ";
        }
    }

    for (int i=0;i<numelmasked;i++,Distribution_PTR++){
        if (*Distribution_PTR>1E32) {
            cout<<"Risk of infinity in distribution"<<endl;
        }
        *Distribution_PTR=NormalisationFactor*expf(-0.5*(*Distribution_PTR));
//        if (*Distribution_PTR>1E32) {
//            cout<<"Risk of infinity after exponentiation"<<endl;
//        }
    }
    // Clearing space needing for inverse of variance

    //    if (DataPointer!=NULL) {
    //        delete [] DataPointer;
    //        DataPointer=NULL;
    //    }
    //    string Filename="/Users/Carole/Documents/PhD/TryDistributionDataT1Nifty";
    //    nifti_image * PartialRes=SavePartialResult(this->GetPartialResult(DISTRIBUTION),this->GetDataImage(),(char *)Filename.c_str());
    //    nifti_image_write(PartialRes);
    //    nifti_image_free(PartialRes);    return;
    return GaussianDistOutput;
}

float * TreeEM::NormalisedPriorsForCCL(){
    vector<TreeEM*> LeavesVector=this->GetAllLeaves();

    int numbLeaves=LeavesVector.size();
    int numelmasked=this->GetNumberMaskedElements();
//    int numel=this->GetNumberElements();

    // Initialisation of the result
    float * NormalisedPriorsResult=new float[numbLeaves*numelmasked];
    for(int i = 0;i<numbLeaves*numelmasked;i++){
        NormalisedPriorsResult[i]=1;
    }
    // Copy of the adapted priors into the results
    for(int l=0;l<numbLeaves;l++){
        int * S2L_PTR=this->GetS2L();
        float * PriorsLeaves=LeavesVector[l]->GetPriorsAdapted();
        float * MRFValue = LeavesVector[l]->GetMRF();
        float PartNormWeight=LeavesVector[l]->GetPartNormWeight();
        for(int i=0;i<numelmasked;i++){
            if(PriorsLeaves!=NULL){
                NormalisedPriorsResult[i]*=PriorsLeaves[S2L_PTR[i]];
            }
            if(MRFValue!=NULL){
                NormalisedPriorsResult[i]*=MRFValue[i];
            }
            if(LeavesVector[l]->GetPriorsDirect()==NULL){
                NormalisedPriorsResult[i]*=PartNormWeight;
            }
        }
    }

    // Normalisation step
    int CountNormZero=0;
    for(int i=0;i<numelmasked;i++){
        float NormFactor=0;
        // Determination of normalisation factor so that sum at each voxel is to 1 after normalisation
        for(int l=0;l<numbLeaves;l++){
            NormFactor+=NormalisedPriorsResult[i+l*numelmasked];
        }
        //Normalisation at each voxel
        if(NormFactor==0){
            CountNormZero++;
        }
        else{
            for(int l=0;l<numbLeaves;l++){
                NormalisedPriorsResult[i+l*numelmasked]/=NormFactor;
            }
        }
    }
    if(CountNormZero>0){
        cout<<"In normalisation of adapted atlas + MRF number of zero pb is "<<CountNormZero<<endl;
    }
    return NormalisedPriorsResult;

}

float TreeEM::CompleteLogLikelihoodFinBis(){
    PrecisionTYPE CompleteLogLikelihood=0;
    int numelmasked=this->GetNumberMaskedElements();
//    int numel=this->GetNumberElements();
//    int numbchild=this->GetNumberChildren();
    vector<TreeEM*> Leaves=this->GetAllLeaves();
    float * NormalisedPriors=this->NormalisedPriorsForCCL();
    int numbLeaves=Leaves.size();

    for (int c=0; c<numbLeaves; c++) {

        float * NormResp_PTR=Leaves[c]->GetNormResp();
        float * Priors_PTR=&NormalisedPriors[c*numelmasked];
        float * Distribution= new float[numelmasked];
        float * Distribution_PTR=Distribution;
        for(int i=0;i<numelmasked;i++){
            Distribution[i]=0;
        }
        Leaves[c]->MakeWeightedDist(Distribution);

        if (this->GetFlagOutliers()==4) {
            float * Typicality_PTR=&this->GetNormResp()[numelmasked];
        
        for(int i=0;i<numelmasked;i++,NormResp_PTR++,Distribution_PTR++,Priors_PTR++,Typicality_PTR++){
            if(*Distribution_PTR>0.00001){
                CompleteLogLikelihood+=(PrecisionTYPE)(*NormResp_PTR)*(*Typicality_PTR)*log(*Distribution_PTR);
            }
            if(*Priors_PTR>0.00001){
                CompleteLogLikelihood+=(PrecisionTYPE)(*NormResp_PTR)*(*Typicality_PTR)*log(*Priors_PTR);
            }
        }
    }
        else{
        for(int i=0;i<numelmasked;i++,NormResp_PTR++,Distribution_PTR++,Priors_PTR++){
            if(*Distribution_PTR>0.00001){
                CompleteLogLikelihood+=(PrecisionTYPE)(*NormResp_PTR)*log(*Distribution_PTR);
            }
            if(*Priors_PTR>0.00001){
                CompleteLogLikelihood+=(PrecisionTYPE)(*NormResp_PTR)*log(*Priors_PTR);
            }
        }
        }

        if(Distribution!=NULL){
            delete [] Distribution;
            Distribution = NULL;
        }
    }
    if(NormalisedPriors!=NULL){
        delete [] NormalisedPriors;
        NormalisedPriors=NULL;
    }
    return (float)CompleteLogLikelihood;
}

// REMARK : Be really careful when Mask is changed from one layer to another. Always check that the right amount of memory is then allocated
float TreeEM::CompleteLogLikelihoodFin(SEG_PARAMETERS * segment_param){
    PrecisionTYPE CompleteLogLikelihood=0;
    int numelmasked=this->GetNumberMaskedElements();
    int numel=this->GetNumberElements();
//    int numbchild=this->GetNumberChildren();
    vector<TreeEM*> Leaves=this->GetAllLeaves();
    int numbLeaves=Leaves.size();
    for (int c=0; c<numbLeaves; c++) {
        int * L2S_PTR=this->GetL2S();
        float * NormResp_PTR=Leaves[c]->GetNormResp();
        float * Priors_PTR=NULL;
//        float * Priors_PTR2=NULL;
        if(Leaves[c]->GetPriors()!=NULL){
//            Priors_PTR=new float[numel];
//            Priors_PTR2=Priors_PTR;
//            Priors_PTR2=Leaves[c]->AdaptPriors(segment_param);
//            Priors_PTR=static_cast<float *>(Leaves[c]->GetPriors()->data);
            Priors_PTR=Leaves[c]->GetPriorsAdapted();
        }
        float * Distribution= new float[numelmasked];
        float * Distribution_PTR=Distribution;
        for(int i=0;i<numelmasked;i++){
            Distribution[i]=0;
        }
        Leaves[c]->MakeWeightedDist(Distribution);

        if (Priors_PTR!=NULL) {
            if (this->GetFlagOutliers()==4) {
                float * Typicality_PTR=&this->GetNormResp()[numelmasked];
            for(int i=0;i<numel;i++){
                if ((*L2S_PTR)>=0){
                    if((*Distribution_PTR)>0.00001){
                        CompleteLogLikelihood+=(PrecisionTYPE)(*NormResp_PTR)*(*Typicality_PTR)*logf(*Distribution_PTR);
                    }
                    else{
                        CompleteLogLikelihood+=(PrecisionTYPE)(*NormResp_PTR)*(*Typicality_PTR)*logf(0.00001);
                    }
                    
                    if((*Priors_PTR)>0.00001){
                        CompleteLogLikelihood+=(PrecisionTYPE)(*NormResp_PTR)*(*Typicality_PTR)*logf(*Priors_PTR);
                    }
                    else{
                        CompleteLogLikelihood+=(PrecisionTYPE)(*NormResp_PTR)*(*Typicality_PTR)*logf(0.00001);
                    }
                    if((Leaves[c]->GetPriorsDirect()==NULL)){
                        CompleteLogLikelihood+=(PrecisionTYPE)(*NormResp_PTR)*(*Typicality_PTR)*logf(Leaves[c]->GetPartNormWeight());
                    }
                    
                    Typicality_PTR++;
                    NormResp_PTR++;
                    Distribution_PTR++;
                }
                Priors_PTR++;
                L2S_PTR++;
            }
        }

        
            
            else{
                if(Leaves[c]->GetPartNormWeight()>10E-6){
            for(int i=0;i<numel;i++){
                if ((*L2S_PTR)>=0){
                    if((*Distribution_PTR)>0.00001){
                        CompleteLogLikelihood+=(PrecisionTYPE)(*NormResp_PTR)*logf(*Distribution_PTR);
                    }
                    else{
                        CompleteLogLikelihood+=(PrecisionTYPE)(*NormResp_PTR)*logf(0.00001);
                    }

                    if((*Priors_PTR)>0.00001){
                        CompleteLogLikelihood+=(PrecisionTYPE)(*NormResp_PTR)*logf(*Priors_PTR);
                    }
                    else{
                        CompleteLogLikelihood+=(PrecisionTYPE)(*NormResp_PTR)*logf(0.00001);
                    }
                    if((Leaves[c]->GetPriorsDirect()==NULL)){
                        CompleteLogLikelihood+=(PrecisionTYPE)(*NormResp_PTR)*logf(Leaves[c]->GetPartNormWeight());
                    }


                    NormResp_PTR++;
                    Distribution_PTR++;
                }
                Priors_PTR++;
                L2S_PTR++;
            }
            }
                else {
                    cout<<"Weight of Leaves "<<c<<"is "<<Leaves[c]->GetPartNormWeight();
                }
            }

//            if(Priors_PTR2!=NULL){
//                delete [] Priors_PTR2;
//                Priors_PTR2=NULL;
//            }
        }

        else {
            for(int i=0;i<numelmasked;i++,Distribution_PTR++,NormResp_PTR++){

                if((*Distribution_PTR)>0){
                    CompleteLogLikelihood+=(PrecisionTYPE)(*NormResp_PTR)*logf(*Distribution_PTR);
                }
                else{
                    CompleteLogLikelihood+=(PrecisionTYPE)(*NormResp_PTR)*logf(0.00001);
                }

                if(this->GetChild(Leaves[c]->FindGeneralClass())->GetNormWeight()>0){
                    CompleteLogLikelihood+=(PrecisionTYPE)(*NormResp_PTR)*logf(this->GetChild(Leaves[c]->FindGeneralClass())->GetNormWeight());
                }
                else{
                    CompleteLogLikelihood+=(PrecisionTYPE)(*NormResp_PTR)*logf(0.00001);
                }
                if(!Leaves[c]->GetParent()->IsRoot()){
                    CompleteLogLikelihood+=(PrecisionTYPE)(*NormResp_PTR)*logf(Leaves[c]->GetNormWeight());
                }

            }

        }
        if(Distribution!=NULL){
            delete [] Distribution;
            Distribution=NULL;
        }
    }

    return (float)CompleteLogLikelihood;
}

// REMARK : Be really careful when Mask is changed from one layer to another. Always check that the right amount of memory is then allocated
float TreeEM::CompleteLogLikelihood(){
    PrecisionTYPE CompleteLogLikelihood=0;
    int numelmasked=this->GetNumberMaskedElements();
    int numel=this->GetNumberElements();
    int numbchild=this->GetNumberChildren();
    for (int c=0; c<numbchild; c++) {
        int * L2S_PTR=this->GetL2S();
        float * NormResp_PTR=this->GetChild(c)->GetNormResp();
        float * Priors_PTR=NULL;
        if(this->GetChild(c)->GetPriors()!=NULL){
            Priors_PTR=static_cast<float *>(this->GetChild(c)->GetPriors()->data);
        }
        float * Distribution= new float[numelmasked];
        float * Distribution_PTR=Distribution;
        for(int i=0;i<numelmasked;i++){
            Distribution[i]=0;
        }
        this->GetChild(c)->MakeWeightedDist(Distribution);

        if (Priors_PTR!=NULL) {
            for(int i=0;i<numel;i++){
                if ((*L2S_PTR)>=0){
                    if((*Distribution_PTR)>0.00001){
                        CompleteLogLikelihood+=(PrecisionTYPE)(*NormResp_PTR)*logf(*Distribution_PTR);
                    }
                    else{
                        CompleteLogLikelihood+=(PrecisionTYPE)(*NormResp_PTR)*logf(0.00001);
                    }

                    if((*Priors_PTR)>0.00001){
                        CompleteLogLikelihood+=(PrecisionTYPE)(*NormResp_PTR)*logf(*Priors_PTR);
                    }
                    else{
                        CompleteLogLikelihood+=(PrecisionTYPE)(*NormResp_PTR)*logf(0.00001);
                    }

                    NormResp_PTR++;
                    Distribution_PTR++;
                }
                Priors_PTR++;
                L2S_PTR++;
            }
        }

        else {
            for(int i=0;i<numelmasked;i++,Distribution_PTR++,NormResp_PTR++){

                if((*Distribution_PTR)>0){
                    CompleteLogLikelihood+=(PrecisionTYPE)(*NormResp_PTR)*logf(*Distribution_PTR);
                }
                else{
                    CompleteLogLikelihood+=(PrecisionTYPE)(*NormResp_PTR)*logf(0.00001);
                }

                if(this->GetChild(c)->GetNormWeight()>0){
                    CompleteLogLikelihood+=(PrecisionTYPE)(*NormResp_PTR)*logf(this->GetChild(c)->GetNormWeight());
                }
                else{
                    CompleteLogLikelihood+=(PrecisionTYPE)(*NormResp_PTR)*logf(0.00001);
                }

            }

        }
        if(Distribution!=NULL){
            delete [] Distribution;
            Distribution=NULL;
        }
    }

    return (float)CompleteLogLikelihood;
}

// To keep in memory parameters that make us obtain the highest LL so that if decrease occurs can come back to maximum
vector<Parameters *> TreeEM::KeepingCopyOfParameters(){
    vector<Parameters *> KeptCopyParams;
    vector<TreeEM *> NodesVector=this->GetAllNodes();
    int numbnodes=NodesVector.size();
    for (int n=0; n<numbnodes; n++) {
        Parameters * CopiedParam=NodesVector[n]->CopyParameters();
        KeptCopyParams.push_back(CopiedParam);
    }
    return KeptCopyParams;
}

// To keep in memory normweights if we want to reuse them combined with parameters to come back to maximum obtained if needed
vector<float> TreeEM::KeepingCopyNormWeight(){
    vector<float> KeptCopyNormWeight;
    vector<TreeEM *> NodesVector=this->GetAllNodes();
    int numbnodes=NodesVector.size();
    for (int n=0; n<numbnodes; n++) {
        float CopiedNormWeight=NodesVector[n]->GetNormWeight();
        KeptCopyNormWeight.push_back(CopiedNormWeight);
    }
    return KeptCopyNormWeight;
}

// To keep Copy of NormResp for all nodes
vector<float *> TreeEM::KeepingCopyNormResp(){
    vector<float *> KeptNormResp;
    vector<TreeEM *>NodesVector=this->GetAllNodes();
    int numbnodes=NodesVector.size();
    for (int n=0; n<numbnodes; n++) {
        float * CopiedNormResp=NodesVector[n]->CopyNormResp();
        KeptNormResp.push_back(CopiedNormResp);
    }
    return KeptNormResp;
}

// To keep Copy of MRF for all leaves
vector<float *> TreeEM::KeepingCopyMRF(){
    vector<float *> KeptMRF;
    vector<TreeEM *>LeavesVector=this->GetAllLeaves();
    int numbleaves=LeavesVector.size();
    for (int l=0; l<numbleaves; l++) {
        float * CopiedMRF=LeavesVector[l]->CopyMRF();
        KeptMRF.push_back(CopiedMRF);
    }
    return KeptMRF;
}

// To keep Copy BF Coeffs
float * TreeEM::KeepingCopyBFCoeffs(vector<int> BForderPerModality){
    int numbmodal=BForderPerModality.size();
    float * BFCoeffsToCopy=this->GetBFCoeffs();
    int sumBF=0;
    for (int m=0; m<numbmodal; m++) {
        sumBF+=(BForderPerModality[m]+1)*(BForderPerModality[m]+2)*(BForderPerModality[m]+3)/6;
    }
    float * CopyBF=new float[sumBF];
    sumBF=0;
    if (BFCoeffsToCopy==NULL) {
    for (int m=0; m<numbmodal; m++) {
        int numbBF=(BForderPerModality[m]+1)*(BForderPerModality[m]+2)*(BForderPerModality[m]+3)/6;
        for (int b=0; b<numbBF; b++) {
            CopyBF[sumBF+b]=0;
        }
        
        sumBF+=numbBF;
    }
    }
    else{
    for (int m=0; m<numbmodal; m++) {
        int numbBF=(BForderPerModality[m]+1)*(BForderPerModality[m]+2)*(BForderPerModality[m]+3)/6;
        for (int b=0; b<numbBF; b++) {
            CopyBF[sumBF+b]=BFCoeffsToCopy[sumBF+b];
        }
        
        sumBF+=numbBF;
    }
    }
    return CopyBF;
}


// Come back to a past (better) parameter estimation (before any crash/decrease/pb of any sort)
void TreeEM::ComeBackInTime(vector<Parameters *> BackupParams, vector<float> BackupNormWeight,SEG_PARAMETERS * segment_param){
    // First check compatibility between Backup and Tree
    vector<TreeEM *> NodesVector=this->GetAllNodes();
    int numbNodes=NodesVector.size();
    int numbBackupP=BackupParams.size();
    int numbBackupW=BackupNormWeight.size();
    if (numbNodes != numbBackupP || numbNodes !=numbBackupW) {
        cout<<"Pb in backup size"<<endl;
        return;
    }
    // Once this security check has been performed, can replace params and weights in the Tree. As the list of nodes is obtained in the same way, no risk for order pb
    for (int n=0; n<numbNodes; n++) {
        NodesVector[n]->SetParameters(BackupParams[n]);
        NodesVector[n]->SetNormWeight(BackupNormWeight[n]);
    }
//    // Updating Accordingly NormResp and NormRespRoot
//    this->UpdateNonNormResp(segment_param);
//    this->UpdateNormResp();
//    this->UpdateNormRespRoot();
}

// Come back to a past (better) parameter estimation (before any crash/decrease/pb of any sort)
void TreeEM::ComeBackInTime(vector<Parameters *> BackupParams, vector<float> BackupNormWeight, vector<float *> BackupNormResp, vector<float *> BackupMRF,SEG_PARAMETERS * segment_param){
    // First check compatibility between Backup and Tree
    vector<TreeEM *> NodesVector=this->GetAllNodes();
    vector<TreeEM *> LeavesVector=this->GetAllLeaves();
    int numbNodes=NodesVector.size();
    int numbBackupP=BackupParams.size();
    int numbBackupW=BackupNormWeight.size();
    int numbBackupN=BackupNormResp.size();
    int numbBackupM=BackupMRF.size();
    int numbLeaves=LeavesVector.size();
    if (numbNodes != numbBackupP || numbNodes !=numbBackupW || numbNodes !=numbBackupN) {
        cout<<"Pb in backup size"<<endl;
        return;
    }
    if (numbLeaves !=numbBackupM) {
        cout<<"Pb in MRF backup size"<<endl;
        return;
    }
    // Once this security check has been performed, can replace params and weights in the Tree. As the list of nodes is obtained in the same way, no risk for order pb
    for (int n=0; n<numbNodes; n++) {
        NodesVector[n]->SetParameters(BackupParams[n]);
        NodesVector[n]->SetNormWeight(BackupNormWeight[n]);
        NodesVector[n]->SetNormResp(BackupNormResp[n]);
    }
    for (int l=0; l<numbLeaves; l++) {
        LeavesVector[l]->SetMRF(BackupMRF[l]);
    }
    //    // Updating Accordingly NormResp and NormRespRoot
    //    this->UpdateNonNormResp(segment_param);
    //    this->UpdateNormResp();
    //    this->UpdateNormRespRoot();
}

// Performs one iteration of the EM algorithm
void TreeEM::EMCompleteIteration(float & LogLikelihood, float & OldLogLikelihood, int & Iteration,SEG_PARAMETERS * segment_param){

    OldLogLikelihood=LogLikelihood;


    this->UpdateNonNormResp(segment_param);
    //cout<<"Update NonNormResp done"<<endl;

    this->UpdateNormResp();
//    this->IsNormRespValidGeneral();
//    this->IsNormRespValidLeaves();
    //cout<<"Update NormResp done"<<endl;
    this->UpdateNormRespRoot();
//    LogLikelihood=this->CompleteLogLikelihoodFinBis();

    if(segment_param->flag_MRF){ // Update of the MRF if has to be performed
        if(!segment_param->flag_GMatrix){
            float * GMatrixToUpdate=this->MRFOptSolveLS(segment_param);
            this->SetGMatrix(GMatrixToUpdate);
            delete [] GMatrixToUpdate;
            GMatrixToUpdate=NULL;
        }
        this->UpdateMRF(segment_param);
    }


//    LogLikelihood=this->GetLogLikelihood();

    this->UpdateNonNormWeights();
    //cout<<"Update NonNormWeights done"<<endl;
    this->UpdateNormWeights();
    this->UpdatePriorsAdapted(segment_param);
    if (segment_param->AtlasWeight.size()>0) {
        if (segment_param->AtlasWeight[0]!=0 && segment_param->PriorsKept==8) { // Only update if priors kept =8
            this->UpdatePartPriorsAdapted();
        }
    }
    if (this->GetFlagOutliers()==4) {
        this->UpdateTypicality(segment_param);
    }

//    CompleteLogLikelihood=this->CompleteLogLikelihoodFin();
//    if(LogLikelihood>this->CompleteLogLikelihoodFinBis()){
////        cout<<"Pb in maximization"<<endl;
//    }
//    LogLikelihood=this->CompleteLogLikelihoodFinBis();

    this->UpdateParameters();
    this->UpdateCovPriors(segment_param);
    if(segment_param->CovPriorsType<=8){
    this->SetFlagCovPriors(segment_param->CovPriorsType); // ADDED APRIL 2016
    }
//    if(LogLikelihood>this->CompleteLogLikelihoodFinBis()){
////        cout<<"Pb in maximization parameters"<<endl;
//    }

//    CompleteLogLikelihood=this->CompleteLogLikelihoodFin();
//    LL=this->GetLogLikelihood();
    //cout<<"Update Parameters done"<<endl;

    //    this->UpdateDistribution();
    //cout<<"Update distribution done"<<endl;
//    this->UpdateNonNormResp();
//    //cout<<"Update NonNormResp done"<<endl;

//    this->UpdateNormResp();
//    //cout<<"Update NormResp done"<<endl;
//    this->UpdateNormRespRoot();
//    this->UpdateNonNormWeights();
//    //cout<<"Update NonNormWeights done"<<endl;
//    this->UpdateNormWeights();
//    bool TestWeights=this->AreWeightsValid();
    if (BFFlag) { // Bias Field correction
        this->UpdateBFCoeffs();
        //        this->UpdateBFCorrection();
        this->UpdateDataBFCorrected();
//        this->SaveBFCorrectedData(segment_param->filename_datacorrected);
//        this->SaveBFCorrection(segment_param->filename_correction);
    }
//    CompleteLogLikelihood=this->CompleteLogLikelihood();
//    CompleteLogLikelihood=this->CompleteLogLikelihoodFin();

    LogLikelihood=this->GetLogLikelihood();
    if (this->GetFlagOutliers()==4) {
        LogLikelihood=this->CompleteLogLikelihoodFin(segment_param);
    }
    if (LogLikelihood==INFINITY || LogLikelihood>1E32 || LogLikelihood<-10) {
        cout<<"Stop here to check what happened with LL"<<endl;
    }
//    cout<< LogLikelihood<<" ";
    Iteration++;
    if(this->GetParent()==NULL){
//            this->SaveAllClasses("/Users/Carole/Documents/PhD/TestResult.nii.gz",segment_param);
    }
}

// Performs a complete EM optimisation
void TreeEM::RunFullEM(float & CompleteLogLikelihood, float & OldCompleteLogLikelihood, int & Iteration,SEG_PARAMETERS * segment_param){
    // Create Backup vectors for Params and NormWeights...
    float VeryOldLogLikelihood=0;
    int numbmodal=this->GetNumberModalities();
    vector<Parameters *> BackupParams=this->KeepingCopyOfParameters();
    vector<float>BackupWeights=this->KeepingCopyNormWeight();
    vector<float *>BackupNormResp=this->KeepingCopyNormResp();
    vector<float *> BackupMRF=this->KeepingCopyMRF();
    float * BackupBF=NULL;
    vector<int>BFOrderperModality;
    vector<int>BackupOrderperModality;
    if (BFFlag) {
        for (int m=0; m<numbmodal; m++) {
            BFOrderperModality.push_back(BForder);
            BackupOrderperModality.push_back(BFOrderperModality[m]);
        }
        BackupBF=this->KeepingCopyBFCoeffs(BFOrderperModality);
    }
    
    bool ValidityInitialisationTree = 1;// this->IsTreeWellInitialised();
    if (!ValidityInitialisationTree){
        cout<< "Tree not well initialised, EM cannot be performed" << endl;
        return;
    }
    cout<<"Tree well initialised we can run the EM"<<endl;
    float RelativeChange=(CompleteLogLikelihood-OldCompleteLogLikelihood)/fabs(OldCompleteLogLikelihood);
    if (Iteration==0) {
        RelativeChange=1;
    }
    
    if (BFFlag && segment_param->flag_progressiveBFC && BForder<segment_param->bias_order && RelativeChange<10*segment_param->Bias_threshold) {
        cout<<"Next step in bias field correction from "<<BForder<<" to "<<BForder+1<<endl;
        BForder++;
    }
    if (BFFlag && !segment_param->flag_progressiveBFC) {
        BForder=segment_param->bias_order;
    }
    int flag_BFChange=0;// Creation of another iteration flag that allow to perform at least 3 iterations each time we change the BForder in order to not cut short too early
    int flag_MaxIteration=1;
    int IterationBias=0;
    while (((CompleteLogLikelihood-OldCompleteLogLikelihood)/fabs(OldCompleteLogLikelihood)>Threshold || Iteration<MinIteration || (BForder<segment_param->bias_order&& BFFlag ) || flag_BFChange < 3) && (((Iteration<MaxIteration)+(BForder<segment_param->bias_order))*flag_MaxIteration)) {
        
        if (Iteration>segment_param->bias_order*MaxIteration && segment_param->bias_order>0) { // If we cannot reach the max bias order in the appropriate number of iterations
            flag_MaxIteration=0;
        }
        //        cout<<"we are at iteration "<<Iteration<<endl;
        //        cout<< CompleteLogLikelihood <<" and the old CLL "<< OldCompleteLogLikelihood<<endl;
        this->EMCompleteIteration(CompleteLogLikelihood, OldCompleteLogLikelihood, Iteration,segment_param);
        IterationBias++;
        RelativeChange=(CompleteLogLikelihood-OldCompleteLogLikelihood)/fabs(OldCompleteLogLikelihood);
//        cout <<"relative change is "<<RelativeChange<<endl;
        if (Iteration==0) {
            RelativeChange=1;
        }
        flag_BFChange++;
        
//        if(BFFlag){
//            this->DeleteUnderWeight(segment_param);
//        }

        if (CompleteLogLikelihood>VeryOldLogLikelihood) { // Refreshing backup
            // First clearing memory of what is already in store
            int sizeBackup=BackupParams.size();
            int sizeBackupM=BackupMRF.size();
            for (int n=0; n<sizeBackup; n++) {
                if (BackupParams[n]!=NULL) {
                    delete BackupParams[n];
                    BackupParams[n]=NULL;
                }
                if (BackupNormResp[n]!=NULL) {
                    delete [] BackupNormResp[n];
                    BackupNormResp[n]=NULL;
                }
            }
            for (int l=0; l<sizeBackupM; l++) {
                if (BackupMRF[l]!=NULL) {
                    delete [] BackupMRF[l];
                    BackupMRF[l]=NULL;
                }
            }
            if (BFFlag) {
                delete [] BackupBF;
                BackupBF=NULL;
            }
            BackupParams.clear();
            BackupWeights.clear();
            BackupMRF.clear();
            BackupNormResp.clear();
            BackupOrderperModality.clear();
            // Recreating the needed backups
            BackupWeights=this->KeepingCopyNormWeight();
            BackupParams=this->KeepingCopyOfParameters();
            BackupNormResp=this->KeepingCopyNormResp();
            BackupMRF=this->KeepingCopyMRF();
            
            if(BFFlag){
                for (int m=0; m<numbmodal; m++) {
                    BFOrderperModality[m]=BForder;
                    BackupOrderperModality.push_back(BFOrderperModality[m]);
                }
                BackupBF=this->KeepingCopyBFCoeffs(BFOrderperModality);
            }
        }
        
        if (CompleteLogLikelihood>VeryOldLogLikelihood) {
            VeryOldLogLikelihood=CompleteLogLikelihood;
        }
        
        if (BFFlag && segment_param->flag_progressiveBFC && BForder<segment_param->bias_order && (RelativeChange<10*segment_param->Bias_threshold||IterationBias>MaxIteration)) {
            cout<<"Next step in bias field correction from "<<BForder<<" to "<<BForder+1<<endl;
            BForder++;
            if (IterationBias>MaxIteration) {
                cout<<"change because too slow for BF correction"<<endl;
            }
            IterationBias=0;
            flag_BFChange=0;
        }
//        this->SaveAllClasses("/Users/Carole/Documents/PhD/TemporaryFiles/DB2/TestEM.nii.gz", segment_param);
//        this->SavePriorsAdapted(segment_param);
//        this->SaveGeneralClasses("/Users/Carole/Documents/PhD/MRFResultWOG.nii.gz",segment_param);
    }
    if (CompleteLogLikelihood<OldCompleteLogLikelihood || CompleteLogLikelihood<VeryOldLogLikelihood) {
        cout<<"EM cut short because of decrease..."<<endl;
//        this->ComeBackInTime(BackupParams, BackupWeights, segment_param);
        this->ComeBackInTime(BackupParams, BackupWeights, BackupNormResp, BackupMRF, segment_param);
        if (BFFlag) {
//            if (BForder<segment_param->bias_order ) {
                int numbBFmax=(segment_param->bias_order+1)*(segment_param->bias_order+2)*(segment_param->bias_order+3)/6;
                int numbBF=(BackupOrderperModality[0]+1)*(BackupOrderperModality[0]+2)*(BackupOrderperModality[0]+3)/6;
                float * TmpCopy=new float[numbBF*numbmodal];
                for (int i=0; i<numbBF*numbmodal; i++) {
                    TmpCopy[i]=BackupBF[i];
                }
                delete [] BackupBF;
                BackupBF=NULL;
                BackupBF=new float[numbBFmax * numbmodal];
                for (int i=0; i<numbBFmax*numbmodal; i++) {
                    BackupBF[i]=0;
                }
                for (int m=0; m<numbmodal; m++) {
                    for (int b=0; b<numbBF; b++) {
                        BackupBF[b+m*numbBFmax]=TmpCopy[b+m*numbBF];
                    }
                }
                delete [] TmpCopy;
                TmpCopy=NULL;
                this->SetBFCoeffs(BackupBF);
                float * DataCorrectedBackUp=this->MakeDataBFCorrected();
                this->SetDataBFCorrected(DataCorrectedBackUp);
                delete [] DataCorrectedBackUp;
                DataCorrectedBackUp=NULL;
//            }
//            else{
//                this->SetBFCoeffs(BackupBF);
//                float * DataCorrectedBackUp=this->MakeDataBFCorrected();
//                this->SetDataBFCorrected(DataCorrectedBackUp);
//                delete [] DataCorrectedBackUp;
//                DataCorrectedBackUp=NULL;
//            }
        }
        else{
            if (BFFlag) {
//                if (BForder<segment_param->bias_order ) {
                    int numbBFmax=(segment_param->bias_order+1)*(segment_param->bias_order+2)*(segment_param->bias_order+3)/6;
                    int numbBF=(BackupOrderperModality[0]+1)*(BackupOrderperModality[0]+2)*(BackupOrderperModality[0]+3)/6;
                    float * TmpCopy=new float[numbBF*numbmodal];
                    for (int i=0; i<numbBF*numbmodal; i++) {
                        TmpCopy[i]=BackupBF[i];
                    }
                    delete [] BackupBF;
                    BackupBF=NULL;
                    BackupBF=new float[numbBFmax * numbmodal];
                    for (int i=0; i<numbBFmax*numbmodal; i++) {
                        BackupBF[i]=0;
                    }
                    for (int m=0; m<numbmodal; m++) {
                        for (int b=0; b<numbBF; b++) {
                            BackupBF[b+m*numbBFmax]=TmpCopy[b+m*numbBF];
                        }
                    }
                    delete [] TmpCopy;
                    TmpCopy=NULL;
                    this->SetBFCoeffs(BackupBF);
                    float * DataBFCorrectedBackUp=this->MakeDataBFCorrected();
                    this->SetDataBFCorrected(DataBFCorrectedBackUp);
                    delete [] DataBFCorrectedBackUp;
                    DataBFCorrectedBackUp=NULL;
//                }
            }
        }

        CompleteLogLikelihood=this->GetLogLikelihood();
        cout<<"...back up done and new LL is ..."<<CompleteLogLikelihood<<endl;
    }
    
//    Have to take into account the case where we reach the max number of iteration without going to the max order...
    if (BFFlag && BForder<segment_param->bias_order) {
        int numbBFmax=(segment_param->bias_order+1)*(segment_param->bias_order+2)*(segment_param->bias_order+3)/6;
        int numbBF=(BackupOrderperModality[0]+1)*(BackupOrderperModality[0]+2)*(BackupOrderperModality[0]+3)/6;
        float * TmpCopy=new float[numbBF*numbmodal];
        for (int i=0; i<numbBF*numbmodal; i++) {
            TmpCopy[i]=BackupBF[i];
        }
        delete [] BackupBF;
        BackupBF=NULL;
        BackupBF=new float[numbBFmax * numbmodal];
        for (int i=0; i<numbBFmax*numbmodal; i++) {
            BackupBF[i]=0;
        }
        for (int m=0; m<numbmodal; m++) {
            for (int b=0; b<numbBF; b++) {
                BackupBF[b+m*numbBFmax]=TmpCopy[b+m*numbBF];
            }
        }
        delete [] TmpCopy;
        TmpCopy=NULL;
        this->SetBFCoeffs(BackupBF);
        float * DataBFCorrectedBackUp=this->MakeDataBFCorrected();
        this->SetDataBFCorrected(DataBFCorrectedBackUp);
        delete [] DataBFCorrectedBackUp;
        DataBFCorrectedBackUp=NULL;
        //                }
    }

    // Clearing memory once Backup not needed anymore
    int numbNodes=BackupParams.size();
    int numbLeaves=BackupMRF.size();
    for (int n=0; n<numbNodes; n++) {
        if(BackupParams[n]!=NULL){
            delete BackupParams[n];
            BackupParams[n]=NULL;
        }
        if (BackupNormResp[n]!=NULL) {
            delete [] BackupNormResp[n];
            BackupNormResp[n]=NULL;
        }
    }
    for (int l=0; l<numbLeaves; l++) {
        if (BackupMRF[l]!=NULL) {
            delete [] BackupMRF[l];
            BackupMRF[l]=NULL;
        }
    }
    if (BFFlag) {
        delete [] BackupBF;
        BackupBF=NULL;
    }
    
    cout << Iteration<<" iterations before convergence and the LogLikelihood at convergence is "<<CompleteLogLikelihood<<endl;
    this->SetFlagCovPriors(segment_param->CovPriorsType); // ADDED APRIL 2016
}

// Performs one iteration of the EM algorithm with the BF separated according to the modalities
void TreeEM::EMCompleteIterationBFSeparated(vector<int> BFOrderperModality, int IndexModalitiesBFTogether,float & LogLikelihood, float & OldLogLikelihood, int & Iteration,SEG_PARAMETERS * segment_param){
    
    OldLogLikelihood=LogLikelihood;
    
    
    this->UpdateNonNormResp(segment_param);
    //cout<<"Update NonNormResp done"<<endl;
    
    this->UpdateNormResp();
    //    this->IsNormRespValidGeneral();
    //    this->IsNormRespValidLeaves();
    //cout<<"Update NormResp done"<<endl;
    this->UpdateNormRespRoot();
    //    LogLikelihood=this->CompleteLogLikelihoodFinBis();
    
    if(segment_param->flag_MRF){ // Update of the MRF if has to be performed
        if(!segment_param->flag_GMatrix){
            float * GMatrixToUpdate=this->MRFOptSolveLS(segment_param);
            this->SetGMatrix(GMatrixToUpdate);
            delete [] GMatrixToUpdate;
            GMatrixToUpdate=NULL;
        }
        this->UpdateMRF(segment_param);
    }
    
    
    //    LogLikelihood=this->GetLogLikelihood();
    
    this->UpdateNonNormWeights();
    //cout<<"Update NonNormWeights done"<<endl;
    this->UpdateNormWeights();
    this->UpdatePriorsAdapted(segment_param);
    if (this->GetFlagOutliers()==4) {
        this->UpdateTypicality(segment_param);
    }
    
    //    CompleteLogLikelihood=this->CompleteLogLikelihoodFin();
    //    if(LogLikelihood>this->CompleteLogLikelihoodFinBis()){
    ////        cout<<"Pb in maximization"<<endl;
    //    }
    //    LogLikelihood=this->CompleteLogLikelihoodFinBis();
    
    this->UpdateParameters();
    this->UpdateCovPriors(segment_param);
    //    if(LogLikelihood>this->CompleteLogLikelihoodFinBis()){
    ////        cout<<"Pb in maximization parameters"<<endl;
    //    }
    
    //    CompleteLogLikelihood=this->CompleteLogLikelihoodFin();
    //    LL=this->GetLogLikelihood();
    //cout<<"Update Parameters done"<<endl;
    
    //    this->UpdateDistribution();
    //cout<<"Update distribution done"<<endl;
    //    this->UpdateNonNormResp();
    //    //cout<<"Update NonNormResp done"<<endl;
    
    //    this->UpdateNormResp();
    //    //cout<<"Update NormResp done"<<endl;
    //    this->UpdateNormRespRoot();
    //    this->UpdateNonNormWeights();
    //    //cout<<"Update NonNormWeights done"<<endl;
    //    this->UpdateNormWeights();
    //    bool TestWeights=this->AreWeightsValid();
    if (BFFlag) { // Bias Field correction
        this->UpdateBFCoeffsSeparated(BFOrderperModality,IndexModalitiesBFTogether);
        //        this->UpdateBFCorrection();
        this->UpdateDataBFCorrectedSeparated(BFOrderperModality);
//        this->SaveBFCorrectedData(segment_param->filename_datacorrected);
//        this->SaveBFCorrection(segment_param->filename_correction);
    }
    //    CompleteLogLikelihood=this->CompleteLogLikelihood();
    //    CompleteLogLikelihood=this->CompleteLogLikelihoodFin();
    
    LogLikelihood=this->GetLogLikelihood();
    if (this->GetFlagOutliers()==4) {
        LogLikelihood=this->CompleteLogLikelihoodFin(segment_param);
    }
    if (LogLikelihood==INFINITY || LogLikelihood>1E32 || LogLikelihood<-10) {
        cout<<"Stop here to check what happened with LL"<<endl;
    }
//    cout<< LogLikelihood<<" ";
    Iteration++;
    if(this->GetParent()==NULL){
        //            this->SaveAllClasses("/Users/Carole/Documents/PhD/TestResult.nii.gz",segment_param);
    }
}


// Performs a complete EM optimisation with separated BF
void TreeEM::RunFullEMSeparatedBF(vector<int> BFOrderperModality, int IndexModalityBFTogether, float & CompleteLogLikelihood, float & OldCompleteLogLikelihood, int & Iteration,SEG_PARAMETERS * segment_param){
    
    // Create Backup vectors for Params and NormWeights...
    int numbmodal=this->GetNumberModalities();
    vector<Parameters *> BackupParams=this->KeepingCopyOfParameters();
    vector<float>BackupWeights=this->KeepingCopyNormWeight();
    vector<float *>BackupNormResp=this->KeepingCopyNormResp();
    vector<float *> BackupMRF=this->KeepingCopyMRF();
    float * BackupBF=NULL;
    vector<int>BFOrderperModality_bck;
    if (BFFlag) {
        for (int m=0; m<numbmodal; m++) {
            BFOrderperModality_bck.push_back(BFOrderperModality[m]);
        }
        BackupBF=this->KeepingCopyBFCoeffs(BFOrderperModality_bck);
    }
    
    
    bool ValidityInitialisationTree = 1;// this->IsTreeWellInitialised();
    if (!ValidityInitialisationTree){
        cout<< "Tree not well initialised, EM cannot be performed" << endl;
        return;
    }
//    cout<<"Tree well initialised we can run the EM"<<endl;
    float RelativeChange=(CompleteLogLikelihood-OldCompleteLogLikelihood)/fabs(OldCompleteLogLikelihood);
    if (Iteration==0) {
        RelativeChange=1;
    }
    BForder=BFOrderperModality[IndexModalityBFTogether];
    if (!segment_param->flag_progressiveBFC) {
        BForder=segment_param->bias_order;
    }
    
    if (BFFlag && segment_param->flag_progressiveBFC && BForder<segment_param->bias_order && RelativeChange<10*segment_param->Bias_threshold) {
        cout<<"Next step in bias field correction from "<<BForder<<" to "<<BForder+1<<endl;
        BForder++;
    }
    while (((CompleteLogLikelihood-OldCompleteLogLikelihood)/fabs(OldCompleteLogLikelihood)>Threshold || Iteration<MinIteration || BForder<segment_param->bias_order) && Iteration<MaxIteration) {
        //        cout<<"we are at iteration "<<Iteration<<endl;
        //        cout<< CompleteLogLikelihood <<" and the old CLL "<< OldCompleteLogLikelihood<<endl;
        this->EMCompleteIterationBFSeparated(BFOrderperModality, IndexModalityBFTogether, CompleteLogLikelihood, OldCompleteLogLikelihood, Iteration,segment_param);
        RelativeChange=(CompleteLogLikelihood-OldCompleteLogLikelihood)/fabs(OldCompleteLogLikelihood);
        if (Iteration==0) {
            RelativeChange=1;
        }
        
        if (BFFlag) {
            this->DeleteUnderWeight(segment_param);
        }
        
        if (BFFlag && segment_param->flag_progressiveBFC && BForder<segment_param->bias_order && RelativeChange<10*segment_param->Bias_threshold) {
            cout<<"Next step in bias field correction from "<<BForder<<" to "<<BForder+1<<endl;
            BForder++;
            for (int m=IndexModalityBFTogether; m<numbmodal; m++) {
                BFOrderperModality[m]++;
            }
        }
        
        if (CompleteLogLikelihood>OldCompleteLogLikelihood) { // Refreshing backup
            // First clearing memory of what is already in store
            int sizeBackup=BackupParams.size();
            int sizeBackupM=BackupMRF.size();
            for (int n=0; n<sizeBackup; n++) {
                if (BackupParams[n]!=NULL) {
                    delete BackupParams[n];
                    BackupParams[n]=NULL;
                }
                if (BackupNormResp[n]!=NULL) {
                    delete [] BackupNormResp[n];
                    BackupNormResp[n]=NULL;
                }
            }
            for (int l=0; l<sizeBackupM; l++) {
                if (BackupMRF[l]!=NULL) {
                    delete [] BackupMRF[l];
                    BackupMRF[l]=NULL;
                }
            }
            if (BFFlag) {
                delete [] BackupBF;
                BackupBF=NULL;
            }
            BackupParams.clear();
            BackupWeights.clear();
            BackupMRF.clear();
            BackupNormResp.clear();
            // Recreating the needed backups
            BackupWeights=this->KeepingCopyNormWeight();
            BackupParams=this->KeepingCopyOfParameters();
            BackupNormResp=this->KeepingCopyNormResp();
            BackupMRF=this->KeepingCopyMRF();
            if (BFFlag) {
                for (int m=0; m<numbmodal; m++) {
                    BFOrderperModality_bck[m]=BFOrderperModality[m];
                }
                BackupBF=this->KeepingCopyBFCoeffs(BFOrderperModality_bck);
            }

        }

        
        
        //        this->SaveAllClasses("/Users/Carole/Documents/PhD/TemporaryFiles/DB2/TestEM.nii.gz", segment_param);
        //        this->SavePriorsAdapted(segment_param);
        //        this->SaveGeneralClasses("/Users/Carole/Documents/PhD/MRFResultWOG.nii.gz",segment_param);
    }
    
    if (CompleteLogLikelihood<OldCompleteLogLikelihood) {
        cout<<"EM cut short because of decrease..."<<endl;
        //        this->ComeBackInTime(BackupParams, BackupWeights, segment_param);
        this->ComeBackInTime(BackupParams, BackupWeights, BackupNormResp, BackupMRF, segment_param);
        if (BFFlag) {
            if (BForder<segment_param->bias_order) {
                for (int i=IndexModalityBFTogether; i<numbmodal; i++) {
                    BFOrderperModality[i]=segment_param->bias_order;
                }
//                int numbBFmax=(segment_param->bias_order+1)*(segment_param->bias_order+2)*(segment_param->bias_order+3)/6;
//                int numbBF=(BForder+1)*(BForder+2)*(BForder+3)/6;
                int sumBF=0;
                int sumBFmax=0;
                for (int m=0; m<numbmodal; m++) {
                    sumBF+=(BFOrderperModality_bck[m]+1)*(BFOrderperModality_bck[m]+2)*(BFOrderperModality_bck[m]+3)/6;
                    sumBFmax+=(BFOrderperModality[m]+1)*(BFOrderperModality[m]+2)*(BFOrderperModality[m]+3)/6;
                }
                float * TmpCopy=new float[sumBF];
                for (int i=0; i<sumBF; i++) {
                    TmpCopy[i]=BackupBF[i];
                }
                delete [] BackupBF;
                BackupBF=NULL;
                BackupBF=new float[sumBFmax];
                for (int i=0; i<sumBFmax; i++) {
                    BackupBF[i]=0;
                }
                sumBF=0;
                sumBFmax=0;
                for (int m=0; m<numbmodal; m++) {
                    int numbBFmax=(BFOrderperModality[m]+1)*(BFOrderperModality[m]+2)*(BFOrderperModality[m]+3)/6;
                    int numbBF=(BFOrderperModality_bck[m]+1)*(BFOrderperModality_bck[m]+2)*(BFOrderperModality_bck[m]+3)/6;
                    for (int b=0; b<numbBF; b++) {
                        BackupBF[b+sumBFmax]=TmpCopy[b+sumBF];
                    }
                    sumBFmax+=numbBFmax;
                    sumBF+=numbBF;
                }
                delete [] TmpCopy;
                TmpCopy=NULL;
                this->SetBFCoeffsSeparated(BackupBF, BFOrderperModality);
                this->MakeDataBFCorrectedSeparated(BFOrderperModality);
            }
            else{
                this->SetBFCoeffsSeparated(BackupBF, BFOrderperModality);
                this->MakeDataBFCorrected();
            }
        }

        CompleteLogLikelihood=this->GetLogLikelihood();
        cout<<"...back up done and new LL is ..."<<CompleteLogLikelihood<<endl;
    }
    // Clearing memory once Backup not needed anymore
    int numbNodes=BackupParams.size();
    int numbLeaves=BackupMRF.size();
    for (int n=0; n<numbNodes; n++) {
        if(BackupParams[n]!=NULL){
            delete BackupParams[n];
            BackupParams[n]=NULL;
        }
        if (BackupNormResp[n]!=NULL) {
            delete [] BackupNormResp[n];
            BackupNormResp[n]=NULL;
        }
    }
    for (int l=0; l<numbLeaves; l++) {
        if (BackupMRF[l]!=NULL) {
            delete [] BackupMRF[l];
            BackupMRF[l]=NULL;
        }
    }
    delete [] BackupBF;
    BackupBF=NULL;
    
    
    
    cout << Iteration<<" iterations before convergence and the LogLikelihood at convergence is "<<CompleteLogLikelihood<<endl;
}




void TreeEM::CEMPartialIteration(float & LogLikelihood, float & OldLogLikelihood, int & Iteration,int c){
    OldLogLikelihood=LogLikelihood;


    this->UpdateNonNormRespCEM();
    //cout<<"Update NonNormResp done"<<endl;

    this->UpdateNormResp();
//    this->IsNormRespValidGeneral();
//    this->IsNormRespValidLeaves();
    //cout<<"Update NormResp done"<<endl;
    this->UpdateNormRespRoot();

//    LogLikelihood=this->GetLogLikelihood();

    this->UpdateNonNormWeightsCEM(c);
    //cout<<"Update NonNormWeights done"<<endl;
    this->UpdateNormWeights();

//    CompleteLogLikelihood=this->CompleteLogLikelihoodFin();
    if(LogLikelihood>this->GetLogLikelihoodCEM(c)){
//        cout<<"Pb in maximization"<<endl;
    }
    LogLikelihood=this->GetLogLikelihoodCEM(c);

    this->UpdateParametersCEM( c);

    if(LogLikelihood>this->GetLogLikelihoodCEM(c)){
//        cout<<"Pb in maximization parameters"<<endl;
    }


    if (BFFlag) {
        this->UpdateBFCoeffs();
        //        this->UpdateBFCorrection();
        this->UpdateDataBFCorrected();
    }

    LogLikelihood=this->GetLogLikelihoodCEM(c);
//    cout<< LogLikelihood<<" ";
    Iteration++;
    if(this->GetParent()==NULL){
        //    this->SaveAllClasses("/Users/Carole/Documents/PhD/TestResult");
    }
}

// Performs a complete CEM optimisation for child c
void TreeEM::RunPartialCEM(float & CompleteLogLikelihood, float & OldCompleteLogLikelihood, int & Iteration, int c){
    bool ValidityInitialisationTree = 1;// this->IsTreeWellInitialised();
    if (!ValidityInitialisationTree){
        cout<< "Tree not well initialised, EM cannot be performed" << endl;
        return;
    }
//    cout<<"Tree well initialised we can run the EM"<<endl;
    if(this->GetNumberChildren()==0){ // If nothing to really optimise since not split
        cout<<"No embedded EM to run"<<endl;
        this->UpdateParametersCEM(c);
    }
    else{
    while (((CompleteLogLikelihood-OldCompleteLogLikelihood)/fabs(OldCompleteLogLikelihood)>Threshold || Iteration<6) && Iteration<MaxIteration) {
        //        cout<<"we are at iteration "<<Iteration<<endl;
        //        cout<< CompleteLogLikelihood <<" and the old CLL "<< OldCompleteLogLikelihood<<endl;
        this->CEMPartialIteration(CompleteLogLikelihood, OldCompleteLogLikelihood, Iteration,c);
    }
    }
    cout << Iteration<<" iterations before convergence and final CompleteLikelihood is "<<CompleteLogLikelihood<<endl;

}


void TreeEM::CEMCompleteIteration(float & LogLikelihood, float & OldLogLikelihood, int & Iteration,SEG_PARAMETERS * segment_param){
    OldLogLikelihood=LogLikelihood;
    int numbchild=this->GetNumberChildren();

    this->UpdateNonNormResp(segment_param);
    //cout<<"Update NonNormResp done"<<endl;

    this->UpdateNormResp();
//    this->IsNormRespValidGeneral();
//    this->IsNormRespValidLeaves();
    //cout<<"Update NormResp done"<<endl;
    this->UpdateNormRespRoot();

//    LogLikelihood=this->GetLogLikelihood();

    this->UpdateNonNormWeights();
    //cout<<"Update NonNormWeights done"<<endl;
    this->UpdateNormWeights();

//    CompleteLogLikelihood=this->CompleteLogLikelihoodFin();
    if(LogLikelihood>this->GetLogLikelihood()){
//        cout<<"Pb in maximization"<<endl;
    }
    LogLikelihood=this->GetLogLikelihood();

    if(numbchild>0){ // Applied Embedded EM if it is not a leaf
    for(int c=0;c<numbchild;c++){
        float LLc=0;
        float OldLLc=0;
        int IterationC=0;
        TreeEM * TmpCEMTree=this->GetChild(c)->CopyTree(NULL);
        TmpCEMTree->SetHardSeg(this->GetHardSeg());
        TmpCEMTree->RunPartialCEM(LLc,OldLLc,IterationC,c);
        this->GetChild(c)->ReplugParameters(TmpCEMTree);
        delete TmpCEMTree;
        TmpCEMTree=NULL;
    }
    }


    if(LogLikelihood>this->GetLogLikelihood()){
//        cout<<"Pb in maximization parameters"<<endl;
    }


    if (BFFlag) {
        this->UpdateBFCoeffs();
        //        this->UpdateBFCorrection();
        this->UpdateDataBFCorrected();
    }

    LogLikelihood=this->GetLogLikelihood();
//    cout<< LogLikelihood<<" ";
    Iteration++;
    if(this->GetParent()==NULL){
        //    this->SaveAllClasses("/Users/Carole/Documents/PhD/TestResult");
    }
}

void TreeEM::ReplugParameters(TreeEM* TreeToReplug){
    // Check if trees are of similar structures
    if(!this->IsStructureSimilar(TreeToReplug)){
        cout<<"The considered trees do not share a similar structure"<<endl;
        return;
    }
    else{
        int numbchild=this->GetNumberChildren();
        this->SetParameters(TreeToReplug->CopyParameters());
        for(int c=0;c<numbchild;c++){
            this->GetChild(c)->ReplugParameters(TreeToReplug->GetChild(c));
        }
    }
}

void TreeEM::RunFullCEM(float & CompleteLogLikelihood, float & OldCompleteLogLikelihood, int & Iteration,SEG_PARAMETERS * segment_param){
    while (((CompleteLogLikelihood-OldCompleteLogLikelihood)/fabs(OldCompleteLogLikelihood)>Threshold || Iteration<6) && Iteration<MaxIteration) {
        //        cout<<"we are at iteration "<<Iteration<<endl;
        //        cout<< CompleteLogLikelihood <<" and the old CLL "<< OldCompleteLogLikelihood<<endl;
        this->CEMCompleteIteration(CompleteLogLikelihood, OldCompleteLogLikelihood, Iteration,segment_param);
    }
    cout << Iteration<<" iterations before convergence and the final loglikelihood is "<<CompleteLogLikelihood<<endl;
}

// Not used anymore
TreeEM * TreeEM::RunFullBiASM(SEG_PARAMETERS * segment_param){
    float CompleteLogLikelihood=0;
    float OldCompleteLogLikelihood=0;
    int Iteration=0;
    cout<< "The weights of the general classes are : ";
//    float * DPChildren=this->GetDPChildrenDirect();
    int numbchild=this->GetNumberChildren();
    for (int c=0;c<numbchild;c++){
        cout<<this->GetChild(c)->GetNormWeight()<< "    ******      ";
    }
    BFFlag=segment_param->flag_Bias;
    BForder=segment_param->bias_order;
    Threshold=segment_param->Bias_threshold;
    MaxIteration=segment_param->maxIterationBF;
    MinIteration=segment_param->minIteration;
    NumbMaxLeaves=segment_param->maxNumbLeaves;
    KernelSize=segment_param->KernelSize;
//    int numbmodal=this->GetNumberModalities();
//    segment_param->choiceInitSplit=segment_param->choiceInitSplit<1?1:segment_param->choiceInitSplit;
//    segment_param->choiceInitSplit=segment_param->choiceInitSplit>numbmodal?numbmodal:segment_param->choiceInitSplit;
    //    BFFlag=0;
//    this->SaveBFCorrectedData("/Users/Carole/Documents/PhD/BRATS_DataCorrected");
//    this->MakeIndFactorTot();
//    cout<<this->GetNumberChildren();
    cout<<this->MakeIndFactorTotMod()<<" "<<this->MakeIndFactorTot()<<endl;
    this->IsNormRespValidGeneral();
    this->IsNormRespValidLeaves();
    vector<float> AtlasWeight=segment_param->AtlasWeight;
//    segment_param->AtlasWeight=0;
    if(!segment_param->flag_intxt){
            segment_param->AtlasWeight[0]=0;
//        this->SaveBFCorrectedData("/Users/Carole/Documents/PhD/TestMSP2.nii.gz");
    this->RunFullEM(CompleteLogLikelihood, OldCompleteLogLikelihood, Iteration,segment_param);
    if(segment_param->flag_EMfirst_out){
        this->SaveAllClasses(segment_param->filename_EMfirst,segment_param);
        string FilenameEMFirst=segment_param->filename_EMfirst;
        FilenameEMFirst+=".txt";
        char FilenameToUse[200];
        strcpy(FilenameToUse,FilenameEMFirst.c_str());
        this->SaveTreeInTextFile(FilenameToUse,segment_param);
    }
        if(segment_param->flag_savePriors){
    this->SavePriorsAdapted(segment_param);
        }
    if(BFFlag){
//        this->SaveBFCorrectedData("/Users/Carole/Documents/PhD/BRATS_DataCorrected");
//        this->SaveBFCorrection("/Users/Carole/Documents/PhD/BRATS_BFCorrection");
        this->SetIndFactor(this->MakeIndFactorTot());
    }
    }
    
    if(segment_param->flag_JuxtaCorrection){
        nifti_image * CorrectionJuxta=this->CorrectInitialEMResultForWrongWMHoles(segment_param);
        nifti_image_free(CorrectionJuxta);
        CorrectionJuxta=NULL;
        this->UpdateNonNormWeights();
        this->UpdateNormWeights();
        this->UpdateParameters();
    }
    this->SetIndFactor(this->MakeIndFactorTot());
    int CountRunEM=1;
    cout<< "The weights of the general classes are : ";
//    int numbchild=this->GetNumberChildren();
    for (int c=0;c<numbchild;c++){
        cout<<this->GetChild(c)->GetNormWeight()<< "    ******      ";
    }
    MaxIteration=segment_param->maxIteration;
    Threshold=segment_param->ConvThreshold;
    BFFlag=0;
    segment_param->AtlasWeight=AtlasWeight;
//    if(this->GetFlagOutliers()>0){
//        segment_param->AtlasWeight=1;
//        this->UpdatePriorsAdapted(segment_param);
//        int LastChild=this->GetNumberChildren()-1;
//        float * OutlierClass= this->GetChild(LastChild)->GetPriorsAdaptedDirect();
//        nifti_image * AdaptedOutlierAtlas= nifti_copy_nim_info(this->GetDataImage());
//        AdaptedOutlierAtlas->dim[0]=3;
//        AdaptedOutlierAtlas->dim[4]=1;
//        nifti_update_dims_from_array(AdaptedOutlierAtlas);
//        AdaptedOutlierAtlas->data=(void *)calloc(AdaptedOutlierAtlas->nvox,sizeof(float));
//        float * AdaptedOutlierAtlas_PTR=static_cast<float*>(AdaptedOutlierAtlas->data);
//        int numel=this->GetNumberElements();
//        for(int i=0;i<numel;i++,AdaptedOutlierAtlas_PTR++,OutlierClass++){
//            *AdaptedOutlierAtlas_PTR=*OutlierClass;
//        }
//            nifti_set_filenames(AdaptedOutlierAtlas, "/Users/Carole/Documents/PhD/OutlierClass.nii.gz", 0, 0);
//            nifti_image_write(AdaptedOutlierAtlas);
//        this->GetChild(LastChild)->SetPriors(AdaptedOutlierAtlas);
//        if(this->GetChild(LastChild)->GetPriorsDirect()!=NULL){
//            //delete [] this->GetChild(LastChild)->GetPriorsDirect();
//            this->GetChild(LastChild)->SetPriors(AdaptedOutlierAtlas);
//        }
//    }
    TreeEM * TreeSplit=this;
    TreeEM * TreeMerge=this;
    if(segment_param->flag_BiASM){
        cout<<"The BiASM part will be conducted"<<endl;
        MergeKLD * MergeTest=TreeMerge->GetToMerge();
        SplitKLD * SplitTest=TreeSplit->GetToSplit(segment_param);
        int numberAllLeaves=this->GetNumberAllLeaves();
        bool TestNormResp=TreeSplit->AreNormRespValid();
        bool TestNormWeights=TreeSplit->AreWeightsValid();
        if(!TestNormResp){
            cout << "Norm resp non valid for TreeMerge"<<endl;
        }
        if(!TestNormWeights){
            cout << "Norm weights non valid for TreeMerge"<<endl;
        }
        bool AcceptanceDecision=0;
        while ((SplitTest!=NULL&& numberAllLeaves<NumbMaxLeaves) || ((MergeTest!=NULL)&&numberAllLeaves<=NumbMaxLeaves)) {
            AcceptanceDecision=0;
            if(SplitTest!=NULL && numberAllLeaves<NumbMaxLeaves){
                CountRunEM+=1;
            }
            if(MergeTest!=NULL){
                CountRunEM+=1;
            }

            int numbchild=TreeSplit->GetNumberChildren();
            if(numberAllLeaves<=NumbMaxLeaves){
                TreeSplit=TreeSplit->RunSplitOperation(SplitTest,AcceptanceDecision,segment_param);

//                for (int c=0; c<numbchild; c++) {
//                    (TreeSplit->GetChild(c))->PutAllLeavesToChildrenLevel();
//                }
                TreeSplit->PutAllLeavesToMainNodesChildrenLevel(segment_param);
            }

            TestNormResp=TreeSplit->AreNormRespValid();
            TestNormWeights=TreeSplit->AreWeightsValid();
            if(!TestNormResp){
                cout << "Norm resp non valid for TreeSplit"<<endl;
            }
            if(!TestNormWeights){
                cout << "Norm weights non valid for TreeSplit"<<endl;
            }
            if(AcceptanceDecision){
                TreeSplit->ClearSMChecks();
//                MergeTest=NULL;
//                MergeTest=TreeSplit->GetToMerge();
                AcceptanceDecision=0;
//                if(MergeTest!=NULL){
//                    delete MergeTest;
//                    MergeTest=NULL;
//                }
//                MergeTest=TreeSplit->GetToMerge();
            }
            MergeTest=NULL;
            MergeTest=TreeSplit->GetToMerge();
            TreeMerge=TreeSplit->RunMergeOperation(MergeTest,AcceptanceDecision,segment_param);
            TestNormResp=TreeMerge->AreNormRespValid();
            TestNormWeights=TreeMerge->AreWeightsValid();

            if(!TestNormResp){
                cout << "Norm resp non valid for TreeMerge"<<endl;
            }
            if(!TestNormWeights){
                cout << "Norm weights non valid for TreeMerge"<<endl;
            }
            TreeSplit=TreeMerge;
//            TreeSplit->SaveTreeInTextFile("/Users/Carole/Documents/PhD/DataTree.txt");

            SplitTest=TreeSplit->GetToSplit(segment_param);
            MergeTest=TreeMerge->GetToMerge();
            numberAllLeaves=TreeSplit->GetNumberAllLeaves();
            numbchild=TreeMerge->GetNumberChildren();
            cout<< "The weights of the general classes are : ";
            for (int c=0;c<numbchild;c++){
                cout<<TreeMerge->GetChild(c)->GetNormWeight()<< "    ******      ";
            }
            cout<<endl;
//            TreeSplit->SaveMRFImage(segment_param);
//            TreeSplit->SaveAllClasses("/Users/Carole/Documents/PhD/TmpResult.nii.gz",segment_param);
//            TreeSplit->SaveTreeInTextFile("/Users/Carole/Documents/PhD/DataTree.txt",segment_param);
        }
        if(MergeTest!=NULL){
            delete MergeTest;
            MergeTest=NULL;
        }
        if(SplitTest!=NULL){
            delete SplitTest;
            SplitTest=NULL;
        }

    }
    TreeEM * TreeResult=TreeSplit->CopyTree(NULL);
    //    if(this!=NULL){
    //        delete this;
    //    }
    if(TreeSplit!=NULL){
        delete TreeSplit;
        TreeSplit=NULL;
    }
    cout<<CountRunEM<<" have been performed "<<endl;
    return TreeResult;
}

// Not used anymore
TreeEM * TreeEM::RunFullBiASM_bis(SEG_PARAMETERS * segment_param){
    float CompleteLogLikelihood=0;
    float OldCompleteLogLikelihood=0;
    int Iteration=0;
    cout<< "The weights of the general classes are : ";
//    float * DPChildren=this->GetDPChildrenDirect();
    int numbchild=this->GetNumberChildren();
    for (int c=0;c<numbchild;c++){
        cout<<this->GetChild(c)->GetNormWeight()<< "    ******      ";
    }
    BFFlag=segment_param->flag_Bias;
    BICFP=segment_param->BICFP;
    BForder=segment_param->bias_order;
    Threshold=segment_param->Bias_threshold;
    MaxIteration=segment_param->maxIterationBF;
    MinIteration=segment_param->minIteration;
    NumbMaxLeaves=segment_param->maxNumbLeaves;
    KernelSize=segment_param->KernelSize;
//    int numbmodal=this->GetNumberModalities();
//    float AtlasWeight=segment_param->AtlasWeight;
//    nifti_image * ImageTest=nifti_copy_nim_info(this->GetMask());
//    ImageTest->data = (void *) calloc(ImageTest->nvox, sizeof(bool));
//    
//    bool * Image_PTRtmp=static_cast<bool *>(ImageTest->data);
//    bool * Data_PTR=static_cast<bool *>(this->GetMask()->data);
//    int numel =ImageTest->nvox;
//    for (int i=0; i<numel; i++,Data_PTR++,Image_PTRtmp++) {
//        *Image_PTRtmp=*Data_PTR;
//    }
//                  nifti_set_filenames(ImageTest, "/Users/Carole/Documents/PhD/TestP2.nii.gz", 0, 0);
//                   nifti_image_write(ImageTest);
//                   nifti_image_free(ImageTest);

    this->SaveBFCorrectedData(segment_param->filename_datacorrected);
    if(!segment_param->flag_intxt){
//        segment_param->AtlasWeight=0;
//        this->SaveBFCorrectedData("/Users/Carole/Documents/PhD/TestMSP2.nii.gz");
    this->RunFullEM(CompleteLogLikelihood, OldCompleteLogLikelihood, Iteration,segment_param);
    if(segment_param->flag_EMfirst_out){
        this->SaveAllClasses(segment_param->filename_EMfirst,segment_param);
        string FilenameEMFirst=nifti_makebasename(segment_param->filename_EMfirst.c_str());
        FilenameEMFirst+=".txt";
        char FilenameToUse[200];
        strcpy(FilenameToUse,FilenameEMFirst.c_str());
        this->SaveTreeInTextFile(FilenameToUse,segment_param);
    }
        if(segment_param->flag_savePriors){
            this->SavePriorsAdapted(segment_param);
        }
    if(BFFlag){
        this->SaveBFCorrectedData(segment_param->filename_datacorrected);

//        this->SaveBFCorrectedData("/Users/Carole/Documents/PhD/BRATS_DataCorrected");
//        this->SaveBFCorrection("/Users/Carole/Documents/PhD/BRATS_BFCorrection");
        this->SetIndFactor(this->MakeIndFactorTot());
    }
    }
    this->SetIndFactor(this->MakeIndFactorTot());
    int CountRunEM=1;
    cout<< "The weights of the general classes are : ";
    for (int c=0;c<numbchild;c++){
        cout<<this->GetChild(c)->GetNormWeight()<< "    ******      ";
    }
    MaxIteration=segment_param->maxIteration;
    Threshold=segment_param->ConvThreshold;
    BFFlag=0;

    
    
    // Different cases for keeping or not Priors
    if (segment_param->PriorsKept==0){
        for (int c=0;c<numbchild;c++){
            if(this->GetChild(c)->GetPriorsDirect()!=NULL){
                nifti_image_free(this->GetChild(c)->GetPriorsDirect());
                this->GetChild(c)->SetPriors(NULL);
            }
        }
        segment_param->BICFP=1; // if the priors are not kept, there is no question about the number of free parameters that has to take into account the mixing coefficients.
    }
    if(segment_param->PriorsKept>=2){
        for(int c=0;c<numbchild;c++){

            nifti_image * NewPriors=this->GetChild(c)->TransformNormRespIntoPriors(segment_param);
            this->GetChild(c)->SetPriors(NewPriors);
            float * NewPriorsAdapted=static_cast<float *>(NewPriors->data);
            this->GetChild(c)->SetPriorsAdapted(NewPriorsAdapted);
        }
        this->NormalisePriors();
        this->NormalisePriorsAdapted();
    }
    if(segment_param->flag_savePriors){
        this->SavePriorsAdapted(segment_param);
    }
    this->MakeHardSeg();
    TreeEM * TreeSplit=this;
    TreeEM * TreeMerge=this;
    if(segment_param->flag_BiASM){
        cout<<"The BiASM part will be conducted"<<endl;

        int numberAllLeaves=this->GetNumberAllLeaves();
        bool TestNormResp=TreeSplit->AreNormRespValid();
        bool TestNormWeights=TreeSplit->AreWeightsValid();
        if(!TestNormResp){
            cout << "Norm resp non valid for TreeMerge"<<endl;
        }
        if(!TestNormWeights){
            cout << "Norm weights non valid for TreeMerge"<<endl;
        }
        bool AcceptanceDecisionSplit=0;
        bool AcceptanceDecisionMerge=0;
        int SeenSplit=0;
        int SeenMerge=0;
//        MergeKLD * MergeTest=TreeMerge->GetToMerge();
        int numbchild=this->GetNumberChildren();

//        int * CombTest=Combination(TreeSplit->GetNumberChildren(),2);
        int NumbCommonChanges=1;
        if(segment_param->flag_CommonChanges && segment_param->SMOrder){
            NumbCommonChanges=numbchild;
        }
        for(int c=NumbCommonChanges;c>0;c--){
            SeenSplit=0;
            SeenMerge=0;
            vector<SplitKLD *> SplitTest;

            vector<MergeKLD*> MergeTest;
            if(segment_param->SMOrder){
                SplitTest  =TreeSplit->GetSplitMoreVertical(c,segment_param);
              MergeTest=TreeMerge->GetMergeMoreVertical(c);
            }
            else{
                SplitTest=TreeSplit->OrderingSplittingLeaves(segment_param);
                MergeTest=TreeMerge->OrderingMergingLeaves();
            }

            cout<<"Now looking at "<<c<<" classes among "<<numbchild<<endl;
        while ((SplitTest.size()>0 && numberAllLeaves<NumbMaxLeaves) || ((MergeTest.size()>0)&&numberAllLeaves<=NumbMaxLeaves)) {
            TreeSplit->IsNormRespValidGeneral();
            TreeSplit->IsNormRespValidLeaves();
            AcceptanceDecisionSplit=0;
            AcceptanceDecisionMerge=0;
            if(SplitTest.size()>0 && numberAllLeaves<NumbMaxLeaves){
                CountRunEM+=1;
            }
            if(MergeTest.size()!=0){
                CountRunEM+=1;
            }

            int numbchild=TreeSplit->GetNumberChildren();
            if(numberAllLeaves<=NumbMaxLeaves && SplitTest.size()>0){
                cout<<SplitTest.size()<< "split operations to test";
                vector<SplitKLD*> SplitTested (SplitTest.begin(),SplitTest.begin()+c);
                TreeSplit=TreeSplit->RunSplitOperation(SplitTested,AcceptanceDecisionSplit,segment_param);

//                for (int c=0; c<numbchild; c++) {
//                    (TreeSplit->GetChild(c))->PutAllLeavesToChildrenLevel();
//                }
                TreeSplit->PutAllLeavesToMainNodesChildrenLevel(segment_param);
            }

            TestNormResp=TreeSplit->AreNormRespValid();
            TestNormWeights=TreeSplit->AreWeightsValid();
            if(!TestNormResp){
                cout << "Norm resp non valid for TreeSplit"<<endl;
            }
            if(!TestNormWeights){
                cout << "Norm weights non valid for TreeSplit"<<endl;
            }


            if (AcceptanceDecisionSplit){
                SeenSplit=0;
                SeenMerge=0;
                if(segment_param->PriorsKept==3){
                    vector<TreeEM *> NodePriors;
                    TreeSplit->GetAllPriorsNodeVector(NodePriors);
                    int numbPriors=NodePriors.size();
                    for (int c=0; c<numbPriors; c++) {
                        nifti_image * NewPriors=NodePriors[c]->TransformNormRespIntoPriors(segment_param);
                        NodePriors[c]->SetPriors(NewPriors);
                        float * NewPriorsAdapted=static_cast<float *>(NewPriors->data);
                        NodePriors[c]->SetPriorsAdapted(NewPriorsAdapted);
                    }
                    TreeSplit->NormalisePriors();
                    TreeSplit->NormalisePriorsAdapted();
                    if(segment_param->flag_savePriors){
                        this->SavePriorsAdapted(segment_param);
                    }
                }
                if(segment_param->PriorsKept==4 && segment_param->uniformTypeChange==5){
                    vector<TreeEM *> NodePriors;
                    NodePriors=TreeSplit->GetOutliersMainNodesVectorChangeableAtlases(segment_param);
                    int numbPriors=NodePriors.size();
                    for (int c=0; c<numbPriors; c++) {
                        nifti_image * NewPriors=NodePriors[c]->TransformNormRespIntoPriors(segment_param);
                        NodePriors[c]->SetPriors(NewPriors);
                        float * NewPriorsAdapted=static_cast<float *>(NewPriors->data);
                        NodePriors[c]->SetPriorsAdapted(NewPriorsAdapted);
                    }
                    TreeSplit->NormalisePriors();
                    TreeSplit->NormalisePriorsAdapted();
                    if(segment_param->flag_savePriors){
                        this->SavePriorsAdapted(segment_param);
                    }
                }
            }
            else{
                SeenSplit++;
                cout<< SeenSplit<< " split operations observed not accepted "<<endl;
            }


            int MergeSize=MergeTest.size();
//            for(int i=0;i<MergeSize;i++){
//                delete MergeTest[i];
//                MergeTest[i]=NULL;
//            }
            MergeTest.clear();
            if(segment_param->SMOrder)
            MergeTest=TreeSplit->GetMergeMoreVertical(c);
            else{
                MergeTest=TreeSplit->OrderingMergingLeaves();
            }
            MergeSize=MergeTest.size();
            vector<MergeKLD*> Merge_tmp;
            for(int i=c*SeenMerge;i<MergeSize;i++){
                Merge_tmp.push_back(MergeTest[i]->CopyMergeKLD());
            }
//            for(int i=0;i<MergeSize;i++){
//                if(MergeTest[i]!=NULL){
//                delete MergeTest[i];
//                MergeTest[i]=NULL;
//                }
//            }
            MergeTest.clear();
            MergeTest=Merge_tmp;
            Merge_tmp.clear();
            MergeSize=MergeTest.size();
            cout<<MergeSize<<" merge operations to test "<<endl;
            if(MergeSize>0){
                vector<MergeKLD*>MergeTested(MergeTest.begin(),MergeTest.begin()+c);
                TreeMerge=TreeSplit->RunMergeOperation(MergeTested,AcceptanceDecisionMerge,segment_param);
            }
            else{
                TreeMerge=TreeSplit;
            }

            if(AcceptanceDecisionMerge){
                SeenMerge=0;
                SeenSplit=0;
                if(segment_param->PriorsKept==3){
//                    for(int c=0;c<numbchild;c++){
//
//                        nifti_image * NewPriors=TreeMerge->GetChild(c)->TransformNormRespIntoPriors(segment_param);
//                        TreeMerge->GetChild(c)->SetPriors(NewPriors);
//                        float * NewPriorsAdapted=static_cast<float *>(NewPriors->data);
//                        TreeMerge->GetChild(c)->SetPriorsAdapted(NewPriorsAdapted);
//                    }
                    vector<TreeEM *> NodePriors;
                    TreeMerge->GetAllPriorsNodeVector(NodePriors);
                    int numbPriors=NodePriors.size();
                    for (int c=0; c<numbPriors; c++) {
                        nifti_image * NewPriors=NodePriors[c]->TransformNormRespIntoPriors(segment_param);
                        NodePriors[c]->SetPriors(NewPriors);
                        float * NewPriorsAdapted=static_cast<float *>(NewPriors->data);
                        NodePriors[c]->SetPriorsAdapted(NewPriorsAdapted);
                    }
                    TreeSplit->NormalisePriors();
                    TreeSplit->NormalisePriorsAdapted();
                }
                if(segment_param->PriorsKept==4 && segment_param->uniformTypeChange==5){
                    vector<TreeEM *> NodePriors;
                    NodePriors=TreeSplit->GetOutliersMainNodesVectorChangeableAtlases(segment_param);
                    int numbPriors=NodePriors.size();
                    for (int c=0; c<numbPriors; c++) {
                        nifti_image * NewPriors=NodePriors[c]->TransformNormRespIntoPriors(segment_param);
                        NodePriors[c]->SetPriors(NewPriors);
                        float * NewPriorsAdapted=static_cast<float *>(NewPriors->data);
                        NodePriors[c]->SetPriorsAdapted(NewPriorsAdapted);
                    }
                    TreeSplit->NormalisePriors();
                    TreeSplit->NormalisePriorsAdapted();
                    if(segment_param->flag_savePriors){
                        this->SavePriorsAdapted(segment_param);
                    }
                }
                
            }
            else{
                SeenMerge++;
                cout<<SeenMerge<<" operations not accepted"<<endl;
            }
            TestNormResp=TreeMerge->AreNormRespValid();
            TestNormWeights=TreeMerge->AreWeightsValid();

            if(!TestNormResp){
                cout << "Norm resp non valid for TreeMerge"<<endl;
            }
            if(!TestNormWeights){
                cout << "Norm weights non valid for TreeMerge"<<endl;
            }
            TreeSplit=TreeMerge;

            // Recalculating the lists of Split and Merge
            int SplitSize=SplitTest.size();
//            for(int i=0;i<SplitSize;i++){
//                if(SplitTest[i]!=NULL){
//                delete SplitTest[i];
//                SplitTest[i]=NULL;
//                }
//            }
            SplitTest.clear();
            if(segment_param->SMOrder){
            SplitTest=TreeSplit->GetSplitMoreVertical(c,segment_param);
            }
            else{
                SplitTest=TreeSplit->OrderingSplittingLeaves(segment_param);
            }
            SplitSize=SplitTest.size();
            vector<SplitKLD*> Split_tmp;
            for(int i=c*SeenSplit;i<SplitSize;i++){
//                cout<<i<<" ";
                SplitKLD * SplitCopied=SplitTest[i]->CopySplitKLD();
                Split_tmp.push_back(SplitCopied);
            }
//            for(int i=0;i<SplitSize;i++){
//                cout<< i <<endl;
//                if(SplitTest[i]!=NULL){
//                    if(SplitTest[i]->KLD!=NULL){
//                delete SplitTest[i];
//                    }
//                SplitTest[i]=NULL;
//                }
//            }
            SplitTest.clear();
            SplitTest=Split_tmp;

            MergeSize=MergeTest.size();
//            for(int i=0;i<MergeSize;i++){
//                if(MergeTest[i]!=NULL){
//                delete MergeTest[i];
//                MergeTest[i]=NULL;
//                }
//            }
            MergeTest.clear();
            if(segment_param->SMOrder){
            MergeTest=TreeSplit->GetMergeMoreVertical(c);
            }
            else{
                MergeTest=TreeSplit->OrderingMergingLeaves();
            }
            MergeSize=MergeTest.size();
//            vector<MergeKLD*> Merge_tmp;
            for(int i=c*SeenMerge;i<MergeSize;i++){
                Merge_tmp.push_back(MergeTest[i]->CopyMergeKLD());
            }

            MergeTest.clear();
            MergeTest=Merge_tmp;
            MergeSize=MergeTest.size();
            SplitSize=SplitTest.size();




TreeSplit->SaveAllClasses(segment_param->filename_out[0],segment_param);
//TreeSplit->SavePriorsAdapted(segment_param);
       TreeSplit->SaveTreeInTextFile(segment_param->filename_datatxt,segment_param);



//            SplitTest=TreeSplit->GetSplitMoreVertical(3);
//            MergeTest=TreeMerge->GetToMerge();
            numberAllLeaves=TreeSplit->GetNumberAllLeaves();
            numbchild=TreeMerge->GetNumberChildren();
            cout<< "The weights of the general classes are : ";
            for (int c=0;c<numbchild;c++){
                cout<<TreeMerge->GetChild(c)->GetNormWeight()<< "    ******      ";
            }
            cout<<endl;
//            AcceptanceDecision=0;
        }
//        if(MergeTest!=NULL){
//            delete MergeTest;
//            MergeTest=NULL;
//        }


    }
    }
    TreeEM * TreeResult=TreeSplit->CopyTree(NULL);
    //    if(this!=NULL){
    //        delete this;
    //    }
    if(TreeSplit!=NULL){
        delete TreeSplit;
        TreeSplit=NULL;
    }
    cout<<CountRunEM<<" have been performed "<<endl;
    return TreeResult;
}

// Currently (09 July 2014) used function to run complete BaMoS process
TreeEM * TreeEM::RunFullBiASM_ter(SEG_PARAMETERS * segment_param){
    float CompleteLogLikelihood=0;
    float OldCompleteLogLikelihood=0;
    int Iteration=0;
//    int * TryCov=new int[4];
    int TryCov[4];
    for (int i=0; i<4; i++) {
        TryCov[i]=i;
    }
    cout<< "The weights of the general classes are : ";
//    float * DPChildren=this->GetDPChildrenDirect();
    int numbchild=this->GetNumberChildren();
    for (int c=0;c<numbchild;c++){
        cout<<this->GetChild(c)->GetNormWeight()<< "    ******      ";
    }
    if(segment_param->flag_savePriors){
        this->SavePriorsAdapted(segment_param);
    }
    
    // Resetting of static values according to segment_param
    BFFlag=segment_param->flag_Bias;
    BICFP=segment_param->BICFP;
    BForder=segment_param->bias_order;
    if (BFFlag && segment_param->flag_progressiveBFC) { // Reinitialisation of BForder if progressive bias field correction chosen
        BForder=1;
    }
    NormMask=segment_param->flag_NormMask;
    Threshold=segment_param->Bias_threshold;
    MaxIteration=segment_param->maxIterationBF;
    MinIteration=segment_param->minIteration;
    NumbMaxLeaves=segment_param->maxNumbLeaves;
    KernelSize=segment_param->KernelSize;
    bool FlagCovPriors=segment_param->flag_CovPriors;
    
    this->SaveBFCorrectedData(segment_param->filename_datacorrected);
//    nifti_image * TestPriorsOut=this->GetChild(0)->GetChild(3)->GetPriorsDirect();
//    nifti_set_filenames(TestPriorsOut, "/Users/Carole/Documents/PhD/PriorsOut.nii.gz", 0, 0);
//    nifti_image_write(TestPriorsOut);
    if(segment_param->flag_savePriors){
        this->SavePriorsAdapted(segment_param);
    }
    
    this->SaveAllClasses("/Users/Carole/Documents/PhD/TemporaryFiles/IMX1/PreEMF2.nii.gz", segment_param);
    if(!segment_param->flag_intxt){ // if not using model from text file to initialise

        // First run of the EM without covariance constraint
        this->SetFlagCovPriors(0);
        this->RunFullEM(CompleteLogLikelihood, OldCompleteLogLikelihood, Iteration,segment_param);
        this->SetFlagCovPriors(segment_param->CovPriorsType);
        
//        //First adaption of the atlases before running with the covariance constraint
//        if(segment_param->PriorsKept>=2){
//            if (segment_param->PriorsKept==5) {
//                if (this->GetFlagOutliers()==7) {
//                    this->AdaptPriorsOM7PK5(segment_param);
//                }
//                else{
//                    this->AdaptPriorsAllLevelsOM3PK5(segment_param);
//                }
//            }
//            else if (segment_param->PriorsKept==6) {
//                if (this->GetFlagOutliers()<5 && this->GetFlagOutliers()!=3) { //Case when there is only one level of adaptation
//                    this->AdaptPriorsAllLevels(segment_param);
//                }
//                else{
//                    this->AdaptPriorsChildren(segment_param);
//                    this->GetChild(0)->AdaptPriorsChildren(segment_param);
//                }
//            }
//            else if (segment_param->PriorsKept==7){ // With choice PK7 : only adaptation at first level
//                if (this->GetFlagOutliers()!=3 && this->GetFlagOutliers()<5){
//                    this->AdaptPriorsAllLevels(segment_param);
//                }
//                else{
//                    this->AdaptPriorsChildren(segment_param);
//                }
//            }
//            else{
//                this->AdaptPriorsAllLevels(segment_param);
//            }
//            this->SavePriorsAdapted(segment_param);
//            this->NormalisePriorsAdapted();
//        }
        

        
        if(segment_param->flag_JuxtaCorrection){
//            this->CorrectInitialEMResultForWrongWMHoles(segment_param);
        }
        
        this->FullAdaptPriors(segment_param);
        this->UpdatePartPriorsAdapted();
        
        // Rerunning of EM with adapted priors and including this time the covariance constraint.
        Iteration=0;
        this->RunFullEM(CompleteLogLikelihood, OldCompleteLogLikelihood, Iteration, segment_param);
        if(this->GetFlagOutliers()==4){
//            float * MSOutliersBeliefs=this->GetMSOutlierBeliefs();
            float * MSOutliersBeliefs=this->GetMSOutlierBeliefs(segment_param);
            string FilenameMSOutliers=nifti_makebasename(segment_param->filename_out[0].c_str());
            FilenameMSOutliers+="_EMVL_MSOut.nii.gz";
            this->SaveTmpResultMasked(MSOutliersBeliefs, FilenameMSOutliers);
            delete [] MSOutliersBeliefs;
        }
        if(segment_param->flag_EMfirst_out){
            this->SaveAllClasses(segment_param->filename_EMfirst,segment_param);
            string FilenameEMFirst=nifti_makebasename(segment_param->filename_EMfirst.c_str());
            FilenameEMFirst+=".txt";
            char FilenameToUse[200];
            strcpy(FilenameToUse,FilenameEMFirst.c_str());
            this->SaveTreeInTextFile(FilenameToUse,segment_param);
        }
        if(segment_param->flag_savePriors){
            this->SavePriorsAdapted(segment_param);
        }
        if(BFFlag){
            this->SaveBFCorrectedData(segment_param->filename_datacorrected);
            
            //        this->SaveBFCorrectedData("/Users/Carole/Documents/PhD/BRATS_DataCorrected");
            //        this->SaveBFCorrection("/Users/Carole/Documents/PhD/BRATS_BFCorrection");
            this->SetIndFactor(this->MakeIndFactorTot());
        }
    }

    this->SetIndFactor(this->MakeIndFactorTot());
    int CountRunEM=1;
    cout<< "The weights of the general classes are : ";
    int numbChildren=this->GetNumberChildren();
    for (int c=0;c<numbChildren;c++){
        cout<<this->GetChild(c)->GetNormWeight()<< "    ******      ";
    }
    
    //Once the first initialisation with EM done, resetting of needed parameters
    MaxIteration=segment_param->maxIteration;
    Threshold=segment_param->ConvThreshold;
    BFFlag=0;
    if(segment_param->PriorsKept!=3 && segment_param->PriorsKept!=4){
        segment_param->AtlasWeight.clear();
        segment_param->AtlasWeight.push_back(0);
        float Smoothing=1;
        if(segment_param->AtlasSmoothing.size()>0){
           Smoothing=segment_param->AtlasSmoothing[0];
            segment_param->AtlasSmoothing.clear();
            segment_param->AtlasSmoothing.push_back(Smoothing);
        }
    }
    
    if(segment_param->PriorsKept==8){ // After the run of the first EM, the PriorsKept option is reset to 5
        segment_param->PriorsKept=5;
    }
    
    if (segment_param->flag_intxt) {
        BFFlag=0;
        this->RunFullEM(CompleteLogLikelihood, OldCompleteLogLikelihood, Iteration, segment_param);
        this->FullAdaptPriors(segment_param);
        this->UpdatePartPriorsAdapted();
    }
    if(!segment_param->flag_intxt){
    this->FullAdaptPriors(segment_param);
        this->UpdatePartPriorsAdapted();
    }
    
//    // Different cases for keeping or not Priors
//    if (segment_param->PriorsKept==0){
//        for (int c=0;c<numbchild;c++){
//            if(this->GetChild(c)->GetPriorsDirect()!=NULL){
//                nifti_image_free(this->GetChild(c)->GetPriorsDirect());
//                this->GetChild(c)->SetPriors(NULL);
//            }
//        }
//        segment_param->BICFP=1; // if the priors are not kept, there is no question about the number of free parameters that has to take into account the mixing coefficients.
//    }
//    if(segment_param->PriorsKept>=2){
//        if (segment_param->PriorsKept==5) {
//            if (this->GetFlagOutliers()==7) {
//                this->AdaptPriorsOM7PK5(segment_param);
//            }
//            else{
//            this->AdaptPriorsAllLevelsOM3PK5(segment_param);
//            }
////            this->SaveTmpResult(this->GetChild(0)->GetChild(1)->GetPriorsAdaptedDirect(), "/Users/Carole/Documents/PhD/TestAdapt0.nii.gz");
////            this->SaveTmpResult(this->GetChild(1)->GetChild(1)->GetPriorsAdaptedDirect(), "/Users/Carole/Documents/PhD/TestAdapt1.nii.gz");
//        }
//
//        else if (segment_param->PriorsKept==6) {
//            if (this->GetFlagOutliers()<5 && this->GetFlagOutliers()!=3) { //Case when there is only one level of adaptation
//                this->AdaptPriorsAllLevels(segment_param);
//            }
//            else{
//                this->AdaptPriorsChildren(segment_param);
//                this->GetChild(0)->AdaptPriorsChildren(segment_param);
//            }
//        }
//        else if (segment_param->PriorsKept==7){ // With choice PK7 : only adaptation at first level
//            if (this->GetFlagOutliers()!=3 && this->GetFlagOutliers()<5){
//                this->AdaptPriorsAllLevels(segment_param);
//            }
//            else{
//                this->AdaptPriorsChildren(segment_param);
//            }
//        }
//        else{
//            this->AdaptPriorsAllLevels(segment_param);
//        }
//        
////        for(int c=0;c<numbchild;c++){
////            nifti_image * NewPriors=this->GetChild(c)->TransformNormRespIntoPriors(segment_param);
////            this->GetChild(c)->SetPriors(NewPriors);
////            float * NewPriorsAdapted=static_cast<float *>(NewPriors->data);
////            this->GetChild(c)->SetPriorsAdapted(NewPriorsAdapted);
////        }
////         float * ToSave=static_cast<float *>(this->GetChild(0)->GetPriorsDirect()->data);
////        SaveTmpResult(ToSave, "/Users/Carole/Documents/PhD/TestTmp1.nii.gz");
////        this->NormalisePriors();
////        ToSave=static_cast<float *>(this->GetChild(0)->GetPriorsDirect()->data);
////        SaveTmpResult(ToSave, "/Users/Carole/Documents/PhD/TestTmp00.nii.gz");
////        ToSave=static_cast<float *>(this->GetChild(1)->GetPriorsDirect()->data);
////        SaveTmpResult(ToSave, "/Users/Carole/Documents/PhD/TestTmp01.nii.gz");
////        ToSave=this->GetChild(0)->GetPriorsAdaptedDirect();
////        SaveTmpResult(ToSave, "/Users/Carole/Documents/PhD/TestTmp0.nii.gz");
////        ToSave=this->GetChild(1)->GetPriorsAdaptedDirect();
////        SaveTmpResult(ToSave, "/Users/Carole/Documents/PhD/TestTmp1.nii.gz");
////        this->SaveTmpResult(this->GetChild(0)->GetChild(1)->GetPriorsAdaptedDirect(), "/Users/Carole/Documents/PhD/TestAdapt0.nii.gz");
////        this->SaveTmpResult(this->GetChild(1)->GetChild(1)->GetPriorsAdaptedDirect(), "/Users/Carole/Documents/PhD/TestAdapt1.nii.gz");
//        this->SavePriorsAdapted(segment_param);
//        this->NormalisePriorsAdapted();
////        ToSave=this->GetChild(0)->GetPriorsAdaptedDirect();
////        SaveTmpResult(ToSave, "/Users/Carole/Documents/PhD/TestTmp0.nii.gz");
////        ToSave=this->GetChild(1)->GetPriorsAdaptedDirect();
////        SaveTmpResult(ToSave, "/Users/Carole/Documents/PhD/TestTmp1.nii.gz");
//    }
    if(segment_param->flag_savePriors){
        this->SavePriorsAdaptedHierarchy(segment_param);
    }
//    this->SavePriorsAdaptedHierarchy(segment_param);
    this->MakeHardSeg();
    TreeEM * TreeSplit=this;
    TreeEM * TreeMerge=this;
    TreeEM * TreeNew=TreeSplit;
    segment_param->flag_CovPriors=FlagCovPriors;
    if(segment_param->flag_BiASM){
        cout<<"The BiASM part will be conducted"<<endl;
        
        int numberAllLeaves=this->GetNumberAllLeaves();
        bool TestNormResp=TreeSplit->AreNormRespValid();
        bool TestNormWeights=TreeSplit->AreWeightsValid();
        if(!TestNormResp){
            cout << "Norm resp non valid for TreeMerge"<<endl;
        }
        if(!TestNormWeights){
            cout << "Norm weights non valid for TreeMerge"<<endl;
        }
        bool AcceptanceDecisionSplit=0;
        bool AcceptanceDecisionMerge=0;
        int SeenSplit=0;
        int SeenMerge=0;
        //        MergeKLD * MergeTest=TreeMerge->GetToMerge();
        int numbchild=this->GetNumberChildren();
        
        //        int * CombTest=Combination(TreeSplit->GetNumberChildren(),2);
        int NumbCommonChanges=1;
        if(segment_param->flag_CommonChanges && segment_param->SMOrder){
            NumbCommonChanges=numbchild;
        }
        for(int c=NumbCommonChanges;c>0;c--){
            SeenSplit=0;
            SeenMerge=0;
            vector<SplitKLD_b *> SplitTest;
            
            vector<MergeKLD_b*> MergeTest;
            if(segment_param->SMOrder){
                SplitTest  =TreeSplit->GetSplitMoreVertical_b(c,segment_param);
                MergeTest= TreeMerge->GetMergeMoreVertical_b(c);
            }
            else{
                SplitTest=TreeSplit->OrderingSplittingLeaves_b(segment_param);
                MergeTest=TreeMerge->OrderingMergingLeaves_b();
                if (segment_param->flag_unifTot && segment_param->VarianceInitUnif==1) { // only if using the kmeans initialisation when splitting the uniform distribution
                    vector<SplitKLD_b *> SplitTestUnifTot=TreeSplit->OrderingSplittingLeavesUniform_b(segment_param, 1);
                    int numbUnif=SplitTestUnifTot.size();
                    for (int u=0; u<numbUnif; u++) {
                        SplitKLD_b * CopySplitUnif=SplitTestUnifTot[u]->CopySplitKLD_b();
                        SplitTest.push_back(CopySplitUnif);
                        delete SplitTestUnifTot[u];
                        SplitTestUnifTot[u]=NULL;
                    }
                }
            }
            
            cout<<"Now looking at "<<c<<" classes among "<<numbchild<<endl;
            
            while ((SplitTest.size()>0 && numberAllLeaves<NumbMaxLeaves) || ((MergeTest.size()>0)&&numberAllLeaves<=NumbMaxLeaves)) {
                TreeNew->IsNormRespValidGeneral();
                TreeNew->IsNormRespValidLeaves();
                AcceptanceDecisionSplit=0;
                AcceptanceDecisionMerge=0;
                if(SplitTest.size()>0 && numberAllLeaves<NumbMaxLeaves){
                    CountRunEM+=1;
                }
                if(MergeTest.size()!=0){
                    CountRunEM+=1;
                }
                
                int numbchild=TreeNew->GetNumberChildren();
                TreeSplit=TreeNew;
                TreeMerge=TreeNew;
                if(numberAllLeaves<=NumbMaxLeaves && SplitTest.size()>0){
                    cout<<SplitTest.size()<< "split operations to test";
                    vector<SplitKLD_b*> SplitTested (SplitTest.begin(),SplitTest.begin()+c);
                    if (segment_param->CovTest==0) {
                            TreeNew=TreeSplit->RunSplitOperation_b(SplitTested,AcceptanceDecisionSplit,segment_param);
                            delete TreeSplit;
                            TreeSplit=NULL;
                    }

                    else{
                        segment_param->CovPriorsSplit=segment_param->CovTest;
                        TreeEM * TreeTmp=TreeSplit->RunSplitOperation_b(SplitTested, AcceptanceDecisionSplit, segment_param);
                        float oldLL=TreeTmp->GetLogLikelihood();
                        bool oldAD=AcceptanceDecisionSplit;
                        bool newAD=AcceptanceDecisionSplit;
                        int BestI=segment_param->CovTest;
                        for (int i=segment_param->CovTest+1; i<4; i++) {
                            segment_param->CovPriorsSplit=TryCov[i];
                            TreeNew=TreeSplit->RunSplitOperation_b(SplitTested, newAD, segment_param);
                            float newLL=TreeNew->GetLogLikelihood();
                            if (newAD && newLL>oldLL) {
                                delete TreeTmp;
                                TreeTmp=NULL;
                                TreeTmp=TreeNew;
                                oldLL=newLL;
                                oldAD=newAD;
                                BestI=i;
                            }
                            else{
                                delete TreeNew;
                                TreeNew=NULL;
                            }
                        }
                        if (!oldAD) {
                            TreeNew=TreeSplit;
                            delete TreeTmp;
                            TreeTmp=NULL;
                        }
                        else{
                            TreeNew=TreeTmp;
                            delete TreeSplit;
                            TreeSplit=NULL;
                        }
                        AcceptanceDecisionSplit=oldAD;
                        cout<< "the best solution is "<<BestI<<endl;
                    }

                    
                    //                for (int c=0; c<numbchild; c++) {
                    //                    (TreeSplit->GetChild(c))->PutAllLeavesToChildrenLevel();
                    //                }
                    TreeNew->PutAllLeavesToMainNodesChildrenLevel(segment_param);
                }
                
                TestNormResp=TreeNew->AreNormRespValid();
                TestNormWeights=TreeNew->AreWeightsValid();
                if(!TestNormResp){
                    cout << "Norm resp non valid for TreeSplit"<<endl;
                }
                if(!TestNormWeights){
                    cout << "Norm weights non valid for TreeSplit"<<endl;
                }
                
                
                if (AcceptanceDecisionSplit){
                    SeenSplit=0;
                    SeenMerge=0;
                    if(segment_param->PriorsKept==3){
                        vector<TreeEM *> NodePriors;
                        TreeNew->GetAllPriorsNodeVector(NodePriors);
                        int numbPriors=NodePriors.size();
                        for (int c=0; c<numbPriors; c++) {
                            nifti_image * NewPriors=NodePriors[c]->TransformNormRespIntoPriors(segment_param);
                            NodePriors[c]->SetPriors(NewPriors);
                            float * NewPriorsAdapted=static_cast<float *>(NewPriors->data);
                            NodePriors[c]->SetPriorsAdapted(NewPriorsAdapted);
                        }
                        TreeNew->NormalisePriors();
                        TreeNew->NormalisePriorsAdapted();
                        if(segment_param->flag_savePriors){
                            this->SavePriorsAdapted(segment_param);
                        }
                    }
                    if(segment_param->PriorsKept==4 && segment_param->uniformTypeChange==5){
                        vector<TreeEM *> NodePriors;
                        NodePriors=TreeNew->GetOutliersMainNodesVectorChangeableAtlases(segment_param);
                        int numbPriors=NodePriors.size();
                        for (int c=0; c<numbPriors; c++) {
                            nifti_image * NewPriors=NodePriors[c]->TransformNormRespIntoPriors(segment_param);
                            NodePriors[c]->SetPriors(NewPriors);
                            float * NewPriorsAdapted=static_cast<float *>(NewPriors->data);
                            NodePriors[c]->SetPriorsAdapted(NewPriorsAdapted);
                        }
                        TreeNew->NormalisePriors();
                        TreeNew->NormalisePriorsAdapted();
                        if(segment_param->flag_savePriors){
                            this->SavePriorsAdapted(segment_param);
                        }
                    }
                }
                else{
                    SeenSplit++;
                    cout<< SeenSplit<< " split operations observed not accepted "<<endl;
                }
                
                TreeNew->PrintGMatrix();
                
                int MergeSize=MergeTest.size();
                //            for(int i=0;i<MergeSize;i++){
                //                delete MergeTest[i];
                //                MergeTest[i]=NULL;
                //            }
                MergeTest.clear();
                if(segment_param->SMOrder)
                    MergeTest=TreeNew->GetMergeMoreVertical_b(c);
                else{
                    MergeTest=TreeNew->OrderingMergingLeaves_b();
                }
                MergeSize=MergeTest.size();
                vector<MergeKLD_b*> Merge_tmp;
                for(int i=c*SeenMerge;i<MergeSize;i++){
                    Merge_tmp.push_back(MergeTest[i]->CopyMergeKLD_b());
                }
                //            for(int i=0;i<MergeSize;i++){
                //                if(MergeTest[i]!=NULL){
                //                delete MergeTest[i];
                //                MergeTest[i]=NULL;
                //                }
                //            }
                MergeTest.clear();
                MergeTest=Merge_tmp;
                Merge_tmp.clear();
                MergeSize=MergeTest.size();
                cout<<MergeSize<<" merge operations to test "<<endl;
                if(MergeSize>0){
                    
                    
                    
                    vector<MergeKLD_b*>MergeTested(MergeTest.begin(),MergeTest.begin()+c);
                    TreeMerge=TreeNew;
                    if (!segment_param->flag_CovPriors) {
                        TreeNew=TreeMerge->RunMergeOperation(MergeTested, AcceptanceDecisionMerge, segment_param);
                        delete TreeMerge;
                        TreeMerge=NULL;
                    }
                    else{
                        if (segment_param->CovTest==0) {
                            TreeNew=TreeMerge->RunMergeOperation(MergeTested,AcceptanceDecisionMerge,segment_param);
                            delete TreeMerge;
                            TreeMerge=NULL;
                        }
                        else{
                        segment_param->CovPriorsMerge=0;
                        bool oldADMerge=0;
                        bool newADMerge=0;
                        TreeEM * TreeTmp=TreeMerge->RunMergeOperation(MergeTested, oldADMerge, segment_param);
                        float oldLL=TreeTmp->GetLogLikelihood();
                        segment_param->CovPriorsMerge=1;
                        TreeNew=TreeMerge->RunMergeOperation(MergeTested, newADMerge, segment_param);
                        float newLL=TreeNew->GetLogLikelihood();
                        if (oldADMerge && newADMerge && newLL>oldLL) {
                            delete TreeTmp;
                            TreeTmp=NULL;
                            delete TreeMerge;
                            TreeMerge=NULL;
                        }
                        else if(!oldADMerge && !newADMerge){
                            delete TreeTmp;
                            TreeTmp=NULL;
                            delete TreeNew;
                            TreeNew=NULL;
                            TreeNew=TreeMerge;
                        }
                        else if(oldADMerge){
                            delete TreeNew;
                            TreeNew=NULL;
                            delete TreeMerge;
                            TreeMerge=NULL;
                            TreeNew=TreeTmp;
                            newADMerge=oldADMerge;
                        }
                        else{
                            delete TreeTmp;
                            TreeTmp=NULL;
                            delete TreeMerge;
                            TreeMerge=NULL;
                        }
                        AcceptanceDecisionMerge=newADMerge;
                        }

                }
                }

                
                if(AcceptanceDecisionMerge){
                    SeenMerge=0;
                    SeenSplit=0;
                    if(segment_param->PriorsKept==3){
                        //                    for(int c=0;c<numbchild;c++){
                        //
                        //                        nifti_image * NewPriors=TreeMerge->GetChild(c)->TransformNormRespIntoPriors(segment_param);
                        //                        TreeMerge->GetChild(c)->SetPriors(NewPriors);
                        //                        float * NewPriorsAdapted=static_cast<float *>(NewPriors->data);
                        //                        TreeMerge->GetChild(c)->SetPriorsAdapted(NewPriorsAdapted);
                        //                    }
                        vector<TreeEM *> NodePriors;
                        TreeNew->GetAllPriorsNodeVector(NodePriors);
                        int numbPriors=NodePriors.size();
                        for (int c=0; c<numbPriors; c++) {
                            nifti_image * NewPriors=NodePriors[c]->TransformNormRespIntoPriors(segment_param);
                            NodePriors[c]->SetPriors(NewPriors);
                            float * NewPriorsAdapted=static_cast<float *>(NewPriors->data);
                            NodePriors[c]->SetPriorsAdapted(NewPriorsAdapted);
                        }
                        TreeNew->NormalisePriors();
                        TreeNew->NormalisePriorsAdapted();
                    }
                    if(segment_param->PriorsKept==4 && segment_param->uniformTypeChange==5){
                        vector<TreeEM *> NodePriors;
                        NodePriors=TreeNew->GetOutliersMainNodesVectorChangeableAtlases(segment_param);
                        int numbPriors=NodePriors.size();
                        for (int c=0; c<numbPriors; c++) {
                            nifti_image * NewPriors=NodePriors[c]->TransformNormRespIntoPriors(segment_param);
                            NodePriors[c]->SetPriors(NewPriors);
                            float * NewPriorsAdapted=static_cast<float *>(NewPriors->data);
                            NodePriors[c]->SetPriorsAdapted(NewPriorsAdapted);
                        }
                        TreeNew->NormalisePriors();
                        TreeNew->NormalisePriorsAdapted();
                        if(segment_param->flag_savePriors){
                            this->SavePriorsAdapted(segment_param);
                        }
                    }
                    
                }
                else{
                    SeenMerge++;
                    cout<<SeenMerge<<" operations not accepted"<<endl;
                }
                TestNormResp=TreeNew->AreNormRespValid();
                TestNormWeights=TreeNew->AreWeightsValid();
                
                if(!TestNormResp){
                    cout << "Norm resp non valid for TreeMerge"<<endl;
                }
                if(!TestNormWeights){
                    cout << "Norm weights non valid for TreeMerge"<<endl;
                }
                
                // Recalculating the lists of Split and Merge
                int SplitSize=SplitTest.size();
                //            for(int i=0;i<SplitSize;i++){
                //                if(SplitTest[i]!=NULL){
                //                delete SplitTest[i];
                //                SplitTest[i]=NULL;
                //                }
                //            }
                SplitTest.clear();
                if(segment_param->SMOrder){
                    SplitTest=TreeNew->GetSplitMoreVertical_b(c,segment_param);
                }
                else{
                    SplitTest=TreeNew->OrderingSplittingLeaves_b(segment_param);
                    if (segment_param->flag_unifTot && segment_param->VarianceInitUnif==1) { // only if using the kmeans initialisation when splitting the uniform distribution
                        vector<SplitKLD_b *> SplitTestUnifTot=TreeNew->OrderingSplittingLeavesUniform_b(segment_param, 1);
                        int numbUnif=SplitTestUnifTot.size();
                        for (int u=0; u<numbUnif; u++) {
                            SplitKLD_b * CopySplitUnif=SplitTestUnifTot[u]->CopySplitKLD_b();
                            SplitTest.push_back(CopySplitUnif);
                            delete SplitTestUnifTot[u];
                            SplitTestUnifTot[u]=NULL;
                        }
                    }
                }
                SplitSize=SplitTest.size();
                vector<SplitKLD_b*> Split_tmp;
                for(int i=c*SeenSplit;i<SplitSize;i++){
                    //                cout<<i<<" ";
                    SplitKLD_b * SplitCopied=SplitTest[i]->CopySplitKLD_b();
                    delete SplitTest[i];
                    SplitTest[i]=NULL;
                    Split_tmp.push_back(SplitCopied);
                }
                //            for(int i=0;i<SplitSize;i++){
                //                cout<< i <<endl;
                //                if(SplitTest[i]!=NULL){
                //                    if(SplitTest[i]->KLD!=NULL){
                //                delete SplitTest[i];
                //                    }
                //                SplitTest[i]=NULL;
                //                }
                //            }
                SplitTest.clear();
                SplitTest=Split_tmp;
                
                MergeSize=MergeTest.size();
                //            for(int i=0;i<MergeSize;i++){
                //                if(MergeTest[i]!=NULL){
                //                delete MergeTest[i];
                //                MergeTest[i]=NULL;
                //                }
                //            }
                MergeTest.clear();
                if(segment_param->SMOrder){
                    MergeTest=TreeNew->GetMergeMoreVertical_b(c);
                }
                else{
                    MergeTest=TreeNew->OrderingMergingLeaves_b();
                }
                MergeSize=MergeTest.size();
                //            vector<MergeKLD*> Merge_tmp;
                for(int i=c*SeenMerge;i<MergeSize;i++){
                    Merge_tmp.push_back(MergeTest[i]->CopyMergeKLD_b());
                }
                
                MergeTest.clear();
                MergeTest=Merge_tmp;
                MergeSize=MergeTest.size();
                SplitSize=SplitTest.size();
                
                
                
                if(AcceptanceDecisionMerge+AcceptanceDecisionSplit>0){
                    cout<<"Saving accepted change"<<endl;
                TreeNew->SaveAllClasses(segment_param->filename_out[0],segment_param);
                //TreeSplit->SavePriorsAdapted(segment_param);
                TreeNew->SaveTreeInTextFile(segment_param->filename_datatxt,segment_param);
                }
                
                
                
                //            SplitTest=TreeSplit->GetSplitMoreVertical(3);
                //            =TreeMerge->GetToMerge();
                numberAllLeaves=TreeNew->GetNumberAllLeaves();
                numbchild=TreeNew->GetNumberChildren();
                cout<< "The weights of the general classes are : ";
                for (int c=0;c<numbchild;c++){
                    cout<<TreeNew->GetChild(c)->GetNormWeight()<< "    ******      ";
                }
                cout<<endl;
//                TreeNew->SaveAllLesionClasses(segment_param);
//                TreeNew->SaveLesionClass(segment_param);
                //            AcceptanceDecision=0;
            }
            //        if(MergeTest!=NULL){
            //            delete MergeTest;
            //            MergeTest=NULL;
            //        }
            
            
        }
    }
//    delete [] TryCov;
//    TryCov=NULL;
    cout<<CountRunEM<<" have been performed "<<endl;
    TreeNew->SaveTreeInTextFile(segment_param->filename_datatxt, segment_param);
    if(segment_param->filename_out.size()>1){
    TreeNew->SaveGeneralClasses(segment_param->filename_out[1], segment_param);
    }
    cout <<"Model saved, now save all classes "<< endl;
    TreeNew->SaveAllClasses(segment_param->filename_out[0], segment_param);
//    TreeNew->SaveAllLesionClasses(segment_param);
//    TreeNew->SaveLesionClass(segment_param);
    return TreeNew;
}


TreeEM * TreeEM::RunBaMoSLoop(SEG_PARAMETERS * segment_param){
//    float CompleteLogLikelihood=0;
//    float OldCompleteLogLikelihood=0;
//    int Iteration=0;
//    int * TryCov=new int[4];
    MaxBaMoSTries=segment_param->MaxRunEM;
    int TryCov[4];
    for (int i=0; i<4; i++) {
        TryCov[i]=i;
    }
    cout<< "The weights of the general classes are : ";
//    float * DPChildren=this->GetDPChildrenDirect();
    int numbchild=this->GetNumberChildren();
    for (int c=0;c<numbchild;c++){
        cout<<this->GetChild(c)->GetNormWeight()<< "    ******      ";
    }
    if(segment_param->flag_savePriors){
        this->SavePriorsAdapted(segment_param);
    }
    
    // Normally at this stage, no bias field correction done anymore since model has already been initialised for further split and merge elsewhere.
    BFFlag=0;
    // Resetting of static values according to segment_param
    NormMask=segment_param->flag_NormMask;
    NumbMaxLeaves=segment_param->maxNumbLeaves;
    KernelSize=segment_param->KernelSize;

    
    //Once the first initialisation with EM done, resetting of needed parameters
    MaxIteration=segment_param->maxIteration;
    Threshold=segment_param->ConvThreshold;
    BFFlag=0;
    if(segment_param->PriorsKept!=3 && segment_param->PriorsKept!=4){
        segment_param->AtlasWeight.clear();
        segment_param->AtlasWeight.push_back(0);
        float Smoothing=1;
        if(segment_param->AtlasSmoothing.size()>0){
            Smoothing=segment_param->AtlasSmoothing[0];
            segment_param->AtlasSmoothing.clear();
            segment_param->AtlasSmoothing.push_back(Smoothing);
        }
        
    }
    TreeEM * TreeSplit=this;
    TreeEM * TreeMerge=this;
    TreeEM * TreeNew=TreeSplit;
    
    segment_param->flag_CovPriors=FlagCovPriors;
        int CountRunEM=0;
        cout<<"The BiASM part will be conducted"<<endl;
        
        int numberAllLeaves=this->GetNumberAllLeaves();
        bool TestNormResp=TreeSplit->AreNormRespValid();
        bool TestNormWeights=TreeSplit->AreWeightsValid();
        if(!TestNormResp){
            cout << "Norm resp non valid for TreeMerge"<<endl;
        }
        if(!TestNormWeights){
            cout << "Norm weights non valid for TreeMerge"<<endl;
        }
        bool AcceptanceDecisionSplit=0;
        bool AcceptanceDecisionMerge=0;
        int SeenSplit=0;
        int SeenMerge=0;
        //        MergeKLD * MergeTest=TreeMerge->GetToMerge();
        
        //        int * CombTest=Combination(TreeSplit->GetNumberChildren(),2);
        int NumbCommonChanges=1;
        if(segment_param->flag_CommonChanges && segment_param->SMOrder){
            NumbCommonChanges=numbchild;
        }
        for(int c=NumbCommonChanges;c>0;c--){
            SeenSplit=0;
            SeenMerge=0;
            vector<SplitKLD_b *> SplitTest;
            
            vector<MergeKLD_b*> MergeTest;
            if(segment_param->SMOrder){
                SplitTest  =TreeSplit->GetSplitMoreVertical_b(c,segment_param);
                MergeTest= TreeMerge->GetMergeMoreVertical_b(c);
            }
            else{
                SplitTest=TreeSplit->OrderingSplittingLeaves_b(segment_param);
                MergeTest=TreeMerge->OrderingMergingLeaves_b();
                if (segment_param->flag_unifTot && segment_param->VarianceInitUnif==1) { // only if using the kmeans initialisation when splitting the uniform distribution
                    vector<SplitKLD_b *> SplitTestUnifTot=TreeSplit->OrderingSplittingLeavesUniform_b(segment_param, 1);
                    int numbUnif=SplitTestUnifTot.size();
                    for (int u=0; u<numbUnif; u++) {
                        SplitKLD_b * CopySplitUnif=SplitTestUnifTot[u]->CopySplitKLD_b();
                        SplitTest.push_back(CopySplitUnif);
                        delete SplitTestUnifTot[u];
                        SplitTestUnifTot[u]=NULL;
                    }
                }
            }
            
            cout<<"Now looking at "<<c<<" classes among "<<numbchild<<endl;
            
            while (((SplitTest.size()>0 && numberAllLeaves<NumbMaxLeaves) || ((MergeTest.size()>0)&&numberAllLeaves<=NumbMaxLeaves))&&CountRunEM<MaxBaMoSTries) {
                TreeNew->IsNormRespValidGeneral();
                TreeNew->IsNormRespValidLeaves();
                AcceptanceDecisionSplit=0;
                AcceptanceDecisionMerge=0;
                if(SplitTest.size()>0 && numberAllLeaves<NumbMaxLeaves){
                    CountRunEM+=1;
                }
                if(MergeTest.size()!=0){
                    CountRunEM+=1;
                }
                
                int numbchild=TreeNew->GetNumberChildren();
                TreeSplit=TreeNew;
                TreeMerge=TreeNew;
                if(numberAllLeaves<=NumbMaxLeaves && SplitTest.size()>0){
                    cout<<SplitTest.size()<< "split operations to test";
                    vector<SplitKLD_b*> SplitTested (SplitTest.begin(),SplitTest.begin()+c);
                    if (segment_param->CovTest==0) {
                        TreeNew=TreeSplit->RunSplitOperation_b(SplitTested,AcceptanceDecisionSplit,segment_param);
                        delete TreeSplit;
                        TreeSplit=NULL;
                    }
                    
                    else{
                        segment_param->CovPriorsSplit=segment_param->CovTest;
                        TreeEM * TreeTmp=TreeSplit->RunSplitOperation_b(SplitTested, AcceptanceDecisionSplit, segment_param);
                        float oldLL=TreeTmp->GetLogLikelihood();
                        bool oldAD=AcceptanceDecisionSplit;
                        bool newAD=AcceptanceDecisionSplit;
                        int BestI=segment_param->CovTest;
                        for (int i=segment_param->CovTest+1; i<4; i++) {
                            segment_param->CovPriorsSplit=TryCov[i];
                            TreeNew=TreeSplit->RunSplitOperation_b(SplitTested, newAD, segment_param);
                            float newLL=TreeNew->GetLogLikelihood();
                            if (newAD && newLL>oldLL) {
                                delete TreeTmp;
                                TreeTmp=NULL;
                                TreeTmp=TreeNew;
                                oldLL=newLL;
                                oldAD=newAD;
                                BestI=i;
                            }
                            else{
                                delete TreeNew;
                                TreeNew=NULL;
                            }
                        }
                        if (!oldAD) {
                            TreeNew=TreeSplit;
                            delete TreeTmp;
                            TreeTmp=NULL;
                        }
                        else{
                            TreeNew=TreeTmp;
                            delete TreeSplit;
                            TreeSplit=NULL;
                        }
                        AcceptanceDecisionSplit=oldAD;
                        cout<< "the best solution is "<<BestI<<endl;
                    }
                    
                    
                    //                for (int c=0; c<numbchild; c++) {
                    //                    (TreeSplit->GetChild(c))->PutAllLeavesToChildrenLevel();
                    //                }
                    TreeNew->PutAllLeavesToMainNodesChildrenLevel(segment_param);
                }
                
                TestNormResp=TreeNew->AreNormRespValid();
                TestNormWeights=TreeNew->AreWeightsValid();
                if(!TestNormResp){
                    cout << "Norm resp non valid for TreeSplit"<<endl;
                }
                if(!TestNormWeights){
                    cout << "Norm weights non valid for TreeSplit"<<endl;
                }
                
                int SplitSize=SplitTest.size();
                if (AcceptanceDecisionSplit){
                    SeenSplit=0;
                    SeenMerge=0;
                    if(segment_param->PriorsKept==3){
                        vector<TreeEM *> NodePriors;
                        TreeNew->GetAllPriorsNodeVector(NodePriors);
                        int numbPriors=NodePriors.size();
                        for (int c=0; c<numbPriors; c++) {
                            nifti_image * NewPriors=NodePriors[c]->TransformNormRespIntoPriors(segment_param);
                            NodePriors[c]->SetPriors(NewPriors);
                            float * NewPriorsAdapted=static_cast<float *>(NewPriors->data);
                            NodePriors[c]->SetPriorsAdapted(NewPriorsAdapted);
                        }
                        TreeNew->NormalisePriors();
                        TreeNew->NormalisePriorsAdapted();
                        if(segment_param->flag_savePriors){
                            this->SavePriorsAdapted(segment_param);
                        }
                    }
                    if(segment_param->PriorsKept==4 && segment_param->uniformTypeChange==5){
                        vector<TreeEM *> NodePriors;
                        NodePriors=TreeNew->GetOutliersMainNodesVectorChangeableAtlases(segment_param);
                        int numbPriors=NodePriors.size();
                        for (int c=0; c<numbPriors; c++) {
                            nifti_image * NewPriors=NodePriors[c]->TransformNormRespIntoPriors(segment_param);
                            NodePriors[c]->SetPriors(NewPriors);
                            float * NewPriorsAdapted=static_cast<float *>(NewPriors->data);
                            NodePriors[c]->SetPriorsAdapted(NewPriorsAdapted);
                        }
                        TreeNew->NormalisePriors();
                        TreeNew->NormalisePriorsAdapted();
                        if(segment_param->flag_savePriors){
                            this->SavePriorsAdapted(segment_param);
                        }
                    }
                }
                else{
                    if (SeenSplit*c<SplitSize+c*SeenSplit) {
                        SeenSplit++;
                    }
                    cout<< SeenSplit<< " split operations observed not accepted "<<endl;
                }
                
                TreeNew->PrintGMatrix();
                int MergeSize=MergeTest.size();
//                Change of merge if split accepted
                if (AcceptanceDecisionSplit) {
                    MergeSize=MergeTest.size();
                    for (int i=0; i<MergeSize; i++) {
                        if (MergeTest[0]!=NULL) {
                            delete MergeTest[0];
                            MergeTest[0]=NULL;
                        }
                        MergeTest.erase(MergeTest.begin());
                    }
                    //            for(int i=0;i<MergeSize;i++){
                    //                delete MergeTest[i];
                    //                MergeTest[i]=NULL;
                    //            }
                    MergeTest.clear();
                    if(segment_param->SMOrder)
                        MergeTest=TreeNew->GetMergeMoreVertical_b(c);
                    else{
                        MergeTest=TreeNew->OrderingMergingLeaves_b();
                    }
                }

//                MergeSize=MergeTest.size();
//                vector<MergeKLD_b*> Merge_tmp;
//                for(int i=c*SeenMerge;i<MergeSize;i++){
//                    Merge_tmp.push_back(MergeTest[i]->CopyMergeKLD_b());
//                }
//                //            for(int i=0;i<MergeSize;i++){
//                //                if(MergeTest[i]!=NULL){
//                //                delete MergeTest[i];
//                //                MergeTest[i]=NULL;
//                //                }
//                //            }
//                MergeTest.clear();
//                MergeTest=Merge_tmp;
//                Merge_tmp.clear();
                MergeSize=MergeTest.size();
                cout<<MergeSize<<" merge operations to test "<<endl;
                if(MergeSize>0){
                    
                    
                    
                    vector<MergeKLD_b*>MergeTested(MergeTest.begin(),MergeTest.begin()+c);
                    TreeMerge=TreeNew;
                    if (!segment_param->flag_CovPriors) {
                        TreeNew=TreeMerge->RunMergeOperation(MergeTested, AcceptanceDecisionMerge, segment_param);
                        delete TreeMerge;
                        TreeMerge=NULL;
                    }
                    else{
                        if (segment_param->CovTest==0) {
                            TreeNew=TreeMerge->RunMergeOperation(MergeTested,AcceptanceDecisionMerge,segment_param);
                            delete TreeMerge;
                            TreeMerge=NULL;
                        }
                        else{
                            segment_param->CovPriorsMerge=0;
                            bool oldADMerge=0;
                            bool newADMerge=0;
                            TreeEM * TreeTmp=TreeMerge->RunMergeOperation(MergeTested, oldADMerge, segment_param);
                            float oldLL=TreeTmp->GetLogLikelihood();
                            segment_param->CovPriorsMerge=1;
                            TreeNew=TreeMerge->RunMergeOperation(MergeTested, newADMerge, segment_param);
                            float newLL=TreeNew->GetLogLikelihood();
                            if (oldADMerge && newADMerge && newLL>oldLL) {
                                delete TreeTmp;
                                TreeTmp=NULL;
                                delete TreeMerge;
                                TreeMerge=NULL;
                            }
                            else if(!oldADMerge && !newADMerge){
                                delete TreeTmp;
                                TreeTmp=NULL;
                                delete TreeNew;
                                TreeNew=NULL;
                                TreeNew=TreeMerge;
                            }
                            else if(oldADMerge){
                                delete TreeNew;
                                TreeNew=NULL;
                                delete TreeMerge;
                                TreeMerge=NULL;
                                TreeNew=TreeTmp;
                                newADMerge=oldADMerge;
                            }
                            else{
                                delete TreeTmp;
                                TreeTmp=NULL;
                                delete TreeMerge;
                                TreeMerge=NULL;
                            }
                            AcceptanceDecisionMerge=newADMerge;
                        }
                        
                    }
                }
                
                
                if(AcceptanceDecisionMerge){
                    SeenMerge=0;
                    SeenSplit=0;
                    if(segment_param->PriorsKept==3){
                        //                    for(int c=0;c<numbchild;c++){
                        //
                        //                        nifti_image * NewPriors=TreeMerge->GetChild(c)->TransformNormRespIntoPriors(segment_param);
                        //                        TreeMerge->GetChild(c)->SetPriors(NewPriors);
                        //                        float * NewPriorsAdapted=static_cast<float *>(NewPriors->data);
                        //                        TreeMerge->GetChild(c)->SetPriorsAdapted(NewPriorsAdapted);
                        //                    }
                        vector<TreeEM *> NodePriors;
                        TreeNew->GetAllPriorsNodeVector(NodePriors);
                        int numbPriors=NodePriors.size();
                        for (int c=0; c<numbPriors; c++) {
                            nifti_image * NewPriors=NodePriors[c]->TransformNormRespIntoPriors(segment_param);
                            NodePriors[c]->SetPriors(NewPriors);
                            float * NewPriorsAdapted=static_cast<float *>(NewPriors->data);
                            NodePriors[c]->SetPriorsAdapted(NewPriorsAdapted);
                        }
                        TreeNew->NormalisePriors();
                        TreeNew->NormalisePriorsAdapted();
                    }
                    if(segment_param->PriorsKept==4 && segment_param->uniformTypeChange==5){
                        vector<TreeEM *> NodePriors;
                        NodePriors=TreeNew->GetOutliersMainNodesVectorChangeableAtlases(segment_param);
                        int numbPriors=NodePriors.size();
                        for (int c=0; c<numbPriors; c++) {
                            nifti_image * NewPriors=NodePriors[c]->TransformNormRespIntoPriors(segment_param);
                            NodePriors[c]->SetPriors(NewPriors);
                            float * NewPriorsAdapted=static_cast<float *>(NewPriors->data);
                            NodePriors[c]->SetPriorsAdapted(NewPriorsAdapted);
                        }
                        TreeNew->NormalisePriors();
                        TreeNew->NormalisePriorsAdapted();
                        if(segment_param->flag_savePriors){
                            this->SavePriorsAdapted(segment_param);
                        }
                    }
                    
                }
                else{
                    if (SeenMerge*c<MergeSize+c*SeenMerge) {
                        SeenMerge++;
                    }
                    cout<<SeenMerge<<" merge operations not accepted"<<endl;
                }
                TestNormResp=TreeNew->AreNormRespValid();
                TestNormWeights=TreeNew->AreWeightsValid();
                
                if(!TestNormResp){
                    cout << "Norm resp non valid for TreeMerge"<<endl;
                }
                if(!TestNormWeights){
                    cout << "Norm weights non valid for TreeMerge"<<endl;
                }
                
                // Recalculating the lists of Split and Merge
                SplitSize=SplitTest.size();
                
                            for(int i=0;i<SplitSize;i++){
                                if(SplitTest[0]!=NULL){
                               delete SplitTest[0];
                                SplitTest[i]=NULL;
                              }
                SplitTest.erase(SplitTest.begin());
                            }
                SplitTest.clear();
                SplitTest.swap(SplitTest);
                
                if(segment_param->SMOrder){
                    SplitTest=TreeNew->GetSplitMoreVertical_b(c,segment_param);
                }
                else{
                    SplitTest=TreeNew->OrderingSplittingLeaves_b(segment_param);
                    if (segment_param->flag_unifTot && segment_param->VarianceInitUnif==1) { // only if using the kmeans initialisation when splitting the uniform distribution
                        vector<SplitKLD_b *> SplitTestUnifTot=TreeNew->OrderingSplittingLeavesUniform_b(segment_param, 1);
                        int numbUnif=SplitTestUnifTot.size();
                        for (int u=0; u<numbUnif; u++) {
                            SplitKLD_b * CopySplitUnif=SplitTestUnifTot[u]->CopySplitKLD_b();
                            SplitTest.push_back(CopySplitUnif);
                            delete SplitTestUnifTot[u];
                            SplitTestUnifTot[u]=NULL;
                        }
                        for(int u=0;u<numbUnif;u++){
                            if (SplitTestUnifTot[u]!=NULL) {
                                delete SplitTestUnifTot[u];
                                SplitTestUnifTot[u]=NULL;
                            }
                        }
                        SplitTestUnifTot.clear();
                        SplitTestUnifTot.swap(SplitTestUnifTot);
                    }
                }
                SplitSize=SplitTest.size();
                
//                Trying for change of size of SplitTest
                if (SplitSize>0 && c*SeenSplit<=SplitSize) {
                    for (int i=0; i<c*SeenSplit; i++) {
                        delete SplitTest[0];
                        SplitTest[0]=NULL;
                        SplitTest.erase(SplitTest.begin());
                    }
                }

                
                
//                vector<SplitKLD_b*> Split_tmp;
//                for(int i=c*SeenSplit;i<SplitSize;i++){
//                    //                cout<<i<<" ";
//                    SplitKLD_b * SplitCopied=SplitTest[i]->CopySplitKLD_b();
//                    delete SplitTest[i];
//                    SplitTest[i]=NULL;
//                    Split_tmp.push_back(SplitCopied);
//                }
//                //            for(int i=0;i<SplitSize;i++){
//                //                cout<< i <<endl;
//                //                if(SplitTest[i]!=NULL){
//                //                    if(SplitTest[i]->KLD!=NULL){
//                //                delete SplitTest[i];
//                //                    }
//                //                SplitTest[i]=NULL;
//                //                }
//                //            }
//                SplitTest.clear();
//                SplitTest=Split_tmp;
                
//                Update of MergeTest Vector
                
                MergeSize=MergeTest.size();
                            for(int i=0;i<MergeSize;i++){
                             if(MergeTest[0]!=NULL){
                              delete MergeTest[0];
                              MergeTest[0]=NULL;
                            }
                MergeTest.erase(MergeTest.begin());
                            }
                MergeTest.clear();
                MergeTest.swap(MergeTest);
                if(segment_param->SMOrder){
                    MergeTest=TreeNew->GetMergeMoreVertical_b(c);
                }
                else{
                    MergeTest=TreeNew->OrderingMergingLeaves_b();
                }
                MergeSize=MergeTest.size();
                if (MergeSize>0 && c*SeenMerge<=MergeSize) {
                    for (int i=0; i<c*SeenMerge; i++) {
                        delete MergeTest[0];
                        MergeTest[0]=NULL;
                        MergeTest.erase(MergeTest.begin());
                    }
                }

                
                
//                //            vector<MergeKLD*> Merge_tmp;
//                for(int i=c*SeenMerge;i<MergeSize;i++){
//                    Merge_tmp.push_back(MergeTest[i]->CopyMergeKLD_b());
//                }
//                
//                MergeTest.clear();
//                MergeTest=Merge_tmp;
                MergeSize=MergeTest.size();
                SplitSize=SplitTest.size();
                
                cout<< MergeSize<<"merge to try and "<<SplitSize<<" split to try"<<endl;
                
                if(AcceptanceDecisionSplit+AcceptanceDecisionMerge>0){
                    cout<<"Saving because change happened"<<endl;
                TreeNew->SaveAllClasses(segment_param->filename_out[0],segment_param);
                //TreeSplit->SavePriorsAdapted(segment_param);
                TreeNew->SaveTreeInTextFile(segment_param->filename_datatxt,segment_param);
                }
                
                
                
                //            SplitTest=TreeSplit->GetSplitMoreVertical(3);
                //            =TreeMerge->GetToMerge();
                numberAllLeaves=TreeNew->GetNumberAllLeaves();
                numbchild=TreeNew->GetNumberChildren();
                cout<< "The weights of the general classes are : ";
                for (int c=0;c<numbchild;c++){
                    cout<<TreeNew->GetChild(c)->GetNormWeight()<< "    ******      ";
                }
                cout<<endl;
                cout<<"Count EM is now "<<CountRunEM<<endl;
                //                TreeNew->SaveAllLesionClasses(segment_param);
                //                TreeNew->SaveLesionClass(segment_param);
                //            AcceptanceDecision=0;
            }
            //        if(MergeTest!=NULL){
            //            delete MergeTest;
            //            MergeTest=NULL;
            //        }
            
            
        }
    
//    delete [] TryCov;
//    TryCov=NULL;
    cout<<CountRunEM<<" have been performed "<<endl;
    TreeNew->SaveTreeInTextFile(segment_param->filename_datatxt, segment_param);
    cout << "Saving stop there "<< endl;
//    TreeNew->SaveGeneralClasses(segment_param->filename_out[1], segment_param);
//    TreeNew->SaveAllClasses(segment_param->filename_out[0], segment_param);
//    TreeNew->SaveAllLesionClasses(segment_param);
//    TreeNew->SaveLesionClass(segment_param);
    return TreeNew;
}

// Run the complete BaMoS with possibility of progressive increased complexity
TreeEM * TreeEM::RunCompleteBaMoS(SEG_PARAMETERS * segment_param){
    float CompleteLogLikelihood=0;
    float OldCompleteLogLikelihood=0;
    int Iteration=0;
//    int * ModalitiesTest=this->GetModalities(segment_param);
    cout<< "The weights of the general classes are : ";
//    float * DPChildren=this->GetDPChildrenDirect();
    int numbchild=this->GetNumberChildren();
    for (int c=0;c<numbchild;c++){
        cout<<this->GetChild(c)->GetNormWeight()<< "    ******      ";
    }
    
    // Resetting of static values according to segment_param
    BFFlag=segment_param->flag_Bias;
    BICFP=segment_param->BICFP;
    BForder=segment_param->bias_order;
    MaxBaMoSTries=segment_param->MaxRunEM;
    if (BFFlag && segment_param->flag_progressiveBFC) { // Reinitialisation of BForder if progressive bias field correction chosen
        BForder=1;
    }
    NormMask=segment_param->flag_NormMask;
    Threshold=segment_param->Bias_threshold;
    MaxIteration=segment_param->maxIterationBF;
    MinIteration=segment_param->minIteration;
    NumbMaxLeaves=segment_param->maxNumbLeaves;
    KernelSize=segment_param->KernelSize;
//    int FlagCovPriors=segment_param->flag_CovPriors;
    this->UpdatePartPriorsAdapted();
    if(segment_param->flag_savePriors){
        this->SavePriorsAdapted(segment_param);
    }
    // Save before altering anything the values that will be changed and then returned to their initial value
    vector<float> AtlasWeightSaved;
    int sizeWeight=segment_param->AtlasWeight.size();
    vector<float> AtlasSmoothingSaved;
    int sizeSmoothing=segment_param->AtlasSmoothing.size();
    for (int s=0; s<sizeSmoothing; s++) {
        AtlasSmoothingSaved.push_back(segment_param->AtlasSmoothing[s]);
    }
    for (int w=0; w<sizeWeight; w++) {
        AtlasWeightSaved.push_back(segment_param->AtlasWeight[w]);
    }
    int PriorsKeptSaved=segment_param->PriorsKept;
    
    
    TreeEM * TreeNew=this;
    TreeEM * TreeTemp=this;
    // First definition of BFOrderperModality and IndexBFModalitiesTogether
    vector<int> BFOrderperModality;
    int numbmodal=this->GetNumberModalities();
    // Define at which step in the complexification we are.
    int maxComplexification=segment_param->NumberAddedModalities.size();
    int StageComplexification=0;
    int sumModalities=0;
    for (int i=0; i<maxComplexification; i++) {
        sumModalities+=segment_param->NumberAddedModalities[i];
        if (numbmodal<=sumModalities) {
            StageComplexification=i;
            break;
        }
    }
    int IndexBFModalitiesTogether=numbmodal-segment_param->NumberAddedModalities[StageComplexification];
    for (int m=0; m<IndexBFModalitiesTogether; m++) {
        BFOrderperModality.push_back(segment_param->bias_order);
    }
    for (int m=IndexBFModalitiesTogether; m<numbmodal; m++) {
        BFOrderperModality.push_back(0);
    }
    bool FirstRun=0;
    BFFlag=segment_param->flag_Bias;
    segment_param->AtlasSmoothing.clear();
    segment_param->AtlasWeight.clear();
    BForder=0;
    TreeNew->RunFullEM(CompleteLogLikelihood, OldCompleteLogLikelihood, Iteration, segment_param);
    if(segment_param->flag_savePriors){
        this->SavePriorsAdapted(segment_param);
    }
    cout<<GetMaxArray(TreeNew->GetChild(1)->GetPriorsAdaptedDirect(),TreeNew->GetNumberElements())<<endl;
    if(segment_param->flag_EMfirst_out){
        string FilenameEMFirst=nifti_makebasename(segment_param->filename_EMfirst.c_str());
        stringstream ss;
        ss << TreeNew->GetNumberModalities();
        string nm=ss.str();
        segment_param->filename_EMfirst=FilenameEMFirst+"_"+nm+".nii.gz";
        TreeNew->SaveAllClasses(segment_param->filename_EMfirst,segment_param);
        FilenameEMFirst+="_"+nm+".txt";
        char FilenameToUse[200];
        strcpy(FilenameToUse,FilenameEMFirst.c_str());
        TreeNew->SaveTreeInTextFile(FilenameToUse,segment_param);
    }
    
    
    
//    Parameters * TestParam=TreeNew->GetChild(1)->GetChild(1)->ParametersForSplittingUniform3(segment_param,0);
    if(segment_param->flag_JuxtaCorrection){
        cout<<"Trying to correct potential WM islands..."<<endl;
//        this->CorrectInitialEMResultForWrongWMHoles(segment_param);
    }
    
//    Reput the Atlasweighting and smoothing to perform the Adaptation of the priors
    for (int w=0; w<sizeWeight; w++) {
        segment_param->AtlasWeight.push_back(AtlasWeightSaved[w]);
    }
    for (int s=0; s<sizeSmoothing; s++) {
        segment_param->AtlasSmoothing.push_back(AtlasSmoothingSaved[s]);
    }
    
    
    
    TreeNew->FullAdaptPriors(segment_param);
    cout<<GetMaxArray(TreeNew->GetChild(1)->GetPriorsAdaptedDirect(),TreeNew->GetNumberElements())<<endl;
    TreeNew->UpdatePartPriorsAdapted();
    cout<<GetMaxArray(TreeNew->GetChild(1)->GetPriorsAdaptedDirect(),TreeNew->GetNumberElements())<<endl;
    
    if(segment_param->flag_EMfirst_out){
        string FilenameEMFirst=nifti_makebasename(segment_param->filename_EMfirst.c_str());
        stringstream ss;
        ss << TreeNew->GetNumberModalities();
        string nm=ss.str();
        segment_param->filename_EMfirst=FilenameEMFirst+"_"+nm+".nii.gz";
        TreeNew->SaveAllClasses(segment_param->filename_EMfirst,segment_param);
        FilenameEMFirst+="_"+nm+".txt";
        char FilenameToUse[200];
        strcpy(FilenameToUse,FilenameEMFirst.c_str());
        TreeNew->SaveTreeInTextFile(FilenameToUse,segment_param);
    }
    
    if(segment_param->flag_savePriors){
        TreeNew->SavePriorsAdapted(segment_param);
    }
    
    segment_param->AtlasSmoothing.clear();
    segment_param->AtlasWeight.clear();
    if (BFFlag) {
        TreeNew->SaveBFCorrection(segment_param->filename_correction);
    }
    BFFlag=0;
    while (numbmodal<segment_param->numbmodal || !FirstRun) {
        cout<< "Running for "<<numbmodal<<" modalities "<<endl;
        // BFFlag=segment_param->flag_Bias;
        Iteration=0;
        CompleteLogLikelihood=0;
        OldCompleteLogLikelihood=0;
        // First operate EM BF Separated on current tree without covariance constraint
//        TreeNew->SetFlagCovPriors(0);
//        TreeNew->RunFullEMSeparatedBF(BFOrderperModality, IndexBFModalitiesTogether, CompleteLogLikelihood, OldCompleteLogLikelihood, Iteration, segment_param);
        TreeNew->RunFullEM(CompleteLogLikelihood, OldCompleteLogLikelihood, Iteration, segment_param);
        if(segment_param->flag_JuxtaCorrection){
            nifti_image * CorrectionJuxta=TreeNew->CorrectInitialEMResultForWrongWMHoles(segment_param);
            nifti_image_free(CorrectionJuxta);
            CorrectionJuxta=NULL;
            TreeNew->UpdateNonNormWeights();
            TreeNew->UpdateNormWeights();
            TreeNew->UpdateParameters();
        }
        
        for (int w=0; w<sizeWeight; w++) {
            segment_param->AtlasWeight.push_back(AtlasWeightSaved[w]);
        }
        for (int s=0; s<sizeSmoothing; s++) {
            segment_param->AtlasSmoothing.push_back(AtlasSmoothingSaved[s]);
        }
        
        TreeNew->FullAdaptPriors(segment_param);
        TreeNew->UpdatePartPriorsAdapted();
        
        if(segment_param->flag_savePriors){
            TreeNew->SavePriorsAdapted(segment_param);
        }
        cout<<GetMaxArray(TreeNew->GetChild(1)->GetPriorsAdaptedDirect(),TreeNew->GetNumberElements())<<endl;
        
        
        segment_param->AtlasSmoothing.clear();
        segment_param->AtlasWeight.clear();
        
//        TEST OF TYPICALITY MAP AS ATLAS
//        nifti_image * WMNiiTyp=TreeNew->MakeTypicalityFloatClass(1, segment_param);
//        nifti_image * TypAtlas4DNii=TreeNew->CreateTypicalityAtlas4D(segment_param);
//        nifti_image * TypAtlasNii=TreeNew->CreateTypicalityAtlas(segment_param);
//        
//        nifti_set_filenames(WMNiiTyp, "/Users/Carole/Documents/PhD/TestWMNiiTyp.nii.gz", 0, 0);
        if(segment_param->flag_TypicalityAtlas){
            
//            TreeNew->SavePriorsAdapted(segment_param);
        CompleteLogLikelihood=0;
        OldCompleteLogLikelihood=0;
        Iteration=0;
        nifti_image * TypAtlasNii=TreeNew->CreateTypicalityAtlas(segment_param);
        nifti_image * TypAtlasComp=CreateNormaliseOppositeImage(TypAtlasNii);
            string FilenamePA=nifti_makebasename(segment_param->filename_out[0].c_str());
            
            
            int Index=FilenamePA.find_last_of('/');
            string FilenamePA_b=FilenamePA.substr(0,Index+1);
            string FilenamePA_e=FilenamePA.substr(Index+1,FilenamePA.length());
            string FilenameTypicality=FilenamePA_b+"TypicalityAtlas_"+FilenamePA_e+".nii.gz";
            nifti_set_filenames(TypAtlasComp, FilenameTypicality.c_str(), 0, 0);
            nifti_image_write(TypAtlasComp);
            
        TreeNew->GetNodeInlier()->SetPriors(TypAtlasNii);
        TreeNew->GetNodeOutlier()->SetPriors(TypAtlasComp);
        TreeNew->GetNodeOutlier()->SetPriorsAdapted(static_cast<float*>(TypAtlasComp->data));
        TreeNew->GetNodeInlier()->SetPriorsAdapted(static_cast<float*>(TypAtlasNii->data));
        TreeNew->UpdatePartPriorsAdapted();
        TreeNew->RunFullEM(CompleteLogLikelihood, OldCompleteLogLikelihood, Iteration, segment_param);
            for (int w=0; w<sizeWeight; w++) {
                segment_param->AtlasWeight.push_back(AtlasWeightSaved[w]);
            }
            for (int s=0; s<sizeSmoothing; s++) {
                segment_param->AtlasSmoothing.push_back(AtlasSmoothingSaved[s]);
            }
            TreeNew->FullAdaptPriors(segment_param);
            TreeNew->UpdatePartPriorsAdapted();
            
            if(segment_param->flag_savePriors){
                TreeNew->SavePriorsAdapted(segment_param);
            }
            TreeNew->FullAdaptPriors(segment_param);
            TreeNew->UpdatePartPriorsAdapted();
//            TreeNew->SavePriorsAdapted(segment_param);
            cout<<"Tried with typicality maps for atlases";
    }
    
//        END OF TEST TYPICALITY MAP
        if (segment_param->flag_BoostAtlas) {
            
        segment_param->AtlasWeight.clear();
        segment_param->AtlasSmoothing.clear();
        
        segment_param->AtlasSmoothing.push_back(0);
        segment_param->AtlasWeight.push_back(0.25);
        segment_param->AtlasWeight.push_back(1);
        
        TreeNew->FullAdaptPriors(segment_param);
        TreeNew->UpdatePartPriorsAdapted();
        
        if(segment_param->flag_savePriors){
            TreeNew->SavePriorsAdapted(segment_param);
        }
        }
        
        // Then rerun an EM on the already BF corrected images /
        BForder=segment_param->bias_order;
        CompleteLogLikelihood=0;
        OldCompleteLogLikelihood=0;
        Iteration=0;
//        TreeNew->SetFlagCovPriors(segment_param->CovPriorsType);
//        TreeNew->RunFullEM(CompleteLogLikelihood, OldCompleteLogLikelihood, Iteration, segment_param);
        if (BFFlag) {
            TreeNew->SaveBFCorrection(segment_param->filename_correction);
        }
        // Saving Results from this first stage
        if(segment_param->flag_EMfirst_out){
            string FilenameEMFirst=nifti_makebasename(segment_param->filename_EMfirst.c_str());
            stringstream ss;
            ss << TreeNew->GetNumberModalities();
            string nm=ss.str();
            segment_param->filename_EMfirst=FilenameEMFirst+"_"+nm+".nii.gz";
            TreeNew->SaveAllClasses(segment_param->filename_EMfirst,segment_param);
            FilenameEMFirst+="_"+nm+".txt";
            char FilenameToUse[200];
            strcpy(FilenameToUse,FilenameEMFirst.c_str());
            TreeNew->SaveTreeInTextFile(FilenameToUse,segment_param);
        }
        if(segment_param->flag_savePriors){
            TreeNew->SavePriorsAdapted(segment_param);
        }
            TreeNew->SaveBFCorrectedData(segment_param->filename_datacorrected);
        // Once that is done, adaptation of the atlases
        //Once the first initialisation with EM done, resetting of needed parameters
        MaxIteration=segment_param->maxIteration;
        Threshold=segment_param->ConvThreshold;
        BFFlag=0;
        if(segment_param->PriorsKept!=3 && segment_param->PriorsKept!=4){
            segment_param->AtlasWeight.clear();
            segment_param->AtlasWeight.push_back(0);
            float Smoothing=1;
            if(segment_param->AtlasSmoothing.size()>0){
                Smoothing=segment_param->AtlasSmoothing[0];
                segment_param->AtlasSmoothing.clear();
                segment_param->AtlasSmoothing.push_back(Smoothing);
            }
        }
        if(segment_param->PriorsKept==8){ // After the run of the first EM, the PriorsKept option is reset to 5
            segment_param->PriorsKept=5;
        }
        
        TreeNew->SetIndFactor(TreeNew->MakeIndFactorTot());
        cout<< "The weights of the general classes are : ";
        for (int c=0;c<TreeNew->GetNumberChildren();c++){
            cout<<TreeNew->GetChild(c)->GetNormWeight()<< "    ******      ";
        }
        
        
//        TreeNew->FullAdaptPriors(segment_param);
        // Then run the BaMoS process if flag_BiASM is up
        TreeNew->DeleteUnderWeight(segment_param);
        if (segment_param->flag_BiASM) {
           TreeTemp=TreeNew->RunBaMoSLoop(segment_param);
        }

        
        if (segment_param->numbmodal!=numbmodal) { // Other modalities have yet to be considered
            // Adding complexity by addition of relevant new modalities
//            delete TreeNew;
//            TreeNew=NULL;
//            TreeTmp->SavePriorsAdapted(segment_param);
            TreeNew=BuildTreeWithAddedModalityFromExistingModel(TreeTemp, segment_param);
            
            numbmodal=TreeNew->GetNumberModalities();
            delete TreeTemp;
            TreeTemp=TreeNew;
            // Redefinition of BFOrderperModality and IndexBFModalitiesTogether
            BFOrderperModality.clear();
            StageComplexification=0;
            sumModalities=0;
            for (int i=0; i<maxComplexification; i++) {
                sumModalities+=segment_param->NumberAddedModalities[i];
                if (numbmodal<=sumModalities) {
                    StageComplexification=i;
                    break;
                }
            }
            int IndexBFModalitiesTogether=numbmodal-segment_param->NumberAddedModalities[StageComplexification];
            for (int m=0; m<IndexBFModalitiesTogether; m++) {
                BFOrderperModality.push_back(segment_param->bias_order);
            }
            for (int m=IndexBFModalitiesTogether; m<numbmodal; m++) {
                BFOrderperModality.push_back(0);
            }
//            BFFlag=segment_param->flag_Bias;
            
            // Put back all saved parameters to run initial EM with appropriate parameters
            if(segment_param->PriorsKept!=3 && segment_param->PriorsKept!=4){
                segment_param->AtlasWeight.clear();
                for (int w=0; w<sizeWeight; w++) {
                    segment_param->AtlasWeight.push_back(AtlasWeightSaved[w]);
                }
                segment_param->AtlasSmoothing.clear();
                for (int s=0; s<sizeSmoothing; s++) {
                    segment_param->AtlasSmoothing.push_back(AtlasSmoothingSaved[s]);
                }
                segment_param->PriorsKept=PriorsKeptSaved;
            }
            
            // Change in name to save temporary results
            string ToChangeEMfirstFilename=nifti_makebasename(segment_param->filename_EMfirst.c_str());
            int ModalChange=TreeNew->GetNumberModalities();
            stringstream ss;
            ss << ModalChange;
            string cb=ss.str();
            ToChangeEMfirstFilename+="_"+cb+".nii.gz";
            segment_param->filename_EMfirst=ToChangeEMfirstFilename;
            int numbout=segment_param->filename_out.size();
            for (int o=0; o<numbout; o++) {
                string ToChangeOut=nifti_makebasename(segment_param->filename_out[o].c_str());
                ToChangeOut+="_"+cb+".nii.gz";
                segment_param->filename_out[o]=ToChangeOut;
                if (o==0) {
                    string ToChangeTxt=nifti_makebasename(segment_param->filename_out[o].c_str());
                    ToChangeTxt+=".txt";
                    segment_param->filename_datatxt=ToChangeTxt;
                }
            }
            
        }
        else{
            FirstRun=1;
        }
    }
    if(segment_param->flag_JuxtaCorrection){
        nifti_image * CorrectionJuxta=TreeTemp->CorrectInitialEMResultForWrongWMHoles(segment_param);
        nifti_image_free(CorrectionJuxta);
        CorrectionJuxta=NULL;
        TreeTemp->UpdateParameters();
    }
    return TreeTemp;
}


/**************  TREE RELATED METHODS ******************/


/*A root element is defined by the fact that the pointer to Parent is NULL. FindRoot recursively finds the element whose Parent is NULL. Should be the only one to use links upwards*/
TreeEM * TreeEM::FindRoot(){
    if(this->GetParent()==NULL){
        return this;
    }
    else{
        return this->GetParent()->FindRoot();
    }
}

// If the current node is considered as a mixture but has only one child, the node is replaced by the child itself and transformed as a simple distribution.
void TreeEM::CollapseOnlyChild(){
    if (this->GetNumberChildren()!=1) {
        cout<<"Collapsing only when number of children is 1"<<endl;
        return;
    }
    if(this->GetChild(0)->IsLeaf()){
    this->SetParameters(this->GetChild(0)->GetParameters());
    delete this->GetChild(0);
    this->Children.erase(this->Children.begin());
    }
    else { // meaning that the child to collapse is a mixture and it is not as simple : need to first copy the considered children, add them before deleting Child0
        int numbChildrenChild0=this->GetChild(0)->GetNumberChildren();
        for (int c=0; c<numbChildrenChild0; c++) {
            TreeEM * CopiedChild=this->GetChild(0)->GetChild(c)->CopyTree(this);
            CopiedChild->NormWeight=this->GetChild(0)->GetNormWeight()*CopiedChild->GetNormWeight();
            this->AddChild(CopiedChild);
        }
        delete this->GetChild(0);
        this->Children.erase(this->Children.begin());
    }

}

// Recursively collapsing all only children in the tree to avoid to have only one child
void TreeEM::CollapseOnlyChildTot(){
    if (this->GetNumberChildren()==1) {
        this->CollapseOnlyChild();
        return;
    }
    else{
        int numbchild=this->GetNumberChildren();
        for (int c=0; c<numbchild; c++) {
            this->GetChild(c)->CollapseOnlyChildTot();
        }
    }
    return;
}



// In case model outliers is 2 and the unif dist is not the last one of the last child, modification of the outlier class so that unif dist is the last one
void TreeEM::ReplaceUnifDist(SEG_PARAMETERS * segment_param){
    if (this->CheckUnifDistPosition(segment_param)) { // if the unif dist is well positioned, no need to modify anything.
        return;
    }
    else if (this->FlagOutliers!=3 && this->FlagOutliers<5){ // the unif dist is not the last one of the second level and the outlier model is not the number 3
        TreeEM * UnifLeave=this->FindUnifDist(segment_param);
        if (UnifLeave==NULL) { // Normally case taken care of in CheckUnifDistPosition but in case NULL return without doing anything.
            return;
        }
        TreeEM * UnifParent=UnifLeave->GetParent();
        int IndexUnif=UnifParent->FindIndex(UnifLeave);
        TreeEM * UnifNew=UnifLeave->CopyTree(UnifParent);
        delete UnifLeave;
        UnifParent->Children.erase(UnifParent->Children.begin()+IndexUnif);
        UnifParent->AddChild(UnifNew);
    }
    else{
        vector<vector<int> > UnifLeavesVector=this->FindAllUniformDistHierarchies(segment_param);
        int numbUnifLeaves=UnifLeavesVector.size();
        for (int u=0; u<numbUnifLeaves; u++) {
            TreeEM * UnifLeave=this->FindFromHierarchy(UnifLeavesVector[u]);
            TreeEM * UnifParent=UnifLeave->GetParent();
            int numbChildrenParentUnif=UnifParent->GetNumberChildren();
            int IndexUnif=UnifLeavesVector[u].back();
            if (IndexUnif<numbChildrenParentUnif-1 && UnifParent!=this->GetNodeOutlier()) {
                cout <<"Pb with unif dist found for "<<u<<endl;
                TreeEM * UnifNew=UnifLeave->CopyTree(UnifParent);
                delete UnifLeave;
                UnifParent->Children.erase(UnifParent->Children.begin()+IndexUnif);
                UnifParent->AddChild(UnifNew);
            }
        }
    }
}


// Create and add to current Tree a child that has been initialised with specific priors and distribution type allocating memory for different fields.
void TreeEM::CreateAndAddChildPriors(SEG_PARAMETERS * segment_param,nifti_image * PriorsInput=NULL,int DistributionType=1 ){

    // First taking care of all needed changes on the created child to make a coherent tree
    TreeEM * ChildCreated=new TreeEM();
    //cout<<ChildCreated->GetDataDirect()<<endl;
    ChildCreated->SetParent(this); // set the parent and allocate the proper amount of memory
    //cout<<ChildCreated->GetDataDirect()<<endl;
    //    cout<<"Allocate memory when creating child"<<endl;
    // Allocation of good amount of memory for Distribution, NonNormResp, NormResp
    int numelmasked=ChildCreated->GetNumberMaskedElements();
    int numel = ChildCreated->GetNumberElements();
    if (ChildCreated->NormResp!=NULL) {
        delete [] ChildCreated->NormResp;
        ChildCreated->NormResp=NULL;
    }
    float * NormRespToSet=NULL;
    if (this->GetFlagOutliers()==4) {
        NormRespToSet=new float[2*numelmasked];
        for(int i=0;i<numelmasked;i++){
            NormRespToSet[i]=0;
            NormRespToSet[i+numelmasked]=1;
        }
        ChildCreated->SetNormResp(NormRespToSet);
        if(NormRespToSet!=NULL){
            delete [] NormRespToSet;
            NormRespToSet=NULL;
        }
    }
    else{
    NormRespToSet=new float[numelmasked];
    for(int i=0;i<numelmasked;i++){
        NormRespToSet[i]=0;
    }
    ChildCreated->SetNormResp(NormRespToSet);
    if(NormRespToSet!=NULL){
        delete [] NormRespToSet;
        NormRespToSet=NULL;
    }
    }
    //cout<< "NormResp set";

    // Handling the Priors input
    ChildCreated->SetPriors(PriorsInput); // Takes care of the validity checking of the priors and of making usable as probabilities

    // If priors used and not null natural initialisation of the adapted priors with the priors themselves
    if(ChildCreated->GetPriorsDirect()!=NULL){
        float * PriorsAdaptedToSet=new float[numel];
        float * Priors_PTR=static_cast<float*>(ChildCreated->GetPriors()->data);
        int CountPriorsZero=0;
        for(int i=0;i<numel;i++,Priors_PTR++){
            PriorsAdaptedToSet[i]=*Priors_PTR;
            if(PriorsAdaptedToSet[i]==0){
                CountPriorsZero++;
            }
        }
        Priors_PTR=static_cast<float*>(ChildCreated->GetPriors()->data);
//        SaveTmpResult(PriorsAdaptedToSet,"/Users/Carole/Documents/PhD/PriorsInit.nii.gz");
        ChildCreated->SetPriorsAdapted(PriorsAdaptedToSet);
        if(PriorsAdaptedToSet!=NULL){
            delete [] PriorsAdaptedToSet;
            PriorsAdaptedToSet=NULL;
        }
    }

    // If leaf, and flag_MRF ON, allocate memory for MRF
    if(ChildCreated->IsLeaf()&&segment_param->flag_MRF){
        float * MRFToSet=new float[numelmasked];
        for(int i=0;i<numelmasked;i++){
            MRFToSet[i]=0;
        }
        ChildCreated->SetMRF(MRFToSet);
        if(MRFToSet !=NULL){
            delete [] MRFToSet;
            MRFToSet=NULL;
        }
    }

    // Handling the distribution type input. Must necessary be a simple distribution. By default Gaussian distribution chosen
    if (DistributionType==0){ // Cannot be a mixture if leaf
        DistributionType=1;
    }
    //cout<<"Normally the distribution type is now "<<DistributionType;
    ChildCreated->CreateAllocateAndInitializeParameters(DistributionType);
    // If leaf, and flag_CovPriors ON, allocate memory for CovPriorsMatrix
    if(ChildCreated->GetDistributionType()==1 &&segment_param->flag_CovPriors){
        int numbmodal=this->GetNumberModalities();
        int numbmodalSq=numbmodal*numbmodal;
        float * CovPriorsMatrix=new float[numbmodalSq];
        for(int i=0;i<numbmodalSq;i++){
            CovPriorsMatrix[i]=0;
        }
        ChildCreated->SetFlagCovPriorsParameters(1);
        ChildCreated->SetCovPriorsMatrix(CovPriorsMatrix);
        if(CovPriorsMatrix !=NULL){
            delete [] CovPriorsMatrix;
            CovPriorsMatrix=NULL;
        }
    }
    //    cout<<"Parameters allocated for child"<<endl;
    // Then taking care of changes needed on parent on which ChildCreated is added
    this->MakeParametersMixture(); // Modify parameters structure : check if it is already a mixture otherwise make it a mixture parameters
    this->Children.push_back(ChildCreated);
}

// Same as before but instead of initialising ans setting Priors, NormWeight is set
void TreeEM::CreateAndAddChildWeight(SEG_PARAMETERS * segment_param,float Weight=0,int DistributionType=1 ){

    // First taking care of all needed changes on the created child to make a coherent tree
    TreeEM * ChildCreated=new TreeEM();
    //cout<<ChildCreated->GetDataDirect()<<endl;
    ChildCreated->SetParent(this); // set the parent and allocate the proper amount of memory
    //cout<<ChildCreated->GetDataDirect()<<endl;
    //    cout<<"Allocate memory when creating child"<<endl;
    // Allocation of good amount of memory for Distribution, NonNormResp, NormResp
    int numelmasked=ChildCreated->GetNumberMaskedElements();
    int numel = ChildCreated->GetNumberElements();
    if (ChildCreated->NormResp!=NULL) {
        delete [] ChildCreated->NormResp;
        ChildCreated->NormResp=NULL;
    }
    float * NormRespToSet=NULL;
    if (this->GetFlagOutliers()==4) {
        NormRespToSet=new float[2*numelmasked];
        for(int i=0;i<numelmasked;i++){
            NormRespToSet[i]=0;
            NormRespToSet[i+numelmasked]=1;
        }
        ChildCreated->SetNormResp(NormRespToSet);
        if(NormRespToSet!=NULL){
            delete [] NormRespToSet;
            NormRespToSet=NULL;
        }
    }
    else{
     NormRespToSet=new float[numelmasked];
    for(int i=0;i<numelmasked;i++){
        NormRespToSet[i]=0;
    }
    ChildCreated->SetNormResp(NormRespToSet);
    if(NormRespToSet!=NULL){
        delete [] NormRespToSet;
        NormRespToSet=NULL;
    }
    }
    //cout<< "NormResp set";

    // Handling the Priors input
    ChildCreated->SetPriors(NULL); // Takes care of the validity checking of the priors and of making usable as probabilities
    // Handling the weight input
    ChildCreated->SetNormWeight(Weight);

    // If priors used and not null natural initialisation of the adapted priors with the priors themselves
    if(ChildCreated->GetPriorsDirect()!=NULL){
        float * PriorsAdaptedToSet=new float[numel];
        float * Priors_PTR=static_cast<float*>(ChildCreated->GetPriors()->data);
        for(int i=0;i<numel;i++,Priors_PTR++){
            PriorsAdaptedToSet[i]=*Priors_PTR;
        }
        Priors_PTR=static_cast<float*>(ChildCreated->GetPriors()->data);
        ChildCreated->SetPriorsAdapted(PriorsAdaptedToSet);
        if(PriorsAdaptedToSet!=NULL){
            delete [] PriorsAdaptedToSet;
            PriorsAdaptedToSet=NULL;
        }
    }

    // If leaf, and flag_MRF ON, allocate memory for MRF
    if(ChildCreated->IsLeaf()&&segment_param->flag_MRF){
        float * MRFToSet=new float[numelmasked];
        for(int i=0;i<numelmasked;i++){
            MRFToSet[i]=0;
        }
        ChildCreated->SetMRF(MRFToSet);
        if(MRFToSet !=NULL){
            delete [] MRFToSet;
            MRFToSet=NULL;
        }
    }
    // Handling the distribution type input. Must necessary be a simple distribution. By default Gaussian distribution chosen
    if (DistributionType==0){ // Cannot be a mixture if leaf
        DistributionType=1;
    }
    //cout<<"Normally the distribution type is now "<<DistributionType;
    ChildCreated->CreateAllocateAndInitializeParameters(DistributionType);
    // If leaf, and flag_CovPriors ON, allocate memory for CovPriorsMatrix
    if(ChildCreated->IsLeaf()&&segment_param->flag_CovPriors){
        int numbmodal=this->GetNumberModalities();
        int numbmodalSq=numbmodal*numbmodal;
        float * CovPriorsMatrix=new float[numbmodalSq];
        for(int i=0;i<numbmodalSq;i++){
            CovPriorsMatrix[i]=0;
        }
        ChildCreated->SetFlagCovPriorsParameters(1);
        ChildCreated->SetCovPriorsMatrix(CovPriorsMatrix);
        if(CovPriorsMatrix !=NULL){
            delete [] CovPriorsMatrix;
            CovPriorsMatrix=NULL;
        }
    }
    //    cout<<"Parameters allocated for child"<<endl;
    // Then taking care of changes needed on parent on which ChildCreated is added
    this->MakeParametersMixture(); // Modify parameters structure : check if it is already a mixture otherwise make it a mixture parameters
    this->Children.push_back(ChildCreated);
}

bool TreeEM::CheckForTreeValidity(){
//    int numbmodal=this->GetNumberModalities();
    vector<TreeEM *> NodesVector=this->GetAllNodes();
    bool ResultValid=1;
    int numbNodes=NodesVector.size();
    for (int n=0; n<numbNodes; n++) {
        ResultValid*=NodesVector[n]->CheckForSizeParametersValidity();
        if (ResultValid==0) {
            cout<<"Invalidity in parameters"<<endl;
            break;
        }
    }
    return ResultValid;
}

// Initialisation of basic Tree
void TreeEM::InitialiseBasicTree(SEG_PARAMETERS * segment_param){
    BFFlag=segment_param->flag_Bias;
    NormMask=segment_param->flag_NormMask;
    if (this->IsBasicTree()) {
        srand (time(NULL));
        
        cout<<"This is a basic Tree !!";
        //vector<nifti_image*> PriorsVector=this->GetPriorsVector();
        //cout<<this->GetPriorsVector().size();
        if(this->ArePriorsNormalised()){
//            bool TestWeight=this->TestInitWeights();
            this->InitialiseNormResp();
//           this->SaveTmpResultMasked(this->GetChild(0)->GetChild(0)->NormResp,"/Users/Carole/Documents/PhD/NormRespInit.nii.gz");
            this->UpdateNormResp();
            this->UpdateNormRespRoot();
            this->UpdateNonNormWeights();
            this->UpdateNormWeights();
            if(this->GetPriorsVector().size()==0){ // Need for parameters random creation if no priors are provided
                vector<TreeEM*> GeneralNodesVector;
                if(this->FlagOutliers==1){
                    GeneralNodesVector=this->GetChild(0)->GetChildren();
                }
                else{
                    GeneralNodesVector=this->GetChildren();
                }
                int numbmodal=this->GetNumberModalities();
                int numbclasses=this->GetNumberGeneralClasses();
                for(int c=0;c<numbclasses;c++){
                    // Random initialisation of the mean, variance set to the identity matrix
                    if(!GeneralNodesVector[c]->CheckForValidityOfParametersStructure()){
                        GeneralNodesVector[c]->CreateAllocateAndInitializeParameters(1);
                    }
                    for (int m=0; m<numbmodal; m++) {
                        this->GetChild(c)->GetMean()[m]=(float)((float)rand()/(float)RAND_MAX);
                        this->GetChild(c)->GetVariance()[m+numbmodal*m]=0.1;
                    }
                }

                this->UpdateNonNormResp(segment_param);
                this->UpdateNormResp();
                this->UpdateNormRespRoot();
                this->UpdateNonNormWeights();
                this->UpdateNormWeights();
                if (segment_param->flag_CovPriors) {
                    this->ModifyCovPriors(segment_param);
                }
                this->UpdateParameters();

            }
            else { // case we have initialised everything with the priors
//                cout<<this->GetGeneralClassesVector().size()<<" anatomical classes"<<endl;
//                cout<<this->GetAllLeaves().size()<<" ready leaves "<<this<<endl;
                if (segment_param->flag_CovPriors) {
                    this->ModifyCovPriors(segment_param);
                }
                this->UpdateParameters();
            }
//            cout<<this->GetGeneralClassesVector().size()<<" anatomical classes"<<endl;
                if(segment_param->flag_MRF){
                    float * GMatrixToSet=NULL;
                    if(segment_param->flag_GMatrixIn){
                        GMatrixToSet=this->CreateGMatrixFromInfo( segment_param->flag_optMRFOut,segment_param->filename_GMatrix);
//                        GMatrixToSet =this->PrepareGMatrixFromFile(segment_param->filename_GMatrix,segment_param->flag_optMRFOut);
                        if(GMatrixToSet==NULL){
                            segment_param->flag_GMatrix=0;
                        }
                        this->SetGMatrix(GMatrixToSet);
                        if (GMatrixToSet!=NULL) {
                            delete [] GMatrixToSet;
                            GMatrixToSet=NULL;
                        }
                    }
                    else {
                        GMatrixToSet=this->MRFOptSolveLS(segment_param);
                        if(GMatrixToSet!=NULL){
                            delete [] GMatrixToSet;
                            GMatrixToSet=NULL;
                        }
                    }
                }
                if(segment_param->flag_MRF){
                    this->UpdateMRF(segment_param);
                }
                this->UpdateNonNormWeights();
                //
                this->UpdateNormWeights();
//                if (BFFlag) {
//                    this->UpdateBFCoeffs();
//                    //                    this->UpdateBFCorrection();
//                    this->UpdateDataBFCorrected();
//                }
            }

        else{ // In case the priors are not normalised, then need to normalise them
            this->NormalisePriors(); // We normalise and call back InitialiseBasicTree
            this->NormalisePriorsAdapted();
            cout<<this->ArePriorsNormalised();
            cout<<this->ArePriorsAdaptedNormalised();
            cout<<"Normalised Priors"<<endl;
            this->InitialiseBasicTree(segment_param);
            this->UpdatePartPriorsAdapted();
        }
        // Treating case where outlier atlas is based on spatial first assumption
        if (segment_param->flag_OutlierAtlas>=0) {
//            float Mahaldistance=segment_param->Mahal;
            int numel=this->GetNumberElements();
            nifti_image * PriorsOutliers=this->BuildOutliersPriors(segment_param);
//            nifti_image * PriorsOutliers=this->BuildOutliersPriors_bis(Mahaldistance);
            nifti_image * PriorsInliers=this->CreateNormaliseOppositeImage(PriorsOutliers);
//            nifti_set_filenames(PriorsInliers, "/Users/Carole/Documents/PhD/TemporaryFiles/SABRE09/AtlasInliers.nii.gz", 0, 0);
//            nifti_image_write(PriorsInliers);
            nifti_set_filenames(PriorsOutliers, "/Users/Carole/Documents/PhD/TemporaryFiles/SABRE09/AtlasOutliers.nii.gz", 0, 0);
//            nifti_image_write(PriorsOutliers);
            this->GetNodeOutlier()->SetPriors(PriorsOutliers);
            float * PriorsOutliers_PTR=static_cast<float *>(PriorsOutliers->data);
            float * PriorsAdaptedOutlier=new float[numel];
            for (int i=0; i<numel; i++) {
                PriorsAdaptedOutlier[i]=PriorsOutliers_PTR[i];
            }
            this->GetNodeOutlier()->SetPriorsAdapted(PriorsAdaptedOutlier);
            delete [] PriorsAdaptedOutlier;
            PriorsAdaptedOutlier=NULL;
            if (this->GetFlagOutliers()==3 || this->GetFlagOutliers()>=5) {
                this->GetNodeInlier()->SetPriors(PriorsInliers);
                float * PriorsInliers_PTR=static_cast<float*>(PriorsInliers->data);
                float * PriorsAdaptedInlier=new float [numel];
                for (int i=0; i<numel; i++) {
                    PriorsAdaptedInlier[i]=PriorsInliers_PTR[i];
                }
                this->GetNodeInlier()->SetPriorsAdapted(PriorsAdaptedInlier);
                delete [] PriorsAdaptedInlier;
                PriorsAdaptedInlier=NULL;
            }
//            nifti_set_filenames(this->GetNodeOutlier()->GetPriorsDirect(), "/Users/Carole/Documents/PhD/TemporaryFiles/SABRE09/AtlasOutliers.nii.gz", 0, 0);
//            nifti_image_write(this->GetNodeOutlier()->GetPriorsDirect());
//            nifti_set_filenames(this->GetNodeInlier()->GetPriorsDirect(), "/Users/Carole/Documents/PhD/TemporaryFiles/SABRE09/AtlasInliers.nii.gz", 0, 0);
//            nifti_image_write(this->GetNodeInlier()->GetPriorsDirect());
            if (!this->FindRoot()->ArePriorsNormalised()) {
                this->FindRoot()->NormalisePriors();
                this->FindRoot()->NormalisePriorsAdapted();
                this->FindRoot()->UpdatePartPriorsAdapted();
            }
            nifti_set_filenames(this->GetNodeOutlier()->GetPriorsDirect(), "/Users/Carole/Documents/PhD/TemporaryFiles/IMX1/AtlasOutliers.nii.gz", 0, 0);
//            nifti_image_write(this->GetNodeOutlier()->GetPriorsDirect());
            
            this->InitialiseNormResp();
//             this->SaveTmpResultMasked(this->NormResp,"/Users/Carole/Documents/PhD/NormRespInit_r.nii.gz");
//                    this->SaveTmpResultMasked(this->GetChild(0)->NormResp,"/Users/Carole/Documents/PhD/NormRespInit.nii.gz");
//            this->SaveTmpResultMasked(this->GetChild(1)->NormResp,"/Users/Carole/Documents/PhD/NormRespInit_o.nii.gz");
//            this->UpdateNonNormResp(segment_param);
            this->UpdateNormResp();
//            this->SaveTmpResultMasked(this->GetChild(0)->NormResp,"/Users/Carole/Documents/PhD/NormRespInit_b.nii.gz");
            this->UpdateNormRespRoot();
//            this->SaveTmpResultMasked(this->GetChild(0)->NormResp,"/Users/Carole/Documents/PhD/NormRespInit_c.nii.gz");
            this->UpdateNonNormWeights();
            this->UpdateNormWeights();
            if (segment_param->flag_CovPriors) {
                this->ModifyCovPriors(segment_param);
            }
            this->UpdateParameters();
        }
        
        
    }
//    else{
//        cout<<"This tree is not to initialise"<<endl;
//    }
//    if (this->GetGMatrix()!=NULL) {
//        int numbLeaves=this->FindRoot()->GetAllLeaves().size();
//        float * GMatrixToDisplay=this->GetGMatrix();
//        cout<<"The GMatrix used is the following"<<endl;
//        for (int i=0; i<numbLeaves; i++) {
//            for (int j=0; j<numbLeaves; j++) {
//                cout<<" "<<GMatrixToDisplay[i+numbLeaves*j];
//            }
//            cout<<endl;
//        }
//    }
    return;
}


/* Reinitialise the checks for the SM operations.*/
void TreeEM::ClearSMChecks(){
    //    int numbDirectLeaves=this->GetNumberDirectLeaves();
    int numbchild=this->GetNumberChildren();

    if (numbchild!=0) {
        if (this->GetSplitCheck()!=NULL) {
            delete [] this->SplitCheck;
        }
        this->SplitCheck=NULL;
        this->SplitCheck=new bool[numbchild];//{0};
        for(int c=0;c<numbchild;c++){
            this->SplitCheck[c]=0;
            if(!this->GetChild(c)->IsLeaf()){ // If the considered child is not a leaf it won't be split therefore set as already checked
                this->SplitCheck[c]=1;
            }
        }
        if (this->GetMergeCheck()!=NULL) {
            delete [] this->MergeCheck;
        }
        this->MergeCheck=NULL;
        int numbchildSq=numbchild*numbchild;
        this->MergeCheck=new bool[numbchildSq];//{0};
        for(int i=0;i<numbchildSq;i++){
            this->MergeCheck[i]=0;
        }
        for (int dl=0; dl<numbchild; dl++) {
            this->MergeCheck[dl+dl*numbchild]=1; // We cannot authorize a merging of the same class with itself !!!
        }
        for(int c1=0;c1<numbchild;c1++){
            if(!this->GetChild(c1)->IsLeaf()){
                for(int c2=0;c2<numbchild;c2++){
                    this->MergeCheck[c1+c2*numbchild]=1; // If one of the child considered is not a leaf, merging cannot be tested
                }

            }
            for(int c2=0;c2<numbchild;c2++){
                if(this->GetChild(c1)->GetDistributionType()!=this->GetChild(c2)->GetDistributionType()){ // cannot accept merging between classes without same distribution
                    this->MergeCheck[c1+c2*numbchild]=1;
                }
            }
        }
    }
    else{
        if (this->GetMergeCheck()!=NULL) {
            delete [] this->MergeCheck;
        }
        this->MergeCheck=NULL;
        if (this->GetSplitCheck()!=NULL) {
            delete [] this->SplitCheck;
        }
        this->SplitCheck=NULL;
    }
    for (int c=0; c<numbchild; c++) {
        this->GetChild(c)->ClearSMChecks();
    }
    return;
}

// Modify NormWeights in the tree in order to just afterwards collapse everything to the children level
void TreeEM::ModifyNormWeightsForChildrenLevel(){
    int numbchild=this->GetNumberChildren();
    for (int c=0; c<numbchild; c++) {
        if (this->GetPriorsDirect()==NULL&& !this->GetParent()->IsRoot()) {
            this->GetChild(c)->SetNormWeight(this->GetNormWeight()*this->GetChild(c)->GetNormWeight());
        }
        //        else{
        //            this->GetChild(c)->SetPriors(this->GetPriorsDirect());
        //        }
        this->GetChild(c)->ModifyNormWeightsForChildrenLevel(); // Recursive part
    }
}

// Modify NormWeights in the tree in order to collapse everything to the main node level afterwards
void TreeEM::ModifyNormWeightsForMainNodesChildrenLevel(){
    TreeEM * MainNode=this->FindMainNode();
    int numbchild=this->GetNumberChildren();
    for(int c=0;c<numbchild;c++){
        if(this->GetPriorsDirect()==NULL && this!=MainNode && MainNode!=NULL){
            this->GetChild(c)->SetNormWeight(this->GetNormWeight()*this->GetChild(c)->GetNormWeight());
        }
        this->GetChild(c)->ModifyNormWeightsForMainNodesChildrenLevel();
    }
}

// Using the preliminary function ModifyNormWeights for ChildrenLevel then collect all the leaves, copy them, delete the children and put the copied leaves instead. Allows for changing the value of parent for the copied leaves right away before adding them as children
void TreeEM::PutAllLeavesToChildrenLevel(){
    this->ModifyNormWeightsForChildrenLevel();
    vector<TreeEM *> Leaves=this->GetAllLeaves();
    int numbLeaves=this->GetNumberAllLeaves();
    vector<TreeEM *> CopiedLeaves;
    // Copy the leaves with the right weights
    for (int l=0; l<numbLeaves; l++) {
        CopiedLeaves.push_back(Leaves[l]->CopyTree(this));
    }
    // Delete the children (not useful anymore)
    int numbchild=this->GetNumberChildren();
    for (int c=0; c<numbchild; c++) {
//        delete this->GetChild(0);
        delete this->Children[0];
        this->Children.erase(this->Children.begin());
    }
    // Set the copied leaves as the children
    for (int l=0; l<numbLeaves; l++) {
        this->AddChild(CopiedLeaves[l]);
    }
}

// Similar to previous one but putting leaves to level of children of main nodes
void TreeEM::PutAllLeavesToMainNodesChildrenLevel(SEG_PARAMETERS * segment_param){
    this->FindRoot()->ModifyNormWeightsForMainNodesChildrenLevel();
    vector<TreeEM *> MainNodes;
    if ((segment_param->uniformTypeChange!=5 || segment_param->OutliersMod==0)&& segment_param->OutliersMod!=3 && segment_param->OutliersMod<5) {
        MainNodes=this->FindRoot()->GetMainNodesVector();
    }
    else{
        MainNodes=this->FindRoot()->GetGeneralClassesVector();
        vector<TreeEM *> OutlierNodes=this->GetOutliersMainNodesVector();
        int numbOutnodes=OutlierNodes.size();
        for (int i=0; i<numbOutnodes; i++) {
            MainNodes.push_back(OutlierNodes[i]);
        }
    }
    
    int numbNodes=MainNodes.size();
    for(int n=0;n<numbNodes;n++){
        int numbLevels=MainNodes[n]->GetNumberLevels();
        if(numbLevels>1){
        vector<TreeEM*> LeavesVectorNode=MainNodes[n]->GetAllLeaves();
        int numbLeaves=LeavesVectorNode.size();
        vector<TreeEM *> CopiedLeaves;
        // Copy the leaves with the right weights
        for (int l=0; l<numbLeaves; l++) {
            CopiedLeaves.push_back(LeavesVectorNode[l]->CopyTree(MainNodes[n]));
        }
        // Delete the children (not useful anymore)
        int numbchild=MainNodes[n]->GetNumberChildren();
        for (int c=0; c<numbchild; c++) {
            delete MainNodes[n]->GetChild(0);
            MainNodes[n]->Children.erase(MainNodes[n]->Children.begin());
        }
        // Set the copied leaves as the children
        for (int l=0; l<numbLeaves; l++) {
            MainNodes[n]->AddChild(CopiedLeaves[l]);
        }
    }
    }
}

void TreeEM::RecPutAllLeavesToChildrenLevel(){
    if (this->GetNumberChildren()==this->GetNumberDirectLeaves()) {
        return;
    }
    else{
        int numbchild=this->GetNumberChildren();
        for (int c=0; c<numbchild; c++) {
            if (this->GetChild(c)->GetNumberChildren()!=0) {
                int numbchild2=this->GetChild(c)->GetNumberChildren();
                for (int c2=0; c2<numbchild2; c2++) {
                    this->GetChild(c)->GetChild(c2)->SetNormWeight(this->GetChild(c)->GetNormWeight()*this->GetChild(c)->GetChild(c2)->GetNormWeight());
                    TreeEM * CopiedChild=this->GetChild(c)->GetChild(c2)->CopyTree(this);
                    this->AddChild(CopiedChild);
                }
                delete this->GetChild(c);
                this->Children.erase(this->Children.begin()+c);
                numbchild=this->GetNumberChildren();
            }
        }
    }
}

// Consists in the deletion of leaves of the model that are underweight and cannot be maintained without bringing instability.
void TreeEM::DeleteUnderWeight( SEG_PARAMETERS * segment_param){
    if (!segment_param->flag_DeleteUnderWeight) {
        return;
    }
    else{
        vector<TreeEM *> LeavesVector=this->GetAllLeaves();
        int numbLeaves=LeavesVector.size();
        int numbchild=this->GetNumberChildren();
        // Determination of the leaves to delete in the obtained tree
        vector<TreeEM *> LeavesToDeleteVector;
        for (int l=0; l<numbLeaves; l++) {
            bool MiniWeightTest=0;
            if (this->GetFlagOutliers()!=7) {
                MiniWeightTest=(LeavesVector[l]->GetPartWeightLevel2()<segment_param->WeightMini);
            }
            else{
                MiniWeightTest=(LeavesVector[l]->GetPartWeightLevel3()<segment_param->WeightMini);
            }
            if(LeavesVector[l]->GetDistributionType()!=0 && LeavesVector[l]->GetDistributionType()!=2 && MiniWeightTest){
                if (LeavesVector[l]->GetParent()->IsRoot() || (LeavesVector[l]->GetLevel()==3 && this->GetFlagOutliers()==7) || (LeavesVector[l]->GetLevel()==2 && this->GetFlagOutliers()==3)) {
                    cout<< "Pb we would have to discard a general class !"<<endl;
                    // Determination of weight to Outlier ensemble
                    float NormWeightOutliers=0;
                    for (int c=segment_param->numb_classes; c<numbchild; c++) {
                        NormWeightOutliers+=this->GetChild(c)->GetNormWeight();
                    }
                    bool MiniWeightTestb=0;
                    if (this->GetFlagOutliers()!=7) {
                        MiniWeightTestb=(LeavesVector[l]->GetPartWeightLevel2()<segment_param->WeightMini * NormWeightOutliers);
                    }
                    else{
                        MiniWeightTestb=(LeavesVector[l]->GetPartWeightLevel3()<segment_param->WeightMini * NormWeightOutliers);
                    }
                    if (LeavesVector[l]->GetParent()->FindIndex(LeavesVector[l])>=segment_param->numb_classes && segment_param->uniformTypeChange==3 && MiniWeightTestb) { // in the case the UTC 3 is chosen, the subclasses coming from outliers even if at the moment seen as nodes in themselves can be discarded
                        cout<< "Belong to outlier portion so can be suppressed"<< endl;
                        LeavesToDeleteVector.push_back(LeavesVector[l]);
                    }
                }
                else {
                LeavesToDeleteVector.push_back(LeavesVector[l]);
                }
            }
        }
        // first clearing memory for this leaves to delete
        int numbDeletions=LeavesToDeleteVector.size();
        for (int l=0; l<numbDeletions; l++) {
            TreeEM * ParentOfChildToDelete=LeavesToDeleteVector[l]->GetParent();
            int index=ParentOfChildToDelete->FindIndex(LeavesToDeleteVector[l]);
            int * LeavesDeleteHierarchy=LeavesToDeleteVector[l]->GetHierarchy();
            int level=LeavesToDeleteVector[l]->GetLevel();
            if (index>=0) {
                if(ParentOfChildToDelete->GetNumberChildren()<=1){
                     if(ParentOfChildToDelete->GetParent()->IsRoot() || (this->GetFlagOutliers()==3 && ParentOfChildToDelete->GetLevel()==2)){
                    cout<<"cannot delete when there is only one child left and is a main node"<<endl;
                }
                     else{
                         cout<<"one of the lesion class has to be erased"<<endl;
                         TreeEM * ParentLevelUp=ParentOfChildToDelete->GetParent();
                         int index2=ParentLevelUp->FindIndex(ParentOfChildToDelete);
                         delete ParentOfChildToDelete;
                         ParentLevelUp->Children.erase(ParentLevelUp->Children.begin()+index2);
                     }
                }
                
                else{
                delete LeavesToDeleteVector[l];
                ParentOfChildToDelete->Children.erase(ParentOfChildToDelete->Children.begin()+index);
                    
                cout<<"Leave with hierarchy ";
                    for (int k=0; k<level; k++) {
                        cout<<LeavesDeleteHierarchy[k]<<" ";
                    }
                    cout<< " deleted and remaining number of children of parent is "<<ParentOfChildToDelete->GetNumberChildren()<<endl;
                }
            }
        }
        // Finally erasing the NULL elements from the tree
//        this->DeleteAllNULLChildren();
        if (numbDeletions>0) {
            cout<<numbDeletions<<" deleted leaves"<<endl;
            this->CollapseOnlyChildTot();
            if(segment_param->PriorsKept>2){
            this->NormalisePriors();
            this->NormalisePriorsAdapted();
            }
            this->UpdateNonNormResp(segment_param);
            this->UpdateNormResp();
            this->UpdateNormRespRoot();
            float * GMatrixToSet=this->CreateGMatrixFromInfo(segment_param->flag_optMRFOut, segment_param->filename_GMatrix);
//            float * GMatrixToSet=this->PrepareGMatrixFromFile(segment_param->filename_GMatrix, segment_param->flag_optMRFOut);
            if (GMatrixToSet!=NULL) {
                this->SetGMatrix(GMatrixToSet);
                delete [] GMatrixToSet;
                GMatrixToSet=NULL;
            }
            if (segment_param->flag_MRF) {
                this->UpdateMRF(segment_param);
            }
            this->UpdateNonNormWeights();
            this->UpdateNormWeights();
        }
        
    }
    
}



// Delete all children set as NULL when deleting them if underweight
void TreeEM::DeleteAllNULLChildren(){
    int numbchild=this->GetNumberChildren();
    for (int c=0; c<numbchild; c++) {
        if (this->GetChild(c)==NULL) { // if child is NULL, erased and iterators modified
            this->Children.erase(this->Children.begin()+c);
            c=c-1;
            numbchild=numbchild-1;
        }
        else{ // if Child not NULL, see what happens for children underneath in recursive way
            this->GetChild(c)->DeleteAllNULLChildren();
        }
    }
}



/**************** TESTS ON TREE *************************/

/* Test if the tree on which applied is a leaf. A leaf is defined as a tree that does not have any children*/
bool TreeEM::IsLeaf(){
    if(this->GetNumberChildren()==0){
        return 1;
    }
    return 0;
}

/* Test if the tree on which applied is a branch. A branch is defined as a tree that has both a defined Parent and Children*/
bool TreeEM::IsBranch(){
    if(this->GetParent()!=NULL && this->GetNumberChildren()>0){
        return 1;
    }
    return 0;
}

/* Test if the tree on which applied is a root. A root is defined as a tree that has no Parent*/
bool TreeEM::IsRoot(){
    if(this->GetParent()==NULL){
        return 1;
    }
    return 0;
}

/*Returns as an integer the type of component (root,branch,leaf,initialNode) considered. Could be coded afterwards as enum*/
int TreeEM::WhatTypeOfTreeComponent(){
    if (this->IsBranch()) {
        return BRANCH;
    }
    if (this->IsRoot()&&this->IsLeaf()) {
        return INITIALNODE; // is an initial node with no parent and no children
    }
    if (this->IsLeaf()) {
        return LEAF;
    }

    return ROOT; // Is a root
}



/* Tests if the tree considered is a basic tree or not. A basic tree is defined as a tree with only a root and one level of children*/
bool TreeEM::IsBasicTree(){
    int numbchild=this->GetNumberChildren();
    if (this->WhatTypeOfTreeComponent()!=ROOT) {
        return 0;
    }
    if(this->FlagOutliers==1 || this->FlagOutliers==3 || (this->FlagOutliers>=5 && this->GetFlagOutliers()!=7)){
        int numbclasses=this->GetChild(0)->GetNumberChildren();
        for (int c=0; c<numbclasses; c++) {
            if (this->GetChild(0)->Children[c]->GetNumberChildren()!=0) {
                return 0;
            }
        }
        if (this->FlagOutliers==3 || this->GetFlagOutliers()>=5) {
            numbclasses=this->GetChild(1)->GetNumberChildren();
            for (int c=0; c<numbclasses; c++) {
                if (this->GetChild(1)->Children[c]->GetNumberChildren()!=0) {
                    return 0;
                }
            }
        }
    }
    else if (this->GetFlagOutliers()==7){
        vector<TreeEM *> VectorLevel2=this->GetAllTreesFromLevel(3);
        int numbLevelTree=VectorLevel2.size();
        for (int t=0; t<numbLevelTree; t++) {
            if (VectorLevel2[t]->GetNumberChildren()!=0) {
                return 0;
            }
        }
    }
    else{
    for (int c=0; c<numbchild; c++) {
        if (this->Children[c]->GetNumberChildren()!=0) {
            return 0;
        }
    }
    }
    return 1;
}

// Check if the tree considered is valid : has data, the data is normalised, the number of stated children is compatible with the distribution type. Recursive as check for all children similar validity.
bool TreeEM::IsTreeValid(int LevelCheck){
    if (this->GetDataImage()==NULL){ // Force the tree to make reference to an image to segment
        cout<< "Not valid because no data image referenced"<<endl;
        return 0;
    }
    if (!this->IsDataImageNormalised() && LevelCheck<1) {
        cout<<"Not valid because data not normalised"<<endl;
        return 0;
    }
    if (this->WhatTypeOfTreeComponent()==LEAF||this->WhatTypeOfTreeComponent()==INITIALNODE){ // Mask is only set at the root level for allocation problems and sizes incompatibilities if changed through the tree
        if(this->GetMaskDirect()!=NULL){
            cout<<"Not valid because Mask defined at wrong place"<<endl;
            return 0;
        }
    }
    if (!this->IsPriorsProbabilityType()) { // Not valid if priors not of probability type
        cout<<"Not valid because Priors not set as probabilities"<<endl;
        return 0;
    }
    if(!this->IsNumbChildOKWithDistType()){ // not valid if number of children not valid with parameters
        cout<<"Not valid of incompatibility between number of children and distribution type"<<endl;
        return 0;
    }
    if(!this->CheckForValidityOfParametersStructure()){ // not valid if parameters structure not valid
        cout<<"Not valid because of unvalidity of Parameters structure"<<endl;
        return 0;
    }
    int numbchild=this->GetNumberChildren();
    for (int c=0; c<numbchild; c++) {
        if (!this->GetChild(c)->IsTreeValid(LevelCheck)) {
            return 0;
        }
    }
    return 1;
}


// Check if the tree considered is valid : has data, the data is normalised, the number of stated children is compatible with the distribution type. Recursive as check for all children similar validity.
bool TreeEM::IsTreeStructureValid(){
    if (this->WhatTypeOfTreeComponent()==LEAF||this->WhatTypeOfTreeComponent()==INITIALNODE){ // Mask is only set at the root level for allocation problems and sizes incompatibilities if changed through the tree
        if(this->GetMaskDirect()!=NULL){
            cout<<"Not valid because Mask defined at wrong place"<<endl;
            return 0;
        }
    }
    if(!this->IsNumbChildOKWithDistType()){ // not valid if number of children not valid with parameters
        cout<<"Not valid of incompatibility between number of children and distribution type"<<endl;
        return 0;
    }
    if(!this->CheckForValidityOfParametersStructure()){ // not valid if parameters structure not valid
        cout<<"Not valid because of unvalidity of Parameters structure"<<endl;
        return 0;
    }
    int numbchild=this->GetNumberChildren();
    for (int c=0; c<numbchild; c++) {
        if (!this->GetChild(c)->IsTreeStructureValid()) {
            return 0;
        }
    }
    return 1;
}


// Check if initialisation is valid
bool TreeEM::IsInitialisationValid() {
    bool ValidInit=1;
    int numbLeaves=this->GetNumberAllLeaves();
    vector<TreeEM *> VectorLeaves=this->GetAllLeaves();
    int numbmodal=this->GetNumberModalities();
    for(int l=0;l<numbLeaves;l++){
        if(VectorLeaves[l]->GetDistributionType()==1){ // check on determinant validity only if Gaussian distribution
            float* VarianceToCheck=VectorLeaves[l]->GetVariance();
            float DetCheck=determinant(VarianceToCheck, numbmodal);
            ValidInit*=(DetCheck>1E-12);
        }
    }
    return ValidInit;
}

// Check if the sum of the normalised weights of the children of the considered node sum to 1 (or close to 1)
bool TreeEM::AreWeightsValid(){
    int numbchild=this->GetNumberChildren();
    bool weightsValidity=1;
    float sumWeight=0;
    if(numbchild==0){
        sumWeight=1;
    }
    for(int c=0;c<numbchild;c++){
        sumWeight+=this->GetChild(c)->GetNormWeight();
    }
    if (sumWeight > 1+1E-6 || sumWeight<1-1E-6){
        weightsValidity*= 0;
        return weightsValidity;
    }
    else{
        weightsValidity*=1;
        for(int c=0;c<numbchild;c++){
            weightsValidity*=this->GetChild(c)->AreWeightsValid();
        }
        return weightsValidity;
    }
}

bool TreeEM::IsNormRespValid(){
    float * NormResp_PTR=this->GetNormResp();
    int numelmasked=this->GetNumberMaskedElements();
    for(int i=0;i<numelmasked;i++,NormResp_PTR++){
        if(*NormResp_PTR>1+10E-6){
            cout<< "High Pb"<<endl;
            return 0;
        }
            else if( *NormResp_PTR<=-10E-6){
            cout<<"Negative Pb"<< *NormResp_PTR<< "at index "<<i<<endl;
            return 0;
        }
    }
    return 1;
}

bool TreeEM::IsNormRespValidGeneral(){
    bool CheckResult=1;
//    Check if it is applied to the Root
    if(!this->IsRoot()){
        cout<<"Validity test not applied on proper level"<<endl;
        return 0;
    }
    int numbchild=this->GetNumberChildren();
    int numelmasked=this->GetNumberMaskedElements();
    float * SumCheckNormResp=new float[numelmasked];
    for(int i=0;i<numelmasked;i++){
        SumCheckNormResp[i]=0;
    }
    // Filling of the checking array and checking validity of NormResp values
    float * SumCheckNormResp_PTR=SumCheckNormResp;
    int NbNegativePb=0;
    int NbIndHighPb=0;
    for(int c=0;c<numbchild;c++){
        float * ChildrenNormResp_PTR=this->GetChild(c)->GetNormResp();
        SumCheckNormResp_PTR=SumCheckNormResp;
        for(int i=0;i<numelmasked;i++,SumCheckNormResp_PTR++,ChildrenNormResp_PTR++){
            *SumCheckNormResp_PTR+=*ChildrenNormResp_PTR;
            if(*ChildrenNormResp_PTR<0){
                NbNegativePb++;
            }
            else if(*ChildrenNormResp_PTR>1+10E-6){
                NbIndHighPb++;
            }
        }
    }
    // Checking operation
    SumCheckNormResp_PTR=SumCheckNormResp;
    int NbLowPb=0;
    int NbHighPb=0;
    for(int i=0;i<numelmasked;i++,SumCheckNormResp_PTR++){
        if(*SumCheckNormResp_PTR>1+10E-6){
            NbHighPb++;
            CheckResult=0;
        }
        else if(*SumCheckNormResp_PTR<1-10E-6){
            NbLowPb++;
            CheckResult=0;
        }
    }
    if(NbIndHighPb!=0 || NbNegativePb!=0){
        CheckResult=0;
    }
    delete [] SumCheckNormResp;
    SumCheckNormResp=NULL;
    if(!CheckResult){
    cout<<"HighPb is "<<NbHighPb<<" and LowPb is "<<NbLowPb<< " NegativePb "<<NbNegativePb<<" IndHighPb "<< NbIndHighPb<<endl;
    }
    return CheckResult;
}

bool TreeEM::IsNormRespValidLeaves(){
    bool CheckResult=1;

//    Check if it is applied to the Root
    if(!this->IsRoot()){
        cout<<"Validity test not applied on proper level"<<endl;
        return 0;
    }

    vector<TreeEM*> LeavesVector=this->GetAllLeaves();
    int numbLeaves=LeavesVector.size();
    int numelmasked=this->GetNumberMaskedElements();
    float * SumCheckNormResp=new float[numelmasked];
    for(int i=0;i<numelmasked;i++){
        SumCheckNormResp[i]=0;
    }
    // Filling of the checking array
    float * SumCheckNormResp_PTR=SumCheckNormResp;
    for(int c=0;c<numbLeaves;c++){
        float * ChildrenNormResp_PTR=LeavesVector[c]->GetNormResp();
        SumCheckNormResp_PTR=SumCheckNormResp;
        for(int i=0;i<numelmasked;i++,SumCheckNormResp_PTR++,ChildrenNormResp_PTR++){
            *SumCheckNormResp_PTR+=*ChildrenNormResp_PTR;
        }
    }
    // Checking operation
    int NbLowPb=0;
    int NbHighPb=0;
    SumCheckNormResp_PTR=SumCheckNormResp;
    for(int i=0;i<numelmasked;i++,SumCheckNormResp_PTR++){
        if(*SumCheckNormResp_PTR>1+10E-6){
            NbHighPb++;
            CheckResult=0;
        }
        else if(*SumCheckNormResp_PTR<1-10E-6){
            NbLowPb++;
            CheckResult=0;
        }
    }
    delete [] SumCheckNormResp;
    SumCheckNormResp=NULL;
    if(!CheckResult){
    cout<<"HighPb is "<<NbHighPb<<" and LowPb is "<<NbLowPb<<endl;
    }
    return CheckResult;
}



bool TreeEM::AreNormRespValid(){
    bool NormRespValidity=1;
    int numbchild=this->GetNumberChildren();
    NormRespValidity*=this->IsNormRespValid();
    if(!NormRespValidity){
        return NormRespValidity;
    }
    else{
        for(int c=0;c<numbchild;c++){
            NormRespValidity*=this->GetChild(c)->AreNormRespValid();
        }
        return NormRespValidity;
    }
}

// Check if the obtained model has authorized weights for the subclasses newly modified. Needs to be further thought about. At the moment check only done at 3rd layer on only newly formed subclasses. Should it be more after having put everything to children level, or at 3rd layer with partnormweight instead of normweight...
bool TreeEM::CheckAcceptanceWeights(vector<SplitKLD *>SplitTry,SEG_PARAMETERS * segment_param){
    int numbclassesSplit=SplitTry.size();
    for(int c=0;c<numbclassesSplit;c++){
        vector<TreeEM*> LeavesWeightToTest=SplitTry[c]->Parent->GetChild(SplitTry[c]->ChildToSplit)->GetAllLeaves();
        if (SplitTry[c]->TypeChange>3 && !SplitTry[c]->Parent->IsRoot()) { // in case the considered new class is stemming from a uniform distribution, have to check the weight of the first before last leave because it is the one for the newly formed Gaussian
            TreeEM * LeaveSupp=SplitTry[c]->Parent->GetChild(SplitTry[c]->Parent->GetNumberChildren()-2);
            LeavesWeightToTest.push_back(LeaveSupp);
        }
//        if (SplitTry[c]->TypeChange==3) {
//            <#statements#>
//        }
        int numbLeavesCheck=LeavesWeightToTest.size();
        for (int l=0; l<numbLeavesCheck; l++) {
            if (LeavesWeightToTest[l]->GetPartNormWeight()<segment_param->WeightMini && LeavesWeightToTest[l]->GetDistributionType()!=2) {
                return 0;
            }
        }
    }
    return 1;
}

// Check if the obtained model has authorized weights for the subclasses newly modified. Needs to be further thought about. At the moment check only done at 3rd layer on only newly formed subclasses. Should it be more after having put everything to children level, or at 3rd layer with partnormweight instead of normweight...
bool TreeEM::CheckAcceptanceWeights(vector<SplitKLD_b *>SplitTry,SEG_PARAMETERS * segment_param){
    int numbclassesSplit=SplitTry.size();
    for(int c=0;c<numbclassesSplit;c++){
        TreeEM * ParentToSplit=this->FindFromHierarchy(SplitTry[c]->HierarchyParent);
        vector<TreeEM*> LeavesWeightToTest=ParentToSplit->GetChild(SplitTry[c]->ChildToSplit)->GetAllLeaves();
        if (SplitTry[c]->TypeChange>3 && !ParentToSplit->IsRoot()) { // in case the considered new class is stemming from a uniform distribution, have to check the weight of the first before last leave because it is the one for the newly formed Gaussian
            TreeEM * LeaveSupp=ParentToSplit->GetChild(ParentToSplit->GetNumberChildren()-2);
            LeavesWeightToTest.push_back(LeaveSupp);
        }
        //        if (SplitTry[c]->TypeChange==3) {
        //            <#statements#>
        //        }
        int numbLeavesCheck=LeavesWeightToTest.size();
        for (int l=0; l<numbLeavesCheck; l++) {
            bool MiniWeightTest=0;
            if (this->GetFlagOutliers()!=7) {
                MiniWeightTest=(LeavesWeightToTest[l]->GetPartWeightLevel2()<segment_param->WeightMini);
            }
            else {
                MiniWeightTest=(LeavesWeightToTest[l]->GetPartWeightLevel3()<segment_param->WeightMini);
            }
            if (MiniWeightTest && LeavesWeightToTest[l]->GetDistributionType()!=2) {
                return 0;
            }
        }
    }
    return 1;
}

//bool TreeEM::CheckUnifDistPosition(SEG_PARAMETERS * segment_param){
//    if (segment_param->OutliersMod==0) {
//        return 1;
//    }
//    else{
//        int numbchild=this->GetNumberChildren();
//        if (this->GetChild(numbchild-1)->GetDistributionType()==2) { // the outlier class is the last one and is not split yet.
//            return 1;
//        }
//        else { // the outlier class that should be the last in the model is split, there should be a uniform dist at the next level if the uniform type change is 3 or 4
//            if (segment_param->uniformTypeChange<=2) { // no more uniform dist if uniform type change is 1 or 2
//                return 1;
//            }
//            else{
//                int numbOutSubClasses=this->GetChild(numbchild-1)->GetNumberChildren();
//                if (this->GetChild(numbchild-1)->GetChild(numbOutSubClasses-1)->GetDistributionType()==2) { // the uniform distribution is the last subclass of the outlier class.
//                    return 1;
//                }
//            }
//            
//        }
//    }
//    return 0;
//}

// Check if the values given by the mean are compatible with staying between 0 and 1 for the correspondig intensity values at each modality
bool TreeEM::CheckCompatibilityParams(){
//     First check that we are in the case of a leaf with Gaussian distribution
    if (this->GetDistributionType()!=1) {
        return 1;
    }
    int numbmodal=this->GetNumberModalities();
    float * MeanParams=this->GetParametersValue();
    for (int m=0; m<numbmodal; m++) {
        if (MeanParams[m]<0|| MeanParams[m]>1) {
            return 0;
        }
    }
    return 1;
}

bool TreeEM::CheckUnifDistPosition(SEG_PARAMETERS * segment_param){
    if (segment_param->OutliersMod==0) {
        return 1;
    }
    else{
        vector<vector<int> > UnifDistHierarchyVector=this->FindAllUniformDistHierarchies(segment_param);
        int numbUnifDist=UnifDistHierarchyVector.size();
        if (numbUnifDist==0) {
            return 1;
        }
        if (numbUnifDist==1) {
            
            TreeEM * UnifNode=this->FindFromHierarchy(UnifDistHierarchyVector[0]);
            int IndexLast=UnifDistHierarchyVector[0][UnifDistHierarchyVector[0].size()-1];
            TreeEM * UnifNodeParent=UnifNode->GetParent();
            if (UnifNodeParent->GetNumberChildren()==IndexLast+1) { // the unif
                return 1;
            }
            else{
                return 0;
            }
        }
        else { // case where there is more than one uniform distribution available therefore necessarily an outlier 3 case or more than 5
            for (int u=0; u<numbUnifDist; u++) {
                TreeEM * UnifNode=this->FindFromHierarchy(UnifDistHierarchyVector[u]);
                int IndexLast=UnifDistHierarchyVector[u][UnifDistHierarchyVector[u].size()-1];
                TreeEM * UnifNodeParent=UnifNode->GetParent();
                if (this->GetFlagOutliers()==7) {
                    if (UnifDistHierarchyVector[u].size()>3 && UnifNodeParent->GetNumberChildren()!=IndexLast+1 ) { // do take into account the fact that if it at the level 2 it is not compelled to be the last one and even more
                        return 0;
                    }
                }
                else {
                    if (UnifDistHierarchyVector[u].size()>2 && UnifNodeParent->GetNumberChildren()!=IndexLast+1 ) { // do take into account the fact that if it at the level 2 it is not compelled to be the last one and even more
                        return 0;
                    }
                }
            }
            return 1;
            
        }
    }
    return 0;
}

bool TreeEM::IsNumbChildOKWithDistType(){
    if (this->GetNumberChildren()==0&&this->GetDistributionType()==0){ // case considered as mixture whereas does not have any child
        return 0;
    }
    if (this->GetNumberChildren()>0 && this->GetDistributionType()>0){ // case where considered as simple distribution whereas has children
        return 0;
    }
    return 1;
}

bool TreeEM::IsDataImageNormalised(){
    if (this->GetDataImage()==NULL) {// no data image in the tree to look at
        cout<<"No data image as reference"<<endl;
        return 0;
    }
    int numbmodal=this->GetNumberModalities();
    for (int m=0; m<numbmodal; m++) {
        //cout << "The number of modalities is "<<this->GetNumberModalities()<<endl;
        float minRes=-2;
        float maxRes=2;
        if (NormMask) {
            minRes=this->GetMinDataMaskedModal(m);
            maxRes=this->GetMaxDataMaskedModal(m);
        }
        else{
            minRes=this->GetMinDataModal(m);
            maxRes=this->GetMaxDataModal(m);
        }
        
        //cout<<(minRes-0.0)<<"and "<<(maxRes-1.0)<<endl;
        if (minRes>10E-6||minRes<-10E-6){
            return 0;
        }
        if (maxRes>1+10E-6||maxRes<1-10E-6){
            return 0;
        }
    }
    return 1;
}

bool TreeEM::IsDataFloat(){
    if (this->GetDataImage()==NULL) {
        cout<<"No data to check"<<endl;
        return 0;
    }
    if (this->GetDataImage()->datatype==DT_FLOAT) {
        return 1;
    }
    return 0;
}

bool TreeEM::IsDataIsotropic(){
    nifti_image * DataImage=this->GetDataImage();
    if (DataImage==NULL) {
        cout<<"No image to consider"<<endl;
        return 0;
    }
    if (DataImage->pixdim[1]==DataImage->pixdim[2] && DataImage->pixdim[2]==DataImage->pixdim[3]) {
        return 1;
    }
    else return 0;
}

float TreeEM::DistanceFactor(int dim){
    nifti_image * DataImage=this->GetDataImage();
    if (this->IsDataIsotropic()) {
        return 1;
    }
    else{
        float Pixdim=DataImage->pixdim[dim+1];
//        cout<< "pixdim in dimension "<<dim<< " is "<<Pixdim<<endl;
        if (Pixdim==0) {
            Pixdim=1;
        }
        return (float)1.0/Pixdim;
    }
}

bool TreeEM::IsPriorsFloat(){
    if (this->GetPriors()==NULL) {
        cout<<"No priors to check"<<endl;
        return 0;
    }
    if (this->GetPriors()->datatype==DT_FLOAT) {
        return 1;
    }
    return 0;
}

bool TreeEM::IsStructureSimilar(TreeEM *TreeTest){
    bool Result=1;
    if(this->GetNumberChildren()==0 && TreeTest->GetNumberChildren()==0){
        return Result*1;
    }
    else if( this->GetNumberChildren()!=TreeTest->GetNumberChildren()){
        return Result*0;
    }
    else{
        int numbchild=this->GetNumberChildren();
        for(int c=0;c<numbchild;c++){
            Result*=this->GetChild(c)->IsStructureSimilar(TreeTest->GetChild(c));
        }
    }
    return Result;
}

// Check if the direct BF coefficients obtained are directly useable or not
bool TreeEM::AreBFCoeffsDirectUseable(){
    //    vector<float*> BFCoeffsToTest=this->GetBFCoeffsDirect();
    //    // 1. Test on the size of the vector
    //    if (BFCoeffsToTest.size()==0) {
    //        return 0;
    //    }
    //    int numbmodal=this->GetNumberModalities();
    //    // 2. Test on the compatibility of the dimensions
    //    if (BFCoeffsToTest.size()!=numbmodal) {
    //        return 0;
    //    }
    //    // 3. Test on the containts of the vector if of the right size.
    //    for (int m=0; m<numbmodal; m++) {
    //        if (BFCoeffsToTest[m]==NULL) {
    //            return 0;
    //        }
    //    }
    if(this->GetBFCoeffsDirect()==NULL){
        return 0;
    }
    return 1;
}

bool TreeEM::IsMRFZero(){
    float * MRFToTest=this->GetMRF();
    int numelmasked=this->GetNumberMaskedElements();
    if(MRFToTest==NULL){
        return 0;
    }
    for(int i=0;i<numelmasked;i++){
        if(MRFToTest[i]>10E-6){
            return 0;
        }
    }
    return 1;
}

// Returns the decision about the choice of the model according to the previous model and the acceptance type chosen
bool TreeEM::IsNewModelAccepted(TreeEM * CopiedTree,OperationType Operation,SEG_PARAMETERS * segment_param){
    bool AcceptanceDecision=0;
    // First initialisation and calculation of the BIC for the two models
    float OldCriterion=0;
    float NewCriterion=0;
    if(this->GetDPChildrenDirect()!=NULL){
        if(segment_param->flag_Countmod){
            switch (Operation) {
                case SPLIT:{
                    OldCriterion=CopiedTree->CriterionCalculationSplitDP();
                    NewCriterion=this->CriterionCalculationSplitDP();
                }
                    break;
                    
                default:// if it is not a split operation then it is a Merge operation
                {
                    OldCriterion=CopiedTree->CriterionCalculationSplitDP();
                    NewCriterion=this->CriterionCalculationSplitDP();
                }
                    break;
            }
            
        }
        else{
            if(segment_param->flag_DistClassInd){
                OldCriterion=CopiedTree->CriterionCalculationDPInd();
                NewCriterion=this->CriterionCalculationDPInd();
            }
            else{
                //                OldCriterion=CopiedTree->CriterionCalculationDPNonInd(SplitTry[c]->Parent->GetChild(SplitTry->ChildToSplit)->FindGeneralClass());
                //                NewCriterion=this->CriterionCalculationDPNonInd(SplitTry[c]->Parent->GetChild(SplitTry->ChildToSplit)->FindGeneralClass());
            }
        }
    }
    else{
        OldCriterion=CopiedTree->CriterionCalculation();
        NewCriterion=this->CriterionCalculation();
    }
    cout<< "The new criterion is "<<NewCriterion<<" and the old criterion is "<<OldCriterion<<endl;
    float AcceptanceLimit=0;
    switch (segment_param->AcceptanceType) { // Final decision according to the acceptance type
        case 1:{ // the change is accepted only if corresponds to high enough change in BIC (improvement significant enough)
            AcceptanceLimit=(NewCriterion-OldCriterion)/NewCriterion;
            AcceptanceDecision=(AcceptanceLimit>segment_param->AcceptanceThreshold)&&((NewCriterion-OldCriterion)>0);
        }
            break;
            
        default:{ // a simple > rule to accept the new model.
            AcceptanceLimit=NewCriterion-OldCriterion;
            AcceptanceDecision=AcceptanceLimit>0;
        }
            
            break;
    }
    return AcceptanceDecision;
}

/********************** METHODS ON PARAMETERS STRUCTURE ***********************/

int TreeEM::CalculateSizeParameters(){
    int SizeParameters;
    switch (this->GetDistributionType()) {
    case 0:{
        //cout << "We are in the case of a mixture" << endl;
        SizeParameters=0;
    }
        break;
    case 2:{ // case uniform distribution no parameters but can be a leaf
        SizeParameters=0;
    }
        break;
    default:
    {
        //cout<< "We are looking at a Gaussian distribution" << endl;
        int numbmodal=this->GetNumberModalities();
        SizeParameters=(int)(numbmodal*(numbmodal+1)); // Size of the mean vector + size of the variance matrix (numbmodal)
        //cout<< "Size parameters is "<<SizeParameters;
        /* REMARK :
             this might be changed if decided then to consider only number of free parameters, then the Gaussian Parameters calculation function must be changed consequently */
    }

    }
    return SizeParameters;

}

int TreeEM::CalculateSizeParameters(int DistributionTypeInput){
    int SizeParameters;

    switch (DistributionTypeInput) {
    case 0:{
        //cout << "We are in the case of a mixture" << endl;
        SizeParameters=0;
    }
        break;
    case 2:{ // case of uniform distribution without any parameters
        SizeParameters=0;
    }
        break;
    default:
    {
        //cout<< "We are looking at a Gaussian distribution" << endl;
        int numbmodal=this->GetNumberModalities();
        SizeParameters=(int)(numbmodal*(numbmodal+1)); // Size of the mean vector + size of the variance matrix (numbmodal)
        //cout<< "Size parameters is "<<SizeParameters;
        /* REMARK :
             this might be changed if decided then to consider only number of free parameters, then the Gaussian Parameters calculation function must be changed consequently */
    }

    }
    return SizeParameters;
}

void TreeEM::CreateAllocateAndInitializeParameters(int DistributionTypeInput){
    if (this->GetNumberChildren()!=0) { // if there are children, it is necessarily a mixture
        cout<<"We have to modify Distribution type"<<endl;
        DistributionTypeInput=0;
    }
    if (this->GetParameters()==NULL) {
        //cout<<"Parameters are NULL at the momemt"<<endl;
        this->ParametersDistribution=new Parameters();
        this->ParametersDistribution->DistributionType=DistributionTypeInput;
        //cout<<this->GetDistributionType()<< "and " << this->ParametersDistribution->DistributionType;
        this->ParametersDistribution->SizeParameters=this->CalculateSizeParameters();
        if (this->GetSizeParameters()>0) {
            this->GetParameters()->ValueParameters=new float[this->GetSizeParameters()];//{0};
            int SizeParametersToUse=this->GetSizeParameters();
            for(int i=0;i<SizeParametersToUse;i++){
                this->GetParameters()->ValueParameters[i]=0;
            }
        }
        else{
            this->GetParameters()->ValueParameters=NULL;
        }
        return;
    }
    this->ParametersDistribution->DistributionType=DistributionTypeInput;
    this->ParametersDistribution->SizeParameters=this->CalculateSizeParameters();
    //cout<<"the size of parameters is "<<this->GetSizeParameters()<<endl;
    if (this->GetSizeParameters()>0) {
        if(this->GetParametersValue()!=NULL){
            delete [] this->GetParametersValue();
            this->GetParameters()->ValueParameters=NULL;
        }
        int numbsp=this->GetSizeParameters();
        this->GetParameters()->ValueParameters=new float[this->GetSizeParameters()];//{0};
        for(int i=0;i<numbsp;i++){
            this->GetParameters()->ValueParameters[i]=0;
        }
    }
    else {
        if(this->GetParametersValue()!=NULL){
            delete [] this->GetParametersValue();
        }
        this->GetParameters()->ValueParameters=NULL;
    }
    return;
}

bool TreeEM::CheckForValidityOfParametersStructure(){
    // Incompatibility between type mixture and existence of values for the parameters
    if (this->GetDistributionType()<0 || this->GetDistributionType()>2) { // Distribution can only take values in 0 1 2
        return 0;
    }
    if(this->GetDistributionType()==0 && this->GetParametersValue()!=NULL){
        return 0;
    }
    // Incompatibility between mixture DistributionType and SizeParameters > 0
    if (this->GetDistributionType()==0 && this->GetSizeParameters()>0) {
        return 0;
    }
    // Compatibility between uniform and no parameters
    if(this->GetDistributionType()==2 && this->GetSizeParameters()==0){
        return 1;
    }
    // Incompatibility between simple distribution and SizeParameters=0
    if (this->GetDistributionType()>0 && this->GetDistributionType()!=2 && this->GetSizeParameters()==0) {
        return 0;
    }
    // Incompatibility between simple distribution and non allocation of values for parameters
    if(this->GetDistributionType()>0 && this->GetParametersValue()==NULL){
        return 0;
    }
    // Incompatibility if SizeParameters is 0 and ValueParameters is allocated
    if (this->GetSizeParameters()==0 && this->GetParametersValue()!=NULL) {
        return 0;
    }
    // Incompatibility if SizeParameters is >0 and ValueParameters is not allocated
    if (this->GetSizeParameters()>0 && this->GetParametersValue()==NULL) {
        return 0;
    }
    else {
        return 1;
    }
}

// Check for the compatibility of the data and the size of the parameters to set
bool TreeEM::CheckForSizeParametersValidity(){
    // First check for the validity of the structure of ParametersToSet
    if(!CheckForValidityOfParametersStructure()){
        return 0;
    }
    // Once checked for the validity of the structure check if mixture type or something else (if mixture, ok by definition)
    if(this->GetDistributionType()==0){
        return 1;
    }
    if (this->GetSizeParameters()!=this->CalculateSizeParameters()){
        return 0;
    }
    return 1;
}

bool TreeEM::ArePriorsNormalised(){
    int numel=this->GetNumberElements();
    if (this->IsPriorsVectorFilledWithNULL()) {
        return 1;
    }
//    int numbclasses=this->GetPriorsVector().size();
    int numbchild=this->GetNumberGeneralClasses();
    int numbclasses=this->GetPriorsVector().size();
    // check if there are compatible number of Priors with number of general classes. Otherwise all priors put to NULL;
    if(numbclasses !=numbchild && numbclasses !=0 && this->GetFlagOutliers()==0){ // incompatibility in the number of priors compared to the number of general classes.
        cout<<"Incompatible number of priors files compared to general classes"<<endl;
        return 0;
    }

    /* if get there : all Priors pointers in the vector correspond to valid pointer to nifti images*/
    vector<float *>PriorsVectorData_PTR;
    vector<nifti_image *> PriorsVector=this->GetPriorsVector();
    //cout << "All pointers correspond to a valid nifti_image"<<endl;
    for (int c=0;c<numbclasses;c++){
        PriorsVectorData_PTR.push_back(static_cast<float *>(this->GetPriorsVector()[c]->data));
    }
//    this->SaveTmpResult(PriorsVectorData_PTR[3], "/Users/Carole/Documents/PhD/PriorsOutFirst.nii.gz");
    PrecisionTYPE sumCheck=0;
    for (int i=0;i<numel;i++){
        sumCheck=0;
        for(int c=0;c<numbclasses;c++){
            sumCheck+=(PrecisionTYPE)*PriorsVectorData_PTR[c];
            PriorsVectorData_PTR[c]++;
        }


        if(fabs(sumCheck-1)>10E-6){
            //cout<<"The priors are not well normalised, the difference to 1 is "<<sumCheck-1<<endl;

            return 0;
        }
    }
    int numbC=this->GetNumberChildren();
    for (int c=0; c<numbC; c++) {
        return this->GetChild(c)->ArePriorsNormalised();
    }
    return 1;
}

bool TreeEM::ArePriorsAdaptedNormalised(){
    int numel=this->GetNumberElements();
    if (this->IsPriorsAdaptedVectorFilledWithNULL()) {
        return 1;
    }
//    int numbclasses=this->GetPriorsAdaptedVector().size();
    int numbclasses=this->GetPriorsAdaptedVectorParent().size();
    int numbchild=this->GetNumberGeneralClasses(); // Priors can only be adapted when there is anatomical knowledge and appropriate behavior
    if(numbchild != numbclasses && numbclasses !=0 && this->GetFlagOutliers()==0){
        cout<<"Inappropriate number of general classes compared to number of adapted priors arrays"<<endl;
        return 0;
    }
//    /*Check if some or all of them are NULL pointers in the vector if not all of them, must be normalised (all must be put to NULL)*/
//    int indexFirstNull=numbclasses;
//    for(int c=numbclasses-1;c>=0;c--){
//        if (this->GetPriorsAdaptedVector()[c]==NULL){
//            indexFirstNull=c;
//        }
//    }
//    if(indexFirstNull<numbclasses){// Means one of the pointer is NULL but one at least the first is not NULL
//        cout<<"One of the Pointer to priors is NULL and is not the first one"<<endl;
//        return 0;
//    }
//    if(indexFirstNull==0){// the first pointer is NULL, we must check for all the others in the vector
//        for (int c=0;c<numbclasses;c++){
//            if (this->GetPriorsAdaptedVector()[c]!=NULL){
//                cout<<"One of the Priors is not NULL whereas the first one is NULL"<<endl;
//                return 0;
//            }
//        }
//        return 1; // All the pointers in the vector are NULL
//    }
    /* if get there : all Priors pointers in the vector correspond to valid pointer to float array*/
//    vector<float *>PriorsVectorData_PTR=this->GetPriorsAdaptedVector();
    vector<float *> PriorsVectorData_PTR=this->GetPriorsAdaptedVectorParent();
    PrecisionTYPE sumCheck=0;
    for (int i=0;i<numel;i++){
        sumCheck=0;
        for(int c=0;c<numbclasses;c++){
            sumCheck+=(PrecisionTYPE)*PriorsVectorData_PTR[c];
            PriorsVectorData_PTR[c]++;
        }
        if(fabs(sumCheck-1)>1E-6){
            //cout<<"The priors are not well normalised, the difference to 1 is "<<sumCheck-1<<endl;

            return 0;
        }
    }
    int numbC=this->GetNumberChildren();
    for (int c=0; c<numbC; c++) {
        return this->GetChild(c)->ArePriorsAdaptedNormalised();
    }
    return 1;
}

bool TreeEM::IsPriorsVectorFilledWithNULL(){
//    int numbchild=this->GetNumberChildren();
    vector<nifti_image*> NodePriorsVector=this->GetPriorsVector();
    int numbchild=NodePriorsVector.size();
//    for (int c=0; c<numbchild; c++) {
////        if (this->GetChild(c)->GetPriors()!=NULL) {
////            return 0;
////        }

//    }
    if(numbchild>0){ // If at least one of the priors is not null
        return 0;
    }
    return 1; // By default return 1 if it is a leaf or an initial Node we are looking at
}

bool TreeEM::IsPriorsAdaptedVectorFilledWithNULL(){
//    vector<float *> NodePriorsAdaptedVector=this->GetPriorsAdaptedVector();
    vector<float *> NodePriorsAdaptedVector=this->GetPriorsAdaptedVectorParent();
    int numbchild=NodePriorsAdaptedVector.size();
    if(numbchild>0){
        return 0;
    }
//    int numbchild=this->GetNumberChildren();
//    for (int c=0; c<numbchild; c++) {
//        if (this->GetChild(c)->GetPriorsAdapted()!=NULL) {
//            return 0;
//        }
//    }
    return 1; // By default return 1 if it is a leaf or an initial Node we are looking at
}

bool TreeEM::IsOneOfThePriorsNULL(){
//    int numbclasses=this->GetNumberGeneralClasses();
//    int numbchild=this->GetPriorsVector().size();
    int numbclasses=this->GetPriorsVector().size();
    int numbchild=this->GetNumberChildren();
//    int numbchild=this->GetNumberChildren();
    if ((numbclasses !=numbchild && numbclasses !=numbchild-1) && numbchild!=0){ // if the number of general classes is different from the number of priors image to use but at least one of then is not NULL
        return 1;
    }
    return 0;
//    int numbchild=this->GetNumberChildren();
//    for (int c=0; c<numbchild; c++) {
//        if (this->GetChild(c)->GetPriors()==NULL) {
//            return 1;
//        }
//    }
//    return 0;
}

bool TreeEM::IsOneOfThePriorsAdaptedNULL(){
//    int numbclasses=this->GetNumberGeneralClasses();
//    int numbchild=this->GetPriorsAdaptedVector().size();
    int numbclasses=this->GetPriorsAdaptedVectorParent().size();
    int numbchild=this->GetNumberChildren();
    if (numbclasses !=numbchild && numbclasses !=numbchild-1 && numbchild!=0){ // if the number of general classes is different from the number of priors image to use but at least one of then is not NULL
        return 1;
    }
    return 0;
//    int numbchild=this->GetNumberChildren();
//    for (int c=0; c<numbchild; c++) {
//        if (this->GetChild(c)->GetPriorsAdapted()==NULL) {
//            return 1;
//        }
//    }
//    return 0;
}


void TreeEM::NormalisePriorsAdaptedOverFlown(){
    int numel=this->GetNumberElements();
    
    if(this->ArePriorsAdaptedNormalised()){
//        cout<<"Priors are already normalised";
        return;
    }
    else{
        //        vector<TreeEM*> NodePriorsVector=this->GetPriorsNodeVector();
        vector<TreeEM*> NodePriorsVector=this->GetAllPriorsNodeVectorParent();
        int numbchild=NodePriorsVector.size();
        // First if one of them is a pointer to NULL, all of the priors are deleted and set to NULL
        if( this->IsOneOfThePriorsAdaptedNULL()){
            for(int c=0;c<numbchild;c++){
                delete [] NodePriorsVector[c]->GetPriorsAdaptedDirect();
                NodePriorsVector[c]->PriorsAdapted=NULL;
            }
        }
        else{ // Priors adapted are not normalised but all pointing to valid float array
            vector<float *> PriorsData_PTR;
            for (int c=0; c<numbchild; c++) { // Pushing pointers to begin of each of the Priors in the vector PriorsData_PTR
                if(!NodePriorsVector[c]->IsPriorsAdaptedProbabilityType()){
                    NodePriorsVector[c]->MakePriorsAdaptedProbabilityType();
                }
                PriorsData_PTR.push_back(NodePriorsVector[c]->GetPriorsAdapted());
            }
            int * L2S_PTR=this->GetL2S(); // Pointer to beginning of L2S
            PrecisionTYPE tmpSum=0;
            for (int i=0; i<numel; i++,L2S_PTR++) { // for each of the voxels
                
                tmpSum=0;
                for (int c=0; c<numbchild; c++) { // calculation of the normalising factor
                    tmpSum+=(PrecisionTYPE)(*PriorsData_PTR[c]);
                }
                for (int c=0; c<numbchild; c++) { // Normalisation of the priors data
                    if(tmpSum>1){
                        (*PriorsData_PTR[c])/=tmpSum;
                    }
                }
                for (int c=0; c<numbchild; c++) { // incrementation of the pointer
                    PriorsData_PTR[c]++;
                }
            }
        }
        for (int c=0; c<numbchild; c++) { // Recursivity in case priors adapted are set on more than one level (will happen with case 5 of splitting uniform)
            this->GetChild(c)->NormalisePriorsAdaptedOverFlown();
        }
        return;
    }
}

void TreeEM::NormalisePriorsAdapted(){
//    int numbchild=this->GetNumberChildren();
//    int numbclasses=this->GetNumberGeneralClasses();
    int numel=this->GetNumberElements();

    if(this->ArePriorsAdaptedNormalised()){
//        cout<<"Priors adapted are already normalised";
        return;
    }
    else{
//        vector<TreeEM*> NodePriorsVector=this->GetPriorsNodeVector();
        vector<TreeEM*> NodePriorsVector=this->GetAllPriorsNodeVectorParent();
        int numbchild=NodePriorsVector.size();
        // First if one of them is a pointer to NULL, all of the priors are deleted and set to NULL
        if( this->IsOneOfThePriorsAdaptedNULL()){
//            int numbchild=this->GetNumberChildren();
//            for (int c=0; c<numbchild; c++) {
//                if(this->GetChild(c)->PriorsAdapted!=NULL){
//                    delete [] this->GetChild(c)->PriorsAdapted;
//                    this->GetChild(c)->PriorsAdapted=NULL;
//                }
//            }
            for(int c=0;c<numbchild;c++){
                delete [] NodePriorsVector[c]->GetPriorsAdaptedDirect();
                NodePriorsVector[c]->PriorsAdapted=NULL;
            }
        }
        else{ // Priors adapted are not normalised but all pointing to valid float array
            vector<float *> PriorsData_PTR;
            for (int c=0; c<numbchild; c++) { // Pushing pointers to begin of each of the Priors in the vector PriorsData_PTR
//                if (!this->GetChild(c)->IsPriorsAdaptedProbabilityType()) {
//                    cout<<"Priors is not of probability type";
//                    this->GetChild(c)->MakePriorsAdaptedProbabilityType();
//                    cout << "and now is of probability type "<<this->GetChild(c)->IsPriorsAdaptedProbabilityType();
//                }
//                //cout<< "Priors already of probability type"<<endl;
//                PriorsData_PTR.push_back(this->GetChild(c)->GetPriorsAdapted());
//            }
                if(!NodePriorsVector[c]->IsPriorsAdaptedProbabilityType()){
                    NodePriorsVector[c]->MakePriorsAdaptedProbabilityType();
                }
                PriorsData_PTR.push_back(NodePriorsVector[c]->GetPriorsAdaptedDirect());
            }
            int * L2S_PTR=this->GetL2S(); // Pointer to beginning of L2S
            PrecisionTYPE tmpSum=0;
            for (int i=0; i<numel; i++,L2S_PTR++) { // for each of the voxels

                tmpSum=0;
                for (int c=0; c<numbchild; c++) { // calculation of the normalising factor
                    tmpSum+=(PrecisionTYPE)(*PriorsData_PTR[c]);
                }
                for (int c=0; c<numbchild; c++) { // Normalisation of the priors data
                    if(tmpSum>0){
                        if(*PriorsData_PTR[c]<1E-6){
                            *PriorsData_PTR[c]=0;
                        }
                        (*PriorsData_PTR[c])/=tmpSum;
                    }
                    else{ // taking care of breaking case where normalisation factor is 0
                        //cout<<"Normalisation factor is 0"<<endl;
                        (*PriorsData_PTR[c])=(float)1.0/numbchild;
                    }
                }
                for (int c=0; c<numbchild; c++) { // incrementation of the pointer
                    PriorsData_PTR[c]++;
                }
            }
        }
        for (int c=0; c<numbchild; c++) { // Recursivity in case priors adapted are set on more than one level (will happen with case 5 of splitting uniform)
            this->GetChild(c)->NormalisePriorsAdapted();
        }
        return;
    }
}


void TreeEM::NormalisePriorsOverFlown(){
    int numel=this->GetNumberElements();
    
    if(this->ArePriorsNormalised()){
//        cout<<"Priors are already normalised";
        return;
    }
    else{
        //    vector<TreeEM*> NodeVector=this->GetPriorsNodeVector();
        vector<TreeEM*> NodeVector=this->GetAllPriorsNodeVectorParent();
        int numbchild=NodeVector.size();
        // First if one of them is a pointer to NULL, all of the priors are deleted and set to NULL
        if( this->IsOneOfThePriorsNULL()){
            for(int c=0;c<numbchild;c++){
                delete NodeVector[c]->Priors;
                NodeVector[c]->Priors=NULL;
            }
        }
        else{ // Priors are not normalised but all pointing to valid nifti images
            vector<float *> PriorsData_PTR;
            for (int c=0; c<numbchild; c++) { // Pushing pointers to begin of each of the Priors in the vector PriorsData_PTR
                if(!NodeVector[c]->IsPriorsProbabilityType()){
                    NodeVector[c]->MakePriorsProbabilityType();
                }
                PriorsData_PTR.push_back(static_cast<float*>(NodeVector[c]->GetPriors()->data));
                
            }
            int * L2S_PTR=this->GetL2S(); // Pointer to beginning of L2S
            PrecisionTYPE tmpSum=0;
//            int CountPbNorm=0;
            int CountPbNormSup=0;
            for (int i=0; i<numel; i++,L2S_PTR++) { // for each of the voxels
                
                tmpSum=0;
                for (int c=0; c<numbchild; c++) { // calculation of the normalising factor
                    tmpSum+=(PrecisionTYPE)(*PriorsData_PTR[c]);
                }
                for (int c=0; c<numbchild; c++) { // Normalisation of the priors data
                    if(tmpSum>1){
                        (*PriorsData_PTR[c])/=(float)tmpSum;
                        if (*PriorsData_PTR[c]>1+10E-6) {
                            CountPbNormSup++;
                            cout << *PriorsData_PTR[c] << " and "<< tmpSum<<endl;
                        }
                    }
                }
                for (int c=0; c<numbchild; c++) { // incrementation of the pointer
                    PriorsData_PTR[c]++;
                }
            }
            if (CountPbNormSup>0) {
                cout<<"CountPbNormSup is "<<CountPbNormSup<<endl;
            }
            
        }
        this->ArePriorsNormalised();
        int numbchildTree=this->GetNumberChildren();
        for (int c=0; c<numbchildTree; c++) { // Recursivity of the normalisation in case priors are set on more than one level
            this->GetChild(c)->NormalisePriorsOverFlown();
        }
        return;
    }
}

void TreeEM::NormalisePriors(){
//    int numbchild=this->GetNumberChildren();
//    int numbchild=this->GetNumberGeneralClasses();
//    int numbchild=this->GetPriorsNodeVector().size();
    int numel=this->GetNumberElements();

    if(this->ArePriorsNormalised()){
//        cout<<"Priors are already normalised";
        return;
    }
    else{
//    vector<TreeEM*> NodeVector=this->GetPriorsNodeVector();
        vector<TreeEM*> NodeVector=this->GetAllPriorsNodeVectorParent();
    int numbchild=NodeVector.size();
        // First if one of them is a pointer to NULL, all of the priors are deleted and set to NULL
        if( this->IsOneOfThePriorsNULL()){
            for(int c=0;c<numbchild;c++){
                delete NodeVector[c]->Priors;
                NodeVector[c]->Priors=NULL;
            }

//            int numbchild=this->GetNumberChildren();
//            for (int c=0; c<numbchild; c++) {
//                if(this->GetChild(c)->Priors!=NULL){
//                    delete this->GetChild(c)->Priors;
//                    this->GetChild(c)->Priors=NULL;
//                }
//            }
        }
        else{ // Priors are not normalised but all pointing to valid nifti images
            vector<float *> PriorsData_PTR;
            for (int c=0; c<numbchild; c++) { // Pushing pointers to begin of each of the Priors in the vector PriorsData_PTR
//                if (!this->GetChild(c)->IsPriorsProbabilityType()) {
//                    cout<<"Priors is not of probability type";
//                    this->GetChild(c)->MakePriorsProbabilityType();
//                    cout << "and now is of probability type "<<this->GetChild(c)->IsPriorsProbabilityType();
//                }
//                //cout<< "Priors already of probability type"<<endl;
//                PriorsData_PTR.push_back(static_cast<float*>(this->GetChild(c)->GetPriors()->data));
                if(!NodeVector[c]->IsPriorsProbabilityType()){
                    NodeVector[c]->MakePriorsProbabilityType();
                }
                PriorsData_PTR.push_back(static_cast<float*>(NodeVector[c]->GetPriorsDirect()->data));
//                PriorsData_PTR.push_back(static_cast<float*>(NodeVector[c]->GetPriors()->data));
                
//                    string SavingPriors="/Users/Carole/Documents/PhD/PriorsKept2";
//                    stringstream ss;
//                    ss << c;
//                    string cb=ss.str();
//                    SavingPriors=SavingPriors+cb+".nii.gz";
//                    nifti_set_filenames(NodeVector[c]->GetPriorsDirect(), SavingPriors.c_str(), 0, 0);
//                    nifti_image_write(NodeVector[c]->GetPriorsDirect());
                
            }
            if (PriorsData_PTR.size()>3) {
//                            this->SaveTmpResult(PriorsData_PTR[3], "/Users/Carole/Documents/PhD/PrePriorsOutNormalised.nii.gz");
            }

            int * L2S_PTR=this->GetL2S(); // Pointer to beginning of L2S
            PrecisionTYPE tmpSum=0;
            int CountPbNorm=0;
            int CountPbNormSup=0;
            int CountPbOut=0;
            for (int i=0; i<numel; i++,L2S_PTR++) { // for each of the voxels

                tmpSum=0;
                for (int c=0; c<numbchild; c++) { // calculation of the normalising factor
                    tmpSum+=(PrecisionTYPE)(*PriorsData_PTR[c]);
                }
                if (tmpSum<=10E-6) {
                    CountPbNorm++;
                }
                for (int c=0; c<numbchild; c++) { // Normalisation of the priors data
                    if(tmpSum>10E-6){
                        if(*PriorsData_PTR[c] < 10E-7){
                            *PriorsData_PTR[c]=0;
                        }
                        float ValueBefore=*PriorsData_PTR[c];

                        (*PriorsData_PTR[c])/=(float)tmpSum;
                        if (ValueBefore < 0.0001 && c==3 && *PriorsData_PTR[c]>0.01 && *PriorsData_PTR[c] < 1.0/numbchild) {
                            CountPbOut++;
//                            cout << *PriorsData_PTR[c] << " and "<< tmpSum<<endl;
                        }
                        if (*PriorsData_PTR[c]>1+10E-6) {
                            CountPbNormSup++;
//cout << *PriorsData_PTR[c] << " and "<< tmpSum<<endl;
                        }
                    }
                    else{ // taking care of breaking case where normalisation factor is 0
                        //cout<<"Normalisation factor is 0"<<endl;
                        (*PriorsData_PTR[c])=(float)1.0/numbchild;
                    }
                }
                for (int c=0; c<numbchild; c++) { // incrementation of the pointer
                    PriorsData_PTR[c]++;
                }
            }
            if (CountPbNorm>0) {
                cout<<"CountPbNorm is "<<CountPbNorm<< " and CountPbNormSup is "<<CountPbNormSup<<endl;
            }
            if (CountPbOut>0) {
                cout<<"CountPbOut is "<<CountPbOut<<endl;
            }
            
        }
//        for (int c=0; c<numbchild; c++) {
//            string SavingPriors="/Users/Carole/Documents/PhD/PriorsKept2";
//            stringstream ss;
//            ss << c;
//            string cb=ss.str();
//            SavingPriors=SavingPriors+cb+".nii.gz";
//            nifti_set_filenames(this->GetChild(c)->GetPriors(), SavingPriors.c_str(), 0, 0);
//            nifti_image_write(this->GetChild(c)->GetPriors());
//        }
        this->ArePriorsNormalised();
        int numbchildTree=this->GetNumberChildren();
        for (int c=0; c<numbchildTree; c++) { // Recursivity of the normalisation in case priors are set on more than one level
            this->GetChild(c)->NormalisePriors();
        }
        return;
    }
}


// Check if the priors is a probability type Prior (everything float between 0 and 1)
bool TreeEM::IsPriorsProbabilityType(){
    if (this->GetPriors()==NULL) {
        return 1;
    }
    else{
        int numel=this->GetNumberElements();
        float * Priors_PTR=static_cast<float*>(this->GetPriors()->data);
        float maxPriors=-1E32;
        float minPriors=1E32;
        for (int i=0; i<numel; i++,Priors_PTR++) {
            if ((*Priors_PTR)>maxPriors) {
                maxPriors=(*Priors_PTR);
            }
            if ((*Priors_PTR)<minPriors) {
                minPriors=(*Priors_PTR);
            }
        }
        bool testminPriors=(minPriors>-1E-6);
        bool testmaxPriors=(maxPriors<1+1E-6);
        if (testmaxPriors&&testminPriors) {
            //cout<<"Truly of probability type"<<endl;
            return 1;
        }
    }
    return 0;
}

// Check if the priors adapted is a probability type Prior (everything float between 0 and 1)
bool TreeEM::IsPriorsAdaptedProbabilityType(){
    if (this->GetPriorsAdapted()==NULL) {
        return 1;
    }
    else{
        int numel=this->GetNumberElements();
        float * Priors_PTR=this->GetPriorsAdapted();
        float maxPriors=-1E32;
        float minPriors=1E32;
        for (int i=0; i<numel; i++,Priors_PTR++) {
            if ((*Priors_PTR)>maxPriors) {
                maxPriors=(*Priors_PTR);
            }
            if ((*Priors_PTR)<minPriors) {
                minPriors=(*Priors_PTR);
            }
        }
        bool testminPriors=(minPriors>-1E-6);
        bool testmaxPriors=(maxPriors<1+1E-6);
        if (testmaxPriors&&testminPriors) {
            //cout<<"Truly of probability type"<<endl;
            return 1;
        }
    }
    return 0;
}


bool TreeEM::CheckForValidityOfParametersStructure(Parameters * ParametersToCheck){
    // Incompatibility between type mixture and existence of values for the parameters
    if((ParametersToCheck->DistributionType==0 || ParametersToCheck->DistributionType==2) && ParametersToCheck->ValueParameters!=NULL){
        return 0;
    }
    // Incompatibility between mixture DistributionType and SizeParameters > 0
    if ((ParametersToCheck->DistributionType==0 || ParametersToCheck->DistributionType==2) && ParametersToCheck->SizeParameters>0) {
        return 0;
    }
    // Incompatibility between simple distribution and SizeParameters=0
    if (ParametersToCheck->DistributionType==1 && ParametersToCheck->SizeParameters==0) {
        return 0;
    }
    // Incompatibility between simple distribution and non allocation of values for parameters
    if(ParametersToCheck->DistributionType==1 && ParametersToCheck->ValueParameters==NULL){
        return 0;
    }
    // Incompatibility if SizeParameters is 0 and ValueParameters is allocated
    if (ParametersToCheck->SizeParameters==0 && ParametersToCheck->ValueParameters!=NULL) {
        return 0;
    }
    // Incompatibility if SizeParameters is >0 and ValueParameters is not allocated
    if (ParametersToCheck->SizeParameters>0 && ParametersToCheck->ValueParameters==NULL) {
        return 0;
    }
    else {
        return 1;
    }
}

// Check for the compatibility of the data and the size of the parameters to set
bool TreeEM::CheckForSizeParametersValidity( Parameters * ParametersToSet){
    // First check for the validity of the structure of ParametersToSet
    if(!CheckForValidityOfParametersStructure(ParametersToSet)){
        return 0;
    }
    // Once checked for the validity of the structure check if mixture type or something else (if mixture, ok by definition)
    if(ParametersToSet->DistributionType==0){
        return 1;
    }
    if (ParametersToSet->SizeParameters!=this->CalculateSizeParameters(ParametersToSet->DistributionType)){
        return 0;
    }
    return 1;
}


/***************************** CALCULATION OF KLD ********************************/

// Update the histogram of the data weighted with NormResp for each of the modality in a vector of float pointer to each of the monomodal histogram
vector<float *> TreeEM::GetDataHistogram(){
    vector<float *> DataHistogram_VEC;
    // First check if there is Data to make histogram
    if (this->GetDataImage()==NULL) {
        cout<<"No data to make histogram from"<<endl;
        return DataHistogram_VEC;
    }

    // Then if modality wanted in histogram is available
//    int numbbinsGet=this->GetNumbbins();
    int numbbinsGet=numbbins;
    if (numbbinsGet<=0) {
        cout<<"No proper number of bins asked for"<<endl;
        return DataHistogram_VEC;
    }
    float sizeBin=(float)1.0/numbbinsGet;
//    int *L2S_PTR=this->GetL2S();
//    int numel=this->GetNumberElements();
    int numelmasked=this->GetNumberMaskedElements();
    int numbmodal=this->GetNumberModalities();
    //    int numbchild=this->GetNumberChildren();
    float tmpValue=0;
    //    float * Data=this->MakeDataBFCorrected();
    float * Data=this->GetDataBFCorrected();
    //float * Data_PTR =static_cast<float*>(this->GetDataImage()->data);
    //vector<float *> DataHistogram_VEC;
    for (int m=0; m<numbmodal; m++) {
        float * InitDataHistToPushBack=new float[numbbinsGet];
        for(int i=0;i<numbbinsGet;i++){
            InitDataHistToPushBack[i]=0;
        }
        DataHistogram_VEC.push_back(InitDataHistToPushBack);
    }
    float * NormResp_PTR=this->GetNormResp();
    for (int m=0; m<numbmodal; m++) {
        float * DataHistogram_PTR=DataHistogram_VEC[m];
        //float * DataHistogram=new float[numbbins]{0};

//        L2S_PTR=this->GetL2S();

        //Data_PTR=&static_cast<float*>(this->GetDataImage()->data)[m*numel];
        float * Data_PTR=&Data[m*numelmasked];
        NormResp_PTR=this->GetNormResp();
        PrecisionTYPE SumNormResp=0;
        tmpValue=0;
        // Case when NormResp is NULL
        if (this->GetNormResp()==NULL) { // then consider that there are 1 everywhere
            for (int i=0; i<numelmasked; i++, Data_PTR++) {
                tmpValue=(float)*Data_PTR/sizeBin-0.5;
                if (tmpValue<0) {
                    DataHistogram_PTR[0]+=1;
                }
                else if (tmpValue>numbbinsGet-1){
                    DataHistogram_PTR[numbbinsGet-1]+=1;
                }
                else{
                    DataHistogram_PTR[(int)floorf(tmpValue)]+=(float)(1-(tmpValue-floorf(tmpValue)));
                    DataHistogram_PTR[(int)floorf(tmpValue)+1]+=(float)(tmpValue-floorf(tmpValue));
                }
                SumNormResp++;
                //NormResp_PTR++;

            }

        }
        else{
            for (int i=0; i<numelmasked; i++, Data_PTR++,NormResp_PTR++) {
                tmpValue=(float)*Data_PTR/sizeBin-0.5;
                if (tmpValue<0) {
                    DataHistogram_PTR[0]+=(float)*NormResp_PTR;
                }
                else if (tmpValue>numbbinsGet-1){
                    DataHistogram_PTR[numbbinsGet-1]+=(float)*NormResp_PTR;
                }
                else{
                    DataHistogram_PTR[(int)floorf(tmpValue)]+=(float)*NormResp_PTR*(1-(tmpValue-floorf(tmpValue)));
                    DataHistogram_PTR[(int)floorf(tmpValue)+1]+=(float)*NormResp_PTR*(tmpValue-floorf(tmpValue));
                }
                SumNormResp+=(float)*NormResp_PTR;
            }
            for (int i=0; i<numbbinsGet; i++) {
                DataHistogram_PTR[i]/=SumNormResp;
            }

        }
        DataHistogram_PTR=DataHistogram_VEC[m];
        //int numelmasked=this->GetNumberMaskedElements();
//        float SumData=0;
//        for (int i=0; i<numbbins; i++,DataHistogram_PTR++) {
//            *DataHistogram_PTR/=SumNormResp;
//            SumData+=*DataHistogram_PTR;
//        }
        //cout<<"SumData in GetDataHistogram is"<<SumData;
    }
    //    if (Data!=NULL) {
    //        delete [] Data;
    //        Data=NULL;
    //    }
    return DataHistogram_VEC;
}



/* Update the DataHistogram with all modalities weighted by NormResp.
 At the root, it will be the true histogram of the masked image*/
float * TreeEM::GetDataHistogramTotal(){
    // First check if there is Data to make histogram
    if (this->GetDataImage()==NULL) {
        cout<<"No data to make histogram from"<<endl;
        return NULL;
    }
    // then check that the number of bins set for the tree is compatible with
    int numbbinsGet=this->GetNumbbins();
    if (numbbinsGet<=0) {
        return NULL;
    }
    
    else{
        int numbmodal=this->GetNumberModalities();
        //        int numbchild=this->GetNumberChildren();
        int numelmasked=this->GetNumberMaskedElements();
        int numelhist=(int)pow_int(numbbinsGet,numbmodal);
        //float * DataHistogram=new float[(int)powf(numbbins,numbmodal)]{0};
        float * DataHistogramTotal_PTR=new float[numelhist];//{0};
        for(int i=0;i<numelhist;i++){
            DataHistogramTotal_PTR[i]=0;
        }
        float sizeBin=(float)1.0/numbbinsGet;
        //        int *L2S_PTR=this->GetL2S();
        
        vector<float *> Data_PTRModalVector;
        //        float * Data=this->MakeDataBFCorrected();
        float * Data=this->GetDataBFCorrected();
        
        for (int m=0; m<numbmodal; m++) {
            //Data_PTRModalVector.push_back(&static_cast<float*>(this->GetDataImage()->data)[m*numel]);
            Data_PTRModalVector.push_back(&Data[m*numelmasked]);
        }
        float * NormResp_PTR=this->GetNormResp();
        float tmpValue[MaxNumbModal];//{0};
        
        for(int i=0;i<MaxNumbModal;i++){
            tmpValue[i]=0;
        }
        int twopowmodal=(int)pow_int(2,numbmodal);
        int twopowMaxmodal=(int)pow_int(2,MaxNumbModal);
        //        int indexTab[twopowMaxmodal];//{0};
        int *indexTab=new int[twopowMaxmodal];
        for(int i=0;i<twopowMaxmodal;i++){
            indexTab[i]=0;
        }
        //        float valuePerc[twopowMaxmodal];//{1};
        float *valuePerc=new float[twopowMaxmodal];
        float * valuePercMod=new float[twopowMaxmodal];
        for(int i=0;i<twopowMaxmodal;i++){
            valuePerc[i]=1;
            valuePercMod[i]=1;
        }
        int CountNormRespZero=0;
        float SumNormResp=0;
        vector<int *> PatternVector;
        int Pattern[2];
        Pattern[0]=0;
        Pattern[1]=1;
        for (int m=0; m<numbmodal; m++) {
            int sizePattern=2;
            int numbLine=twopowmodal/pow_int(2, m+1);
            int numbCol=twopowmodal/numbLine;
            PatternVector.push_back(Repmat<int>(Pattern,sizePattern,numbLine,numbCol));
        }
        int CountNormResp1=0;
        for (int i=0; i<numelmasked; i++) {
            for (int m=0; m<numbmodal; m++) {
                int twopowm=(int)pow_int(2,m);
                tmpValue[m]=*Data_PTRModalVector[m]/sizeBin-0.5;
                tmpValue[m]=tmpValue[m]>(numbbinsGet-1)?numbbinsGet-1:tmpValue[m];
                tmpValue[m]=tmpValue[m]<0?0:tmpValue[m];
                valuePercMod[m]*=(1-tmpValue[m]+floorf(tmpValue[m]));
            }
            for (int c=0; c<twopowmodal; c++) {
                for (int m=0; m<numbmodal; m++) {
                    int binspowm=(int)pow_int(numbbinsGet,m);
                    indexTab[c]+=(PatternVector[m][c]+floorf(tmpValue[m]))*binspowm;
                    float MultValue=PatternVector[m][c]==0?valuePercMod[m]:1-valuePercMod[m];
                    valuePerc[c]*=MultValue;
                }
            }
            float sumValuePerc=0;
            for (int c=0; c<twopowmodal; c++) {
                sumValuePerc+=valuePerc[c];
            }
        
            //cout<<"sumValuePerc "<< sumValuePerc<<" for index "<<i<<endl;
            if(NormResp_PTR!=NULL){
                
                for (int p=0; p<twopowmodal; p++) {
                    DataHistogramTotal_PTR[indexTab[p]]+=(float)valuePerc[p]*(*NormResp_PTR);
                    
                }
                if(*NormResp_PTR>0.95){
                    CountNormResp1++;
                }
                if (*NormResp_PTR<1-1E-6) {
                    CountNormRespZero++;
                }
                SumNormResp+=(PrecisionTYPE)*NormResp_PTR;
                NormResp_PTR++;
            }
            else{
                for(int p=0; p<twopowmodal; p++) {
                    DataHistogramTotal_PTR[indexTab[p]]+=(float)valuePerc[p];
                    
                }
                SumNormResp++;
            }
            
            for (int p=0; p<twopowmodal; p++) {
                indexTab[p]=0;
                valuePerc[p]=1;
                valuePercMod[p]=1;
            }
            for (int m=0; m<numbmodal; m++) {
                Data_PTRModalVector[m]++;
            }
        }
        //cout<<"CountNormRespZero is"<<CountNormRespZero<<endl;
        delete [] indexTab;
        indexTab=NULL;
        delete [] valuePerc;
        valuePerc=NULL;
        //                delete [] tmpValue;
        //                tmpValue=NULL;
        float SumDataHistogram=0;
        
        //        float NumberDataHistogramZero=0;
        //        int numelmasked=this->GetNumberMaskedElements();
        int binspowmodal=(int)pow_int(numbbinsGet,numbmodal);
        
        //Normalisation of the DataHistogram in order to properly calculate the KLD afterwards:
        for(int i=0;i<binspowmodal;i++){
            SumDataHistogram+=DataHistogramTotal_PTR[i];
        }
        if(SumDataHistogram>0){
            for(int i=0;i<binspowmodal;i++){
                DataHistogramTotal_PTR[i]/=SumDataHistogram;
            }
        }
        float MaxDataHist=GetMaxArray(DataHistogramTotal_PTR, numelhist);
        vector<int> Indices=GetIndicesValue(DataHistogramTotal_PTR, MaxDataHist, numelhist);
        
        //        for (int i=0; i<binspowmodal; i++) {
        //            DataHistogramTotal_PTR[i]/=SumNormResp;
        //            SumDataHistogram+=DataHistogramTotal_PTR[i];
        //        }
        
        //        cout<<"Sum DataHistogram is "<<SumDataHistogram<<endl;
        //        if (Data!=NULL) {
        //            delete [] Data;
        //            Data=NULL;
        //        }
        for (int m=0; m<numbmodal; m++) {
            delete [] PatternVector[m];
            PatternVector[m]=NULL;
        }
        return DataHistogramTotal_PTR;
    }
}



/* Update the DataHistogram with all modalities weighted by NormResp.
 At the root, it will be the true histogram of the masked image*/
float * TreeEM::GetDataHistogramTotalAversion(){
    // First check if there is Data to make histogram
    if (this->GetDataImage()==NULL) {
        cout<<"No data to make histogram from"<<endl;
        return NULL;
    }
    // then check that the number of bins set for the tree is compatible with
    int numbbinsGet=this->GetNumbbins();
    if (numbbinsGet<=0) {
        return NULL;
    }

    else{
        int numbmodal=this->GetNumberModalities();
        //        int numbchild=this->GetNumberChildren();
        int numelmasked=this->GetNumberMaskedElements();
        int numelhist=(int)pow_int(numbbinsGet,numbmodal);
        //float * DataHistogram=new float[(int)powf(numbbins,numbmodal)]{0};
        float * DataHistogramTotal_PTR=new float[numelhist];//{0};
        for(int i=0;i<numelhist;i++){
            DataHistogramTotal_PTR[i]=0;
        }
        float sizeBin=(float)1.0/numbbinsGet;
        //        int *L2S_PTR=this->GetL2S();

        vector<float *> Data_PTRModalVector;
        //        float * Data=this->MakeDataBFCorrected();
        float * Data=this->GetDataBFCorrected();

        for (int m=0; m<numbmodal; m++) {
            //Data_PTRModalVector.push_back(&static_cast<float*>(this->GetDataImage()->data)[m*numel]);
            Data_PTRModalVector.push_back(&Data[m*numelmasked]);
        }
        float * NormResp_PTR=this->GetNormResp();
        float tmpValue[MaxNumbModal];//{0};

        for(int i=0;i<MaxNumbModal;i++){
            tmpValue[i]=0;
        }
        int twopowmodal=(int)pow_int(2,numbmodal);
        int twopowMaxmodal=(int)pow_int(2,MaxNumbModal);
//        int indexTab[twopowMaxmodal];//{0};
        int *indexTab=new int[twopowMaxmodal];
        for(int i=0;i<twopowMaxmodal;i++){
            indexTab[i]=0;
        }
//        float valuePerc[twopowMaxmodal];//{1};
        float *valuePerc=new float[twopowMaxmodal];
        for(int i=0;i<twopowMaxmodal;i++){
            valuePerc[i]=1;
        }
        int CountNormRespZero=0;
        float SumNormResp=0;
        for (int i=0; i<numelmasked; i++) {
            for (int m=0; m<numbmodal; m++) {
                int twopowm=(int)pow_int(2,m);
                tmpValue[m]=*Data_PTRModalVector[m]/sizeBin-0.5;
                tmpValue[m]=tmpValue[m]>(numbbinsGet-1)?numbbinsGet-1:tmpValue[m];
                tmpValue[m]=tmpValue[m]<0?0:tmpValue[m];
                for (int c=0; c<twopowm; c++) {
                    indexTab[c+twopowm]=indexTab[c];
                    valuePerc[c+twopowm]=valuePerc[c];
                }
                int binspowm=(int)pow_int(numbbinsGet,m);
                for (int c=0; c<twopowm; c++) {
                    indexTab[c]+=(int)binspowm*floorf(tmpValue[m]);
                    indexTab[c+twopowm]+=(int)binspowm*floorf(tmpValue[m])+1;
                    indexTab[c+twopowm]=indexTab[c+twopowm]>(numbbinsGet-1)?numbbinsGet-1:indexTab[c+twopowm]; // Checking do not get over bounds
                    valuePerc[c]*=(1-tmpValue[m]+floorf(tmpValue[m]));
                    valuePerc[c+twopowm]*=(tmpValue[m]-floorf(tmpValue[m]));
                }
            }
            float sumValuePerc=0;
            for (int c=0; c<twopowmodal; c++) {
                sumValuePerc+=valuePerc[c];
            }
            //cout<<"sumValuePerc "<< sumValuePerc<<" for index "<<i<<endl;
            if(NormResp_PTR!=NULL){

                for (int p=0; p<twopowmodal; p++) {
                    DataHistogramTotal_PTR[indexTab[p]]+=(float)valuePerc[p]*(*NormResp_PTR);

                }
                if (*NormResp_PTR<1-1E-6) {
                    CountNormRespZero++;
                }
                SumNormResp+=(PrecisionTYPE)*NormResp_PTR;
                NormResp_PTR++;
            }
            else{
                for(int p=0; p<twopowmodal; p++) {
                    DataHistogramTotal_PTR[indexTab[p]]+=(float)valuePerc[p];

                }
                SumNormResp++;
            }

            for (int p=0; p<twopowmodal; p++) {
                indexTab[p]=0;
                valuePerc[p]=1;
            }
            for (int m=0; m<numbmodal; m++) {
                Data_PTRModalVector[m]++;
            }
        }
        //cout<<"CountNormRespZero is"<<CountNormRespZero<<endl;
                delete [] indexTab;
                indexTab=NULL;
                delete [] valuePerc;
                valuePerc=NULL;
//                delete [] tmpValue;
//                tmpValue=NULL;
        float SumDataHistogram=0;

        //        float NumberDataHistogramZero=0;
        //        int numelmasked=this->GetNumberMaskedElements();
        int binspowmodal=(int)pow_int(numbbinsGet,numbmodal);

        //Normalisation of the DataHistogram in order to properly calculate the KLD afterwards:
        for(int i=0;i<binspowmodal;i++){
            SumDataHistogram+=DataHistogramTotal_PTR[i];
        }
        if(SumDataHistogram>0){
        for(int i=0;i<binspowmodal;i++){
            DataHistogramTotal_PTR[i]/=SumDataHistogram;
        }
        }

//        for (int i=0; i<binspowmodal; i++) {
//            DataHistogramTotal_PTR[i]/=SumNormResp;
//            SumDataHistogram+=DataHistogramTotal_PTR[i];
//        }

        //        cout<<"Sum DataHistogram is "<<SumDataHistogram<<endl;
        //        if (Data!=NULL) {
        //            delete [] Data;
        //            Data=NULL;
        //        }
        return DataHistogramTotal_PTR;
    }
}

// Returns the histogram of the distribution for numbbins
vector<float *> TreeEM::GetDistHistogram(){
    vector<float *> DistHistogramVector;
    // First check if there is Data to make histogram
    if (this->GetDataImage()==NULL) {
        cout<<"No data to make histogram from"<<endl;
        return DistHistogramVector;
    }
    // Then if modality wanted in histogram is available
    //vector<float *> DistHistogramVector;
    int numbchild=this->GetNumberChildren();
    int numbmodal=this->GetNumberModalities();
//    int numbbinsGet=this->GetNumbbins();
    int numbbinsGet=numbbins;
    if (this->GetNumberChildren()==0) {/* If it is a leaf the distribution is then calculated according to the parameters stored. For the moment, their is only one choice of simple distribution : the Gaussian distribution*/
        switch (this->GetDistributionType()) {
        case 2:{ // case of a uniform distribution
            vector<float*>ChildHistogram_VEC=this->GetUniformDistributionHist();
            for (int m=0; m<numbmodal; m++) {
                DistHistogramVector.push_back(ChildHistogram_VEC[m]);
            }
            break;
        }
        default:
            vector<float*>ChildHistogram_VEC=this->GetGaussianDistributionHist();
            for (int m=0; m<numbmodal; m++) {
                DistHistogramVector.push_back(ChildHistogram_VEC[m]);
            }
            break;
        }
    }
    else{/* It is not a leaf and the distribution is the weighted sum of the distributions below*/
        float * ChildHistogram_PTR;
        float * DistHistogram_PTR;

        float NormWeightChild=1;
        for (int m=0; m<numbmodal; m++) {
            float * InitDistHistToPushBack=new float[numbbinsGet];
            for(int i=0;i<numbbinsGet;i++){
                InitDistHistToPushBack[i]=0;
            }
            DistHistogramVector.push_back(InitDistHistToPushBack);
        }
        for (int c=0; c<numbchild; c++) {
            vector<float*>ChildHistogram_VEC=this->GetChild(c)->GetDistHistogram();
            for (int m=0; m<numbmodal; m++) {
                DistHistogram_PTR=DistHistogramVector[m];
                ChildHistogram_PTR=ChildHistogram_VEC[m];
                NormWeightChild=this->GetChild(c)->GetNormWeight();
                for (int i=0; i<numbbinsGet; i++,DistHistogram_PTR++,ChildHistogram_PTR++) {
                    *DistHistogram_PTR+=NormWeightChild*(*ChildHistogram_PTR);
                }
                // ClearingMemory
                if(ChildHistogram_VEC[m]!=NULL){
                    delete [] ChildHistogram_VEC[m];
                    ChildHistogram_VEC[m]=NULL;
//                    cout<< " Delete done "<<endl;
                }
                //                if (ChildHistogram_VEC[m]!=NULL && ((*ChildHistogram_VEC[m])!= NULL) ) {
                //                                    delete [] ChildHistogram_VEC[m];
                //                                    cout<< "Delete ChildHistogram_VEC partially done for modality "<<m<<" and child "<<c<<endl;
                //                                   ChildHistogram_VEC[m]=NULL;
                //                }
                //                if (ChildHistogram_VEC[m]==NULL) {
                //                    cout<<"ChildHistogram_VEC pointer already NULL"<<endl;
                //                }
                //                if ((*ChildHistogram_VEC[m])==NULL) {
                //                    cout<<"Pb with memory allocation"<<endl;
                //                }

            }
        }
    }
    return DistHistogramVector;
}

// Returns the vector containing the uniform distribution for each modality in a vector of float pointers
vector<float*> TreeEM::GetUniformDistributionHist(){
    vector<float *> UniformDistributionHist;
    if (this->GetNumberChildren()!=0) {
        cout<< "not leaf so cannot return gaussian distribution"<<endl;
        return UniformDistributionHist;
    }
    if(this->GetDistributionType()!=2){
        cout<<"no uniform distribution type"<<endl;
        return UniformDistributionHist;
    }
    //vector<float *> GaussianDistributionHist;
    int numbmodal=this->GetNumberModalities();
//    int numbbinsGet=this->GetNumbbins();
    int numbbinsGet=numbbins;
    float sizeBin=1.0/(float)numbbinsGet;
    for(int m=0;m<numbmodal;m++){
        float * UniformDistTmp=new float[numbbinsGet];
        for(int i=0;i<numbbinsGet;i++){
            UniformDistTmp[i]=sizeBin;
        }
        UniformDistributionHist.push_back(UniformDistTmp);
    }
    return UniformDistributionHist;
}

// Returns the Gaussian Distribution for each modality independently in a vector of float pointers
vector<float *> TreeEM::GetGaussianDistributionHist(){
    vector<float *> GaussianDistributionHist;
//    int numbbinsGet=this->GetNumbbins();
    int numbbinsGet=numbbins;
    if (this->GetNumberChildren()!=0) {
        cout<< "not leaf so cannot return gaussian distribution"<<endl;
        return GaussianDistributionHist;
    }
    if(this->GetDistributionType()!=1){
        cout<<"no gaussian distribution type"<<endl;
        return GaussianDistributionHist;
    }
    //vector<float *> GaussianDistributionHist;
    int numbmodal=this->GetNumberModalities();

    float * VarianceB=this->GetVariance();
    float Variance[MaxNumbModal*MaxNumbModal];
    for(int m1=0;m1<MaxNumbModal;m1++){
        for(int m2=0;m2<MaxNumbModal;m2++){
            if(m1<numbmodal&&m2<numbmodal){
                Variance[m1+m2*MaxNumbModal]=VarianceB[m1+m2*numbmodal];
            }
            else{
                Variance[m1+m2*MaxNumbModal]=0;
            }
        }
    }
    float * MeanB=this->GetMean();
    float Mean[MaxNumbModal];
    for(int m=0;m<MaxNumbModal;m++){
        if(m<numbmodal){
            Mean[m]=MeanB[m];
        }
        else{
            Mean[m]=0;
        }
    }
    float Value=0;
    float sizeBin=1.0/(float)numbbinsGet;
    for (int m=0; m<numbmodal; m++) {
        float * GaussianDist_tmp=new float[numbbinsGet];
        for(int i=0;i<numbbinsGet;i++){
            GaussianDist_tmp[i]=0;
        }
        float * GaussianDist_tmpPTR=GaussianDist_tmp;
        float NormalisationFactor=1.0/powf(2*M_PI*Variance[m+m*MaxNumbModal], 0.5);
        GaussianDist_tmpPTR=GaussianDist_tmp;
        float sumDist=0;
        for (int i=0; i<numbbinsGet; i++,GaussianDist_tmpPTR++) {
            Value=i*sizeBin+0.5*sizeBin;
            *GaussianDist_tmpPTR=NormalisationFactor*expf(-(float)0.5/Variance[m+m*MaxNumbModal]*(Value-Mean[m])*(Value-Mean[m]))*sizeBin;
            sumDist+=*GaussianDist_tmpPTR;
        }
        //        cout<<"sumDist in vectorial Gaussian hist is "<<sumDist<<endl;
        GaussianDistributionHist.push_back(GaussianDist_tmp);
    }
    //    delete [] GaussianDist_tmp;
    //    GaussianDist_tmp=NULL;
    return GaussianDistributionHist;
}

// Returns the complete histogram corresponding to the uniform distribution
float * TreeEM::GetUniformDistributionHistTotal(){
    if (this->GetNumberChildren()!=0) {
        cout<< "not leaf so cannot return uniform distribution"<<endl;
        return NULL;
    }
    if(this->GetDistributionType()!=2){
        cout<<"no uniform distribution type"<<endl;
        return NULL;
    }

    int numbmodal=this->GetNumberModalities();
    int numbbinsGet=this->GetNumbbins();
    int binspowmodal=(int)pow_int(numbbinsGet,numbmodal);
    float * UniformDistributionTotal = new float[binspowmodal];
    float sizeBin=1.0/(float)numbbinsGet;
    float sizeBinpowmodal=(int)pow_int(sizeBin,numbmodal);
    for(int i=0;i<binspowmodal;i++){
        UniformDistributionTotal[i]=sizeBinpowmodal;
    }
    return UniformDistributionTotal;
}

// Returns the complete histogram corresponding to the distribution with the given number of bins. To be used for the derivation of the KLD
float * TreeEM::GetGaussianDistributionHistTotal(){
    if (this->GetNumberChildren()!=0) {
        cout<< "not leaf so cannot return gaussian distribution"<<endl;
        return NULL;
    }
    if(this->GetDistributionType()!=1){
        cout<<"no gaussian distribution type"<<endl;
        return NULL;
    }

    int numbmodal=this->GetNumberModalities();

    // First initialise the Variance Matrix and inverted one
//    matrix<float> VarianceMatrix=matrix<float>(numbmodal);
    float * VarianceToSet=this->GetVariance();

//    for (int m1=0; m1<numbmodal; m1++) {
//        for (int m2=0; m2<numbmodal; m2++) {
//            VarianceMatrix.setvalue(m1, m2, VarianceToSet[m1+m2*numbmodal]);
//        }
//    }

    float * VarianceMatrixToInvert=new float[numbmodal*numbmodal];
    for (int m1=0; m1<numbmodal; m1++) {
        for (int m2=0; m2<numbmodal; m2++) {
            VarianceMatrixToInvert[m1+m2*numbmodal]=VarianceToSet[m1+m2*numbmodal];
        }
    }

    //    matrix<float>VarianceMatrixCopy=matrix<float>(MaxNumbModal);
    //    VarianceMatrixCopy.copymatrix(VarianceMatrix);


    // Calculation of the factor in front of the exponential
//    float DeterminantVariance=VarianceMatrix.determinant();
    float DeterminantVariance=determinant(VarianceMatrixToInvert,numbmodal);
    float * MeanB=this->GetMean();
    float Mean[MaxNumbModal];
    for(int m=0;m<MaxNumbModal;m++){
        if(m<numbmodal){
            Mean[m]=MeanB[m];
        }
        else{
            Mean[m]=0;
        }
    }
    int numbbinsGet=this->GetNumbbins();
    float sizeBin=1.0/(float)numbbinsGet;
    //cout<<"the Variance determinant is "<<DeterminantVariance<<endl;
    float NormalisationFactor=1.0/(float)(powf(2*M_PI , (float)((float)numbmodal/2.0))*powf(DeterminantVariance, 0.5));
    //cout <<"The normalisation factor is "<<NormalisationFactor<<endl;
    //Initialisation of the needed element to calculate the inside of the exponential
    int binspowmodal=(int)pow_int(numbbinsGet,numbmodal);
    float * GaussianDistributionTotal = new float[binspowmodal];//{0};
    for(int i=0;i<binspowmodal;i++){
        GaussianDistributionTotal[i]=0;
    }
    float * GaussianDistribution_PTR=GaussianDistributionTotal;
    float InvertedVariance[MaxNumbModal*MaxNumbModal];
    for(int i=0;i<MaxNumbModal*MaxNumbModal;i++){
        InvertedVariance[i]=0;
    }
    if (numbmodal>1) {
//        VarianceMatrix.invert();
        invertMatrix(VarianceMatrixToInvert,numbmodal);
        //        matrix<float>TestMatrix=matrix<float>(MaxNumbModal);
        //        TestMatrix.settoproduct(VarianceMatrixCopy,VarianceMatrix);
        //        TestMatrix.comparetoidentity();
//        bool success;
        for(int m1=0;m1<numbmodal;m1++){
            for (int m2=0; m2<numbmodal; m2++) {
//                VarianceMatrix.getvalue(m1, m2, InvertedVariance[m1+m2*MaxNumbModal], success);
                InvertedVariance[m1+m2*MaxNumbModal]=VarianceMatrixToInvert[m1+m2*numbmodal];
            }
        }
    }
    else{
//        bool success;
//        VarianceMatrix.getvalue(0, 0, InvertedVariance[0], success);
        *InvertedVariance=(float)1.0/DeterminantVariance;
        //*InvertedVariance=1/(*InvertedVariance);
    }
    float temp;
    int  IndexConversion [MaxNumbModal];//{0};
    for(int i=0;i<MaxNumbModal;i++){
        IndexConversion[i]=0;
    }
    delete [] VarianceMatrixToInvert;
    VarianceMatrixToInvert=NULL;
    int Rem;
    // Calculation of the inside of the exponential
    //cout<<InvertedVariance[0]<<endl;
    int CountNegativeValues=0;
    for (int i=0; i<binspowmodal; i++) {
        Rem=i;

        // Conversion of the index i into the different index for each modality giving then the value to consider
        for (int m=numbmodal-1; m>=0; m--) {
            int binspowm=(int)pow_int(numbbinsGet,m);
            IndexConversion[m]=Rem/binspowm;
            Rem-=IndexConversion[m]*binspowm;
        }
        for (int m1=0; m1<numbmodal; m1++) {
            temp=0;
            for (int m2=0; m2<numbmodal; m2++) {
                temp+=((sizeBin*IndexConversion[m2]+0.5*sizeBin)-Mean[m2])*InvertedVariance[m2+m1*MaxNumbModal];
            }
            *GaussianDistribution_PTR=(*GaussianDistribution_PTR)+temp*((sizeBin*IndexConversion[m1]+0.5*sizeBin)-Mean[m1]);
        }
        if (*GaussianDistribution_PTR<0) {
            CountNegativeValues++;
        }
        GaussianDistribution_PTR++;
    }
    //cout<<"The number of negative values is "<<CountNegativeValues<<endl;
    // Filling the distribution array with the value
    GaussianDistribution_PTR=GaussianDistributionTotal;
    //cout << "Normalisation factor in GetGaussianDistHistTotal is "<<NormalisationFactor<<endl;
    float sumDist=0;
    //    int numelmasked=this->GetNumberMaskedElements();
    float sizeBinpowmodal=(int)pow_int(sizeBin,numbmodal);
    for (int i=0;i<binspowmodal;i++,GaussianDistribution_PTR++){
        *GaussianDistribution_PTR=NormalisationFactor*expf(-0.5*(*GaussianDistribution_PTR))*sizeBinpowmodal;
        sumDist+=*GaussianDistribution_PTR;
    }
    //cout<<"sumDist in GetGaussianTotal is "<<sumDist<<endl;
    // Clearing space needing for inverse of variance


    // Return result
    return GaussianDistributionTotal;
}

float * TreeEM::GetDistHistogramTotal(){

    // Then if modality wanted in histogram is available
    int numbchild=this->GetNumberChildren();
    int numbmodal=this->GetNumberModalities();
    int numbbinsGet=this->GetNumbbins();
    int binspowmodal=(int)pow_int(numbbinsGet,numbmodal);
    float * DistHistogramTotal=new float[binspowmodal];//{0};
    for(int i=0;i<binspowmodal;i++){
        DistHistogramTotal[i]=0;
    }

    if (this->GetNumberChildren()==0) {/* If it is a leaf the distribution is then calculated according to the parameters stored. For the moment, their is only one choice of simple distribution : the Gaussian distribution*/
        switch (this->GetDistributionType()) {
        case 2:{ // case of uniform distribution
            float * LeafHistogramTotal=this->GetUniformDistributionHistTotal();
            float * LeafHistogramTotal_PTR=LeafHistogramTotal;
            for (int i=0; i<binspowmodal; i++,LeafHistogramTotal_PTR++) {
                DistHistogramTotal[i]=*LeafHistogramTotal_PTR;
                //SumLeaf+=*LeafHistogramTotal_PTR;
            }
            //cout << "Sum leaf is "<<SumLeaf<<endl;
            delete [] LeafHistogramTotal;
            LeafHistogramTotal=NULL;
            LeafHistogramTotal_PTR=NULL;
            break;
        }
        default:
            float * LeafHistogramTotal=this->GetGaussianDistributionHistTotal();
            //            vector<float *> LeafVectorHistogram=this->GetGaussianDistributionHist();
            //            float * LeafVectorHistogram_PTR=LeafVectorHistogram[0];
            float * LeafHistogramTotal_PTR=LeafHistogramTotal;
            //            int CountDifference=0;
            //            for (int i=0; i<numbbins; i++,LeafHistogramTotal_PTR++,LeafVectorHistogram_PTR++) {
            //                if (fabsf((*LeafHistogramTotal_PTR)-(*LeafVectorHistogram_PTR))>1E-6) {
            //                    CountDifference++;
            //                }
            //            }
            //            //cout<<"Count difference direct gaussian is "<<CountDifference<<endl;
            //            LeafHistogramTotal_PTR=LeafHistogramTotal;
            //            float SumLeaf=0;
            for (int i=0; i<binspowmodal; i++,LeafHistogramTotal_PTR++) {
                DistHistogramTotal[i]=*LeafHistogramTotal_PTR;
                //SumLeaf+=*LeafHistogramTotal_PTR;
            }
            //cout << "Sum leaf is "<<SumLeaf<<endl;
            delete [] LeafHistogramTotal;
            LeafHistogramTotal=NULL;
            LeafHistogramTotal_PTR=NULL;
            break;
        }
    }
    else{/* It is not a leaf and the distribution is the weighted sum of the distributions below*/

        float * DistHistogram_PTR=DistHistogramTotal;
        float * ChildDistHistogram=NULL;
        float * ChildDistHistogram_PTR=NULL;
        float NormWeightChild;
        for (int c=0; c<numbchild; c++) {

            ChildDistHistogram=(this->GetChild(c))->GetDistHistogramTotal();
            ChildDistHistogram_PTR=ChildDistHistogram;
            DistHistogram_PTR=DistHistogramTotal;
            NormWeightChild=this->GetChild(c)->GetNormWeight();
            for (int i=0; i<binspowmodal; i++) {
                *DistHistogram_PTR+=NormWeightChild*(*ChildDistHistogram_PTR);
                DistHistogram_PTR++;
                ChildDistHistogram_PTR++;
            }
            // Clearing
            ChildDistHistogram_PTR=NULL;
            if (ChildDistHistogram!=NULL) {
                delete [] ChildDistHistogram;
                ChildDistHistogram=NULL;
//                cout<< "Delete done for child "<<c<<endl;
            }
            //        if ((ChildDistHistogram!=NULL) && ((*ChildDistHistogram)!= NULL)) {
            //
            //            delete [] ChildDistHistogram;
            //            ChildDistHistogram=NULL;
            //            cout<<"Delete done for child "<<c<<endl;
            //        }
            //        if (ChildDistHistogram==NULL) {
            //            cout<<"ChildDistHistogram is NULL"<<endl;
            //        }
            //        cout<<ChildDistHistogram<<" and "<< *ChildDistHistogram<<endl;


        }
    }
    return DistHistogramTotal;
}

// Returns the KLD when comparing the total histogram of the distribution modelled and the data
float TreeEM::GetDistCompKLDTotal(){
    float * DistHistTotal=this->GetDistHistogramTotal();
    float * DistHistTotal_PTR=DistHistTotal;
    float * DataHistTotal=this->GetDistHistogramTotal();
    float * DataHistTotal_PTR=DataHistTotal;
    PrecisionTYPE KLD=0;
    int numbmodal=this->GetNumberModalities();
    int numbbinsGet=this->GetNumbbins();
    int binspowmodal=(int)pow_int(numbbinsGet,numbmodal);
    for (int i=0; i<binspowmodal; i++,DataHistTotal_PTR++,DistHistTotal_PTR++) {
        KLD+=(PrecisionTYPE)logf(((*DataHistTotal_PTR)/(*DistHistTotal_PTR)))*(*DataHistTotal_PTR);
    }
    delete [] DistHistTotal;
    DistHistTotal=NULL;
    delete [] DataHistTotal;
    DataHistTotal = NULL;
    return (float)KLD;
}

float * TreeEM::GetDistCompKLD(){
    int numbmodal=this->GetNumberModalities();
    int numbbinsGet=this->GetNumbbins();
    int binspowmodal=(int)pow_int(numbbinsGet,numbmodal);
    float * KLD=new float[numbmodal];//{0};
    for(int i=0;i<numbmodal;i++){
        KLD[i]=0;
    }
    vector<float *> DistHist_VEC=this->GetDistHistogram();
    vector<float *> DataHist_VEC=this->GetDataHistogram();

    for (int m=0; m<numbmodal; m++) {
        PrecisionTYPE KLD_tmp=0;
        float * DistHist_PTR=DistHist_VEC[m];
        float * DataHist_PTR=DataHist_VEC[m];
        for (int i=0; i<binspowmodal; i++, DataHist_PTR++,DistHist_PTR++) {
            KLD_tmp+=(PrecisionTYPE)logf(((*DataHist_PTR)/(*DistHist_PTR)))*(*DataHist_PTR);
        }
        KLD[m]=KLD_tmp;
        delete [] DistHist_VEC[m];
        DistHist_VEC[m]=NULL;
        delete [] DataHist_VEC[m];
        DataHist_VEC[m]=NULL;
    }
    return KLD;
}

float TreeEM::CriterionCalculation(){
    int numbFreeParams=this->GetNumberFreeParameters();
    if (BICFP) {
        numbFreeParams+=this->GetNumberAllLeaves()-1;
    }
    int numelmasked=this->GetNumberMaskedElements();
    float IndFactor=this->GetIndFactor();
    float LL=this->GetLogLikelihood();
    float BIC=LL*IndFactor-(float)numbFreeParams/2.0*logf(numelmasked*IndFactor);
    return BIC;
}

float TreeEM::CriterionCalculationDPInd(){

    float LL=this->GetLogLikelihood();
    int numbchild=this->GetNumberChildren();
    int numelmasked=this->GetNumberMaskedElements();
    float DP=1;
    float * DPChildren=this->GetDPChildren();
//    if(this->IsRoot() && DPChildren.size()==numbchild){
    if(this->IsRoot()){
    for(int c=0;c<numbchild;c++ ){
            //float * AlphaResult=AlphaCalculation(DPtemp);
            int numbLeaves=this->GetChild(c)->GetNumberAllLeaves();
            if(numbLeaves >=2){
                DP*=DPChildren[c*MaxSupport+numbLeaves-1];
            }
            else{
                DP*=DPChildren[0+c*MaxSupport];
            }

        }
    }
    int numbFreeParams=this->GetNumberFreeParameters();
    float IndFactor=this->GetIndFactor();
    return (LL+numelmasked*logf(DP))*IndFactor-(float)numbFreeParams/2.0*logf(numelmasked*IndFactor);
}

float TreeEM::CriterionCalculationDPNonInd(int ChildModified){

    float LL=this->GetLogLikelihood();
    int numbchild=this->GetNumberChildren();
    int numelmasked=this->GetNumberMaskedElements();
//    float DP=1;
    float logDP=0;
    float * DPChildren=this->GetDPChildren();
//    if(this->IsRoot() && DPChildren.size()==numbchild){
    if(this->IsRoot()){
        int * numbLeaves=new int[numbchild];
        int indexHistogram=0;
        for(int c=0;c<numbchild;c++){
            numbLeaves[c]=this->GetChild(c)->GetNumberAllLeaves();
            indexHistogram+=(int)(numbLeaves[c]*pow_int(MaxSupport,c));

        }
        int Shift=(int)pow_int(MaxSupport,ChildModified);
        int indexInitHist=indexHistogram-numbLeaves[ChildModified]*Shift;
        float Denominator=0;
        for (int i=0;i<MaxSupport;i++){
            Denominator+=DPChildren[indexInitHist+i*Shift];
        }
//        float Numerator=DPChildren[indexHistogram];
//         DP=Numerator/Denominator;
         delete [] numbLeaves;
//         DP=Numerator;
         numbLeaves=NULL;
        int sizeLogDP=(int)pow_int(MaxSupport,numbchild);
         float * LogDP=LogGaussBlur(DPChildren,sizeLogDP);
//         cout<< LogDP[indexHistogram];
         logDP=LogDP[indexHistogram];

    }
    float IndFactor=this->GetIndFactor();
    cout<<"LL component : "<< LL*IndFactor << "DP Coeff "<<logDP<<endl;
    int numbFreeParams=this->GetNumberFreeParameters();

//    return (LL*IndFactor)+logf(DP)-(float)numbFreeParams/2.0*logf(numelmasked*IndFactor);
    return (LL*IndFactor)+logDP-(float)numbFreeParams/2.0*logf(numelmasked*IndFactor);
}

float TreeEM::CriterionCalculationSplitDP(){

    float LL=this->GetLogLikelihood();
    int numbchild=this->GetNumberChildren();
    int numelmasked=this->GetNumberMaskedElements();
    float DP=1;
    float * DPChildren=this->GetDPChildren();
    if(this->IsRoot() && DPChildren!=NULL){
        for(int c=0;c<numbchild;c++ ){
            float * DPtemp=DPChildren;
            float DPtemp_test[MaxSupport];
            for(int i=0;i<MaxSupport;i++){
                DPtemp_test[i]=0;
            }
            for(int i=0;i<MaxSupport;i++){
                float tmp=0;
                for(int j=MaxSupport-1;j>=i;j--){
                    tmp+=DPtemp[j];
                }
                DPtemp_test[i]=tmp;
            }
            //float * AlphaResult=AlphaCalculation(DPtemp);
            int numbLeaves=this->GetChild(c)->GetNumberAllLeaves();
            if(numbLeaves >=2){
                DP*=DPtemp_test[numbLeaves-1];
            }
            else{
                DP*=1;
            }

        }
    }
    return LL+numelmasked*logf(DP);
}

float TreeEM::CriterionCalculationMergeDP(){

    float LL=this->GetLogLikelihood();
    int numbchild=this->GetNumberChildren();
    int numelmasked=this->GetNumberMaskedElements();
    float DP=1;
    float * DPChildren=this->GetDPChildren();
    if(this->IsRoot() && DPChildren!=NULL){
        for(int c=0;c<numbchild;c++ ){
            float * DPtemp=DPChildren;
            float DPtemp_test[MaxSupport];
            for(int i=0;i<MaxSupport;i++){
                DPtemp_test[i]=0;
            }
            for(int i=0;i<MaxSupport;i++){
                float tmp=0;
                for(int j=0;j<=i;j++){
                    tmp+=DPtemp[j];
                }
                DPtemp_test[i]=tmp;
            }
            //float * AlphaResult=AlphaCalculation(DPtemp);
            int numbLeaves=this->GetChild(c)->GetNumberAllLeaves();
            if(numbLeaves >=2){
                DP*=DPtemp_test[numbLeaves-1];
            }
            else{
                DP*=DPtemp_test[0];
            }

        }
    }
    return LL+numelmasked*logf(DP);
}

/************************** METHODS FOR MERGING OPERATIONS ******************************/

// Returns the comparison between the two modelled distributions if comparable meaning that the two trees compared have the same Parent
MergeKLD * TreeEM::GetKLDMerge(int Child1Input,int Child2Input){
    // Check that the given Children exist
    int numbchild=this->GetNumberChildren();
    if (Child1Input>=numbchild||Child2Input>=numbchild||Child1Input<0||Child2Input<0) {
//        cout<<"Out of bound for the children to merge"<<endl;
        return NULL;
    }
    // Check if the merging try is made on leaves
    if (this->GetChild(Child1Input)->GetNumberChildren()!=0||this->GetChild(Child2Input)->GetNumberChildren()!=0) {
//        cout<< "One of the children is not a leaf, merging cannot be done"<<endl;
        return NULL;
    }
    // Check if the merging is tried on leaves with same priors
    //    cout<< this->GetChild(Child1Input)->GetPriors()<<" and "<<this->GetChild(Child2Input)->GetPriors();
    if (this->GetChild(Child1Input)->GetPriors()!=this->GetChild(Child2Input)->GetPriors()) {
//        cout<<"Impossible to merge leaves with not same priors"<<endl;
        return NULL;
    }
    // Check if merging is done on leaves with same distribution type
    if(this->GetChild(Child1Input)->GetDistributionType()!=this->GetChild(Child2Input)->GetDistributionType()){
//        cout<<"No merging for components without same distribution";
        return NULL;
    }
    if(this->IsRoot()){
//        cout<<"Impossible to merge general classes"<<endl;
        return NULL;
    }
    int numbmodal=this->GetNumberModalities();
    int numbbinsGet=this->GetNumbbins();
    int binspowmodal=(int)pow_int(numbbinsGet,numbmodal);
    // Initialisation of ResultMergeKLD
    MergeKLD * ResultMergeKLD=new MergeKLD();
    ResultMergeKLD->Parent=this;
    ResultMergeKLD->Child1=Child1Input;
    ResultMergeKLD->Child2=Child2Input;
    ResultMergeKLD->KLDTot=0;
//    ResultMergeKLD->KLD=new float[MaxNumbModal];//{0};
//    for(int i=0;i<MaxNumbModal;i++){
//        ResultMergeKLD->KLD[i]=0;
//    }

    // Calculation of the needed histograms for the calculation of the KLDcompTot
    float * DistHistTotal1=this->GetChild(Child1Input)->GetDistHistogramTotal();
    float * DistHistTotal1_PTR=DistHistTotal1;
    float * DistHistTotal2=this->GetChild(Child2Input)->GetDistHistogramTotal();
    float * DistHistTotal2_PTR=DistHistTotal2;
    //    int CountNan1=0;
    //    int CountNan2=0;
    //    int CountNanAdd=0;

//    // check sum of distribution in order to calculate KLD
//    PrecisionTYPE sumDist1=0;
//    PrecisionTYPE sumDist2=0;
//    for(int i=0;i<binspowmodal;i++){
//        sumDist1+=(PrecisionTYPE)DistHistTotal1[i];
//        sumDist2+=(PrecisionTYPE)DistHistTotal2[i];
//    }
//    cout<< "sumDist1 is "<<sumDist1<< " and sumDist2 is "<<sumDist2<<endl;


    for (int i=0; i<binspowmodal; i++,DistHistTotal1_PTR++,DistHistTotal2_PTR++) {
        float DistValue1=(*DistHistTotal1_PTR)<=0.00001?0.00001:(*DistHistTotal1_PTR);
        float DistValue2=(*DistHistTotal2_PTR)<=0.00001?0.00001:(*DistHistTotal2_PTR);
        //        if (logf(DistValue1/DistValue2)*(*DistHistTotal1_PTR)!=logf(DistValue1/DistValue2)*(*DistHistTotal1_PTR)) {
        //            CountNan1++;
        //        }
        //        if (logf(DistValue2/DistValue1)*(*DistHistTotal2_PTR)!=logf(DistValue2/DistValue1)*(*DistHistTotal2_PTR)) {
        //            CountNan2++;
        //        }
        //        if (0.5*(logf(DistValue1/DistValue2)*(*DistHistTotal1_PTR)+logf(DistValue2/DistValue1)*(*DistHistTotal2_PTR))!=0.5*(logf(DistValue1/DistValue2)*(*DistHistTotal1_PTR)+logf(DistValue2/DistValue1)*(*DistHistTotal2_PTR))) {
        //            CountNanAdd++;
        //        }
        ResultMergeKLD->KLDTot+=0.5*(logf(((DistValue1)/(DistValue2)))*(*DistHistTotal1_PTR)+logf(((DistValue2)/(DistValue1)))*(*DistHistTotal2_PTR)); // Use of the symmetric KLD between the two distributions
        //cout<<ResultMergeKLD->KLDTot<< "   -   ";
    }
//    cout<<endl;
    delete [] DistHistTotal1;
    DistHistTotal1=NULL;
    delete [] DistHistTotal2;
    DistHistTotal2=NULL;

//    // Calculation of KLDcomp
//    vector<float *> DistHist1_VEC=this->GetChild(Child1Input)->GetDistHistogram();
//    vector<float *> DistHist2_VEC=this->GetChild(Child2Input)->GetDistHistogram();
//    for (int m=0; m<numbmodal; m++) {
//        float * DistHist1_PTR=DistHist1_VEC[m];
//        float * DistHist2_PTR=DistHist2_VEC[m];
//        for (int i=0; i<numbbins; i++,DistHist1_PTR++,DistHist2_PTR++) {
//            float DistValue1=(*DistHist1_PTR)<=0.00001?0.00001:(*DistHist1_PTR);
//            float DistValue2=(*DistHist2_PTR)<=0.00001?0.00001:(*DistHist2_PTR);
//            ResultMergeKLD->KLD[m]+=0.5*(logf(((DistValue1/DistValue2)))*(*DistHist1_PTR)+logf(((DistValue2)/(DistValue1)))*(*DistHist2_PTR)); // Use of the symmetric KLD between the two distributions
//        }
//        delete [] DistHist1_VEC[m];
//        DistHist1_VEC[m]=NULL;
//        delete [] DistHist2_VEC[m];
//        DistHist2_VEC[m]=NULL;
//    }
    return ResultMergeKLD;
}

// Returns the comparison between the two modelled distributions if comparable meaning that the two trees compared have the same Parent
MergeKLD_b * TreeEM::GetKLDMerge_b(int Child1Input,int Child2Input){
    // Check that the given Children exist
    int numbchild=this->GetNumberChildren();
    if (Child1Input>=numbchild||Child2Input>=numbchild||Child1Input<0||Child2Input<0) {
        //        cout<<"Out of bound for the children to merge"<<endl;
        return NULL;
    }
    // Check if the merging try is made on leaves
    if (this->GetChild(Child1Input)->GetNumberChildren()!=0||this->GetChild(Child2Input)->GetNumberChildren()!=0) {
        //        cout<< "One of the children is not a leaf, merging cannot be done"<<endl;
        return NULL;
    }
    // Check if the merging is tried on leaves with same priors
    //    cout<< this->GetChild(Child1Input)->GetPriors()<<" and "<<this->GetChild(Child2Input)->GetPriors();
    if (this->GetChild(Child1Input)->GetPriors()!=this->GetChild(Child2Input)->GetPriors()) {
        //        cout<<"Impossible to merge leaves with not same priors"<<endl;
        return NULL;
    }
    // Check if merging is done on leaves with same distribution type
    if(this->GetChild(Child1Input)->GetDistributionType()!=this->GetChild(Child2Input)->GetDistributionType()){
        //        cout<<"No merging for components without same distribution";
        return NULL;
    }
    if(this->GetChild(Child1Input)->GetDistributionType()==2 || this->GetChild(Child2Input)->GetDistributionType()==2){
        // cout << "No merging between uniform distributions"
        return NULL;
    }
    if(this->IsRoot()){
        //        cout<<"Impossible to merge general classes"<<endl;
        return NULL;
    }
    int numbmodal=this->GetNumberModalities();
    int numbbinsGet=this->GetNumbbins();
    int binspowmodal=(int)pow_int(numbbinsGet,numbmodal);
    // Initialisation of ResultMergeKLD
    MergeKLD_b * ResultMergeKLD=new MergeKLD_b();
    ResultMergeKLD->HierarchyParent=this->GetHierarchyVector();
    ResultMergeKLD->Child1=Child1Input;
    ResultMergeKLD->Child2=Child2Input;
    ResultMergeKLD->KLDTot=0;
    
    // Calculation of the needed histograms for the calculation of the KLDcompTot
    float * DistHistTotal1=this->GetChild(Child1Input)->GetDistHistogramTotal();
    float * DistHistTotal1_PTR=DistHistTotal1;
    float * DistHistTotal2=this->GetChild(Child2Input)->GetDistHistogramTotal();
    float * DistHistTotal2_PTR=DistHistTotal2;
    
    
    for (int i=0; i<binspowmodal; i++,DistHistTotal1_PTR++,DistHistTotal2_PTR++) {
        float DistValue1=(*DistHistTotal1_PTR)<=0.00001?0.00001:(*DistHistTotal1_PTR);
        float DistValue2=(*DistHistTotal2_PTR)<=0.00001?0.00001:(*DistHistTotal2_PTR);
        ResultMergeKLD->KLDTot+=0.5*(logf(((DistValue1)/(DistValue2)))*(*DistHistTotal1_PTR)+logf(((DistValue2)/(DistValue1)))*(*DistHistTotal2_PTR)); // Use of the symmetric KLD between the two distributions
        //cout<<ResultMergeKLD->KLDTot<< "   -   ";
    }
    //    cout<<endl;
    delete [] DistHistTotal1;
    DistHistTotal1=NULL;
    delete [] DistHistTotal2;
    DistHistTotal2=NULL;
    
    return ResultMergeKLD;
}

GenKLD * TreeEM::GetGenKLD(){
    int numbmodal=this->GetNumberModalities();
    int numbbinsGet=this->GetNumbbins();
    int binspowmodal=(int)pow_int(numbbinsGet,numbmodal);
    // Initialisation of ResultMergeKLD
    GenKLD * ResultKLD=new GenKLD();

    ResultKLD->KLDTot=0;
//    ResultKLD->KLD=new float[MaxNumbModal];//{0};
//    for(int i=0;i<MaxNumbModal;i++){
//        ResultKLD->KLD[i]=0;
//    }

    // Calculation of the needed histograms for the calculation of the KLDcompTot
    float * DistHistTotal1=this->GetDistHistogramTotal();
    float * DistHistTotal1_PTR=DistHistTotal1;
    float * DistHistTotal2=this->GetDataHistogramTotal();
    float * DistHistTotal2_PTR=DistHistTotal2;
    //    int CountNan1=0;
    //    int CountNan2=0;
    //    int CountNanAdd=0;
    PrecisionTYPE tmpResultKLD=0;
    for (int i=0; i<binspowmodal; i++,DistHistTotal1_PTR++,DistHistTotal2_PTR++) {
        float DistValue1=(*DistHistTotal1_PTR)<=0.00001?0.00001:(*DistHistTotal1_PTR);
        float DistValue2=(*DistHistTotal2_PTR)<=0.00001?0.00001:(*DistHistTotal2_PTR);
        //        if (logf(DistValue1/DistValue2)*(*DistHistTotal1_PTR)!=logf(DistValue1/DistValue2)*(*DistHistTotal1_PTR)) {
        //            CountNan1++;
        //        }
        //        if (logf(DistValue2/DistValue1)*(*DistHistTotal2_PTR)!=logf(DistValue2/DistValue1)*(*DistHistTotal2_PTR)) {
        //            CountNan2++;
        //        }
        //        if (0.5*(logf(DistValue1/DistValue2)*(*DistHistTotal1_PTR)+logf(DistValue2/DistValue1)*(*DistHistTotal2_PTR))!=0.5*(logf(DistValue1/DistValue2)*(*DistHistTotal1_PTR)+logf(DistValue2/DistValue1)*(*DistHistTotal2_PTR))) {
        //            CountNanAdd++;
        //        }
        tmpResultKLD+=(PrecisionTYPE)0.5*(log(((DistValue1)/(DistValue2)))*(*DistHistTotal1_PTR)+log(((DistValue2)/(DistValue1)))*(*DistHistTotal2_PTR)); // Use of the symmetric KLD between the two distributions
        //cout<<ResultMergeKLD->KLDTot<< "   -   ";
    }
    ResultKLD->KLDTot=(float)tmpResultKLD;
//    cout<<endl;
    delete [] DistHistTotal1;
    DistHistTotal1=NULL;
    delete [] DistHistTotal2;
    DistHistTotal2=NULL;

//    // Calculation of KLDcomp
//    vector<float *> DistHist1_VEC=this->GetDistHistogram();
//    vector<float *> DistHist2_VEC=this->GetDataHistogram();
//    for (int m=0; m<numbmodal; m++) {
//        float * DistHist1_PTR=DistHist1_VEC[m];
//        float * DistHist2_PTR=DistHist2_VEC[m];
//        for (int i=0; i<numbbins; i++,DistHist1_PTR++,DistHist2_PTR++) {
//            float DistValue1=(*DistHist1_PTR)<=0.00001?0.00001:(*DistHist1_PTR);
//            float DistValue2=(*DistHist2_PTR)<=0.00001?0.00001:(*DistHist2_PTR);
//            ResultKLD->KLD[m]+=0.5*(logf(((DistValue1/DistValue2)))*(*DistHist1_PTR)+logf(((DistValue2)/(DistValue1)))*(*DistHist2_PTR)); // Use of the symmetric KLD between the two distributions
//        }
//        delete [] DistHist1_VEC[m];
//        DistHist1_VEC[m]=NULL;
//        delete [] DistHist2_VEC[m];
//        DistHist2_VEC[m]=NULL;
//    }
    return ResultKLD;
}

// Returns for all children of a TreeEM the pairwise MergeKLD in a vector;
vector<MergeKLD *> TreeEM::GetVectorKLDMergeChildren(){
    int numbchild=this->GetNumberChildren();
    vector<MergeKLD *> ResultCompChildrenKLD;
    for (int c1=0; c1<numbchild; c1++) {
        for (int c2=c1+1; c2<numbchild; c2++) {
            MergeKLD * MergeKLDToAdd=this->GetKLDMerge(c1, c2);
            if (MergeKLDToAdd!=NULL) {
                ResultCompChildrenKLD.push_back(MergeKLDToAdd);
            }

        }
    }
    return ResultCompChildrenKLD;
}

// Returns for all children of a TreeEM the pairwise MergeKLD in a vector;
vector<MergeKLD_b *> TreeEM::GetVectorKLDMergeChildren_b(){
    int numbchild=this->GetNumberChildren();
    vector<MergeKLD_b *> ResultCompChildrenKLD;
    for (int c1=0; c1<numbchild; c1++) {
        for (int c2=c1+1; c2<numbchild; c2++) {
            MergeKLD_b * MergeKLDToAdd=this->GetKLDMerge_b(c1, c2);
            if (MergeKLDToAdd!=NULL) {
                ResultCompChildrenKLD.push_back(MergeKLDToAdd);
            }
            
        }
    }
    return ResultCompChildrenKLD;
}

vector<MergeKLD*> TreeEM::GetVectorKLDMergeLeaves(){
    vector<MergeKLD *> VectorKLDMergeLeaves;
    vector<MergeKLD *> VectorKLDMergeChildren=this->GetVectorKLDMergeChildren();
    int numbKLDMergeChildren=VectorKLDMergeChildren.size();
    for (int i=0; i<numbKLDMergeChildren; i++) {
        VectorKLDMergeLeaves.push_back(VectorKLDMergeChildren[i]);
    }
    //VectorKLDMergeChildren.clear();
    int numbchild=this->GetNumberChildren();
    for (int c=0; c<numbchild; c++) {
        VectorKLDMergeChildren=(this->GetChild(c))->GetVectorKLDMergeLeaves();
        numbKLDMergeChildren=VectorKLDMergeChildren.size();
        for (int i=0; i<numbKLDMergeChildren; i++) {
            VectorKLDMergeLeaves.push_back(VectorKLDMergeChildren[i]);
        }
        //VectorKLDMergeChildren.clear();
    }
    return VectorKLDMergeLeaves;
}

vector<MergeKLD_b *> TreeEM::GetVectorKLDMergeLeaves_b(){
    vector<MergeKLD_b *> VectorKLDMergeLeaves;
    vector<MergeKLD_b *> VectorKLDMergeChildren=this->GetVectorKLDMergeChildren_b();
    int numbKLDMergeChildren=VectorKLDMergeChildren.size();
    for (int i=0; i<numbKLDMergeChildren; i++) {
        VectorKLDMergeLeaves.push_back(VectorKLDMergeChildren[i]);
    }
    //VectorKLDMergeChildren.clear();
    int numbchild=this->GetNumberChildren();
    for (int c=0; c<numbchild; c++) {
        VectorKLDMergeChildren=(this->GetChild(c))->GetVectorKLDMergeLeaves_b();
        numbKLDMergeChildren=VectorKLDMergeChildren.size();
        for (int i=0; i<numbKLDMergeChildren; i++) {
            VectorKLDMergeLeaves.push_back(VectorKLDMergeChildren[i]);
        }
        //VectorKLDMergeChildren.clear();
    }
    return VectorKLDMergeLeaves;
}

MergeKLD * TreeEM::GetToMerge(){
    vector<MergeKLD *> VectorKLDMergeLeaves=this->GetVectorKLDMergeLeaves();
    int numbKLDMergeLeaves=VectorKLDMergeLeaves.size();
    if (numbKLDMergeLeaves==0) {
        return NULL;
    }
    else{
//        int numbmodal=this->GetNumberModalities();
        MergeKLD * MergeMin=new MergeKLD();
        MergeMin->Parent=NULL;
        MergeMin->Child1=-1;
        MergeMin->Child2=-1;
        MergeMin->KLDTot=1E32;
//        MergeMin->KLD=new float[numbmodal];//{0};
//        for(int i=0;i<numbmodal;i++){
//            MergeMin->KLD[i]=0;
//        }

        for (int i=0; i<numbKLDMergeLeaves; i++) {
            int Child1=VectorKLDMergeLeaves[i]->Child1;
            int Child2=VectorKLDMergeLeaves[i]->Child2;
            int numbDirectLeaves=VectorKLDMergeLeaves[i]->Parent->GetNumberDirectLeaves();
            float KLDTotTry=VectorKLDMergeLeaves[i]->KLDTot;
//            float * KLDTry=VectorKLDMergeLeaves[i]->KLD;
            // Update if not already checked and is lowest KLDTot
            bool MergeCheckTest=VectorKLDMergeLeaves[i]->Parent->GetMergeCheck()[Child1+Child2*numbDirectLeaves];
            bool MergingPossibility=VectorKLDMergeLeaves[i]->Parent->GetChild(Child1)->GetPriors()==VectorKLDMergeLeaves[i]->Parent->GetChild(Child2)->GetPriors();
            if (MergingPossibility) {
                //                cout<<"Possible merging"<<endl;
                if (!MergeCheckTest&& KLDTotTry<MergeMin->KLDTot) {
                    MergeMin->Parent=VectorKLDMergeLeaves[i]->Parent;
                    MergeMin->Child1=Child1;
                    MergeMin->Child2=Child2;
                    MergeMin->KLDTot=KLDTotTry;
//                    for (int m=0; m<numbmodal; m++) {
//                        MergeMin->KLD[m]=KLDTry[m];
//                    }
                }
            }

            // clear space needed by ith element of VectorKLDMergeLeaves once it has been looked at
            delete VectorKLDMergeLeaves[i];
            VectorKLDMergeLeaves[i]=NULL;
        }
        // if MergeMin not modified <=> no possible merging return NULL
        if (MergeMin->Child1==-1) {
            delete MergeMin;
            return NULL;
        }
        else{
            return MergeMin;
        }
    }
}



// Returns the vector of indices of the children ordered according to increasing KLDTot and availability of leaves to merge
vector<int> TreeEM::OrderingMergingChildren(){
    int numbchild=this->GetNumberChildren();
    vector<GenKLD*> MergeOrder;
    vector<int> OrderMerge;
    for(int c=0;c<numbchild;c++){
        if(this->GetChild(c)->GetNumberAllLeaves()>0){
            MergeOrder.push_back(this->GetChild(c)->GetGenKLD());
            OrderMerge.push_back(c);
        }
    }
    bool flag_swap=1;
    int Csize=MergeOrder.size();
    while(flag_swap==1){
        flag_swap=0;
        for(int c=0;c<Csize-1;c++){
            if(MergeOrder[c]->KLDTot>MergeOrder[c+1]->KLDTot){
                GenKLD * tmp1=MergeOrder[c]->CopyGenKLD();
                GenKLD * tmp2=MergeOrder[c+1]->CopyGenKLD();
                int tmpInd=OrderMerge[c];
                delete MergeOrder[c];
                delete MergeOrder[c+1];
                MergeOrder[c]=tmp2;
                OrderMerge[c]=OrderMerge[c+1];
                MergeOrder[c+1]=tmp1;
                OrderMerge[c+1]=tmpInd;
                flag_swap=1;
            }
        }
    }
    for(int i=0;i<Csize;i++){
        delete MergeOrder[i];
        MergeOrder[i]=NULL;
    }
return OrderMerge;
}

vector<MergeKLD *> TreeEM::OrderingMergingLeaves(){
    int numbleaves=this->GetNumberAllLeaves();
    vector<MergeKLD*> MergeToOrder;
    if(numbleaves>0){
    MergeToOrder=this->GetVectorKLDMergeLeaves();
    int MergeSize=MergeToOrder.size();
    bool flag_swap=1;
    while(flag_swap==1){
        flag_swap=0;
        for(int c=0;c<MergeSize-1;c++){
            if(MergeToOrder[c]->KLDTot>MergeToOrder[c+1]->KLDTot){
                MergeKLD * tmp1=MergeToOrder[c]->CopyMergeKLD();
                MergeKLD * tmp2=MergeToOrder[c+1]->CopyMergeKLD();
                delete MergeToOrder[c];
                MergeToOrder[c]=NULL;
                delete MergeToOrder[c+1];
                MergeToOrder[c+1]=NULL;
                MergeToOrder[c]=tmp2;
                MergeToOrder[c+1]=tmp1;
                flag_swap=1;
            }
        }
    }
    }
    return MergeToOrder;
}

vector<MergeKLD_b *> TreeEM::OrderingMergingLeaves_b(){
    int numbleaves=this->GetNumberAllLeaves();
    vector<MergeKLD_b*> MergeToOrder;
    if(numbleaves>0){
        MergeToOrder=this->GetVectorKLDMergeLeaves_b();
        int MergeSize=MergeToOrder.size();
        bool flag_swap=1;
        while(flag_swap==1){
            flag_swap=0;
            for(int c=0;c<MergeSize-1;c++){
                if(MergeToOrder[c]->KLDTot>MergeToOrder[c+1]->KLDTot){
                    MergeKLD_b * tmp1=MergeToOrder[c]->CopyMergeKLD_b();
                    MergeKLD_b * tmp2=MergeToOrder[c+1]->CopyMergeKLD_b();
                    delete MergeToOrder[c];
                    MergeToOrder[c]=NULL;
                    delete MergeToOrder[c+1];
                    MergeToOrder[c+1]=NULL;
                    MergeToOrder[c]=tmp2;
                    MergeToOrder[c+1]=tmp1;
                    flag_swap=1;
                }
            }
        }
    }
    return MergeToOrder;
}

vector<MergeKLD*> TreeEM::GetMergeOrderVertical(){
    vector<int> MergeOrderedChildren=this->OrderingMergingChildren();
//    int numbchild=this->GetNumberChildren();
    vector<MergeKLD*> VerticalMergeVector;
    int numbchildmerging=MergeOrderedChildren.size();
    for(int c=0;c<numbchildmerging;c++){
        // if the considered element is a leaf, put directly into the vector

            vector<MergeKLD*> ChildMergeVector=this->GetChild(MergeOrderedChildren[c])->OrderingMergingLeaves();
            VerticalMergeVector.insert(VerticalMergeVector.end(),ChildMergeVector.begin(),ChildMergeVector.end());
            delete ChildMergeVector[c];
            ChildMergeVector[c]=NULL;
    }
    return VerticalMergeVector;
}

//vector<MergeKLD *> TreeEM::GetMergeDiagonal(){
//    vector<MergeKLD *> VectorMergeKLD=this->GetVectorKLDMergeLeaves();
//    bool flag_swap=1;
//    int Csize=VectorMergeKLD.size();
//    while(flag_swap==1){
//        flag_swap=0;
//        for(int c=0;c<Csize-1;c++){
//            if(VectorMergeKLD[c]->KLDTot>VectorMergeKLD[c+1]->KLDTot){
//                MergeKLD * tmp1=VectorMergeKLD[c]->CopyMergeKLD();
//                MergeKLD * tmp2=VectorMergeKLD[c+1]->CopyMergeKLD();
//                delete VectorMergeKLD[c];
//                VectorMergeKLD[c]=NULL;
//                delete VectorMergeKLD[c+1];
//                VectorMergeKLD[c+1]=NULL;
//                VectorMergeKLD[c]=tmp2;
//                VectorMergeKLD[c+1]=tmp1;
//                flag_swap=1;
//            }
//        }
//    }
//    return VectorMergeKLD;
//}

vector<MergeKLD *> TreeEM::GetMergeMoreVertical(int numbclasses){
//    int numbchild=this->GetNumberChildren();
//    int MaxNumbClasses=6;
    vector<MergeKLD*> ResultMergeVectorList;
    vector<int > ChildrenMergeFirstLevelOrdered=this->OrderingMergingChildren(); // Ordering the general class to split
    int numbposchild=ChildrenMergeFirstLevelOrdered.size();
    vector<MergeKLD *> * ChildrenMergeKLDVec=new vector<MergeKLD*>[numbposchild];
    if(numbclasses>numbposchild || numbclasses<=0){
        return ResultMergeVectorList;
    }
    for(int c=0;c<numbposchild;c++){
        int Child=ChildrenMergeFirstLevelOrdered[c];
        ChildrenMergeKLDVec[c]=this->GetChild(Child)->OrderingMergingLeaves();
    }
    int* ChildrenCombinations=Combination(numbposchild,numbclasses);
    int numbChildrenCombinations=NumbComb(numbclasses,numbposchild);
    for(int i=0;i<numbChildrenCombinations;i++){
        int * TabSize=new int[numbclasses];
        for(int c=0;c<numbclasses;c++){
            TabSize[c]=ChildrenMergeKLDVec[ChildrenCombinations[i*numbclasses+c]].size();
        }
        int * CombinationLeaves=this->CombinationBis(TabSize,numbclasses);
        int prodTabSize=1;
        for(int c=0;c<numbclasses;c++){
            prodTabSize*=TabSize[c];
        }
        for(int j=0;j<prodTabSize;j++){
            for(int c=0;c<numbclasses;c++){
                ResultMergeVectorList.push_back(ChildrenMergeKLDVec[ChildrenCombinations[i*numbclasses+c]][CombinationLeaves[j*numbclasses+c]]);
//                delete [] ChildrenMergeKLDVec[ChildrenCombinations[i*numbclasses+c]][CombinationLeaves[j*numbclasses+c]];
//                ChildrenMergeKLDVec[ChildrenCombinations[i*numbclasses+c]][CombinationLeaves[j*numbclasses+c]]=NULL;
            }
        }
        delete[]TabSize;
        TabSize=NULL;
        delete[]CombinationLeaves;
        CombinationLeaves=NULL;
    }
//    for(int c=0;c<numbposchild;c++){
//        ChildrenMergeKLDVec[c].clear();
//    }
//    delete [] ChildrenMergeKLDVec;
//    ChildrenMergeKLDVec=NULL;
    delete [] ChildrenCombinations;
    ChildrenCombinations=NULL;
return ResultMergeVectorList;
}

vector<MergeKLD_b *> TreeEM::GetMergeMoreVertical_b(int numbclasses){
    //    int numbchild=this->GetNumberChildren();
//    int MaxNumbClasses=6;
    vector<MergeKLD_b*> ResultMergeVectorList;
    vector<int > ChildrenMergeFirstLevelOrdered=this->OrderingMergingChildren(); // Ordering the general class to split
    int numbposchild=ChildrenMergeFirstLevelOrdered.size();
    vector<MergeKLD_b *> * ChildrenMergeKLDVec=new vector<MergeKLD_b *>[numbposchild];
    if(numbclasses>numbposchild || numbclasses<=0){
        return ResultMergeVectorList;
    }
    for(int c=0;c<numbposchild;c++){
        int Child=ChildrenMergeFirstLevelOrdered[c];
        ChildrenMergeKLDVec[c]=this->GetChild(Child)->OrderingMergingLeaves_b();
    }
    int* ChildrenCombinations=Combination(numbposchild,numbclasses);
    int numbChildrenCombinations=NumbComb(numbclasses,numbposchild);
    for(int i=0;i<numbChildrenCombinations;i++){
        int * TabSize=new int[numbclasses];
        for(int c=0;c<numbclasses;c++){
            TabSize[c]=ChildrenMergeKLDVec[ChildrenCombinations[i*numbclasses+c]].size();
        }
        int * CombinationLeaves=this->CombinationBis(TabSize,numbclasses);
        int prodTabSize=1;
        for(int c=0;c<numbclasses;c++){
            prodTabSize*=TabSize[c];
        }
        for(int j=0;j<prodTabSize;j++){
            for(int c=0;c<numbclasses;c++){
                ResultMergeVectorList.push_back(ChildrenMergeKLDVec[ChildrenCombinations[i*numbclasses+c]][CombinationLeaves[j*numbclasses+c]]);
                //                delete [] ChildrenMergeKLDVec[ChildrenCombinations[i*numbclasses+c]][CombinationLeaves[j*numbclasses+c]];
                //                ChildrenMergeKLDVec[ChildrenCombinations[i*numbclasses+c]][CombinationLeaves[j*numbclasses+c]]=NULL;
            }
        }
        delete[]TabSize;
        TabSize=NULL;
        delete[]CombinationLeaves;
        CombinationLeaves=NULL;
    }
    //    for(int c=0;c<numbposchild;c++){
    //        ChildrenMergeKLDVec[c].clear();
    //    }
    //    delete [] ChildrenMergeKLDVec;
    //    ChildrenMergeKLDVec=NULL;
    delete [] ChildrenCombinations;
    ChildrenCombinations=NULL;
    return ResultMergeVectorList;
}

void TreeEM::MergeOperation(int Child1, int Child2,SEG_PARAMETERS* segment_param){
    int numbchild=this->GetNumberChildren();
    if (Child1>=numbchild||Child1<0||Child2<0||Child2>=numbchild) {
        cout<<"Index children out of bound, no merging possible"<<endl;
        return;
    }
    if ((this->GetChild(Child1))->GetNumberChildren()!=0|| (this->GetChild(Child2))->GetNumberChildren()!=0) {
        cout << "Nothing other than leaf can be merged"<<endl;
        return;
    }
    if (Child1==Child2) {
        cout<<"Impossible to merge the same child"<<endl;
        return;
    }
    if (Child1>Child2) {// Reorder Child index in order to properly erase them afterwards
        int tmp=Child1;
        Child1=Child2;
        Child2=tmp;
    }
    this->CreateAndAddChildPriors(segment_param,this->GetChild(Child1)->GetPriorsDirect(),1);
    int newnumbchild=this->GetNumberChildren();
    this->GetChild(newnumbchild-1)->NormWeight=(this->GetChild(Child1))->GetNormWeight()+(this->GetChild(Child2))->GetNormWeight();
//    float NewNormWeight=this->GetChild(newnumbchild-1)->GetNormWeight();
    Parameters * ParametersMerge=this->ParametersForMerging(Child1,Child2);
    // taking care of priors on covariance
    if (segment_param->flag_CovPriors) {
        if (segment_param->CovPriorsMerge==0) { // case where we do not enforce the covariance
            ParametersMerge->PriorsCovFlag=0;
            if (ParametersMerge->PriorsCov!=NULL) {
                delete [] ParametersMerge->PriorsCov;
                ParametersMerge->PriorsCov=NULL;
            }
        }
        else{ // Covariance prior is defined for the new child
            ParametersMerge->PriorsCovFlag=1;
            int numelmasked=this->GetNumberMaskedElements();
            int numbmodal=this->GetNumberModalities();
            switch (segment_param->CovPriorsType) {
                case 1: {// Using diagonal elements
                    // Determination of Nz from NormWeight and NormResp of parent
                    float * NormRespChild1=this->GetChild(Child1)->GetNormResp();
                    float * NormRespChild2=this->GetChild(Child2)->GetNormResp();
                    PrecisionTYPE sumResp=0;
                    for (int i=0; i<numelmasked; i++, NormRespChild1++,NormRespChild2++) {
                        sumResp+=*NormRespChild1;
                        sumResp+=*NormRespChild2;
                    }
                    if (ParametersMerge->PriorsCov!=NULL) {
                        delete [] ParametersMerge->PriorsCov;
                        ParametersMerge->PriorsCov=NULL;
                    }
                    ParametersMerge->PriorsCov=new float[numbmodal*numbmodal];
                    for (int m1=0; m1<numbmodal; m1++) {
                        for (int m2=0;m2<numbmodal; m2++) {
                            if (m1==m2) {
                                ParametersMerge->PriorsCov[m1+m2*numbmodal]=sumResp*ParametersMerge->ValueParameters[numbmodal+m1+m2*numbmodal];
                            }
                            else{
                                ParametersMerge->PriorsCov[m1+m2*numbmodal]=0;
                            }
                            
                        }
                    }
                }
                    break;
//                case 2:{ // case when using a global covariance priors
//                    
//                    float * PrePriorsCov=this->GetPriorsCovMatrixGeneral(segment_param);
//                    float * NormRespChild1=this->GetChild(Child1)->GetNormResp();
//                    float * NormRespChild2=this->GetChild(Child2)->GetNormResp();
//                    PrecisionTYPE sumResp=0;
//                    for (int i=0; i<numelmasked; i++,NormRespChild1++,NormRespChild2++) {
//                        sumResp+=*NormRespChild1;
//                        sumResp+=*NormRespChild2;
//                    }
//                    if (ParametersMerge->PriorsCov!=NULL) {
//                        delete [] ParametersMerge->PriorsCov;
//                        ParametersMerge->PriorsCov=NULL;
//                    }
//                    ParametersMerge->PriorsCov=new float[numbmodal*numbmodal];
//                    for (int m1=0; m1<numbmodal; m1++) {
//                        for (int m2=0;m2<numbmodal; m2++) {
//                                ParametersMerge->PriorsCov[m1+m2*numbmodal]=sumResp*PrePriorsCov[m1+m2*numbmodal];
//                            
//                        }
//                    }
//                    
//                }
//                    break;
                default:
                    break;
            }
            
        }
    }
    this->GetChild(newnumbchild-1)->SetParameters(ParametersMerge);
    //    delete[] ParametersMerge->ValueParameters;
    //    ParametersMerge->ValueParameters=NULL;
    delete ParametersMerge;
    ParametersMerge=NULL;
    delete this->GetChild(Child1);
    //this->GetChild(Child1)=NULL;
    delete this->GetChild(Child2);
    //this->GetChild(Child2)=NULL;
    //cout<<this->GetChildren().begin()+Child1<<" is the place to look at in the vector"<<endl;
    (this->Children).erase(this->Children.begin()+Child1);
    this->Children.erase(this->Children.begin()+Child2-1);
    newnumbchild=this->GetNumberChildren();
    if (newnumbchild==1) {
        this->CollapseOnlyChild();
    }

}

Parameters * TreeEM::ParametersForMerging(int Child1, int Child2){
    int numbchild=this->GetNumberChildren();
    int numbmodal=this->GetNumberModalities();
    if (Child1>=numbchild||Child1<0||Child2<0||Child2>=numbchild) {
        cout<<"Index children out of bound, no merging possible"<<endl;
        return NULL;
    }
    if ((this->GetChild(Child1))->GetNumberChildren()!=0|| (this->GetChild(Child2))->GetNumberChildren()!=0) {
        cout << "Nothing other than leaf can be merged"<<endl;
        return NULL;
    }
    if (Child1==Child2) {
        cout<<"Impossible to merge the same child"<<endl;
        return NULL;
    }
    if(this->GetChild(Child1)->GetDistributionType()!=this->GetChild(Child2)->GetDistributionType()){
        cout<< "Impossible to merge leaves of different distribution type"<<endl;
        return NULL;
    }
    Parameters * ParametersMerge=new Parameters;
    ParametersMerge->DistributionType=(this->GetChild(Child1))->GetDistributionType();
    ParametersMerge->SizeParameters=(this->GetChild(Child1))->GetSizeParameters();
    ParametersMerge->ValueParameters=new float[ParametersMerge->SizeParameters];//{0};
    for(int i=0;i<ParametersMerge->SizeParameters;i++){
        ParametersMerge->ValueParameters[i]=0;
    }
    // As checked before it is a leaf, necessary of simple distribution type so there is no problem with SizeParameters that is necessarily strictly positive
    switch (ParametersMerge->DistributionType) {


    default: // Gaussian case as default
        float * Mean1_PTR=(this->GetChild(Child1))->GetMean();
        float * Mean2_PTR=(this->GetChild(Child2))->GetMean();
        float * Variance1_PTR=(this->GetChild(Child1))->GetVariance();
        float * Variance2_PTR=(this->GetChild(Child2))->GetVariance();
        float Weight1=this->GetChild(Child1)->GetNormWeight();
        float Weight2=this->GetChild(Child2)->GetNormWeight();
        // Mean for ParametersMerge
        for (int m=0; m<numbmodal; m++) {
            ParametersMerge->ValueParameters[m]=(Weight1*Mean1_PTR[m]+Weight2*Mean2_PTR[m])/(Weight1+Weight2);
        }
        // Variance for ParametersMerge
        for (int m1=0; m1<numbmodal; m1++) {
            for (int m2=0; m2<numbmodal; m2++) {
                ParametersMerge->ValueParameters[numbmodal+m1+m2*numbmodal]=(Weight1*(Variance1_PTR[m1+m2*numbmodal]+(Mean1_PTR[m1]-ParametersMerge->ValueParameters[m1])*(Mean1_PTR[m2]-ParametersMerge->ValueParameters[m2]))+Weight2*(Variance2_PTR[m1+m2*numbmodal]+(Mean2_PTR[m1]-ParametersMerge->ValueParameters[m1])*(Mean2_PTR[m2]-ParametersMerge->ValueParameters[m2])))/(Weight1+Weight2);
            }
        }
        break;
    }
    return ParametersMerge;
}

// When testing a S operation returns the best of the two models obtained.
TreeEM* TreeEM::RunMergeOperation(MergeKLD * MergeTry, bool & AcceptanceDecision,SEG_PARAMETERS * segment_param){
    //    MergeKLD * MergeTry=this->GetToMerge();
    if (MergeTry==NULL) {
        cout<<"No merging to try"<<endl;
        return this;
    }
    else if(MergeTry!=NULL){
        int numbmodal=this->GetNumberModalities();
        float * MeanChild1=MergeTry->Parent->GetChild(MergeTry->Child1)->GetMeanDirect();
        float * VarianceChild1=MergeTry->Parent->GetChild(MergeTry->Child1)->GetVarianceDirect(MeanChild1);
        float * MeanChild2=MergeTry->Parent->GetChild(MergeTry->Child2)->GetMeanDirect();
        float * VarianceChild2=MergeTry->Parent->GetChild(MergeTry->Child2)->GetVarianceDirect(MeanChild2);
        float * InvertedVarianceChild1=this->InvertMatrix(VarianceChild1, numbmodal);
        float * InvertedVarianceChild2=this->InvertMatrix(VarianceChild2, numbmodal);
        float MahalDistChild1=this->GetMahalDist(MeanChild1,MeanChild2,InvertedVarianceChild1,numbmodal);
        float MahalDistChild2=this->GetMahalDist(MeanChild2,MeanChild1,InvertedVarianceChild2,numbmodal);
        delete [] MeanChild1;
        delete [] MeanChild2;
        delete [] VarianceChild2;
        delete [] VarianceChild1;
        delete [] InvertedVarianceChild1;
        delete [] InvertedVarianceChild2;
        MeanChild2=NULL;
        MeanChild1=NULL;
        InvertedVarianceChild2=NULL;
        InvertedVarianceChild1=NULL;
        VarianceChild1=NULL;
        VarianceChild2=NULL;
        if(MahalDistChild1>2 || MahalDistChild2>2){
            cout<<"Not trying to merge too far away classes..."<<endl;
            return this;
        }

    }
    
    // Updating of the checking
    cout<< "Trying merging"<<endl;
    int numbDirectLeaves=(MergeTry->Parent)->GetNumberDirectLeaves();
    (MergeTry->Parent)->GetMergeCheck()[MergeTry->Child1+numbDirectLeaves*MergeTry->Child2]=1;
    (MergeTry->Parent)->GetMergeCheck()[MergeTry->Child2+numbDirectLeaves*MergeTry->Child1]=1;
    // Copy of the current tree
    TreeEM * CopiedTree=this->CopyTree(NULL);
    (MergeTry->Parent)->MergeOperation(MergeTry->Child1,MergeTry->Child2,segment_param);
    this->CollapseOnlyChildTot();
    this->ClearSMChecks();

    // Clear memory for MergeTry
    //    delete [] MergeTry->KLD;
    //    MergeTry->KLD=NULL;


    // Partial EM first
    //    float PartCLL=0;
    //    float PartOldCLL=0;
    //    int PartIteration=0;
    //(MergeTry->Parent)->RunFullEM(PartCLL, PartOldCLL, PartIteration);
    // Run EM
    //    this->UpdateDistribution();
    //    this->UpdateNonNormResp();
    this->UpdateNonNormResp(segment_param);
    this->UpdateNormResp();
    this->UpdateNormRespRoot();
    if(segment_param->flag_MRF){
        this->ClearMRFModel();
        float * GMatrixToSet;
        if(segment_param->flag_GMatrixIn){
            GMatrixToSet=this->CreateGMatrixFromInfo(segment_param->flag_optMRFOut, segment_param->filename_GMatrix);
//            GMatrixToSet=this->PrepareGMatrixFromFile(segment_param->filename_GMatrix,segment_param->flag_optMRFOut);
            if(GMatrixToSet==NULL){
                cout<< "Pb in the preparation of GMatrix"<<endl;
                segment_param->flag_GMatrix=0;
            }
        }
        else{
            GMatrixToSet=this->MRFOptSolveLS(segment_param);
        }
        this->SetGMatrix(GMatrixToSet);
        if(GMatrixToSet!=NULL){
            delete [] GMatrixToSet;
            GMatrixToSet=NULL;
        }
        this->UpdateMRF(segment_param);
    }
//    this->SaveAllClasses("/Users/Carole/Documents/PhD/TestMergeResult");
//    this->UpdateNonNormWeights();
//    this->UpdateNormWeights();
    //    CopiedTree->UpdateNormResp();
    //    CopiedTree->UpdateNonNormWeights();
    //    CopiedTree->UpdateNormWeights();
    float CompleteLogLikelihood=0;
    float OldCompleteLogLikelihood=0;
    int Iteration=0;
    if(this->GetFlagCovPriors()>0){
        this->ModifyCovPriors(segment_param);
    }
    if(segment_param->flag_CEM){
        this->RunFullCEM(CompleteLogLikelihood, OldCompleteLogLikelihood,Iteration,segment_param);
    }
    else{
    this->RunFullEM(CompleteLogLikelihood, OldCompleteLogLikelihood,Iteration,segment_param);
    }
//    this->SaveAllClasses("/Users/Carole/Documents/PhD/TestMergeResult");
    // Test of the operation
    float OldCriterion=0;
    float NewCriterion=0;
    if(this->GetDPChildrenDirect()!=NULL){
        if(segment_param->flag_Countmod){
            OldCriterion=CopiedTree->CriterionCalculationMergeDP();
            NewCriterion=this->CriterionCalculationMergeDP();
        }
        else{
            if(!segment_param->flag_DistClassInd){
                OldCriterion=CopiedTree->CriterionCalculationDPInd();
                NewCriterion=this->CriterionCalculationDPInd();
            }
            else{
                OldCriterion=CopiedTree->CriterionCalculationDPNonInd(MergeTry->Parent->FindGeneralClass());
                NewCriterion=this->CriterionCalculationDPNonInd(MergeTry->Parent->FindGeneralClass());
            }

        }
    }
    else{
     OldCriterion=CopiedTree->CriterionCalculation();
     NewCriterion=this->CriterionCalculation();
    }
    delete MergeTry;
    MergeTry=NULL;
    cout<< "The new criterion is "<<NewCriterion<<" and the old criterion is "<<OldCriterion<<endl;
    if (OldCriterion>=NewCriterion) { // Criterion of change not met, delete the modified tree and return the copied one
        delete this;
        AcceptanceDecision=0;
        cout<<"No merging accepted"<<endl;
        return CopiedTree;
    }
    else{ // Criterion of change met delete the not modified tree stored in CopiedTree and return the new model.
        delete CopiedTree;
        AcceptanceDecision=1;
        cout<<"Merging accepted"<<endl;
        this->CollapseOnlyChildTot();
        this->ClearSMChecks();
        return this;
    }
}


// When testing a M operation returns the best of the two models obtained.
TreeEM* TreeEM::RunMergeOperation(vector<MergeKLD *> MergeTry, bool & AcceptanceDecision,SEG_PARAMETERS * segment_param){
    //    MergeKLD * MergeTry=this->GetToMerge();
    int Msize=MergeTry.size();
    if (Msize==0) {
        cout<<"No merging to try"<<endl;
        return this;
    }
    else if(MergeTry.size()>0){
        int numbmodal=this->GetNumberModalities();
        float * MeanChild1=MergeTry[0]->Parent->GetChild(MergeTry[0]->Child1)->GetMeanDirect();
        float * VarianceChild1=MergeTry[0]->Parent->GetChild(MergeTry[0]->Child1)->GetVarianceDirect(MeanChild1);
        float * MeanChild2=MergeTry[0]->Parent->GetChild(MergeTry[0]->Child2)->GetMeanDirect();
        float * VarianceChild2=MergeTry[0]->Parent->GetChild(MergeTry[0]->Child2)->GetVarianceDirect(MeanChild2);
        float * InvertedVarianceChild1=this->InvertMatrix(VarianceChild1, numbmodal);
        float * InvertedVarianceChild2=this->InvertMatrix(VarianceChild2, numbmodal);
        float MahalDistChild1=this->GetMahalDist(MeanChild1,MeanChild2,InvertedVarianceChild1,numbmodal);
        float MahalDistChild2=this->GetMahalDist(MeanChild2,MeanChild1,InvertedVarianceChild2,numbmodal);
        delete [] MeanChild1;
        delete [] MeanChild2;
        delete [] VarianceChild2;
        delete [] VarianceChild1;
        delete [] InvertedVarianceChild1;
        delete [] InvertedVarianceChild2;
        MeanChild2=NULL;
        MeanChild1=NULL;
        InvertedVarianceChild2=NULL;
        InvertedVarianceChild1=NULL;
        VarianceChild1=NULL;
        VarianceChild2=NULL;
        if(MahalDistChild1>2 || MahalDistChild2>2){
            cout<<"Not trying to merge too far away classes..."<<endl;
            return this;
        }
        
    }

    int IndGenClassMerge=-1;
    TreeEM * GeneralClassToMerge=MergeTry[0]->Parent->FindMainNode();
    if(GeneralClassToMerge->GetParent()!=NULL){
        IndGenClassMerge=GeneralClassToMerge->GetParent()->FindIndex(GeneralClassToMerge);
    }
    cout<< "Trying merge operation on node "<<IndGenClassMerge<<endl;
    // Updating of the checking
//    cout<< "Trying merging on node "<<MergeTry[0]->Parent->FindMainNode()<<endl;

//    int numbDirectLeaves=(MergeTry->Parent)->GetNumberDirectLeaves();
//    (MergeTry->Parent)->GetMergeCheck()[MergeTry->Child1+numbDirectLeaves*MergeTry->Child2]=1;
//    (MergeTry->Parent)->GetMergeCheck()[MergeTry->Child2+numbDirectLeaves*MergeTry->Child1]=1;
    // Copy of the current tree
    TreeEM * CopiedTree=this->CopyTree(NULL);
    for(int c=0;c<Msize;c++){
        (MergeTry[c]->Parent)->MergeOperation(MergeTry[c]->Child1,MergeTry[c]->Child2,segment_param);
        this->CollapseOnlyChildTot();
    }
    this->ClearSMChecks();

    // Clear memory for MergeTry
    //    delete [] MergeTry->KLD;
    //    MergeTry->KLD=NULL;


    // Partial EM first
    //    float PartCLL=0;
    //    float PartOldCLL=0;
    //    int PartIteration=0;
    //(MergeTry->Parent)->RunFullEM(PartCLL, PartOldCLL, PartIteration);
    // Run EM
    //    this->UpdateDistribution();
    //    this->UpdateNonNormResp();
    this->UpdateNonNormResp(segment_param);
    this->UpdateNormResp();
    this->UpdateNormRespRoot();
    if(segment_param->flag_MRF){
        this->ClearMRFModel();
        float * GMatrixToSet;
        if(segment_param->flag_GMatrixIn){
            GMatrixToSet=this->CreateGMatrixFromInfo(segment_param->flag_optMRFOut, segment_param->filename_GMatrix);
//            GMatrixToSet=this->PrepareGMatrixFromFile(segment_param->filename_GMatrix,segment_param->flag_optMRFOut);
            if(GMatrixToSet==NULL){
                cout<< "Pb in the preparation of GMatrix"<<endl;
                segment_param->flag_GMatrix=0;
            }
        }
        else{
            GMatrixToSet=this->MRFOptSolveLS(segment_param);
        }
        this->SetGMatrix(GMatrixToSet);
        if(GMatrixToSet!=NULL){
            delete [] GMatrixToSet;
            GMatrixToSet=NULL;
        }
        this->UpdateMRF(segment_param);
    }
//    this->SaveAllClasses("/Users/Carole/Documents/PhD/TestMergeResult");
//    this->UpdateNonNormWeights();
//    this->UpdateNormWeights();
    //    CopiedTree->UpdateNormResp();
    //    CopiedTree->UpdateNonNormWeights();
    //    CopiedTree->UpdateNormWeights();
    float CompleteLogLikelihood=0;
    float OldCompleteLogLikelihood=0;
    int Iteration=0;
    if(segment_param->flag_CEM){
        this->RunFullCEM(CompleteLogLikelihood, OldCompleteLogLikelihood,Iteration,segment_param);
    }
    else{
    this->RunFullEM(CompleteLogLikelihood, OldCompleteLogLikelihood,Iteration,segment_param);
    }
//    this->SaveAllClasses("/Users/Carole/Documents/PhD/TestMergeResult");
    // Test of the operation
//    float OldCriterion=0;
//    float NewCriterion=0;
//    if(this->GetDPChildrenDirect()!=NULL){
//        if(segment_param->flag_Countmod){
//            OldCriterion=CopiedTree->CriterionCalculationMergeDP();
//            NewCriterion=this->CriterionCalculationMergeDP();
//        }
//        else{
//            if(segment_param->flag_DistClassInd){
//                OldCriterion=CopiedTree->CriterionCalculationDPInd();
//                NewCriterion=this->CriterionCalculationDPInd();
//            }
////            else{
////                OldCriterion=CopiedTree->CriterionCalculationDPNonInd(MergeTry->Parent->FindGeneralClass());
////                NewCriterion=this->CriterionCalculationDPNonInd(MergeTry->Parent->FindGeneralClass());
////            }
//
//        }
//    }
//    else{
//     OldCriterion=CopiedTree->CriterionCalculation();
//     NewCriterion=this->CriterionCalculation();
//    }
////    delete MergeTry;
////    MergeTry=NULL;
//    cout<< "The new criterion is "<<NewCriterion<<" and the old criterion is "<<OldCriterion<<endl;
    OperationType Operation=MERGE; // OperationType corresponding to split
    AcceptanceDecision=this->IsNewModelAccepted(CopiedTree,Operation,segment_param);
    
    
    if (!AcceptanceDecision) { // Criterion of change not met, delete the modified tree and return the copied one
        delete this;
        AcceptanceDecision=0;
        cout<<"No merging accepted"<<endl;
        bool checkUnifPos=CopiedTree->CheckUnifDistPosition(segment_param);
        if (!checkUnifPos) {
            cout<<"Pb with position of the unif dist position"<<endl;
        }
        return CopiedTree;
    }
    else{ // Criterion of change met delete the not modified tree stored in CopiedTree and return the new model.
        delete CopiedTree;
        AcceptanceDecision=1;
        cout<<"Merging accepted"<<endl;
        this->CollapseOnlyChildTot();
        bool checkUnifPos=this->CheckUnifDistPosition(segment_param);
        if (!checkUnifPos) {
            cout<<"Pb with position of the unif dist position"<<endl;
            this->ReplaceUnifDist(segment_param);
        }
        this->ClearSMChecks();
        return this;
    }
}


// When testing a M operation returns the best of the two models obtained.
TreeEM* TreeEM::RunMergeOperation(vector<MergeKLD_b *> MergeTry, bool & AcceptanceDecision,SEG_PARAMETERS * segment_param){
    //    MergeKLD * MergeTry=this->GetToMerge();
    int Msize=MergeTry.size();
    TreeEM * CopiedTree=this->CopyTree(NULL);
    if (Msize==0) {
        cout<<"No merging to try"<<endl;
        return CopiedTree;
    }
    else if(Msize>0){
        TreeEM * ParentMerg=CopiedTree->FindFromHierarchy(MergeTry[0]->HierarchyParent);
        int numbmodal=this->GetNumberModalities();
        float * MeanChild1=ParentMerg->GetChild(MergeTry[0]->Child1)->GetMeanDirect();
        float * VarianceChild1=ParentMerg->GetChild(MergeTry[0]->Child1)->GetVarianceDirect(MeanChild1);
        float * MeanChild2=ParentMerg->GetChild(MergeTry[0]->Child2)->GetMeanDirect();
        float * VarianceChild2=ParentMerg->GetChild(MergeTry[0]->Child2)->GetVarianceDirect(MeanChild2);
        float * InvertedVarianceChild1=this->InvertMatrix(VarianceChild1, numbmodal);
        float * InvertedVarianceChild2=this->InvertMatrix(VarianceChild2, numbmodal);
        float MahalDistChild1=this->GetMahalDist(MeanChild1,MeanChild2,InvertedVarianceChild1,numbmodal);
        float MahalDistChild2=this->GetMahalDist(MeanChild2,MeanChild1,InvertedVarianceChild2,numbmodal);
        delete [] MeanChild1;
        delete [] MeanChild2;
        delete [] VarianceChild2;
        delete [] VarianceChild1;
        delete [] InvertedVarianceChild1;
        delete [] InvertedVarianceChild2;
        MeanChild2=NULL;
        MeanChild1=NULL;
        InvertedVarianceChild2=NULL;
        InvertedVarianceChild1=NULL;
        VarianceChild1=NULL;
        VarianceChild2=NULL;
        if(MahalDistChild1>2 || MahalDistChild2>2){
            cout<<"Not trying to merge too far away classes..."<<endl;
            AcceptanceDecision=0;
            return CopiedTree;
        }
        
    }

    int IndGenClassMerge=-1;
    TreeEM * GeneralClassToMerge=CopiedTree->FindFromHierarchy(MergeTry[0]->HierarchyParent)->FindMainNode();
    if(GeneralClassToMerge->GetParent()!=NULL){
        IndGenClassMerge=GeneralClassToMerge->GetParent()->FindIndex(GeneralClassToMerge);
    }
    cout<< "Trying merge operation on node "<<IndGenClassMerge<<endl;
    cout<< "Trying merging between";
    int sizeHierarch=MergeTry[0]->HierarchyParent.size();
    for (int l=0; l<sizeHierarch; l++) {
        cout<<" "<<MergeTry[0]->HierarchyParent[l];
    }
    cout<<" "<<MergeTry[0]->Child1<<" and ";
    for (int l=0; l<sizeHierarch; l++) {
        cout<<" "<<MergeTry[0]->HierarchyParent[l];
    }
    cout<<" "<<MergeTry[0]->Child2<<endl;
    // Updating of the checking
    //    cout<< "Trying merging on node "<<MergeTry[0]->Parent->FindMainNode()<<endl;
    
    //    int numbDirectLeaves=(MergeTry->Parent)->GetNumberDirectLeaves();
    //    (MergeTry->Parent)->GetMergeCheck()[MergeTry->Child1+numbDirectLeaves*MergeTry->Child2]=1;
    //    (MergeTry->Parent)->GetMergeCheck()[MergeTry->Child2+numbDirectLeaves*MergeTry->Child1]=1;
    // Copy of the current tree
    TreeEM * CopiedTree2=this->CopyTree(NULL);
    for(int c=0;c<Msize;c++){
        TreeEM * ParentMerging=CopiedTree2->FindFromHierarchy(MergeTry[c]->HierarchyParent);
        ParentMerging->MergeOperation(MergeTry[c]->Child1,MergeTry[c]->Child2,segment_param);
        CopiedTree2->CollapseOnlyChildTot();
    }
    CopiedTree2->ClearSMChecks();
    

    CopiedTree2->UpdateNonNormResp(segment_param);
    CopiedTree2->UpdateNormResp();
    CopiedTree2->UpdateNormRespRoot();
    if(segment_param->flag_MRF){
        CopiedTree2->ClearMRFModel();
        float * GMatrixToSet;
        if(segment_param->flag_GMatrixIn){
//            GMatrixToSet=CopiedTree2->PrepareGMatrixFromFile(segment_param->filename_GMatrix,segment_param->flag_optMRFOut);
            GMatrixToSet=CopiedTree2->CreateGMatrixFromInfo(segment_param->flag_optMRFOut, segment_param->filename_GMatrix);
            if(GMatrixToSet==NULL){
                cout<< "Pb in the preparation of GMatrix"<<endl;
                segment_param->flag_GMatrix=0;
            }
        }
        else{
            GMatrixToSet=CopiedTree2->MRFOptSolveLS(segment_param);
        }
        CopiedTree2->SetGMatrix(GMatrixToSet);
        if(GMatrixToSet!=NULL){
            delete [] GMatrixToSet;
            GMatrixToSet=NULL;
        }
        CopiedTree2->UpdateMRF(segment_param);
    }

    float CompleteLogLikelihood=0;
    float OldCompleteLogLikelihood=0;
    int Iteration=0;
    if(segment_param->flag_CEM){
        CopiedTree2->RunFullCEM(CompleteLogLikelihood, OldCompleteLogLikelihood,Iteration,segment_param);
    }
    else{
        if (CopiedTree2->GetFlagCovPriors()>0) {
            CopiedTree2->ModifyCovPriors(segment_param);
        }
        CopiedTree2->RunFullEM(CompleteLogLikelihood, OldCompleteLogLikelihood,Iteration,segment_param);
    }

    OperationType Operation=MERGE; // OperationType corresponding to split
    AcceptanceDecision=CopiedTree2->IsNewModelAccepted(CopiedTree,Operation,segment_param);
    
    
    if (!AcceptanceDecision) { // Criterion of change not met, delete the modified tree and return the copied one
        delete CopiedTree2;
        AcceptanceDecision=0;
        cout<<"No merging accepted"<<endl;
        bool checkUnifPos=CopiedTree->CheckUnifDistPosition(segment_param);
        if (!checkUnifPos) {
            cout<<"Pb with position of the unif dist position"<<endl;
        }
        return CopiedTree;
    }
    else{ // Criterion of change met delete the not modified tree stored in CopiedTree and return the new model.
        delete CopiedTree;
        AcceptanceDecision=1;
        cout<<"Merging accepted"<<endl;
        CopiedTree2->CollapseOnlyChildTot();
        bool checkUnifPos=CopiedTree2->CheckUnifDistPosition(segment_param);
        if (!checkUnifPos) {
            cout<<"Pb with position of the unif dist position"<<endl;
            CopiedTree2->ReplaceUnifDist(segment_param);
        }
        if (segment_param->flag_DeleteUnderWeight) {
            CopiedTree2->DeleteUnderWeight(segment_param); // delete the classes then update the tree
        }
        CopiedTree2->CollapseOnlyChildTot();
        CopiedTree2->ClearSMChecks();
        return CopiedTree2;
    }
}

float * TreeEM::GetKLDModel(){

    int numbmodal=this->GetNumberModalities();
    int numbbinsGet=this->GetNumbbins();
    int binspowmodal=(int)pow_int(numbbinsGet,numbmodal);
    
    // Calculating KLDTot and deleting the corresponding float arrays needed after use
    float * DistHistTotal=this->GetDistHistogramTotal();
    float * DistHistTotal_PTR=DistHistTotal;
    float * DataHistTotal=this->GetDataHistogramTotal();
    float * DataHistTotal_PTR=DataHistTotal;
    float SumDist=0;
    float SumData=0;
    float * KLDFin=new float[1+numbmodal];
    for (int m=0; m<=numbmodal; m++) {
        KLDFin[m]=0;
    }
    
    PrecisionTYPE tmpKLDTot=0;
    int CountNanSplit=0;
    
    for (int i=0; i<binspowmodal; i++,DistHistTotal_PTR++,DataHistTotal_PTR++) {
        SumDist+=*DistHistTotal_PTR;
        SumData+=*DataHistTotal_PTR;
        float DistValue=(*DistHistTotal_PTR)<=0.00001?0.00001:(*DistHistTotal_PTR);
        float DataValue=(*DataHistTotal_PTR)<=0.00001?0.00001:(*DataHistTotal_PTR);
        
        tmpKLDTot+=(PrecisionTYPE)0.5*(log(DataValue/DistValue)*(*DataHistTotal_PTR)+log(DistValue/DataValue)*(*DistHistTotal_PTR)); // Use of the symmetric KLD between the data and the distribution
        if (tmpKLDTot!=tmpKLDTot) {
            //            cout<<"Pb at index "<<i<<" : "<<DataValue<<" and "<<DistValue<<endl;
            CountNanSplit++;
        }
    }
    //    cout<<"Number of Nan for split KLD is "<<CountNanSplit<<endl;
    KLDFin[0]=(float)tmpKLDTot;
    //    cout<<SplitKLDResult->KLDTot<< " and SumData "<<SumData<< "and SumDist are "<<SumDist<<endl;
    
    
    
        // Calculation of KLDcomp
        vector<float *> DistHist_VEC=this->GetDistHistogram();
        vector<float *> DataHist_VEC=this->GetDataHistogram();
        DistHistTotal_PTR=DistHistTotal;
        DataHistTotal_PTR=DataHistTotal;
    
    
        for (int m=0; m<numbmodal; m++) {
            float * DistHist_PTR=DistHist_VEC[m];
            float * DataHist_PTR=DataHist_VEC[m];
            for (int i=0; i<numbbins; i++,DistHist_PTR++,DataHist_PTR++) {
                float DistValue=(*DistHist_PTR)<=0.00001?0.00001:(*DistHist_PTR);
    
                float DataValue=(*DataHist_PTR)<=0.00001?0.00001:(*DataHist_PTR);
    
                KLDFin[m+1]+=0.5*(logf(DataValue/DistValue)*(*DataHist_PTR)+logf(DistValue/DataValue)*(*DistHist_PTR)); // Use of the symmetric KLD between the two distributions
            }
            delete [] DistHist_VEC[m];
            DistHist_VEC[m]=NULL;
            delete [] DataHist_VEC[m];
            DataHist_VEC[m]=NULL;
       }
    delete [] DistHistTotal;
    DistHistTotal=NULL;
    delete [] DataHistTotal;
    DataHistTotal=NULL;
    
    return KLDFin;
}

float * TreeEM::GetSSDModel(){
    
    int numbmodal=this->GetNumberModalities();
    int numbbinsGet=this->GetNumbbins();
    int binspowmodal=(int)pow_int(numbbinsGet,numbmodal);
    
    // Calculating KLDTot and deleting the corresponding float arrays needed after use
    float * DistHistTotal=this->GetDistHistogramTotal();
    float * DistHistTotal_PTR=DistHistTotal;
    float * DataHistTotal=this->GetDataHistogramTotal();
    float * DataHistTotal_PTR=DataHistTotal;
    float SumDist=0;
    float SumData=0;
    float * SSDFin=new float[1+numbmodal];
    for (int m=0; m<=numbmodal; m++) {
        SSDFin[m]=0;
    }
    
    PrecisionTYPE tmpSSDTot=0;
    int CountNanSplit=0;
    
    for (int i=0; i<binspowmodal; i++,DistHistTotal_PTR++,DataHistTotal_PTR++) {
        SumDist+=*DistHistTotal_PTR;
        SumData+=*DataHistTotal_PTR;
        
        tmpSSDTot+=(PrecisionTYPE)pow_int(*DataHistTotal_PTR-*DistHistTotal_PTR, 2); // Use of the symmetric KLD between the data and the distribution
        if (tmpSSDTot!=tmpSSDTot) {
            //            cout<<"Pb at index "<<i<<" : "<<DataValue<<" and "<<DistValue<<endl;
            CountNanSplit++;
        }
    }
    //    cout<<"Number of Nan for split KLD is "<<CountNanSplit<<endl;
    SSDFin[0]=(float)tmpSSDTot;
    //    cout<<SplitKLDResult->KLDTot<< " and SumData "<<SumData<< "and SumDist are "<<SumDist<<endl;
    
    
    
    // Calculation of SSDcomp
    vector<float *> DistHist_VEC=this->GetDistHistogram();
    vector<float *> DataHist_VEC=this->GetDataHistogram();
    DistHistTotal_PTR=DistHistTotal;
    DataHistTotal_PTR=DataHistTotal;
    
    
    for (int m=0; m<numbmodal; m++) {
        float * DistHist_PTR=DistHist_VEC[m];
        float * DataHist_PTR=DataHist_VEC[m];
        for (int i=0; i<numbbins; i++,DistHist_PTR++,DataHist_PTR++) {
            
            SSDFin[m+1]+=pow_int(*DataHist_PTR-*DistHist_PTR, 2);
        }
        delete [] DistHist_VEC[m];
        DistHist_VEC[m]=NULL;
        delete [] DataHist_VEC[m];
        DataHist_VEC[m]=NULL;
    }
    delete [] DistHistTotal;
    DistHistTotal=NULL;
    delete [] DataHistTotal;
    DataHistTotal=NULL;
    
    return SSDFin;
}


/******** METHODS FOR SPLITTING OPERATIONS *************************/
SplitKLD * TreeEM::GetKLDSplit(int ChildInput){
    // First check if input integer is correct
    int numbchild=this->GetNumberChildren();
    if (ChildInput<0||ChildInput>=numbchild) {
        cout<<"Out of bound for child to split"<<endl;
        return NULL;
    }
    // then check if can be split <=> check if split a leaf
    if (this->GetChild(ChildInput)->GetNumberChildren()!=0) {
        cout<<"It is not a leaf so cannot be split"<<endl;
        return NULL;
    }
    SplitKLD * SplitKLDResult=new SplitKLD();
    SplitKLDResult->Parent=this;
    SplitKLDResult->ChildToSplit=ChildInput;
    SplitKLDResult->KLDTot=0;
    int numbmodal=this->GetNumberModalities();
    int numbbinsGet=this->GetNumbbins();
    int binspowmodal=(int)pow_int(numbbinsGet,numbmodal);
    SplitKLDResult->KLD=new float[MaxNumbModal];//{0};
    for(int i=0;i<MaxNumbModal;i++){
        SplitKLDResult->KLD[i]=0;
    }

    // Calculating KLDTot and deleting the corresponding float arrays needed after use
    float * DistHistTotal=(this->GetChild(ChildInput))->GetDistHistogramTotal();
    float * DistHistTotal_PTR=DistHistTotal;
    float * DataHistTotal=(this->GetChild(ChildInput))->GetDataHistogramTotal();
    float * DataHistTotal_PTR=DataHistTotal;
    float SumDist=0;
    float SumData=0;

    PrecisionTYPE tmpSplitKLDTot=0;
    int CountNanSplit=0;

    for (int i=0; i<binspowmodal; i++,DistHistTotal_PTR++,DataHistTotal_PTR++) {
        SumDist+=*DistHistTotal_PTR;
        SumData+=*DataHistTotal_PTR;
        float DistValue=(*DistHistTotal_PTR)<=0.00001?0.00001:(*DistHistTotal_PTR);
        float DataValue=(*DataHistTotal_PTR)<=0.00001?0.00001:(*DataHistTotal_PTR);

        tmpSplitKLDTot+=(PrecisionTYPE)0.5*(log(DataValue/DistValue)*(*DataHistTotal_PTR)+log(DistValue/DataValue)*(*DistHistTotal_PTR)); // Use of the symmetric KLD between the data and the distribution
        if (tmpSplitKLDTot!=tmpSplitKLDTot) {
//            cout<<"Pb at index "<<i<<" : "<<DataValue<<" and "<<DistValue<<endl;
            CountNanSplit++;
        }
    }
//    cout<<"Number of Nan for split KLD is "<<CountNanSplit<<endl;
    SplitKLDResult->KLDTot=(float)tmpSplitKLDTot;
//    cout<<SplitKLDResult->KLDTot<< " and SumData "<<SumData<< "and SumDist are "<<SumDist<<endl;



//    // Calculation of KLDcomp
//    vector<float *> DistHist_VEC=this->GetChild(ChildInput)->GetDistHistogram();
//    vector<float *> DataHist_VEC=this->GetChild(ChildInput)->GetDataHistogram();
//    DistHistTotal_PTR=DistHistTotal;
//    DataHistTotal_PTR=DataHistTotal;

//    //    float * DiffDistHist=new float[numbbins];//{0};
//    //    for(int i=0;i<numbbins;i++){
//    //        DiffDistHist[i]=0;
//    //    }
//    //    float * DiffDataHist=new float[numbbins];//{0};
//    //    for(int i=0;i<numbbins;i++){
//    //        DiffDataHist[i]=0;
//    //    }

//    //    float * DiffDistHist_PTR=DiffDistHist;
//    //    float * DiffDataHist_PTR=DiffDataHist;
//    //    float * DistHist_PTR=DistHist_VEC[0];
//    //    float * DataHist_PTR=DataHist_VEC[0];
//    //    int CountNonZeroDiffDist=0;
//    //    int CountNonZeroDiffData=0;
//    //      SumData=0;
//    //    for (int i=0; i<numbbins; i++,DistHist_PTR++,DistHistTotal_PTR++,DataHistTotal_PTR++,DataHist_PTR++,DiffDataHist_PTR++,DiffDistHist_PTR++) {

//    //        *DiffDistHist_PTR=(*DistHist_PTR)-(*DistHistTotal_PTR);
//    //        *DiffDataHist_PTR=(*DataHist_PTR)-(*DataHistTotal_PTR);
//    //        SumData+=*DistHistTotal_PTR;
//    //        if (fabsf(*DiffDistHist_PTR)>1E-6) {
//    //            CountNonZeroDiffDist++;
//    //            //cout<<*DiffDistHist_PTR<<endl;
//    //        }
//    //        if (fabsf(*DiffDataHist_PTR)>1E-6) {
//    //            CountNonZeroDiffData++;
//    //        }
//    //    }
//    //    delete [] DiffDataHist;
//    //    DiffDataHist=NULL;
//    //    delete [] DiffDistHist;
//    //    DiffDistHist=NULL;

//    for (int m=0; m<numbmodal; m++) {
//        float * DistHist_PTR=DistHist_VEC[m];
//        float * DataHist_PTR=DataHist_VEC[m];
//        for (int i=0; i<numbbins; i++,DistHist_PTR++,DataHist_PTR++) {
//            float DistValue=(*DistHist_PTR)<=0.00001?0.00001:(*DistHist_PTR);

//            float DataValue=(*DataHist_PTR)<=0.00001?0.00001:(*DataHist_PTR);

//            SplitKLDResult->KLD[m]+=0.5*(logf(DataValue/DistValue)*(*DataHist_PTR)+logf(DistValue/DataValue)*(*DistHist_PTR)); // Use of the symmetric KLD between the two distributions
//        }
//        delete [] DistHist_VEC[m];
//        DistHist_VEC[m]=NULL;
//        delete [] DataHist_VEC[m];
//        DataHist_VEC[m]=NULL;
//    }
    delete [] DistHistTotal;
    DistHistTotal=NULL;
    delete [] DataHistTotal;
    DataHistTotal=NULL;

    return SplitKLDResult;
}

SplitKLD_b * TreeEM::GetKLDSplit_b(int ChildInput){
    // First check if input integer is correct
    int numbchild=this->GetNumberChildren();
    if (ChildInput<0||ChildInput>=numbchild) {
        cout<<"Out of bound for child to split"<<endl;
        return NULL;
    }
    // then check if can be split <=> check if split a leaf
    if (this->GetChild(ChildInput)->GetNumberChildren()!=0) {
        cout<<"It is not a leaf so cannot be split"<<endl;
        return NULL;
    }
    SplitKLD_b * SplitKLDResult=new SplitKLD_b();
    SplitKLDResult->HierarchyParent=this->GetHierarchyVector();
    SplitKLDResult->ChildToSplit=ChildInput;
    SplitKLDResult->KLDTot=0;
    int numbmodal=this->GetNumberModalities();
    int numbbinsGet=this->GetNumbbins();
    int binspowmodal=(int)pow_int(numbbinsGet,numbmodal);
//    SplitKLDResult->KLD=new float[MaxNumbModal];//{0};
//    for(int i=0;i<MaxNumbModal;i++){
//        SplitKLDResult->KLD[i]=0;
//    }
    
    // Calculating KLDTot and deleting the corresponding float arrays needed after use
    float * DistHistTotal=(this->GetChild(ChildInput))->GetDistHistogramTotal();
    float * DistHistTotal_PTR=DistHistTotal;
    float * DataHistTotal=(this->GetChild(ChildInput))->GetDataHistogramTotal();
    float * DataHistTotal_PTR=DataHistTotal;
    float SumDist=0;
    float SumData=0;
    
    PrecisionTYPE tmpSplitKLDTot=0;
    int CountNanSplit=0;
    
    for (int i=0; i<binspowmodal; i++,DistHistTotal_PTR++,DataHistTotal_PTR++) {
        SumDist+=*DistHistTotal_PTR;
        SumData+=*DataHistTotal_PTR;
        float DistValue=(*DistHistTotal_PTR)<=0.00001?0.00001:(*DistHistTotal_PTR);
        float DataValue=(*DataHistTotal_PTR)<=0.00001?0.00001:(*DataHistTotal_PTR);
        
        tmpSplitKLDTot+=(PrecisionTYPE)0.5*(log(DataValue/DistValue)*(*DataHistTotal_PTR)+log(DistValue/DataValue)*(*DistHistTotal_PTR)); // Use of the symmetric KLD between the data and the distribution
        if (tmpSplitKLDTot!=tmpSplitKLDTot) {
            //            cout<<"Pb at index "<<i<<" : "<<DataValue<<" and "<<DistValue<<endl;
            CountNanSplit++;
        }
    }
    //    cout<<"Number of Nan for split KLD is "<<CountNanSplit<<endl;
    SplitKLDResult->KLDTot=(float)tmpSplitKLDTot;
    //    cout<<SplitKLDResult->KLDTot<< " and SumData "<<SumData<< "and SumDist are "<<SumDist<<endl;
    
    

    delete [] DistHistTotal;
    DistHistTotal=NULL;
    delete [] DataHistTotal;
    DataHistTotal=NULL;
    
    return SplitKLDResult;
}

// Returns the vector containing the pointers to all the SplitKLD of the children of the considered tree. Used to obtain ordered list of Splitting to try.
vector<SplitKLD *> TreeEM::GetVectorKLDSplitChildren(SEG_PARAMETERS * segment_param){
    int numbchild=this->GetNumberChildren();
    vector<SplitKLD *> KLDSplitChildren;
    for (int c=0; c<numbchild; c++) {
        SplitKLD * SplitKLDToPush=this->GetKLDSplit(c);
        if(this->GetChild(c)->GetDistributionType()==2){
            SplitKLDToPush->TypeChange=segment_param->uniformTypeChange;
        }

        KLDSplitChildren.push_back(SplitKLDToPush);
    }
    return KLDSplitChildren;
}

// Returns the vector containing the pointers to all the SplitKLD of the children of the considered tree. Used to obtain ordered list of Splitting to try.
vector<SplitKLD_b *> TreeEM::GetVectorKLDSplitChildren_b(SEG_PARAMETERS * segment_param){
    int numbchild=this->GetNumberChildren();
    vector<SplitKLD_b *> KLDSplitChildren;
    for (int c=0; c<numbchild; c++) {
        SplitKLD_b * SplitKLDToPush=this->GetKLDSplit_b(c);
        if(this->GetChild(c)->GetDistributionType()==2){
            SplitKLDToPush->TypeChange=segment_param->uniformTypeChange;
        }
        
        KLDSplitChildren.push_back(SplitKLDToPush);
    }
    return KLDSplitChildren;
}

// Returns the vector of pointers to all SplitKLD structures for the leaves of a given tree.
vector<SplitKLD *> TreeEM::GetVectorKLDSplitLeaves(SEG_PARAMETERS * segment_param){
    vector<SplitKLD *> KLDSplitLeaves;
    //cout<<KLDSplitLeaves.size()<<endl;
    int numbchild=this->GetNumberChildren();
    for (int c=0; c<numbchild; c++) {
        if (this->GetChild(c)->GetNumberChildren()==0) {
            //cout<<"Leaf for KLD calculation"<<endl;
            SplitKLD * SplitKLDToPush=this->GetKLDSplit(c);
            if(this->GetChild(c)->GetDistributionType()==2){ // case where we try to change a uniform distribution split into 1 gaussian (type change 0) or 2 gaussians (type change 2)

                SplitKLDToPush->TypeChange=segment_param->uniformTypeChange;
            }
            if(this->GetChild(c)->GetNormWeight()>10E-3){ // Possible to split only if weight is high enough
                KLDSplitLeaves.push_back(SplitKLDToPush);
            }

        }
        else{
            vector<SplitKLD*> KLDSplitLeavesChild=this->GetChild(c)->GetVectorKLDSplitLeaves(segment_param);
            int sizeKLDSplit=KLDSplitLeavesChild.size();
            for (int i=0; i<sizeKLDSplit; i++) {
                KLDSplitLeaves.push_back(KLDSplitLeavesChild[i]);
            }
        }
    }
    //cout<<"Size of KLDVector before return "<<KLDSplitLeaves.size()<<endl;
    return KLDSplitLeaves;
}

// Returns the vector of pointers to all SplitKLD structures for the leaves of a given tree.
vector<SplitKLD_b *> TreeEM::GetVectorKLDSplitLeaves_b(SEG_PARAMETERS * segment_param){
    vector<SplitKLD_b *> KLDSplitLeaves;
    //cout<<KLDSplitLeaves.size()<<endl;
    int numbchild=this->GetNumberChildren();
    for (int c=0; c<numbchild; c++) {
        if (this->GetChild(c)->GetNumberChildren()==0) {
            //cout<<"Leaf for KLD calculation"<<endl;
            SplitKLD_b * SplitKLDToPush=this->GetKLDSplit_b(c);
            if(this->GetChild(c)->GetDistributionType()==2){ // case where we try to change a uniform distribution split into 1 gaussian (type change 0) or 2 gaussians (type change 2)
                
                SplitKLDToPush->TypeChange=segment_param->uniformTypeChange;
            }
            if(this->GetChild(c)->GetNormWeight()>10E-6){ // Possible to split only if weight is high enough
                KLDSplitLeaves.push_back(SplitKLDToPush);
            }
            
        }
        else{
            vector<SplitKLD_b*> KLDSplitLeavesChild=this->GetChild(c)->GetVectorKLDSplitLeaves_b(segment_param);
            int sizeKLDSplit=KLDSplitLeavesChild.size();
            for (int i=0; i<sizeKLDSplit; i++) {
                KLDSplitLeaves.push_back(KLDSplitLeavesChild[i]);
            }
        }
    }
    //cout<<"Size of KLDVector before return "<<KLDSplitLeaves.size()<<endl;
    return KLDSplitLeaves;
}

// Returns the vector of pointers to all SplitKLD structures for the leaves of a given tree.
vector<SplitKLD_b *> TreeEM::GetVectorKLDSplitLeavesUniform_b(SEG_PARAMETERS * segment_param){
    vector<SplitKLD_b *> KLDSplitLeavesUnif;
    vector<TreeEM *> VectorUnifLeaves=this->GetUniformLeavesVector();
    int numbUnif=VectorUnifLeaves.size();
    if (numbUnif==0) {
        cout<<"no uniform Leaves to consider"<<endl;
        return KLDSplitLeavesUnif;
    }
    else {
        for (int u=0; u<numbUnif; u++) {
            vector<int> HierarchyUnif=VectorUnifLeaves[u]->GetHierarchyVector();
            TreeEM * ParentUnif=this->FindRoot()->FindFromHierarchy(HierarchyUnif)->GetParent();
            SplitKLD_b * SplitKLDToPush=ParentUnif->GetKLDSplit_b(HierarchyUnif[HierarchyUnif.size()-1]);
            SplitKLDToPush->TypeChange=segment_param->uniformTypeChange;
            KLDSplitLeavesUnif.push_back(SplitKLDToPush);
        }
    }
    return KLDSplitLeavesUnif;
}

vector<SplitKLD_b*> TreeEM::GetToSplitMore_b(vector<int> ClassesToSplit, SEG_PARAMETERS * segment_param){
    int numbchild=this->GetNumberChildren();
    int sizeVec=ClassesToSplit.size();
    vector<SplitKLD_b*> SplitKLDVec;
    if(sizeVec>numbchild){
        return SplitKLDVec;
    }
    // first check if the classes we are trying to split really do exist
    for(int i=0;i<sizeVec;i++){
        if (ClassesToSplit[i]>=numbchild){
            return SplitKLDVec;
        }
    }
    // Now for each of the classes, get the max SplitKLD or the split KLD of this class itself if it is a leaf
    for(int i=0;i<sizeVec;i++){
        if(this->GetChild(ClassesToSplit[i])->IsLeaf()){
            SplitKLDVec.push_back(this->GetKLDSplit_b(ClassesToSplit[i]));
        }
        else{
            SplitKLDVec.push_back(this->GetChild(ClassesToSplit[i])->GetToSplit_b(segment_param));
        }
    }
    return SplitKLDVec;

}

// Returns the vector of SplitKLD pointers ordered according to decreasing KLDTot
vector<int> TreeEM::OrderingSplittingChildren(){
    int numbchild=this->GetNumberChildren();
    vector<GenKLD*> SplitTryToOrder;
    vector<int> OrderedChildren;
    for(int c=0;c<numbchild;c++){
        if(this->GetChild(c)->GetNumberAllLeaves()<MaxSupport && this->GetChild(c)->GetNormWeight()>WeightThreshold){
            SplitTryToOrder.push_back(this->GetChild(c)->GetGenKLD());
            OrderedChildren.push_back(c);
        }
    }
    bool flag_swap=1;
    int Csize=SplitTryToOrder.size();
    while(flag_swap==1){
        flag_swap=0;
        for(int c=0;c<Csize-1;c++){
            if(SplitTryToOrder[c]->KLDTot<SplitTryToOrder[c+1]->KLDTot){
                GenKLD * tmp1=SplitTryToOrder[c]->CopyGenKLD();
                GenKLD * tmp2=SplitTryToOrder[c+1]->CopyGenKLD();
                int tmpInd=OrderedChildren[c];
                delete SplitTryToOrder[c];
                delete SplitTryToOrder[c+1];
                SplitTryToOrder[c]=tmp2;
                OrderedChildren[c]=OrderedChildren[c+1];
                SplitTryToOrder[c+1]=tmp1;
                OrderedChildren[c+1]=tmpInd;
                flag_swap=1;
            }
        }
    }
    for(int c=0;c<Csize;c++){
        delete SplitTryToOrder[c];
        SplitTryToOrder[c]=NULL;
    }
return OrderedChildren;
}

vector<SplitKLD *> TreeEM::OrderingSplittingLeaves(SEG_PARAMETERS * segment_param){
    int numbleaves=this->GetNumberAllLeaves();
    vector<SplitKLD*> SplitTryToOrder;
    if(numbleaves>0){
    SplitTryToOrder=this->GetVectorKLDSplitLeaves(segment_param);
    int numbSplit=SplitTryToOrder.size();
    bool flag_swap=1;
    while(flag_swap==1){
        flag_swap=0;
        for(int c=0;c<numbSplit-1;c++){
            if(SplitTryToOrder[c]->KLDTot<SplitTryToOrder[c+1]->KLDTot){
                SplitKLD * tmp1=SplitTryToOrder[c]->CopySplitKLD();
                SplitKLD * tmp2=SplitTryToOrder[c+1]->CopySplitKLD();
                delete SplitTryToOrder[c];
                SplitTryToOrder[c]=NULL;
                delete SplitTryToOrder[c+1];
                SplitTryToOrder[c+1]=NULL;
                SplitTryToOrder[c]=tmp2;
                SplitTryToOrder[c+1]=tmp1;
                flag_swap=1;
            }
        }
    }
    }
    else{
        int Child=this->GetParent()->FindIndex(this);
        SplitTryToOrder.push_back(this->GetParent()->GetKLDSplit(Child));
    }
    return SplitTryToOrder;
}

vector<SplitKLD_b *> TreeEM::OrderingSplittingLeaves_b(SEG_PARAMETERS * segment_param){
    int numbleaves=this->GetNumberAllLeaves();
    vector<SplitKLD_b*> SplitTryToOrder;
    if(numbleaves>0){
        SplitTryToOrder=this->GetVectorKLDSplitLeaves_b(segment_param);
        int numbSplit=SplitTryToOrder.size();
        bool flag_swap=1;
        while(flag_swap==1){
            flag_swap=0;
            for(int c=0;c<numbSplit-1;c++){
                if(SplitTryToOrder[c]->KLDTot<SplitTryToOrder[c+1]->KLDTot){
                    SplitKLD_b * tmp1=SplitTryToOrder[c]->CopySplitKLD_b();
                    SplitKLD_b * tmp2=SplitTryToOrder[c+1]->CopySplitKLD_b();
                    delete SplitTryToOrder[c];
                    SplitTryToOrder[c]=NULL;
                    delete SplitTryToOrder[c+1];
                    SplitTryToOrder[c+1]=NULL;
                    SplitTryToOrder[c]=tmp2;
                    SplitTryToOrder[c+1]=tmp1;
                    flag_swap=1;
                }
            }
        }
        if(segment_param->flag_RefinedSOrdering){ // In case we decide to have a different order for the uniform that qualify, strengthening the possibility (in terms of order of try) for a uniform to split compared to a Gaussian
            std::vector<SplitKLD_b *>::iterator it;
            it=SplitTryToOrder.begin();
            int numbRefined=0;
            int numbFirstH=0;
            for (int l=0; l<numbSplit; l++) {
                it=SplitTryToOrder.begin();
                TreeEM * ParentTested=this->FindFromHierarchy(SplitTryToOrder[l]->HierarchyParent);
                TreeEM * LeaveTested=ParentTested->GetChild(SplitTryToOrder[l]->ChildToSplit);
                if(LeaveTested->GetDistributionType()==2 && SplitTryToOrder[l]->HierarchyParent.size()<=1){
                    SplitKLD_b * ToAddFirst=SplitTryToOrder[l]->CopySplitKLD_b();
                    delete SplitTryToOrder[l];
                    SplitTryToOrder[l]=NULL;
                    SplitTryToOrder.erase(SplitTryToOrder.begin()+l);
                    SplitTryToOrder.insert(it+numbFirstH, ToAddFirst);
                    numbRefined++;
                    numbFirstH++;
                }
                else if(LeaveTested->GetDistributionType()==2){
                    vector<TreeEM *> BrothersVector=ParentTested->GetChildren();
                    float SumWeight=0;
                    int numbBrothers=BrothersVector.size();
                    for(int b=0;b<numbBrothers;b++){
                        if (BrothersVector[b]->GetDistributionType()!=2) {
                            SumWeight+=BrothersVector[b]->GetNormWeight();
                        }
                    }
                    float MeanWeight=numbBrothers>1?SumWeight/(numbBrothers-1):SumWeight;
                    if (LeaveTested->GetNormWeight()>MeanWeight/2) {
                        SplitKLD_b * ToAddFirst=SplitTryToOrder[l]->CopySplitKLD_b();
                        delete SplitTryToOrder[l];
                        SplitTryToOrder[l]=NULL;
                        SplitTryToOrder.erase(SplitTryToOrder.begin()+l);
                        SplitTryToOrder.insert(it+numbRefined, ToAddFirst);
                        numbRefined++;
                    }

                }
            }
        }
    }
    else{
        int Child=this->GetParent()->FindIndex(this);
        SplitTryToOrder.push_back(this->GetParent()->GetKLDSplit_b(Child));
    }
    return SplitTryToOrder;
}

vector<SplitKLD_b *> TreeEM::OrderingSplittingLeavesUniform_b(SEG_PARAMETERS * segment_param, int InitSplitUnif=0){
    vector<TreeEM *> UnifVector=this->GetUniformLeavesVector();
    int numbUnif=UnifVector.size();
    vector<SplitKLD_b*> SplitTryToOrder;
    if(numbUnif>0){
        SplitTryToOrder=this->GetVectorKLDSplitLeavesUniform_b(segment_param);
        int numbSplit=SplitTryToOrder.size();
        bool flag_swap=1;
        while(flag_swap==1){
            flag_swap=0;
            for(int c=0;c<numbSplit-1;c++){
                if(SplitTryToOrder[c]->KLDTot<SplitTryToOrder[c+1]->KLDTot){
                    SplitKLD_b * tmp1=SplitTryToOrder[c]->CopySplitKLD_b();
                    SplitKLD_b * tmp2=SplitTryToOrder[c+1]->CopySplitKLD_b();
                    delete SplitTryToOrder[c];
                    SplitTryToOrder[c]=NULL;
                    delete SplitTryToOrder[c+1];
                    SplitTryToOrder[c+1]=NULL;
                    SplitTryToOrder[c]=tmp2;
                    SplitTryToOrder[c+1]=tmp1;
                    flag_swap=1;
                }
            }
        }
    }
    for (int u=0; u<numbUnif; u++) {
        SplitTryToOrder[u]->InitSplitUnif=InitSplitUnif;
    }
    return SplitTryToOrder;
}

vector<SplitKLD*> TreeEM::GetSplitOrderVertical(SEG_PARAMETERS * segment_param){
    vector<int> SplitOrderedChildren=this->OrderingSplittingChildren();
//    int numbchild=this->GetNumberChildren();
    vector<SplitKLD*> VerticalSplitVector;
    int numbposchild=SplitOrderedChildren.size();
    for(int c=0;c<numbposchild;c++){
        // if the considered element is a leaf, put directly into the vector
        if(this->GetChild(SplitOrderedChildren[c])->IsLeaf()){
            VerticalSplitVector.push_back(this->GetKLDSplit(SplitOrderedChildren[c]));
//            delete SplitOrderedChildren[c];
//            SplitOrderedChildren[c]=NULL;
        }
        else {
            vector<SplitKLD*> ChildSplitVector=this->GetChild(SplitOrderedChildren[c])->OrderingSplittingLeaves(segment_param);
            VerticalSplitVector.insert(VerticalSplitVector.end(),ChildSplitVector.begin(),ChildSplitVector.end());
//            delete SplitOrderedChildren[c];
//            SplitOrderedChildren[c]=NULL;
        }
    }
    return VerticalSplitVector;
}

vector<SplitKLD_b*> TreeEM::GetSplitOrderVertical_b(SEG_PARAMETERS * segment_param){
    vector<int> SplitOrderedChildren=this->OrderingSplittingChildren();
    //    int numbchild=this->GetNumberChildren();
    vector<SplitKLD_b*> VerticalSplitVector;
    int numbposchild=SplitOrderedChildren.size();
    for(int c=0;c<numbposchild;c++){
        // if the considered element is a leaf, put directly into the vector
        if(this->GetChild(SplitOrderedChildren[c])->IsLeaf()){
            VerticalSplitVector.push_back(this->GetKLDSplit_b(SplitOrderedChildren[c]));
            //            delete SplitOrderedChildren[c];
            //            SplitOrderedChildren[c]=NULL;
        }
        else {
            vector<SplitKLD_b*> ChildSplitVector=this->GetChild(SplitOrderedChildren[c])->OrderingSplittingLeaves_b(segment_param);
            VerticalSplitVector.insert(VerticalSplitVector.end(),ChildSplitVector.begin(),ChildSplitVector.end());
            //            delete SplitOrderedChildren[c];
            //            SplitOrderedChildren[c]=NULL;
        }
    }
    return VerticalSplitVector;
}


vector<SplitKLD*> TreeEM::GetSplitMoreVertical(int numbclasses,SEG_PARAMETERS * segment_param){
    int numbchild=this->GetNumberChildren();
//    int MaxNumbClasses=6;
    vector<SplitKLD*> ResultVectorSplitList;
    vector<int > ChildrenSplitFirstLevelOrdered=this->OrderingSplittingChildren(); // Ordering the general class to split
    int numbposchild=ChildrenSplitFirstLevelOrdered.size();
    vector<SplitKLD *> * ChildrenSplitKLDVec=new vector<SplitKLD*>[numbposchild];
    if(numbclasses>numbposchild || numbclasses<=0){
        return ResultVectorSplitList;
    }
    for(int c=0;c<numbchild;c++){
        int Child=ChildrenSplitFirstLevelOrdered[c];
        ChildrenSplitKLDVec[c]=this->GetChild(Child)->OrderingSplittingLeaves(segment_param);
    }
    int* ChildrenCombinations=Combination(numbposchild,numbclasses);
    int numbChildrenCombinations=NumbComb(numbclasses,numbposchild);
    for(int i=0;i<numbChildrenCombinations;i++){
        int * TabSize=new int[numbclasses];
        for(int c=0;c<numbclasses;c++){
            TabSize[c]=ChildrenSplitKLDVec[ChildrenCombinations[i*numbclasses+c]].size();
        }
        int * CombinationLeaves=this->CombinationBis(TabSize,numbclasses);
        int prodTabSize=1;
        for(int c=0;c<numbclasses;c++){
            prodTabSize*=TabSize[c];
        }
        for(int j=0;j<prodTabSize;j++){
            for(int c=0;c<numbclasses;c++){
//                cout<< ChildrenCombinations[i*numbclasses+c]<< " "<<CombinationLeaves[j*numbclasses+c]<<endl;
                ResultVectorSplitList.push_back(ChildrenSplitKLDVec[ChildrenCombinations[i*numbclasses+c]][CombinationLeaves[j*numbclasses+c]]);
//                delete [] ChildrenSplitKLDVec[ChildrenCombinations[i*numbclasses+c]][CombinationLeaves[j*numbclasses+c]];
//                ChildrenSplitKLDVec[ChildrenCombinations[i*numbclasses+c]][CombinationLeaves[j*numbclasses+c]]=NULL;
            }
        }

        delete[]TabSize;
        TabSize=NULL;
        delete[]CombinationLeaves;
        CombinationLeaves=NULL;
    }

    if(ChildrenCombinations!=NULL){
        delete[] ChildrenCombinations;
        ChildrenCombinations=NULL;
    }
return ResultVectorSplitList;
}

vector<SplitKLD_b *> TreeEM::GetSplitMoreVertical_b(int numbclasses,SEG_PARAMETERS * segment_param){
    int numbchild=this->GetNumberChildren();
//    int MaxNumbClasses=6;
    vector<SplitKLD_b*> ResultVectorSplitList;
    vector<int > ChildrenSplitFirstLevelOrdered=this->OrderingSplittingChildren(); // Ordering the general class to split
    int numbposchild=ChildrenSplitFirstLevelOrdered.size();
    vector<SplitKLD_b *> * ChildrenSplitKLDVec=new vector<SplitKLD_b*>[numbposchild];
    if(numbclasses>numbposchild || numbclasses<=0){
        return ResultVectorSplitList;
    }
    for(int c=0;c<numbchild;c++){
        int Child=ChildrenSplitFirstLevelOrdered[c];
        ChildrenSplitKLDVec[c]=this->GetChild(Child)->OrderingSplittingLeaves_b(segment_param);
    }
    int* ChildrenCombinations=Combination(numbposchild,numbclasses);
    int numbChildrenCombinations=NumbComb(numbclasses,numbposchild);
    for(int i=0;i<numbChildrenCombinations;i++){
        int * TabSize=new int[numbclasses];
        for(int c=0;c<numbclasses;c++){
            TabSize[c]=ChildrenSplitKLDVec[ChildrenCombinations[i*numbclasses+c]].size();
        }
        int * CombinationLeaves=this->CombinationBis(TabSize,numbclasses);
        int prodTabSize=1;
        for(int c=0;c<numbclasses;c++){
            prodTabSize*=TabSize[c];
        }
        for(int j=0;j<prodTabSize;j++){
            for(int c=0;c<numbclasses;c++){
                //                cout<< ChildrenCombinations[i*numbclasses+c]<< " "<<CombinationLeaves[j*numbclasses+c]<<endl;
                ResultVectorSplitList.push_back(ChildrenSplitKLDVec[ChildrenCombinations[i*numbclasses+c]][CombinationLeaves[j*numbclasses+c]]);
                //                delete [] ChildrenSplitKLDVec[ChildrenCombinations[i*numbclasses+c]][CombinationLeaves[j*numbclasses+c]];
                //                ChildrenSplitKLDVec[ChildrenCombinations[i*numbclasses+c]][CombinationLeaves[j*numbclasses+c]]=NULL;
            }
        }
        
        delete[]TabSize;
        TabSize=NULL;
        delete[]CombinationLeaves;
        CombinationLeaves=NULL;
    }

    if(ChildrenCombinations!=NULL){
        delete[] ChildrenCombinations;
        ChildrenCombinations=NULL;
    }
    return ResultVectorSplitList;
}

int * TreeEM::Combination(int n,int k){
    if(n<k){
        cout<<"Impossible to take more than what is available"<<endl;
        return NULL;
    }
    int * Combinations=new int[k*NumbComb(k,n)];
    int SizeComb=k*NumbComb(k,n);
//    int Comb_tmp[k];
    int * Comb_tmp=new int[k];
    for(int i=0;i<k;i++){
        Comb_tmp[i]=i;
    }
    int Ind=0;
    for(int i=0;i<k;i++){
        Combinations[Ind+i]=Comb_tmp[i];
    }
    Ind=Ind+k;
    while(Comb_tmp[0]<=n-k && Ind<SizeComb){
        int i=k-1;
        bool flag_change=0;
        while(i>=0 && !flag_change){
            if(Comb_tmp[i]<n-k+i){
                Comb_tmp[i]++;
                flag_change=1;
            }
            i--;
        }
        for(int j=0;j<k;j++){
            Combinations[Ind+j]=Comb_tmp[j];
        }
        Ind+=k;
    }
    if(Ind<SizeComb){
    Comb_tmp[0]++;
    for(int j=0;j<k;j++){
        Combinations[Ind+j]=Comb_tmp[j];
    }
    }
    if(Comb_tmp!=NULL){
        delete[] Comb_tmp;
        Comb_tmp=NULL;
    }
    return Combinations;
}

int * TreeEM::CombinationBis(int * TabSize,int numbclasses){
    // Calculation of the number of possible combinations and initialisation of the array
    int prodTabSize=1;
//    int Shift[numbclasses];
    int * Shift=new int[numbclasses];
    for(int i=0;i<numbclasses;i++){
        prodTabSize*=TabSize[i];
        Shift[i]=1;
    }
    for(int c=numbclasses-1;c>=0;c--){
        if(c<numbclasses-1){
            Shift[c]=Shift[c+1]*TabSize[c+1];
        }
    }
    int * Combination=new int[numbclasses*prodTabSize];
    int Ind=0;
    for(int i=0;i<prodTabSize;i++){
        int tmpind=i;
        for(int c=0;c<numbclasses;c++){
            Combination[Ind+c]=tmpind/Shift[c];
            tmpind-=Combination[Ind+c]*Shift[c];
        }
        Ind+=numbclasses;
    }
    if(Shift!=NULL){
        delete [] Shift;
        Shift=NULL;
    }
//cout<<Ind;
return Combination;
}

inline int TreeEM::Factorial(int x) {
  return (x <= 1 ? 1 : x * Factorial(x - 1));
}

int TreeEM::NumbComb(int k, int n){
    if(k>n){
        return 0;
    }
    cout<< n << " "<<k<<" "<<Factorial(n-k);
//    printf("the factorial components are %d %d %d \n",Factorial(n),Factorial(n-k),Factorial(k));
    return Factorial(n)/(Factorial(n-k)*Factorial(k));
}

SplitKLD * TreeEM::GetToSplit(SEG_PARAMETERS * segment_param){
    vector<SplitKLD *> VectorSplit( this->GetVectorKLDSplitLeaves(segment_param));
    int numbLeaves=VectorSplit.size();
    //cout<<VectorSplit.size()<<"is the size of Vector Split"<<endl;
    if (numbLeaves<=0) {
        return NULL;
    }
    // Initialisation of the result
    SplitKLD * SplitMax=new SplitKLD;
    SplitMax->KLDTot=-1E32;
    int numbmodal=this->GetNumberModalities();
    SplitMax->KLD=new float[numbmodal];//{-1E32};
    for(int i=0;i<numbmodal;i++){
        SplitMax->KLD[i]=-1E32;
    }
    for (int i=0; i<numbLeaves; i++) {
        bool SplitCheckTest=(VectorSplit[i]->Parent)->GetSplitCheck()[VectorSplit[i]->ChildToSplit];
        if (!SplitCheckTest&& SplitMax->KLDTot<VectorSplit[i]->KLDTot) { // if the leave has not been checked yet for the split and the KLD is more than the previous one, we update SplitMax by copying the structure of VectorSplit[i]
            SplitMax->Parent=VectorSplit[i]->Parent;
            SplitMax->ChildToSplit=VectorSplit[i]->ChildToSplit;
            SplitMax->KLDTot=VectorSplit[i]->KLDTot;
            for (int m=0; m<numbmodal; m++) {
                SplitMax->KLD[m]=VectorSplit[i]->KLD[m];
            }
        }
        // Delete and free the considered element of VectorSplit.
        //delete [] VectorSplit[i]->KLD;
        delete VectorSplit[i];
        VectorSplit[i]=NULL;
    }
    if (SplitMax->KLDTot<0) {
        delete SplitMax;
        SplitMax=NULL;
    }
    return SplitMax;
}

SplitKLD_b * TreeEM::GetToSplit_b(SEG_PARAMETERS * segment_param){
    vector<SplitKLD_b *> VectorSplit( this->GetVectorKLDSplitLeaves_b(segment_param));
    int numbLeaves=VectorSplit.size();
    //cout<<VectorSplit.size()<<"is the size of Vector Split"<<endl;
    if (numbLeaves<=0) {
        return NULL;
    }
    // Initialisation of the result
    SplitKLD_b * SplitMax=new SplitKLD_b();
    SplitMax->KLDTot=-1E32;
//    int numbmodal=this->GetNumberModalities();
//    SplitMax->KLD=new float[numbmodal];//{-1E32};
//    for(int i=0;i<numbmodal;i++){
//        SplitMax->KLD[i]=-1E32;
//    }
    for (int i=0; i<numbLeaves; i++) {
        TreeEM * ParentSplit=this->FindFromHierarchy(VectorSplit[i]->HierarchyParent);
        bool SplitCheckTest=ParentSplit->GetSplitCheck()[VectorSplit[i]->ChildToSplit];
        if (!SplitCheckTest&& SplitMax->KLDTot<VectorSplit[i]->KLDTot) { // if the leave has not been checked yet for the split and the KLD is more than the previous one, we update SplitMax by copying the structure of VectorSplit[i]
            int LengthHierarchy=VectorSplit[i]->HierarchyParent.size();
            SplitMax->HierarchyParent.clear();
            for (int l=0; l<LengthHierarchy; l++) {
                SplitMax->HierarchyParent.push_back(VectorSplit[i]->HierarchyParent[l]);
            }
            SplitMax->ChildToSplit=VectorSplit[i]->ChildToSplit;
            SplitMax->KLDTot=VectorSplit[i]->KLDTot;
            SplitMax->InitSplitUnif=segment_param->choiceInitSplitUnifKMeans;
//            for (int m=0; m<numbmodal; m++) {
//                SplitMax->KLD[m]=VectorSplit[i]->KLD[m];
//            }
        }
        // Delete and free the considered element of VectorSplit.
        //delete [] VectorSplit[i]->KLD;
        delete VectorSplit[i];
        VectorSplit[i]=NULL;
    }
    if (SplitMax->KLDTot<0) {
        delete SplitMax;
        SplitMax=NULL;
    }
    return SplitMax;
}

// Performs the Split operation and modify accordingly the tree
void TreeEM::SplitOperation(SplitKLD * SplitTry, int choiceInit,SEG_PARAMETERS * segment_param){
    // Check if it is effectively a child that can be split
    int numbchild=SplitTry->Parent->GetNumberChildren();
    int numbmodal=this->GetNumberModalities();
    int ChildToSplit=SplitTry->ChildToSplit;
    TreeEM* ParentToSplit=SplitTry->Parent;
    if (ChildToSplit>=numbchild||ChildToSplit<0) {
        cout<<"Child to split out of bounds"<<endl;
        return;
    }
    else if (ParentToSplit->GetChild(ChildToSplit)->GetNumberChildren()!=0) {
        cout<<"Impossible to split something else than leaf"<<endl;
        return;
    }
    else if (segment_param->SplitAccept <2 && ParentToSplit->GetChild(ChildToSplit)->GetNormWeight()<segment_param->WeightMini/5) {
        cout<<"Impossible to split an already too small class"<<endl;
        return;
    }
    else if(segment_param->SplitAccept==2 && !ParentToSplit->IsRoot() && ParentToSplit->GetChild(ChildToSplit)->GetNormWeight()<segment_param->WeightMini/5){
        cout<<"Impossible to split a too small class on the second level"<<endl;
        return;
    }
    else{
    switch(SplitTry->TypeChange){
    case 0:{ // case where the split transforms the uniform distribution into a unique Gaussian
        float * Mean=ParentToSplit->GetChild(ChildToSplit)->GetMeanDirect();
        float * Variance=ParentToSplit->GetChild(ChildToSplit)->GetDiagVarianceDirect_corr();
        // Building of the parameters of newly formed Gaussian
        Parameters * ParametersSplit=new Parameters();
        ParametersSplit->DistributionType=1;
        ParametersSplit->SizeParameters=CalculateSizeParameters(ParametersSplit->DistributionType);
        ParametersSplit->ValueParameters=new float[ParametersSplit->SizeParameters];//{0};
        for(int i=0;i<ParametersSplit->SizeParameters;i++){
            ParametersSplit->ValueParameters[i]=0;
        }
        for(int m=0;m<numbmodal;m++){
            ParametersSplit->ValueParameters[m]=Mean[m];
        }
        for(int m1=0;m1<numbmodal;m1++){
            for(int m2=0;m2<numbmodal;m2++){
                if(m1==m2){
                    ParametersSplit->ValueParameters[numbmodal+m1*numbmodal+m2]=Variance[m1];
                }
            }
        }
        ParentToSplit->GetChild(ChildToSplit)->SetParameters(ParametersSplit);
        // Clearing memory used for parameters construction
        delete [] Mean;
        Mean=NULL;
        delete [] Variance;
        Variance = NULL;
        delete ParametersSplit;
        ParametersSplit=NULL;
        break;
    }
    case 2:{//or uniform giving two gaussian at first step
                Parameters ** ParametersSplit=(ParentToSplit->GetChild(ChildToSplit))->ParametersDoubleForSplittingUniform( choiceInit);
        //Modification of the parameters according to flag_PriorsCov and CovPriorsSplit
        if (segment_param->flag_CovPriors) {
            int numelmasked=this->GetNumberMaskedElements();
            int numbmodal=this->GetNumberModalities();
            switch (segment_param->CovPriorsSplit) {
                case 1: {// ParametersSplit[0] modified only
                    switch (segment_param->CovPriorsType) {
                        case 1:{
                            ParametersSplit[0]->PriorsCovFlag=1;
                            // Get Nz from ParentToSplit and NormWeight
                            float * NormRespParent=ParentToSplit->GetChild(ChildToSplit)->GetNormResp();
                            PrecisionTYPE sumResp=0;
                            for (int i=0; i<numelmasked; i++,NormRespParent++) {
                                sumResp+=*NormRespParent;
                            }
                            if (ParametersSplit[0]->PriorsCov!=NULL) {
                                delete [] ParametersSplit[0]->PriorsCov;
                                ParametersSplit[0]->PriorsCov=NULL;
                            }
                            ParametersSplit[0]->PriorsCov=new float[numbmodal*numbmodal];
                            for (int m1=0; m1<numbmodal; m1++) {
                                for (int m2=0; m2<numbmodal; m2++) {
                                    if (m1==m2) {
                                        ParametersSplit[0]->PriorsCov[m1+m2*numbmodal]=sumResp*0.5*ParametersSplit[0]->ValueParameters[numbmodal+m1+m2*numbmodal];
                                    }
                                    else{
                                        ParametersSplit[0]->PriorsCov[m1+m2*numbmodal]=0;
                                    }
                                }
                            }
                            // Ensure that there is nothing on other parameter structure
                            ParametersSplit[1]->PriorsCovFlag=0;
                            if (ParametersSplit[1]->PriorsCov!=NULL) {
                                delete [] ParametersSplit[1]->PriorsCov;
                                ParametersSplit[1]->PriorsCov=NULL;
                            }
                        }
                            break;

                        default:
                            break;
                    }
                    
                }
                    break;
                case 2:{ // ParametersSplit[1] constrained only
                    switch (segment_param->CovPriorsType) {
                        case 1:{
                            ParametersSplit[1]->PriorsCovFlag=1;
                            // Get Nz from ParentToSplit and NormWeight
                            float * NormRespParent=ParentToSplit->GetChild(ChildToSplit)->GetNormResp();
                            PrecisionTYPE sumResp=0;
                            for (int i=0; i<numelmasked; i++,NormRespParent++) {
                                sumResp+=*NormRespParent;
                            }
                            if (ParametersSplit[1]->PriorsCov!=NULL) {
                                delete [] ParametersSplit[1]->PriorsCov;
                                ParametersSplit[1]->PriorsCov=NULL;
                            }
                            ParametersSplit[1]->PriorsCov=new float[numbmodal*numbmodal];
                            for (int m1=0; m1<numbmodal; m1++) {
                                for (int m2=0; m2<numbmodal; m2++) {
                                    if (m1==m2) {
                                        ParametersSplit[1]->PriorsCov[m1+m2*numbmodal]=sumResp*0.5*ParametersSplit[1]->ValueParameters[numbmodal+m1+m2*numbmodal];
                                    }
                                    else{
                                        ParametersSplit[1]->PriorsCov[m1+m2*numbmodal]=0;
                                    }
                                }
                            }
                            // Ensure that there is nothing on other parameter structure
                            ParametersSplit[0]->PriorsCovFlag=0;
                            if (ParametersSplit[0]->PriorsCov!=NULL) {
                                delete [] ParametersSplit[1]->PriorsCov;
                                ParametersSplit[0]->PriorsCov=NULL;
                            }
                        }
                            break;
                            
                        default:
                            break;
                    }
                }
                    break;
                case 3: { // Both ParametersSplit constrained
                    switch (segment_param->CovPriorsType) {
                        case 1:{
                            ParametersSplit[0]->PriorsCovFlag=1;
                            ParametersSplit[1]->PriorsCovFlag=1;
                            // Get Nz from ParentToSplit and NormWeight
                            float * NormRespParent=ParentToSplit->GetChild(ChildToSplit)->GetNormResp();
                            PrecisionTYPE sumResp=0;
                            for (int i=0; i<numelmasked; i++,NormRespParent++) {
                                sumResp+=*NormRespParent;
                            }
                            if (ParametersSplit[0]->PriorsCov!=NULL) {
                                delete [] ParametersSplit[0]->PriorsCov;
                                ParametersSplit[0]->PriorsCov=NULL;
                            }
                            if (ParametersSplit[1]->PriorsCov!=NULL) {
                                delete [] ParametersSplit[1]->PriorsCov;
                                ParametersSplit[1]->PriorsCov=NULL;
                            }
                            ParametersSplit[0]->PriorsCov=new float[numbmodal*numbmodal];
                            ParametersSplit[1]->PriorsCov=new float[numbmodal*numbmodal];
                            for (int m1=0; m1<numbmodal; m1++) {
                                for (int m2=0; m2<numbmodal; m2++) {
                                    if (m1==m2) {
                                        ParametersSplit[0]->PriorsCov[m1+m2*numbmodal]=sumResp*0.5*ParametersSplit[0]->ValueParameters[numbmodal+m1+m2*numbmodal];
                                        ParametersSplit[1]->PriorsCov[m1+m2*numbmodal]=sumResp*0.5*ParametersSplit[1]->ValueParameters[numbmodal+m1+m2*numbmodal];
                                    }
                                    else{
                                        ParametersSplit[0]->PriorsCov[m1+m2*numbmodal]=0;
                                        ParametersSplit[1]->PriorsCov[m1+m2*numbmodal]=0;
                                    }
                                }
                            }
                        }
                            break;
//                        case 2:{ // case with the general covariance matrix Both sides are enforced, no test needed
//                            ParametersSplit[0]->PriorsCovFlag=1;
//                            ParametersSplit[1]->PriorsCovFlag=1;
//                            // Get Nz from ParentToSplit and NormWeight
//                            float * GeneralCovPriors= this->GetPriorsCovMatrixGeneral(segment_param);
//                            float * NormRespParent=ParentToSplit->GetChild(ChildToSplit)->GetNormResp();
//                            PrecisionTYPE sumResp=0;
//                            for (int i=0; i<numelmasked; i++,NormRespParent++) {
//                                sumResp+=*NormRespParent;
//                            }
//                            if (ParametersSplit[0]->PriorsCov!=NULL) {
//                                delete [] ParametersSplit[0]->PriorsCov;
//                                ParametersSplit[0]->PriorsCov=NULL;
//                            }
//                            if (ParametersSplit[1]->PriorsCov!=NULL) {
//                                delete [] ParametersSplit[1]->PriorsCov;
//                                ParametersSplit[1]->PriorsCov=NULL;
//                            }
//                            ParametersSplit[0]->PriorsCov=new float[numbmodal*numbmodal];
//                            ParametersSplit[1]->PriorsCov=new float[numbmodal*numbmodal];
//                            for (int m1=0; m1<numbmodal; m1++) {
//                                for (int m2=0; m2<numbmodal; m2++) {
//                                        ParametersSplit[0]->PriorsCov[m1+m2*numbmodal]=sumResp*0.5*GeneralCovPriors[m1+m2*numbmodal];                                        ParametersSplit[1]->PriorsCov[m1+m2*numbmodal]=sumResp*0.5*GeneralCovPriors[m1+m2*numbmodal];
//                                }
//                            }
//
//                        }
//                            break;
//                        case 3:{ // General covariance matrix with no change
//                            ParametersSplit[0]->PriorsCovFlag=1;
//                            ParametersSplit[1]->PriorsCovFlag=1;
//                            // Get Nz from ParentToSplit and NormWeight
//                            float * GeneralCovPriors= this->GetPriorsCovMatrixGeneral(segment_param);
//                            if (ParametersSplit[0]->PriorsCov!=NULL) {
//                                delete [] ParametersSplit[0]->PriorsCov;
//                                ParametersSplit[0]->PriorsCov=NULL;
//                            }
//                            if (ParametersSplit[1]->PriorsCov!=NULL) {
//                                delete [] ParametersSplit[1]->PriorsCov;
//                                ParametersSplit[1]->PriorsCov=NULL;
//                            }
//                            ParametersSplit[0]->PriorsCov=new float[numbmodal*numbmodal];
//                            ParametersSplit[1]->PriorsCov=new float[numbmodal*numbmodal];
//                            for (int m1=0; m1<numbmodal; m1++) {
//                                for (int m2=0; m2<numbmodal; m2++) {
//                                    ParametersSplit[0]->PriorsCov[m1+m2*numbmodal]=GeneralCovPriors[m1+m2*numbmodal];                                        ParametersSplit[1]->PriorsCov[m1+m2*numbmodal]=GeneralCovPriors[m1+m2*numbmodal];
//                                }
//                            }
//                        }
//                            break;
                        default:
                            break;
                    }
                }
                    break;
                default: // value 0 or other : No change made.
                    break;
            }
            
        }

        
        
                (ParentToSplit->GetChild(ChildToSplit))->CreateAndAddChildWeight(segment_param,0.5,1);
                (ParentToSplit->GetChild(ChildToSplit))->CreateAndAddChildWeight(segment_param,0.5,1);
                (ParentToSplit->GetChild(ChildToSplit)->GetChild(0))->SetParameters(ParametersSplit[0]);
                (ParentToSplit->GetChild(ChildToSplit)->GetChild(1))->SetParameters(ParametersSplit[1]);

                // Clearing memory dedicated to Parameters split
                delete ParametersSplit[0];
                ParametersSplit[0]=NULL;
                delete ParametersSplit[1];
                ParametersSplit[1]=NULL;
                delete ParametersSplit;
                ParametersSplit=NULL;
        //        this->GetChild(ChildToSplit)->GetChild(0)->SetNormWeight(0.5);
        //        this->GetChild(ChildToSplit)->GetChild(1)->SetNormWeight(0.5);
                //    this->PutAllLeavesToChildrenLevel();
                break;
                return;
    }
    case 3:{ // uniform giving one gaussian + uniform
        Parameters * ParametersSplit=(ParentToSplit->GetChild(ChildToSplit))->ParametersForSplittingUniform3(segment_param,SplitTry->InitSplitUnif);
//        nifti_image * PriorsToAdd=ParentToSplit->GetChild(ChildToSplit)->CreatePriorsFromAdaptedPriors();
//        nifti_image * PriorsConstant=ParentToSplit->BuildConstantPriors(segment_param->OutliersWeight);
        nifti_image * PriorsToAdd=ParentToSplit->GetChild(ChildToSplit)->CreatePriorsFromAdaptedPriors();
        MultiplyNii(PriorsToAdd,0.5);
        nifti_image * PriorsConstant=ParentToSplit->BuildConstantPriors(ParentToSplit->GetChild(ChildToSplit)->GetNormWeight()*0.5); // In this case, the uniform is always at the first level, so NormWeight is proper value to take into account
        ParentToSplit->GetChild(ChildToSplit)->SetPriors(PriorsToAdd);
        ParentToSplit->GetChild(ChildToSplit)->SetParameters(ParametersSplit);
        ParentToSplit->NormalisePriors(); // first normalisation before adding the uniform as done at first initialisation otherwise prior of uniform not constant over image.
        ParentToSplit->NormalisePriorsAdapted();
        ParentToSplit->CreateAndAddChildPriors(segment_param,PriorsConstant,2);
        ParentToSplit->NormalisePriors();
        ParentToSplit->NormalisePriorsAdapted();

        // Clearing memory dedicated to Parameters split
        delete ParametersSplit;
        ParametersSplit=NULL;
        break;
        return;

    }
    case 4:{ // uniform giving one gaussian and one uniform under same priors
        Parameters * ParametersSplit=(ParentToSplit->GetChild(ChildToSplit))->ParametersForSplittingUniform3(segment_param,SplitTry->InitSplitUnif);
        
       (ParentToSplit->GetChild(ChildToSplit))->CreateAndAddChildWeight(segment_param,1-segment_param->UnifSplitWeight,1);
       (ParentToSplit->GetChild(ChildToSplit)->GetChild(0))->SetParameters(ParametersSplit);
               (ParentToSplit->GetChild(ChildToSplit))->CreateAndAddChildWeight(segment_param,segment_param->UnifSplitWeight,2);

       // Clearing memory dedicated to Parameters split
       delete ParametersSplit;
       ParametersSplit=NULL;
       break;
       return;
    }
    case 5:{ // case where a uniform gives one gaussian and one uniform with adapted initial atlases
         vector<nifti_image *> PriorsSUG=ParentToSplit->GetChild(ChildToSplit)->CreatePriorsFromSplittingUniform(segment_param,SplitTry->InitSplitUnif); // After this operation, a child has already been added with the appropriate parameters for the gaussian part of the splitting.
        if (ParentToSplit->IsRoot()) { // the additional layer added by the previous operation is conserved.
            ParentToSplit->GetChild(ChildToSplit)->GetChild(0)->SetPriors(PriorsSUG[0]);
            ParentToSplit->GetChild(ChildToSplit)->CreateAndAddChildPriors(segment_param,PriorsSUG[1],2);
        }
        else{ // In this case, put the uniform and the Gaussian side by side instead of creating new layer
            // First set the parameters to the
            ParentToSplit->GetChild(ChildToSplit)->SetParameters(ParentToSplit->GetChild(ChildToSplit)->GetChild(0)->GetParameters());
            delete ParentToSplit->GetChild(ChildToSplit)->GetChild(0);
            ParentToSplit->GetChild(ChildToSplit)->Children.erase(ParentToSplit->GetChild(ChildToSplit)->Children.begin()); // <=> collapse only child
            // Then need to take care of atlases. As only one level for the outliers main node, need to multiply the atlases formed for the split by the atlas of the uniform split.
            int sizeSUGPriors=PriorsSUG.size();
            for (int i=0; i<sizeSUGPriors; i++) {
                MultiplyNiiByNii(PriorsSUG[i], ParentToSplit->GetChild(ChildToSplit)->GetPriorsDirect());
            }
            ParentToSplit->GetChild(ChildToSplit)->SetPriors(PriorsSUG[0]);
            ParentToSplit->GetChild(ChildToSplit)->SetPriorsAdapted(static_cast<float *>(PriorsSUG[0]->data));
            ParentToSplit->CreateAndAddChildPriors(segment_param,PriorsSUG[1],2);
            ParentToSplit->NormalisePriors();
            ParentToSplit->NormalisePriorsAdapted();
            if(segment_param->flag_savePriors){
                this->SavePriorsAdapted(segment_param);
            }
//            nifti_set_filenames(PriorsSUG[0], "/Users/Carole/Documents/PhD/TestGcase5.nii.gz", 0, 0);
//            nifti_set_filenames(PriorsSUG[1], "/Users/Carole/Documents/PhD/TestUcase5.nii.gz", 0, 0);
//            nifti_image_write(PriorsSUG[0]);
//            nifti_image_write(PriorsSUG[1]);
        }
        break;
        return;
        }

    default :{ // classical case where the split happens on a gaussian distributed class
        Parameters ** ParametersSplit=(ParentToSplit->GetChild(ChildToSplit))->ParametersForSplitting( choiceInit);
        //Modification of the parameters according to flag_PriorsCov and CovPriorsSplit
        if (segment_param->flag_CovPriors) {
            int numelmasked=this->GetNumberMaskedElements();
            int numbmodal=this->GetNumberModalities();
            switch (segment_param->CovPriorsSplit) {
                case 1: {// ParametersSplit[0] modified only
                    switch (segment_param->CovPriorsType) {
                        case 1:{
                            ParametersSplit[0]->PriorsCovFlag=1;
                            // Get Nz from ParentToSplit and NormWeight
                            float * NormRespParent=ParentToSplit->GetChild(ChildToSplit)->GetNormResp();
                            PrecisionTYPE sumResp=0;
                            for (int i=0; i<numelmasked; i++,NormRespParent++) {
                                sumResp+=*NormRespParent;
                            }
                            if (ParametersSplit[0]->PriorsCov!=NULL) {
                                delete [] ParametersSplit[0]->PriorsCov;
                                ParametersSplit[0]->PriorsCov=NULL;
                            }
                            ParametersSplit[0]->PriorsCov=new float[numbmodal*numbmodal];
                            for (int m1=0; m1<numbmodal; m1++) {
                                for (int m2=0; m2<numbmodal; m2++) {
                                    if (m1==m2) {
                                        ParametersSplit[0]->PriorsCov[m1+m2*numbmodal]=sumResp*0.5*ParametersSplit[0]->ValueParameters[numbmodal+m1+m2*numbmodal];
                                    }
                                    else{
                                        ParametersSplit[0]->PriorsCov[m1+m2*numbmodal]=0;
                                    }
                                }
                            }
                            // Ensure that there is nothing on other parameter structure
                            ParametersSplit[1]->PriorsCovFlag=0;
                            if (ParametersSplit[1]->PriorsCov!=NULL) {
                                delete [] ParametersSplit[1]->PriorsCov;
                                ParametersSplit[1]->PriorsCov=NULL;
                            }
                        }
                            break;
                            
                        default:
                            break;
                    }
                    
                }
                    break;
                case 2:{ // ParametersSplit[1] constrained only
                    switch (segment_param->CovPriorsType) {
                        case 1:{
                            ParametersSplit[1]->PriorsCovFlag=1;
                            // Get Nz from ParentToSplit and NormWeight
                            float * NormRespParent=ParentToSplit->GetChild(ChildToSplit)->GetNormResp();
                            PrecisionTYPE sumResp=0;
                            for (int i=0; i<numelmasked; i++,NormRespParent++) {
                                sumResp+=*NormRespParent;
                            }
                            if (ParametersSplit[1]->PriorsCov!=NULL) {
                                delete [] ParametersSplit[1]->PriorsCov;
                                ParametersSplit[1]->PriorsCov=NULL;
                            }
                            ParametersSplit[1]->PriorsCov=new float[numbmodal*numbmodal];
                            for (int m1=0; m1<numbmodal; m1++) {
                                for (int m2=0; m2<numbmodal; m2++) {
                                    if (m1==m2) {
                                        ParametersSplit[1]->PriorsCov[m1+m2*numbmodal]=sumResp*0.5*ParametersSplit[1]->ValueParameters[numbmodal+m1+m2*numbmodal];
                                    }
                                    else{
                                        ParametersSplit[1]->PriorsCov[m1+m2*numbmodal]=0;
                                    }
                                }
                            }
                            // Ensure that there is nothing on other parameter structure
                            ParametersSplit[0]->PriorsCovFlag=0;
                            if (ParametersSplit[0]->PriorsCov!=NULL) {
                                delete [] ParametersSplit[1]->PriorsCov;
                                ParametersSplit[0]->PriorsCov=NULL;
                            }
                        }
                            break;
                            
                        default:
                            break;
                    }
                }
                    break;
                case 3: { // Both ParametersSplit constrained
                    switch (segment_param->CovPriorsType) {
                        case 1:{
                            ParametersSplit[0]->PriorsCovFlag=1;
                            ParametersSplit[1]->PriorsCovFlag=1;
                            // Get Nz from ParentToSplit and NormWeight
                            float * NormRespParent=ParentToSplit->GetChild(ChildToSplit)->GetNormResp();
                            PrecisionTYPE sumResp=0;
                            for (int i=0; i<numelmasked; i++,NormRespParent++) {
                                sumResp+=*NormRespParent;
                            }
                            if (ParametersSplit[0]->PriorsCov!=NULL) {
                                delete [] ParametersSplit[0]->PriorsCov;
                                ParametersSplit[0]->PriorsCov=NULL;
                            }
                            if (ParametersSplit[1]->PriorsCov!=NULL) {
                                delete [] ParametersSplit[1]->PriorsCov;
                                ParametersSplit[1]->PriorsCov=NULL;
                            }
                            ParametersSplit[0]->PriorsCov=new float[numbmodal*numbmodal];
                            ParametersSplit[1]->PriorsCov=new float[numbmodal*numbmodal];
                            for (int m1=0; m1<numbmodal; m1++) {
                                for (int m2=0; m2<numbmodal; m2++) {
                                    if (m1==m2) {
                                        ParametersSplit[0]->PriorsCov[m1+m2*numbmodal]=sumResp*0.5*ParametersSplit[0]->ValueParameters[numbmodal+m1+m2*numbmodal];
                                        ParametersSplit[1]->PriorsCov[m1+m2*numbmodal]=sumResp*0.5*ParametersSplit[1]->ValueParameters[numbmodal+m1+m2*numbmodal];
                                    }
                                    else{
                                        ParametersSplit[0]->PriorsCov[m1+m2*numbmodal]=0;
                                        ParametersSplit[1]->PriorsCov[m1+m2*numbmodal]=0;
                                    }
                                }
                            }
                        }
                            break;
//                        case 2:{ // case with the general covariance matrix Both sides are enforced, no test needed
//                            ParametersSplit[0]->PriorsCovFlag=1;
//                            ParametersSplit[1]->PriorsCovFlag=1;
//                            // Get Nz from ParentToSplit and NormWeight
//                            float * GeneralCovPriors= this->GetPriorsCovMatrixGeneral(segment_param);
//                            float * NormRespParent=ParentToSplit->GetChild(ChildToSplit)->GetNormResp();
//                            PrecisionTYPE sumResp=0;
//                            for (int i=0; i<numelmasked; i++,NormRespParent++) {
//                                sumResp+=*NormRespParent;
//                            }
//                            if (ParametersSplit[0]->PriorsCov!=NULL) {
//                                delete [] ParametersSplit[0]->PriorsCov;
//                                ParametersSplit[0]->PriorsCov=NULL;
//                            }
//                            if (ParametersSplit[1]->PriorsCov!=NULL) {
//                                delete [] ParametersSplit[1]->PriorsCov;
//                                ParametersSplit[1]->PriorsCov=NULL;
//                            }
//                            ParametersSplit[0]->PriorsCov=new float[numbmodal*numbmodal];
//                            ParametersSplit[1]->PriorsCov=new float[numbmodal*numbmodal];
//                            for (int m1=0; m1<numbmodal; m1++) {
//                                for (int m2=0; m2<numbmodal; m2++) {
//                                    ParametersSplit[0]->PriorsCov[m1+m2*numbmodal]=sumResp*0.5*GeneralCovPriors[m1+m2*numbmodal];                                        ParametersSplit[1]->PriorsCov[m1+m2*numbmodal]=sumResp*0.5*GeneralCovPriors[m1+m2*numbmodal];
//                                }
//                            }
//                            
//                        }
//                            break;
                        default:
                            break;
                    }
                }
                    break;
                default: // value 0 or other : No change made.
                    break;
            }

        }
        
        
        (ParentToSplit->GetChild(ChildToSplit))->CreateAndAddChildWeight(segment_param,0.5,1);
        (ParentToSplit->GetChild(ChildToSplit))->CreateAndAddChildWeight(segment_param,0.5,1);
        (ParentToSplit->GetChild(ChildToSplit)->GetChild(0))->SetParameters(ParametersSplit[0]);
        (ParentToSplit->GetChild(ChildToSplit)->GetChild(1))->SetParameters(ParametersSplit[1]);

        // Clearing memory dedicated to Parameters split
        delete ParametersSplit[0];
        ParametersSplit[0]=NULL;
        delete ParametersSplit[1];
        ParametersSplit[1]=NULL;
        delete [] ParametersSplit;
        ParametersSplit=NULL;
//        this->GetChild(ChildToSplit)->GetChild(0)->SetNormWeight(0.5);
//        this->GetChild(ChildToSplit)->GetChild(1)->SetNormWeight(0.5);
        //    this->PutAllLeavesToChildrenLevel();
        return;
    }
    }
    }

    return;
}

// Performs the Split operation and modify accordingly the tree
void TreeEM::SplitOperation(SplitKLD_b * SplitTry, int choiceInit,SEG_PARAMETERS * segment_param){
    // Check if it is effectively a child that can be split
    TreeEM * ParentToSplit = this->FindFromHierarchy(SplitTry->HierarchyParent);
    int numbchild=ParentToSplit->GetNumberChildren();
    int numbmodal=this->GetNumberModalities();
    int ChildToSplit=SplitTry->ChildToSplit;
    if (ChildToSplit>=numbchild||ChildToSplit<0) {
        cout<<"Child to split out of bounds"<<endl;
        return;
    }
    else if (ParentToSplit->GetChild(ChildToSplit)->GetNumberChildren()!=0) {
        cout<<"Impossible to split something else than leaf"<<endl;
        return;
    }
    else if (segment_param->SplitAccept <2 && ParentToSplit->GetChild(ChildToSplit)->GetNormWeight()<segment_param->WeightMini/5) {
        cout<<"Impossible to split an already too small class"<<endl;
        return;
    }
    else if(segment_param->SplitAccept==2 && !ParentToSplit->IsRoot() && ParentToSplit->GetChild(ChildToSplit)->GetNormWeight()<segment_param->WeightMini/5){
        cout<<"Impossible to split a too small class on the second level"<<endl;
        return;
    }
    else{
        cout<<"Trying split operation initialisation"<<endl;
        switch(SplitTry->TypeChange){
            case 0:{ // case where the split transforms the uniform distribution into a unique Gaussian
                float * Mean=ParentToSplit->GetChild(ChildToSplit)->GetMeanDirect();
                float * Variance=ParentToSplit->GetChild(ChildToSplit)->GetDiagVarianceDirect_corr();
                // Building of the parameters of newly formed Gaussian
                Parameters * ParametersSplit=new Parameters();
                ParametersSplit->DistributionType=1;
                ParametersSplit->SizeParameters=CalculateSizeParameters(ParametersSplit->DistributionType);
                ParametersSplit->ValueParameters=new float[ParametersSplit->SizeParameters];//{0};
                for(int i=0;i<ParametersSplit->SizeParameters;i++){
                    ParametersSplit->ValueParameters[i]=0;
                }
                for(int m=0;m<numbmodal;m++){
                    ParametersSplit->ValueParameters[m]=Mean[m];
                }
                for(int m1=0;m1<numbmodal;m1++){
                    for(int m2=0;m2<numbmodal;m2++){
                        if(m1==m2){
                            ParametersSplit->ValueParameters[numbmodal+m1*numbmodal+m2]=Variance[m1];
                        }
                    }
                }
                ParentToSplit->GetChild(ChildToSplit)->SetParameters(ParametersSplit);
                // Clearing memory used for parameters construction
                delete [] Mean;
                Mean=NULL;
                delete [] Variance;
                Variance = NULL;
                delete ParametersSplit;
                ParametersSplit=NULL;
                break;
            }
            case 2:{//or uniform giving two gaussian at first step
                Parameters ** ParametersSplit=(ParentToSplit->GetChild(ChildToSplit))->ParametersDoubleForSplittingUniform( choiceInit);
                (ParentToSplit->GetChild(ChildToSplit))->CreateAndAddChildWeight(segment_param,0.5,1);
                (ParentToSplit->GetChild(ChildToSplit))->CreateAndAddChildWeight(segment_param,0.5,1);
                (ParentToSplit->GetChild(ChildToSplit)->GetChild(0))->SetParameters(ParametersSplit[0]);
                (ParentToSplit->GetChild(ChildToSplit)->GetChild(1))->SetParameters(ParametersSplit[1]);
                
                // Clearing memory dedicated to Parameters split
                delete ParametersSplit[0];
                ParametersSplit[0]=NULL;
                delete ParametersSplit[1];
                ParametersSplit[1]=NULL;
                delete ParametersSplit;
                ParametersSplit=NULL;
                //        this->GetChild(ChildToSplit)->GetChild(0)->SetNormWeight(0.5);
                //        this->GetChild(ChildToSplit)->GetChild(1)->SetNormWeight(0.5);
                //    this->PutAllLeavesToChildrenLevel();
                break;
                return;
            }
            case 3:{ // uniform giving one gaussian + uniform
                Parameters * ParametersSplit=(ParentToSplit->GetChild(ChildToSplit))->ParametersForSplittingUniform3(segment_param,SplitTry->InitSplitUnif);
                //        nifti_image * PriorsToAdd=ParentToSplit->GetChild(ChildToSplit)->CreatePriorsFromAdaptedPriors();
                //        nifti_image * PriorsConstant=ParentToSplit->BuildConstantPriors(segment_param->OutliersWeight);
                nifti_image * PriorsToAdd=ParentToSplit->GetChild(ChildToSplit)->CreatePriorsFromAdaptedPriors();
                MultiplyNii(PriorsToAdd,0.5);
                nifti_image * PriorsConstant=ParentToSplit->BuildConstantPriors(ParentToSplit->GetChild(ChildToSplit)->GetNormWeight()*0.5); // In this case, the uniform is always at the first level, so NormWeight is proper value to take into account
                ParentToSplit->GetChild(ChildToSplit)->SetPriors(PriorsToAdd);
                ParentToSplit->GetChild(ChildToSplit)->SetParameters(ParametersSplit);
                ParentToSplit->NormalisePriors(); // first normalisation before adding the uniform as done at first initialisation otherwise prior of uniform not constant over image.
                ParentToSplit->NormalisePriorsAdapted();
                ParentToSplit->CreateAndAddChildPriors(segment_param,PriorsConstant,2);
                ParentToSplit->NormalisePriors();
                ParentToSplit->NormalisePriorsAdapted();
                
                
                // Clearing memory dedicated to Parameters split
                delete ParametersSplit;
                ParametersSplit=NULL;
                break;
                return;
                
            }
            case 4:{ // uniform giving one gaussian and one uniform under same priors
                Parameters * ParametersSplit=(ParentToSplit->GetChild(ChildToSplit))->ParametersForSplittingUniform3(segment_param,SplitTry->InitSplitUnif);
                cout<<"Parameters obtained"<<endl;
                (ParentToSplit->GetChild(ChildToSplit))->CreateAndAddChildWeight(segment_param,1-segment_param->UnifSplitWeight,1);
                (ParentToSplit->GetChild(ChildToSplit)->GetChild(0))->SetParameters(ParametersSplit);
                (ParentToSplit->GetChild(ChildToSplit))->CreateAndAddChildWeight(segment_param,segment_param->UnifSplitWeight,2);
                cout<<"Consequent children created"<<endl;
                // Clearing memory dedicated to Parameters split
                delete ParametersSplit;
                ParametersSplit=NULL;
                break;
                return;
            }
            case 5:{ // case where a uniform gives one gaussian and one uniform with adapted initial atlases
                vector<nifti_image *> PriorsSUG=ParentToSplit->GetChild(ChildToSplit)->CreatePriorsFromSplittingUniform(segment_param,SplitTry->InitSplitUnif); // After this operation, a child has already been added with the appropriate parameters for the gaussian part of the splitting.
                if (ParentToSplit->IsRoot() || (ParentToSplit->GetLevel()==1 && (this->GetFlagOutliers()==3||this->GetFlagOutliers()>=5))) { // the additional layer added by the previous operation is conserved.
                    ParentToSplit->GetChild(ChildToSplit)->GetChild(0)->SetPriors(PriorsSUG[0]);
                    ParentToSplit->GetChild(ChildToSplit)->CreateAndAddChildPriors(segment_param,PriorsSUG[1],2);
                }
                else{ // In this case, put the uniform and the Gaussian side by side instead of creating new layer
                    // First set the parameters to the
                    ParentToSplit->GetChild(ChildToSplit)->SetParameters(ParentToSplit->GetChild(ChildToSplit)->GetChild(0)->GetParameters());
                    delete ParentToSplit->GetChild(ChildToSplit)->GetChild(0);
                    ParentToSplit->GetChild(ChildToSplit)->Children.erase(ParentToSplit->GetChild(ChildToSplit)->Children.begin()); // <=> collapse only child
                    // Then need to take care of atlases. As only one level for the outliers main node, need to multiply the atlases formed for the split by the atlas of the uniform split.
                    int sizeSUGPriors=PriorsSUG.size();
                    for (int i=0; i<sizeSUGPriors; i++) {
                        MultiplyNiiByNii(PriorsSUG[i], ParentToSplit->GetChild(ChildToSplit)->GetPriorsDirect());
                    }
                    ParentToSplit->GetChild(ChildToSplit)->SetPriors(PriorsSUG[0]);
                    ParentToSplit->GetChild(ChildToSplit)->SetPriorsAdapted(static_cast<float *>(PriorsSUG[0]->data));
                    ParentToSplit->CreateAndAddChildPriors(segment_param,PriorsSUG[1],2);
                    ParentToSplit->NormalisePriors();
                    ParentToSplit->NormalisePriorsAdapted();
                    if(segment_param->flag_savePriors){
                        this->SavePriorsAdapted(segment_param);
                    }
                    //            nifti_set_filenames(PriorsSUG[0], "/Users/Carole/Documents/PhD/TestGcase5.nii.gz", 0, 0);
                    //            nifti_set_filenames(PriorsSUG[1], "/Users/Carole/Documents/PhD/TestUcase5.nii.gz", 0, 0);
                    //            nifti_image_write(PriorsSUG[0]);
                    //            nifti_image_write(PriorsSUG[1]);
                }
                break;
                return;
            }
                
            default :{ // classical case where the split happens on a gaussian distributed class
                Parameters ** ParametersSplit=(ParentToSplit->GetChild(ChildToSplit))->ParametersForSplitting( choiceInit);
                
                if (segment_param->flag_CovPriors) {
                    int numelmasked=this->GetNumberMaskedElements();
                    int numbmodal=this->GetNumberModalities();
                    switch (segment_param->CovPriorsSplit) {
                        case 1: {// ParametersSplit[0] modified only
                            switch (segment_param->CovPriorsType) {
                                case 1:{
                                    ParametersSplit[0]->PriorsCovFlag=1;
                                    // Get Nz from ParentToSplit and NormWeight
                                    float * NormRespParent=ParentToSplit->GetChild(ChildToSplit)->GetNormResp();
                                    PrecisionTYPE sumResp=0;
                                    for (int i=0; i<numelmasked; i++,NormRespParent++) {
                                        sumResp+=*NormRespParent;
                                    }
                                    if (ParametersSplit[0]->PriorsCov!=NULL) {
                                        delete [] ParametersSplit[0]->PriorsCov;
                                        ParametersSplit[0]->PriorsCov=NULL;
                                    }
                                    ParametersSplit[0]->PriorsCov=new float[numbmodal*numbmodal];
                                    for (int m1=0; m1<numbmodal; m1++) {
                                        for (int m2=0; m2<numbmodal; m2++) {
                                            if (m1==m2) {
                                                ParametersSplit[0]->PriorsCov[m1+m2*numbmodal]=sumResp*0.5*ParametersSplit[0]->ValueParameters[numbmodal+m1+m2*numbmodal];
                                            }
                                            else{
                                                ParametersSplit[0]->PriorsCov[m1+m2*numbmodal]=0;
                                            }
                                        }
                                    }
                                    // Ensure that there is nothing on other parameter structure
                                    ParametersSplit[1]->PriorsCovFlag=0;
                                    if (ParametersSplit[1]->PriorsCov!=NULL) {
                                        delete [] ParametersSplit[1]->PriorsCov;
                                        ParametersSplit[1]->PriorsCov=NULL;
                                    }
                                }
                                    break;
                                    
                                default:
                                    break;
                            }
                            
                        }
                            break;
                        case 2:{ // ParametersSplit[1] constrained only
                            switch (segment_param->CovPriorsType) {
                                case 1:{
                                    ParametersSplit[1]->PriorsCovFlag=1;
                                    // Get Nz from ParentToSplit and NormWeight
                                    float * NormRespParent=ParentToSplit->GetChild(ChildToSplit)->GetNormResp();
                                    PrecisionTYPE sumResp=0;
                                    for (int i=0; i<numelmasked; i++,NormRespParent++) {
                                        sumResp+=*NormRespParent;
                                    }
                                    if (ParametersSplit[1]->PriorsCov!=NULL) {
                                        delete [] ParametersSplit[1]->PriorsCov;
                                        ParametersSplit[1]->PriorsCov=NULL;
                                    }
                                    ParametersSplit[1]->PriorsCov=new float[numbmodal*numbmodal];
                                    for (int m1=0; m1<numbmodal; m1++) {
                                        for (int m2=0; m2<numbmodal; m2++) {
                                            if (m1==m2) {
                                                ParametersSplit[1]->PriorsCov[m1+m2*numbmodal]=sumResp*0.5*ParametersSplit[1]->ValueParameters[numbmodal+m1+m2*numbmodal];
                                            }
                                            else{
                                                ParametersSplit[1]->PriorsCov[m1+m2*numbmodal]=0;
                                            }
                                        }
                                    }
                                    // Ensure that there is nothing on other parameter structure
                                    ParametersSplit[0]->PriorsCovFlag=0;
                                    if (ParametersSplit[0]->PriorsCov!=NULL) {
                                        delete [] ParametersSplit[1]->PriorsCov;
                                        ParametersSplit[0]->PriorsCov=NULL;
                                    }
                                }
                                    break;
                                    
                                default:
                                    break;
                            }
                        }
                            break;
                        case 3: { // Both ParametersSplit constrained
                            switch (segment_param->CovPriorsType) {
                                case 1:{
                                    ParametersSplit[0]->PriorsCovFlag=1;
                                    ParametersSplit[1]->PriorsCovFlag=1;
                                    // Get Nz from ParentToSplit and NormWeight
                                    float * NormRespParent=ParentToSplit->GetChild(ChildToSplit)->GetNormResp();
                                    PrecisionTYPE sumResp=0;
                                    for (int i=0; i<numelmasked; i++,NormRespParent++) {
                                        sumResp+=*NormRespParent;
                                    }
                                    if (ParametersSplit[0]->PriorsCov!=NULL) {
                                        delete [] ParametersSplit[0]->PriorsCov;
                                        ParametersSplit[0]->PriorsCov=NULL;
                                    }
                                    if (ParametersSplit[1]->PriorsCov!=NULL) {
                                        delete [] ParametersSplit[1]->PriorsCov;
                                        ParametersSplit[1]->PriorsCov=NULL;
                                    }
                                    ParametersSplit[0]->PriorsCov=new float[numbmodal*numbmodal];
                                    ParametersSplit[1]->PriorsCov=new float[numbmodal*numbmodal];
                                    for (int m1=0; m1<numbmodal; m1++) {
                                        for (int m2=0; m2<numbmodal; m2++) {
                                            if (m1==m2) {
                                                ParametersSplit[0]->PriorsCov[m1+m2*numbmodal]=sumResp*0.5*ParametersSplit[0]->ValueParameters[numbmodal+m1+m2*numbmodal];
                                                ParametersSplit[1]->PriorsCov[m1+m2*numbmodal]=sumResp*0.5*ParametersSplit[1]->ValueParameters[numbmodal+m1+m2*numbmodal];
                                            }
                                            else{
                                                ParametersSplit[0]->PriorsCov[m1+m2*numbmodal]=0;
                                                ParametersSplit[1]->PriorsCov[m1+m2*numbmodal]=0;
                                            }
                                        }
                                    }
                                }
                                    break;
//                                case 2:{ // case with the general covariance matrix Both sides are enforced, no test needed
//                                    ParametersSplit[0]->PriorsCovFlag=1;
//                                    ParametersSplit[1]->PriorsCovFlag=1;
//                                    // Get Nz from ParentToSplit and NormWeight
//                                    float * GeneralCovPriors= this->GetPriorsCovMatrixGeneral(segment_param);
//                                    float * NormRespParent=ParentToSplit->GetChild(ChildToSplit)->GetNormResp();
//                                    PrecisionTYPE sumResp=0;
//                                    for (int i=0; i<numelmasked; i++,NormRespParent++) {
//                                        sumResp+=*NormRespParent;
//                                    }
//                                    if (ParametersSplit[0]->PriorsCov!=NULL) {
//                                        delete [] ParametersSplit[0]->PriorsCov;
//                                        ParametersSplit[0]->PriorsCov=NULL;
//                                    }
//                                    if (ParametersSplit[1]->PriorsCov!=NULL) {
//                                        delete [] ParametersSplit[1]->PriorsCov;
//                                        ParametersSplit[1]->PriorsCov=NULL;
//                                    }
//                                    ParametersSplit[0]->PriorsCov=new float[numbmodal*numbmodal];
//                                    ParametersSplit[1]->PriorsCov=new float[numbmodal*numbmodal];
//                                    for (int m1=0; m1<numbmodal; m1++) {
//                                        for (int m2=0; m2<numbmodal; m2++) {
//                                            ParametersSplit[0]->PriorsCov[m1+m2*numbmodal]=sumResp*0.5*GeneralCovPriors[m1+m2*numbmodal];                                        ParametersSplit[1]->PriorsCov[m1+m2*numbmodal]=sumResp*0.5*GeneralCovPriors[m1+m2*numbmodal];
//                                        }
//                                    }
//                                    
//                                }
//                                    break;
                                    
                                default:
                                    break;
                            }
                        }
                            break;
                        default: // value 0 or other : No change made.
                            break;
                    }
                    
                }
                
                (ParentToSplit->GetChild(ChildToSplit))->CreateAndAddChildWeight(segment_param,0.5,1);
                (ParentToSplit->GetChild(ChildToSplit))->CreateAndAddChildWeight(segment_param,0.5,1);
                (ParentToSplit->GetChild(ChildToSplit)->GetChild(0))->SetParameters(ParametersSplit[0]);
                (ParentToSplit->GetChild(ChildToSplit)->GetChild(1))->SetParameters(ParametersSplit[1]);
                
                // Clearing memory dedicated to Parameters split
                delete ParametersSplit[0];
                ParametersSplit[0]=NULL;
                delete ParametersSplit[1];
                ParametersSplit[1]=NULL;
                delete [] ParametersSplit;
                ParametersSplit=NULL;
                //        this->GetChild(ChildToSplit)->GetChild(0)->SetNormWeight(0.5);
                //        this->GetChild(ChildToSplit)->GetChild(1)->SetNormWeight(0.5);
                //    this->PutAllLeavesToChildrenLevel();
                return;
            }
        }
    }
    
    return;
}

void TreeEM::MultiplyNii(nifti_image * ImageToMultiply, float MultFactor){
    float * DataPTR=static_cast<float *>(ImageToMultiply->data);
    int numel=ImageToMultiply->nvox;
    for (int i=0; i<numel; i++,DataPTR++) {
        *DataPTR*=MultFactor;
    }
}

nifti_image * TreeEM::AddNii(nifti_image * ImageToChange, float FloatToAdd){
    if (ImageToChange==NULL) {
        return NULL;
    }
    nifti_image * NewImage=nifti_copy_nim_info(ImageToChange);
    // We assume that it is a float image...
    NewImage->data=(void *)calloc(NewImage->nvox, sizeof(float));
    float * NewImage_PTR=static_cast<float *>(NewImage->data);
    float * ImageToChange_PTR=static_cast<float *>(ImageToChange->data);
    int numel=NewImage->nvox;
    for (int i=0; i<numel; i++,NewImage_PTR++,ImageToChange_PTR++) {
        *NewImage_PTR=*ImageToChange_PTR+FloatToAdd;
    }
    return NewImage;
}

nifti_image * TreeEM::CreateNormaliseOppositeImage(nifti_image * ImageToOppose){
    if (ImageToOppose==NULL) {
        return NULL;
    }
    nifti_image * NewImage=nifti_copy_nim_info(ImageToOppose);
    NewImage->data=(void *)calloc(NewImage->nvox, sizeof(float));
    int numel=NewImage->nvox;
    float * NewImage_PTR=static_cast<float *>(NewImage->data);
    for (int i=0; i<numel; i++) {
        NewImage_PTR[i]=1;
    }
    float * ImageToOppose_PTR=static_cast<float *>(ImageToOppose->data);
    
    for (int i=0; i<numel; i++) {
        NewImage_PTR[i]-=ImageToOppose_PTR[i];
        if (NewImage_PTR[i]+(ImageToOppose_PTR[i])<1) {
            cout<<"Pb inf 1";
        }
    }
    return NewImage;
}

void TreeEM::MultiplyNii(nifti_image * ImageToMultiply, nifti_image * MultiplicativeImage){
    if (ImageToMultiply->nx!=MultiplicativeImage->nx || ImageToMultiply->nu!=MultiplicativeImage->nu || ImageToMultiply->ny!=MultiplicativeImage->ny || ImageToMultiply->nz!=MultiplicativeImage->nz || MultiplicativeImage==NULL) {
        cout << "Dimensionality pb"<<endl;
        return;
    }
    else{
        int numel=ImageToMultiply->nvox;
        float * Data_PTR=static_cast<float*>(ImageToMultiply->data);
        float * Multiplicative_PTR=static_cast<float*>(MultiplicativeImage->data);
        for (int i=0; i<numel; i++,Data_PTR++,Multiplicative_PTR++) {
            *Data_PTR*=*Multiplicative_PTR;
        }
    }
}

// Performs the Split operation and modify accordingly the tree
void TreeEM::SplitOperation(int ChildToSplit, int choiceInit,SEG_PARAMETERS * segment_param){
    // Check if it is effectively a child that can be split
    int numbchild=this->GetNumberChildren();
    if (ChildToSplit>=numbchild||ChildToSplit<0) {
        cout<<"Child to split out of bounds"<<endl;
        return;
    }
    if (this->GetChild(ChildToSplit)->GetNumberChildren()!=0) {
        cout<<"Impossible to split something else than leaf"<<endl;
        return;
    }
    Parameters ** ParametersSplit=(this->GetChild(ChildToSplit))->ParametersForSplitting( choiceInit);
    (this->GetChild(ChildToSplit))->CreateAndAddChildPriors(segment_param,NULL,1);
    (this->GetChild(ChildToSplit))->CreateAndAddChildPriors(segment_param,NULL,1);
    (this->GetChild(ChildToSplit)->GetChild(0))->SetParameters(ParametersSplit[0]);
    (this->GetChild(ChildToSplit)->GetChild(1))->SetParameters(ParametersSplit[1]);

    // Clearing memory dedicated to Parameters split
    delete ParametersSplit[0];
    ParametersSplit[0]=NULL;
    delete ParametersSplit[1];
    ParametersSplit[1]=NULL;
    delete [] ParametersSplit;
    ParametersSplit=NULL;
    this->GetChild(ChildToSplit)->GetChild(0)->SetNormWeight(0.5);
    this->GetChild(ChildToSplit)->GetChild(1)->SetNormWeight(0.5);
    //    this->PutAllLeavesToChildrenLevel();
    return;
}

Parameters * TreeEM::ParametersForSplittingUniform3(SEG_PARAMETERS * segment_param, int InitSplitUnif=0){
    if(this->GetDistributionType()!=2){ // check if we are trying to split a uniform distribution
        return NULL;
    }
    int numbmodal=this->GetNumberModalities();
    int numbbinsGet=this->GetNumbbins();
    float * DataHistogram=this->GetDataHistogramTotal();
    vector<int> dimHist;
    for(int m=0;m<numbmodal;m++){
        dimHist.push_back(numbbinsGet);
    }
    float sizeBins=1.0/numbbinsGet;
    float * DataHistogramBlurred=GaussianBlurring(DataHistogram,1,dimHist);
    float maxHist=-1;
    int numberHistElements=(int)pow_int(numbbinsGet,numbmodal);
    int maxInd=numbbinsGet/2;
    for(int i=0;i<numberHistElements;i++){
        
        if(DataHistogramBlurred[i]>maxHist){
            maxInd=i;
            maxHist=DataHistogramBlurred[i];
        }
    }
    
//    for(int i=numbbinsGet;i<numberHistElements-numbbinsGet;i=i+numbbinsGet){
//        for (int j=1; j<numbbinsGet-1; j++) {
//            if(DataHistogramBlurred[i+j]>maxHist){
//                maxInd=i+j;
//                maxHist=DataHistogramBlurred[i+j];
//            }
//        }
//    }

    // Transform maxInd found into Index for each modality
    int * MaxIndPerModal=new int[numbmodal];
    for(int m=0;m<numbmodal;m++){
        MaxIndPerModal[m]=0;
    }
    int tmp=maxInd;
    for(int m=numbmodal-1;m>=0;m--){
        int powNumbGetm=(int)pow_int(numbbinsGet, m);
        MaxIndPerModal[m]=tmp/powNumbGetm;
        tmp=tmp-MaxIndPerModal[m]*powNumbGetm;
    }
    // create the parameters corresponding to the gaussian to create
    Parameters * ParametersSplit=new Parameters();
    ParametersSplit->DistributionType=1;
    ParametersSplit->SizeParameters=CalculateSizeParameters(ParametersSplit->DistributionType);
    ParametersSplit->ValueParameters=new float[ParametersSplit->SizeParameters];
        //Initialise parameters at value 0:
    int SizeParametersToUse=numbmodal+numbmodal*numbmodal;
    for(int m=0;m<SizeParametersToUse;m++){
        ParametersSplit->ValueParameters[m]=0;
    }
//    MaxIndPerModal[0]=15;
//    MaxIndPerModal[1]=55;

    // Transform the index max to form the mean of the parameters
    float * Variance=this->GetVarianceDirect();
//    float DeterminantVarianceDirect=determinant(Variance, numbmodal);
//    float MinVariance=pow_int(sizeBins, numbmodal);
    float * Mean = new float[numbmodal];
    for(int m=0;m<numbmodal;m++){
        Mean[m]=MaxIndPerModal[m]*sizeBins;
    }
    // copy values into value parameters. Only one possibility for mean but might have different choices for the initialisation of the variance. Look more into the changes introduced
    for(int m1=0;m1<numbmodal;m1++){
        ParametersSplit->ValueParameters[m1]=Mean[m1];
    }
    // switch for the variance initialisation
    switch (segment_param->VarianceInitUnif) {
        case 0: // divide all values of variance direct by 10 but might be extremely peaked.
            for (int m1=0; m1<numbmodal; m1++) {
                for(int m2=0;m2<numbmodal;m2++){
                    ParametersSplit->ValueParameters[numbmodal+m1+m2*numbmodal]=Variance[m1+numbmodal*m2]/10;
                }
            }
            break;
        case 1:{
            // To modify and put the k-means initialisation there
            int numbLabels=2;
//            TreeEM * UnifNode=this->FindUnifDist(segment_param);
            TreeEM * UnifNode=this;
            float * VarianceDirect=UnifNode->GetVarianceDirect();
            SVD SVDUnifNode=SVD(VarianceDirect,numbmodal,numbmodal);
            float * SVDEigen=SVDUnifNode.getSingularValues();
            float * SVDVec=SVDUnifNode.getV();
            float *MeanDirect=NULL;
            float ** MeanK=new float* [numbLabels];
            if(segment_param->flag_KMeansModif){ // Case where the kmeans do not use the MeanDirect but the MaxHist to be initialised
                MeanDirect=new float[numbmodal];
                for (int m=0; m<numbmodal; m++) {
                    MeanDirect[m]=Mean[m];
                }
                float * Check=UnifNode->GetMeanDirect();
                cout<<"Checking..."<<endl;
                MeanK[0]=new float[numbmodal];
                MeanK[1]=new float[numbmodal];
                for (int m=0; m<numbmodal; m++) {
                    MeanK[0][m]=MeanDirect[m];
                    MeanK[1][m]=Check[m];
                }
                delete [] Check;
                Check=NULL;
            }
            else{
            MeanDirect=UnifNode->GetMeanDirect();
                for (int l=0; l<numbLabels; l++) {
                    MeanK[l]=new float [numbmodal];
                    float powm1l=pow_int(-1, l);
                    for (int m=0; m<numbmodal; m++) {
                        MeanK[l][m]=MeanDirect[m]+sqrtf(SVDEigen[0])*l*segment_param->DistInitUnif/2*powm1l*SVDVec[m];
                    }
                }
            }

            delete [] MeanDirect;
            MeanDirect=NULL;
            delete [] VarianceDirect;
            VarianceDirect=NULL;
            int * Label=this->KMeansInitialisationForUniform(MeanK, numbLabels, segment_param);
            float ** MeanKMeans=UnifNode->GetMeanDirectLabel(Label,numbLabels);
            float ** VarianceKMeans=UnifNode->GetVarianceDirectLabel(Label,numbLabels);
            // Choice of the set of parameters to be consider for the Gaussian
            int OptChoiceInitSplitUnifKMeans=0;
            if (InitSplitUnif==0) {
                OptChoiceInitSplitUnifKMeans=segment_param->choiceInitSplitUnifKMeans;
            }
            else{
                OptChoiceInitSplitUnifKMeans=InitSplitUnif;
            }
            switch (OptChoiceInitSplitUnifKMeans) {
                case 0: // choose the set of parameters corresponding to the smallest variance determinant
                {
                    float * Determinant=new float[numbLabels];
                    for (int l=0; l<numbLabels; l++) {
                        Determinant[l]=0;
                    }
                    // Determine the lowest variance determinant and the corresponding index
                    float minDet=1E32;
                    int minDetLabel=-1;
                    for (int l=0; l<numbLabels; l++) {
                        Determinant[l]=determinant(VarianceKMeans[l], numbmodal);
                        bool NanInMeanK=0;
                        for (int m=0; m<numbmodal; m++) {
                            if (MeanK[l][m]!=MeanK[l][m]) {
                                NanInMeanK=1;
                                cout<<"Nan in mean !"<<endl;
                                break;
                            }
                        }
                        if (minDet>Determinant[l] && Determinant[l]>0 && !NanInMeanK) {
                            minDet=Determinant[l];
                            minDetLabel=l;
                        }
                    }
                    delete [] Determinant;
                    Determinant=NULL;
                    // Once the corresponding label determined, fill the values of parameterSplit
                    if (minDetLabel==-1) {
                        float * MeanDirect=UnifNode->GetMeanDirect();
                        float * VarianceDirect=UnifNode->GetVarianceDirect();
                        for (int m1=0; m1<numbmodal; m1++) {
                            ParametersSplit->ValueParameters[m1]=MeanDirect[m1];
                            for (int m2=0; m2<numbmodal; m2++) {
                                ParametersSplit->ValueParameters[numbmodal+m1*numbmodal+m2]=VarianceDirect[m1*numbmodal+m2];
                            }
                        }
                        if (MeanDirect!=NULL) {
                            delete [] MeanDirect;
                            MeanDirect=NULL;
                        }
                        if (VarianceDirect!=NULL) {
                            delete [] VarianceDirect;
                            VarianceDirect=NULL;
                        }
                    }
                    else{
                        float * PotentialVar=NULL;
                        int numelmasked=this->GetNumberMaskedElements();
                        if (this->GetFlagCovPriors()>=8) {
                            float * PotentialVar= this->FindRoot()->CreateCovPriorsForInverseWishart();
                            if (PotentialVar!=NULL) {
                                for (int m1=0; m1<numbmodal; m1++) {
                                    for (int m2=0; m2<numbmodal; m2++) {
                                        PotentialVar[m1+numbmodal*m2]*=1.0/(expf(MeanKMeans[minDetLabel][m1]+MeanKMeans[minDetLabel][m2])*numelmasked);
                                    }
                                }
                            }
                        }
                        for (int m1=0; m1<numbmodal; m1++) {
                            ParametersSplit->ValueParameters[m1]=MeanKMeans[minDetLabel][m1];
                            if (PotentialVar!=NULL) {
                                for (int m2=0; m2<numbmodal; m2++) {
                                    ParametersSplit->ValueParameters[numbmodal+m1*numbmodal+m2]=PotentialVar[m1*numbmodal+m2];
                            }
                            }
                            else{
                            for (int m2=0; m2<numbmodal; m2++) {
                                ParametersSplit->ValueParameters[numbmodal+m1*numbmodal+m2]=VarianceKMeans[minDetLabel][m1*numbmodal+m2];
                            }
                            }
                        }
                        if (PotentialVar!=NULL) {
                            delete [] PotentialVar;
                            PotentialVar=NULL;
                        }
                    }
                }
                    break;
                case 1: // choose the set of parameters corresponding to the largest variance determinant
                {
                    float * Determinant=new float[numbLabels];
                    for (int l=0; l<numbLabels; l++) {
                        Determinant[l]=0;
                    }
                    // Determine the lowest variance determinant and the corresponding index
                    float maxDet=-1E32;
                    int maxDetLabel=0;
                    for (int l=0; l<numbLabels; l++) {
                        Determinant[l]=determinant(VarianceKMeans[l], numbmodal);
                        if (maxDet<Determinant[l]) {
                            maxDet=Determinant[l];
                            maxDetLabel=l;
                        }
                    }
                    delete [] Determinant;
                    Determinant=NULL;
                    // Once the corresponding label determined, fill the values of parameterSplit
                    for (int m1=0; m1<numbmodal; m1++) {
                        ParametersSplit->ValueParameters[m1]=MeanKMeans[maxDetLabel][m1];
                        for (int m2=0; m2<numbmodal; m2++) {
                            ParametersSplit->ValueParameters[numbmodal+m1*numbmodal+m2]=VarianceKMeans[maxDetLabel][m1*numbmodal+m2];
                        }
                    }
                }
                    break;
                    
                    
                default: // choose the set of parameters corresponding to the largest portion of the uniform class according to Labels and NormResp
                {
                    float * NormResp_PTR=UnifNode->GetNormResp();
                    float * WeightLabel=new float[numbLabels];
                    for (int l=0; l<numbLabels; l++) {
                        WeightLabel[l]=0;
                    }
                    int numelmasked=this->GetNumberMaskedElements();
                    for (int i=0; i<numelmasked; i++) {
                        WeightLabel[Label[i]]+=NormResp_PTR[i];
                    }
                    float maxWeightLabel=0;
                    int indMaxWeightLabel=0;
                    for (int l=0; l<numbLabels; l++) {
                        if (WeightLabel[l]>maxWeightLabel) {
                            maxWeightLabel=WeightLabel[l];
                            indMaxWeightLabel=l;
                        }
                    }
                    // Once the corresponding label determined, fill the values of parameterSplit
                    for (int m1=0; m1<numbmodal; m1++) {
                        ParametersSplit->ValueParameters[m1]=MeanKMeans[indMaxWeightLabel][m1];
                        for (int m2=0; m2<numbmodal; m2++) {
                            ParametersSplit->ValueParameters[numbmodal+m1*numbmodal+m2]=VarianceKMeans[indMaxWeightLabel][m1*numbmodal+m2];
                        }
                    }
                    delete [] WeightLabel;
                    WeightLabel=NULL;
                }
                    break;
            }
            for (int l=0; l<numbLabels; l++) {
                delete [] MeanK[l];
                MeanK[l]=NULL;
                delete [] MeanKMeans [l];
                MeanKMeans[l]=NULL;
                delete [] VarianceKMeans [l];
                VarianceKMeans[l]=NULL;
            }
            delete [] MeanK;
            MeanK=NULL;
            delete[] VarianceKMeans;
            VarianceKMeans=NULL;
            delete[] MeanKMeans;
            MeanKMeans=NULL;
            
            delete [] Label;
            Label=NULL;
        }
            break;
        default: // isotropic variance with variance size of a bin of the histogram or the variance direct divided by 2
            for (int m1=0; m1<numbmodal; m1++) {
                for(int m2=0;m2<numbmodal;m2++){
                    if(m1==m2){
                    ParametersSplit->ValueParameters[numbmodal+m1+m2*numbmodal]=min(sizeBins,Variance[m1+numbmodal*m2]/2);
                    }
                    else{
                        ParametersSplit->ValueParameters[numbmodal+m1+m2*numbmodal]=0;
                    }
                }
            }
            break;
    }
    
    // Determination of priors cov matrix if needed
    if (segment_param->flag_CovPriors) {
        int numelmasked=this->GetNumberMaskedElements();
        if (segment_param->CovPriorsSplit>0) {
 //priors on covariance enforced
                switch (segment_param->CovPriorsType) {
                    case 1:{
                        ParametersSplit->PriorsCovFlag=1;
                        // Get Nz from ParentToSplit and NormWeight
                        float * NormRespParent=this->GetNormResp();
                        PrecisionTYPE sumResp=0;
                        for (int i=0; i<numelmasked; i++,NormRespParent++) {
                            sumResp+=*NormRespParent;
                        }
                        if (ParametersSplit->PriorsCov!=NULL) {
                            delete [] ParametersSplit->PriorsCov;
                            ParametersSplit->PriorsCov=NULL;
                        }
                        ParametersSplit->PriorsCov=new float[numbmodal*numbmodal];
                        for (int m1=0; m1<numbmodal; m1++) {
                            for (int m2=0; m2<numbmodal; m2++) {
                                if (m1==m2) {
                                    ParametersSplit->PriorsCov[m1+m2*numbmodal]=sumResp*0.5*ParametersSplit->ValueParameters[numbmodal+m1+m2*numbmodal];
                                }
                                else{
                                    ParametersSplit->PriorsCov[m1+m2*numbmodal]=0;
                                }
                            }
                        }
                    }
                        break;
//                    case 2:{ // case with the general covariance matrix Both sides are enforced, no test needed
//                        ParametersSplit->PriorsCovFlag=1;
//                        
//                        // Get Nz from ParentToSplit and NormWeight
//                        float * GeneralCovPriors= this->GetPriorsCovMatrixGeneral();
//                        float * NormRespParent=this->GetNormResp();
//                        PrecisionTYPE sumResp=0;
//                        for (int i=0; i<numelmasked; i++,NormRespParent++) {
//                            sumResp+=*NormRespParent;
//                        }
//                        if (ParametersSplit->PriorsCov!=NULL) {
//                            delete [] ParametersSplit->PriorsCov;
//                            ParametersSplit->PriorsCov=NULL;
//                        }
//                        ParametersSplit->PriorsCov=new float[numbmodal*numbmodal];
//
//                        for (int m1=0; m1<numbmodal; m1++) {
//                            for (int m2=0; m2<numbmodal; m2++) {
//                                ParametersSplit->PriorsCov[m1+m2*numbmodal]=sumResp*0.5*GeneralCovPriors[m1+m2*numbmodal];
//                            }
//                        }
//                        
//                    }
//                        break;
                        
                    default:
                        break;
                }
 
            }
            else{// no covariance enforced
                ParametersSplit->PriorsCovFlag=0;
                if (ParametersSplit->PriorsCov!=NULL) {
                    delete [] ParametersSplit->PriorsCov;
                    ParametersSplit->PriorsCov=NULL;
                }
            }
    }


    // clearing memory
    delete [] Variance;
    Variance = NULL;
    delete [] Mean;
    Mean = NULL;
    delete[] MaxIndPerModal;
    MaxIndPerModal=NULL;
    delete [] DataHistogram;
    DataHistogram=NULL;
    delete [] DataHistogramBlurred;
    DataHistogramBlurred = NULL;
    dimHist.clear();

    return ParametersSplit;

}

int * TreeEM::KMeansInitialisationForUniform(float ** MeanK, int numbLabels, SEG_PARAMETERS * segment_param){
    int numelmasked=this->GetNumberMaskedElements();
    bool flag_change=1;
    int * LabelResult=new int[numelmasked];
    //Initialisation of the label result;
    for (int i=0; i<numelmasked; i++) {
        LabelResult[i]=0;
    }
    int numbmodal=this->GetNumberModalities();
//    TreeEM * UnifNode=this->FindUnifDist(segment_param);
    TreeEM * UnifNode=this;
    if (UnifNode->GetDistributionType()!=2) {
        return LabelResult;
    }
    float * UnifSeg=UnifNode->GetNormResp();
    float * DataCorrected=this->GetDataBFCorrected();
    float ** MeanKtmp=new float*[numbLabels];
    float * SumNormResp=new float[numbLabels];
    for (int l=0; l<numbLabels; l++) {
        MeanKtmp[l]=new float[numbmodal];
        SumNormResp[l]=0;
        for (int m=0; m<numbmodal; m++) {
            MeanKtmp[l][m]=0;
        }
    }
    float * Distance = new float[numbLabels];
    for (int l=0; l<numbLabels; l++) {
        Distance[l]=0;
    }
    int it=0;
    while (flag_change==1) {
        flag_change=0;
        it++;
        // First update of the classification according to the mean
        for (int i=0; i<numelmasked; i++) {
            // calculation of the distance
            for (int l=0; l<numbLabels; l++) {
                Distance[l]=0;
            }

            for (int m=0; m<numbmodal; m++) {
                for (int l=0; l<numbLabels; l++) {
                    Distance[l]+=pow_int(MeanK[l][m]-DataCorrected[i+m*numelmasked], 2);
                }
            }
            int LabelMin=-1;
            float MinDistLabel=1E32;
            for (int l=0; l<numbLabels; l++) {
                if (Distance[l]<MinDistLabel) {
                    MinDistLabel=Distance[l];
                    LabelMin=l;
                }
            }

            for (int l=0; l<numbLabels; l++) {
                if (LabelResult[i]!=LabelMin) {
                    LabelResult[i]=l;
                    flag_change=1;
                }
            }

                    }
        // Then update of the mean according to the previous classification
        for (int l=0; l<numbLabels; l++) {
            SumNormResp[l]=0;
            for (int m=0; m<numbmodal; m++) {
                MeanKtmp[l][m]=0;
            }
        }
        for (int i=0; i<numelmasked; i++) {
                SumNormResp[LabelResult[i]]+=UnifSeg[i];
                for (int m=0; m<numbmodal; m++) {
                    MeanKtmp[LabelResult[i]][m]+=UnifSeg[i]*DataCorrected[i+m*numelmasked];
                }
            }
        for (int l=0; l<numbLabels; l++) {
            for (int m=0; m<numbmodal; m++) {
                if(SumNormResp[l]>0){
                MeanK[l][m]=MeanKtmp[l][m]/SumNormResp[l];
                }
                else{
                    cout << "Label void in K means init"<<endl;
                }
            }
        }
        if (it>=10000) { // In case convergence cannot be reached in less than 10 000 iterations, consider that the convergence has been reached
            flag_change=0;
        }
    }
    for (int l=0; l<numbLabels; l++) {
        delete[] MeanKtmp[l];
        MeanKtmp[l]=NULL;
    }
    delete [] Distance;
    Distance=NULL;
    delete [] MeanKtmp;
    MeanKtmp=NULL;
    delete [] SumNormResp;
    SumNormResp=NULL;
    return LabelResult;
}

Parameters ** TreeEM::ParametersDoubleForSplittingUniform(int choiceInit){
    // Check if it is really a leaf to split and if it is really a uniform distribution
    if (this->GetNumberChildren()!=0 || this->GetDistributionType()!=2) {
        return NULL;
    }
    Parameters ** ParametersSplit=new Parameters* [2];
    ParametersSplit[0]=new Parameters();
    ParametersSplit[1]=new Parameters();
    ParametersSplit[0]->DistributionType=1;
    ParametersSplit[1]->DistributionType=1;
    ParametersSplit[0]->SizeParameters=CalculateSizeParameters(ParametersSplit[0]->DistributionType);
    ParametersSplit[1]->SizeParameters=CalculateSizeParameters(ParametersSplit[1]->DistributionType);
    ParametersSplit[0]->ValueParameters=new float[ParametersSplit[0]->SizeParameters];//{0};
    for(int i=0;i<ParametersSplit[0]->SizeParameters;i++){
        ParametersSplit[0]->ValueParameters[i]=0;
    }
    ParametersSplit[1]->ValueParameters=new float[ParametersSplit[1]->SizeParameters];//{0};
    for(int i=0;i<ParametersSplit[1]->SizeParameters;i++){
        ParametersSplit[1]->ValueParameters[i]=0;
    }
    //    float * ParametersMean=this->GetMean();
    //    float * ParametersVariance=this->GetVariance();

    // Temporary values for splitting initialisation :
    int numbmodal=this->GetNumberModalities();
    //    for (int m=0; m<numbmodal; m++) {
    //
    //        //Mean Initialisation
    //        ParametersSplit[0]->ValueParameters[m]=ParametersMean[m]-0.5*powf(ParametersVariance[m+numbmodal*m], 0.5);
    //        ParametersSplit[1]->ValueParameters[m]=ParametersMean[m]+0.5*powf(ParametersVariance[m+numbmodal*m], 0.5);
    //
    //        //Variance Initialisation
    //        ParametersSplit[0]->ValueParameters[numbmodal+m+numbmodal*m]=ParametersVariance[m+numbmodal*m]/2.0;
    //        ParametersSplit[1]->ValueParameters[numbmodal+m+numbmodal*m]=ParametersVariance[m+numbmodal*m]/2.0;
    //
    //    }

    // Splitting initialisation with Richardson initialisation
//    float * VarianceDiag=this->GetDiagVarianceDirect();

//    // Possibly to change if we have GetVarianceDirect instead of GetDiagVarianceDirect
//    float * VarianceToStudy=new float[numbmodal*numbmodal];
//    for(int m1=0;m1<numbmodal;m1++){
//        for(int m2=0;m2<numbmodal;m2++){
//            if(m1==m2){
//                VarianceToStudy[m1+m2*numbmodal]=VarianceDiag[m1];
//            }
//            else{
//                VarianceToStudy[m1+m2*numbmodal]=0;
//            }

//        }
//    }

    float * VarianceToStudy=this->GetVarianceDirect();
    SVD SVDForSplit=SVD(VarianceToStudy, numbmodal,numbmodal);
    float * SVDEigen=SVDForSplit.getSingularValues();
    float * SVDVec=SVDForSplit.getV();
//    int IndMaxEigen=0;
    float MaxEigen=1E-6;
    float * MaxVec=SVDVec;
    int * Index=new int[numbmodal];
    for(int m=0;m<numbmodal;m++){
        Index[m]=m;
    }
    this->SortingSVDEigen(SVDEigen,Index);
    if(choiceInit<=numbmodal){
        MaxEigen=SVDEigen[choiceInit-1];
        MaxVec=&SVDVec[Index[choiceInit-1]*numbmodal];

    }

    else {

    for (int i=0; i<numbmodal; i++) {
        if (SVDEigen[i]>MaxEigen) {
//            IndMaxEigen=i;
            MaxEigen=SVDEigen[i];
            MaxVec=&SVDVec[i*numbmodal];
        }
    }
    }
    delete [] Index;
    Index=NULL;
    delete [] VarianceToStudy;
    VarianceToStudy=NULL;

    float * MeanInitSplit=this->MeanForSplitInitialisationUniform(MaxEigen,MaxVec);
    float * VarianceInitSplit=this->VarianceForSplitInitialisationUniform(MaxEigen,MaxVec);

    // Filling in the parameters
    for (int m1=0; m1<numbmodal; m1++) {
        ParametersSplit[0]->ValueParameters[m1]=MeanInitSplit[m1];
        ParametersSplit[1]->ValueParameters[m1]=MeanInitSplit[m1+numbmodal];
        for (int m2=0; m2<numbmodal; m2++) {
            ParametersSplit[0]->ValueParameters[numbmodal+m1+m2*numbmodal]=VarianceInitSplit[m1+m2*numbmodal];
            ParametersSplit[1]->ValueParameters[numbmodal+m1+m2*numbmodal]=VarianceInitSplit[numbmodal*numbmodal+m1+m2*numbmodal];
        }
    }
    // Memory clearing
    delete [] MeanInitSplit;
    MeanInitSplit=NULL;
    delete [] VarianceInitSplit;
    VarianceInitSplit=NULL;

    return ParametersSplit;
}

// Returns the pointer to the array of Parameters pointer initialising the classes formed by the split
Parameters ** TreeEM::ParametersForSplitting(int choiceInit){

    // Check if it is really a leaf to split
    if (this->GetNumberChildren()!=0) {
        return NULL;
    }
    Parameters ** ParametersSplit=new Parameters* [2];
    ParametersSplit[0]=new Parameters();
    ParametersSplit[1]=new Parameters();
    ParametersSplit[0]->DistributionType=this->GetDistributionType();
    ParametersSplit[1]->DistributionType=this->GetDistributionType();
    ParametersSplit[0]->SizeParameters=this->GetSizeParameters();
    ParametersSplit[1]->SizeParameters=this->GetSizeParameters();
    ParametersSplit[0]->ValueParameters=new float[ParametersSplit[0]->SizeParameters];//{0};
    for(int i=0;i<ParametersSplit[0]->SizeParameters;i++){
        ParametersSplit[0]->ValueParameters[i]=0;
    }
    ParametersSplit[1]->ValueParameters=new float[ParametersSplit[1]->SizeParameters];//{0};
    for(int i=0;i<ParametersSplit[1]->SizeParameters;i++){
        ParametersSplit[1]->ValueParameters[i]=0;
    }
    //    float * ParametersMean=this->GetMean();
    //    float * ParametersVariance=this->GetVariance();

    // Temporary values for splitting initialisation :
    int numbmodal=this->GetNumberModalities();
    //    for (int m=0; m<numbmodal; m++) {
    //
    //        //Mean Initialisation
    //        ParametersSplit[0]->ValueParameters[m]=ParametersMean[m]-0.5*powf(ParametersVariance[m+numbmodal*m], 0.5);
    //        ParametersSplit[1]->ValueParameters[m]=ParametersMean[m]+0.5*powf(ParametersVariance[m+numbmodal*m], 0.5);
    //
    //        //Variance Initialisation
    //        ParametersSplit[0]->ValueParameters[numbmodal+m+numbmodal*m]=ParametersVariance[m+numbmodal*m]/2.0;
    //        ParametersSplit[1]->ValueParameters[numbmodal+m+numbmodal*m]=ParametersVariance[m+numbmodal*m]/2.0;
    //
    //    }

    // Splitting initialisation with Richardson initialisation
    SVD SVDForSplit=SVD(this->GetVariance(), numbmodal,numbmodal);
    float * SVDEigen=SVDForSplit.getSingularValues();
    float * SVDVec=SVDForSplit.getV();
//    int IndMaxEigen=0;
    float MaxEigen=1E-6;
    float * MaxVec=SVDVec;
    int * Index=new int[numbmodal];
    for(int m=0;m<numbmodal;m++){
        Index[m]=m;
    }
    this->SortingSVDEigen(SVDEigen,Index);
    if(choiceInit<=numbmodal){
        MaxEigen=SVDEigen[choiceInit-1];
        MaxVec=&SVDVec[Index[choiceInit-1]*numbmodal];

    }

    else {

    for (int i=0; i<numbmodal; i++) {
        if (SVDEigen[i]>MaxEigen) {
//            IndMaxEigen=i;
            MaxEigen=SVDEigen[i];
            MaxVec=&SVDVec[i*numbmodal];
        }
    }
    }
    delete [] Index;
    Index=NULL;

    float * MeanInitSplit=this->MeanForSplitInitialisation(MaxEigen,MaxVec);
    float * VarianceInitSplit=this->VarianceForSplitInitialisation(MaxEigen,MaxVec);

    // Filling in the parameters
    for (int m1=0; m1<numbmodal; m1++) {
        ParametersSplit[0]->ValueParameters[m1]=MeanInitSplit[m1];
        ParametersSplit[1]->ValueParameters[m1]=MeanInitSplit[m1+numbmodal];
        for (int m2=0; m2<numbmodal; m2++) {
            ParametersSplit[0]->ValueParameters[numbmodal+m1+m2*numbmodal]=VarianceInitSplit[m1+m2*numbmodal];
            ParametersSplit[1]->ValueParameters[numbmodal+m1+m2*numbmodal]=VarianceInitSplit[numbmodal*numbmodal+m1+m2*numbmodal];
        }
    }
    // Memory clearing
    delete [] MeanInitSplit;
    MeanInitSplit=NULL;
    delete [] VarianceInitSplit;
    VarianceInitSplit=NULL;

    return ParametersSplit;
}

// Applied on the leaf to split returns a pointer to the float array containing the initialisation to use for the mean
float * TreeEM::MeanForSplitInitialisation(float MaxEigen, float * MaxVec){
    if (this->GetNumberChildren()!=0) {
        cout<<"Nothing to split since not leaf"<<endl;
        return NULL;
    }
    int numbmodal=this->GetNumberModalities();
    float * MeanSplitInit=new float[2*numbmodal];
    float * MeanToSplit=this->GetMean();

    for (int m=0; m<numbmodal; m++) {
        MeanSplitInit[m]=MeanToSplit[m]-0.5*MaxVec[m]*sqrtf(MaxEigen);
        MeanSplitInit[m+numbmodal]= MeanToSplit[m]+0.5*MaxVec[m]*sqrtf(MaxEigen);
    }
    //    delete [] SVDForSplit.getU();
    //    delete [] SVDForSplit.getV();
    //    delete [] SVDForSplit.getSingularValues();
    return MeanSplitInit;
}

float * TreeEM::MeanForSplitInitialisationUniform(float MaxEigen,float*MaxVec){
    if (this->GetNumberChildren()!=0 || this->GetDistributionType()!=2) {
        cout<<"Nothing to split since not leaf"<<endl;
        return NULL;
    }
    int numbmodal=this->GetNumberModalities();
    float * MeanSplitInit=new float[2*numbmodal];
    float * MeanToSplit=this->GetMeanDirect();

    for (int m=0; m<numbmodal; m++) {
        MeanSplitInit[m]=MeanToSplit[m]-0.5*MaxVec[m]*sqrtf(MaxEigen);
        MeanSplitInit[m+numbmodal]= MeanToSplit[m]+0.5*MaxVec[m]*sqrtf(MaxEigen);
    }
    //    delete [] SVDForSplit.getU();
    //    delete [] SVDForSplit.getV();
    //    delete [] SVDForSplit.getSingularValues();
    delete[]MeanToSplit;
    MeanToSplit=NULL;
    return MeanSplitInit;
}

void TreeEM::SortingSVDEigen(float * SVDEigen, int * Index){
    int numbmodal=this->GetNumberModalities();
    bool flag_swap=1;
    while(flag_swap){
        flag_swap=0;
        for(int i=0;i<numbmodal-1;i++){
            if(SVDEigen[i+1]>SVDEigen[i]){
                float tmp=SVDEigen[i];
                SVDEigen[i]=SVDEigen[i+1];
                SVDEigen[i+1]=tmp;

                int tmp_ind=Index[i];
                Index[i]=Index[i+1];
                Index[i+1]=tmp_ind;

                flag_swap=1;
            }
        }
    }
}

float * TreeEM::VarianceForSplitInitialisation(float MaxEigen,float * MaxVec){
    if (this->GetNumberChildren()!=0) {
        cout<<"Nothing to split since not leaf"<<endl;
        return NULL;
    }
    int numbmodal=this->GetNumberModalities();
    float * VarianceSplitInit=new float[2*numbmodal*numbmodal];
    float * VarianceToSplit=this->GetVariance();

    for (int m1=0; m1<numbmodal; m1++) {
        for (int m2=0; m2<numbmodal; m2++) {
            VarianceSplitInit[m1+m2*numbmodal]=VarianceToSplit[m1+m2*numbmodal]+2*(0.5-1-0.5*0.5*0.5)*MaxVec[m1]*MaxVec[m2]*MaxEigen+MaxVec[m1]*MaxVec[m2]*MaxEigen;
            VarianceSplitInit[m1+m2*numbmodal+numbmodal*numbmodal]=VarianceToSplit[m1+m2*numbmodal]+2*(0.5*0.5*0.5-0.5-0.5*0.5)*MaxVec[m1]*MaxVec[m2]*MaxEigen+MaxVec[m1]*MaxVec[m2]*MaxEigen;
        }
    }
    //delete &SVDForSplit;
    //    delete [] SVDForSplit.getU();
    //    delete [] SVDForSplit.getV();
    //    delete [] SVDForSplit.getSingularValues();
    return VarianceSplitInit;
}

float * TreeEM::VarianceForSplitInitialisationUniform(float MaxEigen,float * MaxVec){
    if (this->GetNumberChildren()!=0) {
        cout<<"Nothing to split since not leaf"<<endl;
        return NULL;
    }
    int numbmodal=this->GetNumberModalities();
    float * VarianceSplitInit=new float[2*numbmodal*numbmodal];
    float * VarianceToSplit=this->GetVarianceDirect();

    for (int m1=0; m1<numbmodal; m1++) {
        for (int m2=0; m2<numbmodal; m2++) {
            VarianceSplitInit[m1+m2*numbmodal]=VarianceToSplit[m1+m2*numbmodal]+2*(0.5-1-0.5*0.5*0.5)*MaxVec[m1]*MaxVec[m2]*MaxEigen+MaxVec[m1]*MaxVec[m2]*MaxEigen;
            VarianceSplitInit[m1+m2*numbmodal+numbmodal*numbmodal]=VarianceToSplit[m1+m2*numbmodal]+2*(0.5*0.5*0.5-0.5-0.5*0.5)*MaxVec[m1]*MaxVec[m2]*MaxEigen+MaxVec[m1]*MaxVec[m2]*MaxEigen;
        }
    }
    //delete &SVDForSplit;
    //    delete [] SVDForSplit.getU();
    //    delete [] SVDForSplit.getV();
    //    delete [] SVDForSplit.getSingularValues();
    delete [] VarianceToSplit;
    VarianceToSplit=NULL;
    return VarianceSplitInit;
}


bool TreeEM::AreSplitPossible(vector<SplitKLD *> SplitTry, SEG_PARAMETERS * segment_param){
    bool SplitPossible=0;
    int numbclassesSplit = SplitTry.size();
    switch (segment_param->SplitAccept) {
        case 0:{ // do not perform EM if split not operated because of too small class
            for (int c=0; c<numbclassesSplit; c++) {
                TreeEM * ParentToSplit=SplitTry[c]->Parent;
                int ChildToSplit=SplitTry[c]->ChildToSplit;
                if (ParentToSplit->GetChild(ChildToSplit)->GetNormWeight()<segment_param->WeightMini/5) {
                    SplitPossible=0;
                }
            }
        }
            break;
        default:
            SplitPossible=1;
            break;
    }
    return SplitPossible;
}

bool TreeEM::AreSplitPossible(vector<SplitKLD_b *> SplitTry, SEG_PARAMETERS * segment_param){
    bool SplitPossible=1;
    int numbclassesSplit = SplitTry.size();
    switch (segment_param->SplitAccept) {
        case 0:{ // do not perform EM if split not operated because of too small class
            for (int c=0; c<numbclassesSplit; c++) {
                TreeEM * ParentToSplit=this->FindFromHierarchy(SplitTry[c]->HierarchyParent);
                int ChildToSplit=SplitTry[c]->ChildToSplit;
                if (ParentToSplit->GetChild(ChildToSplit)->GetNormWeight()<segment_param->WeightMini/5) {
                    SplitPossible=0;
                }
            }
        }
            break;
        case 2:{
            for (int c=0; c<numbclassesSplit; c++) {
                TreeEM * ParentToSplit=this->FindFromHierarchy(SplitTry[c]->HierarchyParent);
                int ChildToSplit=SplitTry[c]->ChildToSplit;
                if (ParentToSplit->GetChild(ChildToSplit)->GetNormWeight()<segment_param->WeightMini/5 && ParentToSplit->GetChild(ChildToSplit)->GetDistributionType()==1) {
                    SplitPossible=0;
                }
            }
        }
        default:
            SplitPossible=1;
            break;
    }
    return SplitPossible;
}

// When testing a S operation returns the best of the two models obtained.
TreeEM* TreeEM::RunSplitOperation(vector<SplitKLD *> SplitTry, bool & AcceptanceDecision, SEG_PARAMETERS * segment_param){
    //    SplitKLD * SplitTry=this->GetToSplit();
    int numbclassesSplit=SplitTry.size();
    if (numbclassesSplit==0) {
        return this;
    }
    bool SplitPossible=this->AreSplitPossible(SplitTry,segment_param);
    if (!SplitPossible) {
        AcceptanceDecision=0;
        cout<<"Split not accepted because no split correct"<<endl;
        return this;
    }
    // Updating of the checking

    TreeEM * GeneralClassToSplit=SplitTry[0]->Parent->GetChild(SplitTry[0]->ChildToSplit)->FindMainNode();
    int IndGenClassSplit=-1;
    if(GeneralClassToSplit->GetParent()!=NULL){
     IndGenClassSplit=GeneralClassToSplit->GetParent()->FindIndex(GeneralClassToSplit);
    }
    cout<< "Trying split operation on node "<<IndGenClassSplit<<endl;

//    SplitTry->Parent->GetSplitCheck()[SplitTry->ChildToSplit]=1;
    // Copy of the current tree


    TreeEM * CopiedTree=this->CopyTree(NULL);
    for(int c=0;c<numbclassesSplit;c++){
//        (SplitTry[c]->Parent)->SplitOperation(SplitTry[c]->ChildToSplit,segment_param->choiceInitSplit,segment_param);
        this->SplitOperation(SplitTry[c],segment_param->choiceInitSplit,segment_param);
    }



    this->ClearSMChecks();

    // Partial EM first
//    float PartCLL=0;
//    float PartOldCLL=0;
//    int PartIteration=0;
    //    (SplitTry->Parent->GetChild(SplitTry->ChildToSplit))->UpdateDistribution();
    //    (SplitTry->Parent->GetChild(SplitTry->ChildToSplit))->UpdateNonNormResp();
    //    (SplitTry->Parent->GetChild(SplitTry->ChildToSplit))->UpdateNormResp();
    //    (SplitTry->Parent->GetChild(SplitTry->ChildToSplit))->UpdateNormRespRoot();
    //    (SplitTry->Parent->GetChild(SplitTry->ChildToSplit))->UpdateNonNormWeights();
    //    (SplitTry->Parent->GetChild(SplitTry->ChildToSplit))->UpdateNormWeights();
    //    (SplitTry->Parent->GetChild(SplitTry->ChildToSplit))->RunFullEM(PartCLL, PartOldCLL, PartIteration);
    // Run EM
    float CompleteLogLikelihood=0;
    float OldCompleteLogLikelihood=0;
    int Iteration=0;
    //    this->UpdateDistribution();
    this->UpdateNonNormResp(segment_param);
    this->UpdateNormResp();
//    this->SaveAllClasses("/Users/Carole/Documents/PhD/TestSplitResult.nii.gz",segment_param);
    this->UpdateNormRespRoot();
    if(segment_param->flag_MRF){
        this->ClearMRFModel();
        float * GMatrixToSet=NULL;
        if(segment_param->flag_GMatrixIn){
            GMatrixToSet=this->CreateGMatrixFromInfo(segment_param->flag_optMRFOut, segment_param->filename_GMatrix);
//            GMatrixToSet=this->PrepareGMatrixFromFile(segment_param->filename_GMatrix,segment_param->flag_optMRFOut);
            if(GMatrixToSet==NULL){
                cout<< "Pb in the preparation of GMatrix"<<endl;
                segment_param->flag_GMatrix=0;
            }
        }
        else{
            GMatrixToSet=this->MRFOptSolveLS(segment_param);
        }
        this->SetGMatrix(GMatrixToSet);
        if(GMatrixToSet!=NULL){
            delete [] GMatrixToSet;
            GMatrixToSet=NULL;
        }
        this->UpdateMRF(segment_param);
    }
//    this->UpdateNonNormWeights();
//    this->UpdateNormWeights();

    //this->RunFullEM(PartCLL, PartOldCLL, PartIteration);
    if(segment_param->flag_CEM){
        this->RunFullCEM(CompleteLogLikelihood,OldCompleteLogLikelihood,Iteration,segment_param);
    }
    else{
    this->RunFullEM(CompleteLogLikelihood, OldCompleteLogLikelihood,Iteration,segment_param);
    }
//    this->SaveAllClasses("/Users/Carole/Documents/PhD/TestSplitResult");
    // Test of the operation
//    float OldCriterion=0;
//    float NewCriterion=0;
//    if(this->GetDPChildrenDirect()!=NULL){
//        if(segment_param->flag_Countmod){
//            OldCriterion=CopiedTree->CriterionCalculationSplitDP();
//            NewCriterion=this->CriterionCalculationSplitDP();
//        }
//        else{
//            if(segment_param->flag_DistClassInd){
//         OldCriterion=CopiedTree->CriterionCalculationDPInd();
//         NewCriterion=this->CriterionCalculationDPInd();
//            }
//            else{
////                OldCriterion=CopiedTree->CriterionCalculationDPNonInd(SplitTry[c]->Parent->GetChild(SplitTry->ChildToSplit)->FindGeneralClass());
////                NewCriterion=this->CriterionCalculationDPNonInd(SplitTry[c]->Parent->GetChild(SplitTry->ChildToSplit)->FindGeneralClass());
//            }
//        }
//    }
//    else{
//     OldCriterion=CopiedTree->CriterionCalculation();
//     NewCriterion=this->CriterionCalculation();
//    }
//    cout<< "The new criterion is "<<NewCriterion<<" and the old criterion is "<<OldCriterion<<endl;
    OperationType Operation=SPLIT; // OperationType corresponding to split
    AcceptanceDecision=this->IsNewModelAccepted(CopiedTree,Operation,segment_param);

//    // Clear SplitTry
//    if (SplitTry!=NULL) {
//        delete SplitTry;
//        SplitTry=NULL;
//    }

    bool TestNormResp=this->AreNormRespValid();
    bool TestNormWeight=this->AreWeightsValid();
    if(!TestNormResp){
        cout<<"Pb of norm resp in Split operation"<<endl;
    }
    if(!TestNormWeight){
        cout<<"Pb of norm weights in Split operation"<<endl;
    }

    if (!AcceptanceDecision) { // Criterion of change not met, delete the modified tree and return the copied one
        delete this;
        AcceptanceDecision=0;
        cout<<"Split not accepted"<<endl;
        bool checkUnifPos=CopiedTree->CheckUnifDistPosition(segment_param);
        if (!checkUnifPos) {
            cout<<"Pb with position of the unif dist position"<<endl;
        }
        return CopiedTree;
    }
    else{ // Criterion of change met delete the not modified tree stored in CopiedTree and return the new model.
        bool AcceptanceWeights=this->CheckAcceptanceWeights(SplitTry,segment_param);
        if (!AcceptanceWeights) {
            delete this;
            AcceptanceDecision=0;
            cout<<"Split not accepted because of inappropriate weight"<<endl;
            return CopiedTree;
        }
        else {
            delete CopiedTree;
            AcceptanceDecision=1;
            cout<<"Split accepted"<<endl;
            //        int numbchild=this->GetNumberChildren();
            //        for(int c=0;c<numbchild;c++){
            //            this->GetChild(c)->PutAllLeavesToChildrenLevel();
            //        }
            if (segment_param->flag_DeleteUnderWeight) {
//                cout<< this->CriterionCalculation()<<endl;
                this->DeleteUnderWeight(segment_param); // delete the classes then update the tree
//                cout<<this->CriterionCalculation()<<endl;
//                this->UpdateNonNormResp(segment_param);
//                this->UpdateNormResp();
//                this->UpdateNormRespRoot();
//                if (segment_param->flag_MRF) {
//                    this->UpdateMRF();
//                }
//                this->UpdateNonNormWeights();
//                this->UpdateNormWeights();
//                cout<<this->CriterionCalculation()<<endl;
            }
            this->PutAllLeavesToMainNodesChildrenLevel(segment_param);
//            cout<<this->CriterionCalculation()<<endl;
            bool checkUnifPos=this->CheckUnifDistPosition(segment_param);
            if (!checkUnifPos) {
                cout<<"Pb with position of the unif dist position"<<endl;
            }
            TestNormWeight=this->AreWeightsValid();
            if(!TestNormWeight){
                cout<<"Pb when putting all leaves to main nodes children level at split operation"<<endl;
            }
            this->ClearSMChecks();
            return this;

        }
     }
}


// When testing a S operation returns the best of the two models obtained.
TreeEM* TreeEM::RunSplitOperation_b(vector<SplitKLD_b *> SplitTry, bool & AcceptanceDecision, SEG_PARAMETERS * segment_param){
    //    SplitKLD * SplitTry=this->GetToSplit();
    int numbclassesSplit=SplitTry.size();
    TreeEM * CopiedTree=this->CopyTree(NULL);
    if (numbclassesSplit==0) {
        return CopiedTree;
    }
    bool SplitPossible=this->AreSplitPossible(SplitTry,segment_param);
    if (!SplitPossible) {
        AcceptanceDecision=0;
        cout<<"Split not accepted because no split correct"<<endl;
        return CopiedTree;
    }
    // Updating of the checking
    
//    TreeEM * GeneralClassToSplit=CopiedTree->FindFromHierarchy(SplitTry[0]->HierarchyParent)->FindMainNode();
//    int IndGenClassSplit=-1;
//    if (GeneralClassToSplit==NULL) {
//        IndGenClassSplit=SplitTry[0]->ChildToSplit;
//    }
//    
//    else if(GeneralClassToSplit->GetParent()!=NULL){
//        IndGenClassSplit=GeneralClassToSplit->GetParent()->FindIndex(GeneralClassToSplit);
//    }
//    cout<< "Trying split operation on node "<<IndGenClassSplit<<endl;
    cout<<"Trying split operation on node ";
    //    SplitTry->Parent->GetSplitCheck()[SplitTry->ChildToSplit]=1;
    // Copy of the current tree
    int sizeHierarch=SplitTry[0]->HierarchyParent.size();
    for (int l=0; l<sizeHierarch; l++) {
        cout<<" "<<SplitTry[0]->HierarchyParent[l];
    }
    cout<<" "<<SplitTry[0]->ChildToSplit<<endl;
    
    TreeEM * CopiedTree2=this->CopyTree(NULL);
//    cout<<"Tree copied for Split"<<endl;
    for(int c=0;c<numbclassesSplit;c++){
        //        (SplitTry[c]->Parent)->SplitOperation(SplitTry[c]->ChildToSplit,segment_param->choiceInitSplit,segment_param);
        CopiedTree2->SplitOperation(SplitTry[c],segment_param->choiceInitSplit,segment_param);
//        cout<<"Split operation initialised"<<endl;
    }
    
    bool ValidInit=CopiedTree2->IsInitialisationValid();
    if (!ValidInit){
        delete CopiedTree2;
        cout<<"Initialisation after operation split not valid"<<endl;
        return CopiedTree;
    }
    
    CopiedTree2->ClearSMChecks();
    
    // Partial EM first
    //    float PartCLL=0;
    //    float PartOldCLL=0;
    //    int PartIteration=0;
    //    (SplitTry->Parent->GetChild(SplitTry->ChildToSplit))->UpdateDistribution();
    //    (SplitTry->Parent->GetChild(SplitTry->ChildToSplit))->UpdateNonNormResp();
    //    (SplitTry->Parent->GetChild(SplitTry->ChildToSplit))->UpdateNormResp();
    //    (SplitTry->Parent->GetChild(SplitTry->ChildToSplit))->UpdateNormRespRoot();
    //    (SplitTry->Parent->GetChild(SplitTry->ChildToSplit))->UpdateNonNormWeights();
    //    (SplitTry->Parent->GetChild(SplitTry->ChildToSplit))->UpdateNormWeights();
    //    (SplitTry->Parent->GetChild(SplitTry->ChildToSplit))->RunFullEM(PartCLL, PartOldCLL, PartIteration);
    // Run EM
    float CompleteLogLikelihood=0;
    float OldCompleteLogLikelihood=0;
    int Iteration=0;
    //    this->UpdateDistribution();
    CopiedTree2->UpdateNonNormResp(segment_param);
    CopiedTree2->UpdateNormResp();
    //    this->SaveAllClasses("/Users/Carole/Documents/PhD/TestSplitResult.nii.gz",segment_param);
    CopiedTree2->UpdateNormRespRoot();
    if(segment_param->flag_MRF){
        this->ClearMRFModel();
        float * GMatrixToSet=NULL;
        if(segment_param->flag_GMatrixIn){
            GMatrixToSet=CopiedTree2->CreateGMatrixFromInfo(segment_param->flag_optMRFOut, segment_param->filename_GMatrix);
//            GMatrixToSet=CopiedTree2->PrepareGMatrixFromFile(segment_param->filename_GMatrix,segment_param->flag_optMRFOut);
            if(GMatrixToSet==NULL){
                cout<< "Pb in the preparation of GMatrix"<<endl;
                segment_param->flag_GMatrix=0;
            }
        }
        else{
            GMatrixToSet=CopiedTree2->MRFOptSolveLS(segment_param);
        }
        CopiedTree2->SetGMatrix(GMatrixToSet);
        if(GMatrixToSet!=NULL){
            delete [] GMatrixToSet;
            GMatrixToSet=NULL;
        }
        CopiedTree2->UpdateMRF(segment_param);
    }
    //    this->UpdateNonNormWeights();
    //    this->UpdateNormWeights();
    if(this->GetFlagCovPriors()>0){
        CopiedTree2->ModifyCovPriors(segment_param);
    }
    //this->RunFullEM(PartCLL, PartOldCLL, PartIteration);
    if(segment_param->flag_CEM){
        CopiedTree2->RunFullCEM(CompleteLogLikelihood,OldCompleteLogLikelihood,Iteration,segment_param);
    }
    else{
        CopiedTree2->RunFullEM(CompleteLogLikelihood, OldCompleteLogLikelihood,Iteration,segment_param);
    }
    //    this->SaveAllClasses("/Users/Carole/Documents/PhD/TestSplitResult");
    // Test of the operation
    //    float OldCriterion=0;
    //    float NewCriterion=0;
    //    if(this->GetDPChildrenDirect()!=NULL){
    //        if(segment_param->flag_Countmod){
    //            OldCriterion=CopiedTree->CriterionCalculationSplitDP();
    //            NewCriterion=this->CriterionCalculationSplitDP();
    //        }
    //        else{
    //            if(segment_param->flag_DistClassInd){
    //         OldCriterion=CopiedTree->CriterionCalculationDPInd();
    //         NewCriterion=this->CriterionCalculationDPInd();
    //            }
    //            else{
    ////                OldCriterion=CopiedTree->CriterionCalculationDPNonInd(SplitTry[c]->Parent->GetChild(SplitTry->ChildToSplit)->FindGeneralClass());
    ////                NewCriterion=this->CriterionCalculationDPNonInd(SplitTry[c]->Parent->GetChild(SplitTry->ChildToSplit)->FindGeneralClass());
    //            }
    //        }
    //    }
    //    else{
    //     OldCriterion=CopiedTree->CriterionCalculation();
    //     NewCriterion=this->CriterionCalculation();
    //    }
    //    cout<< "The new criterion is "<<NewCriterion<<" and the old criterion is "<<OldCriterion<<endl;
    OperationType Operation=SPLIT; // OperationType corresponding to split
    AcceptanceDecision=CopiedTree2->IsNewModelAccepted(CopiedTree,Operation,segment_param);
    
    //    // Clear SplitTry
    //    if (SplitTry!=NULL) {
    //        delete SplitTry;
    //        SplitTry=NULL;
    //    }
    
    bool TestNormResp=CopiedTree2->AreNormRespValid();
    bool TestNormWeight=CopiedTree2->AreWeightsValid();
    if(!TestNormResp){
        cout<<"Pb of norm resp in Split operation"<<endl;
    }
    if(!TestNormWeight){
        cout<<"Pb of norm weights in Split operation"<<endl;
    }
    
    if (!AcceptanceDecision) { // Criterion of change not met, delete the modified tree and return the copied one
        delete CopiedTree2;
        CopiedTree2=NULL;
        AcceptanceDecision=0;
        cout<<"Split not accepted"<<endl;
        bool checkUnifPos=CopiedTree->CheckUnifDistPosition(segment_param);
        if (!checkUnifPos) {
            cout<<"Pb with position of the unif dist position"<<endl;
        }
        return CopiedTree;
    }
    else{ // Criterion of change met delete the not modified tree stored in CopiedTree and return the new model.
        bool AcceptanceWeights=CopiedTree2->CheckAcceptanceWeights(SplitTry,segment_param);
        if (!AcceptanceWeights) {
            delete CopiedTree2;
            AcceptanceDecision=0;
            cout<<"Split not accepted because of inappropriate weight"<<endl;
            return CopiedTree;
        }
        else {
            delete CopiedTree;
            AcceptanceDecision=1;
            cout<<"Split accepted"<<endl;
            //        int numbchild=this->GetNumberChildren();
            //        for(int c=0;c<numbchild;c++){
            //            this->GetChild(c)->PutAllLeavesToChildrenLevel();
            //
            CopiedTree2->PutAllLeavesToMainNodesChildrenLevel(segment_param);
            if (segment_param->flag_DeleteUnderWeight) {
                //                cout<< this->CriterionCalculation()<<endl;
                CopiedTree2->DeleteUnderWeight(segment_param); // delete the classes then update the tree
                //                cout<<this->CriterionCalculation()<<endl;
                //                this->UpdateNonNormResp(segment_param);
                //                this->UpdateNormResp();
                //                this->UpdateNormRespRoot();
                //                if (segment_param->flag_MRF) {
                //                    this->UpdateMRF();
                //                }
                //                this->UpdateNonNormWeights();
                //                this->UpdateNormWeights();
                //                cout<<this->CriterionCalculation()<<endl;
            }
            
            
            CopiedTree2->CollapseOnlyChildTot();
            //            cout<<this->CriterionCalculation()<<endl;
            bool checkUnifPos=CopiedTree2->CheckUnifDistPosition(segment_param);
            if (!checkUnifPos) {
                cout<<"Pb with position of the unif dist position"<<endl;
            }
            TestNormWeight=this->AreWeightsValid();
            if(!TestNormWeight){
                cout<<"Pb when putting all leaves to main nodes children level at split operation"<<endl;
            }
            CopiedTree2->ClearSMChecks();
            return CopiedTree2;
            
        }
    }
}


// When testing a S operation returns the best of the two models obtained.
TreeEM* TreeEM::RunSplitOperation(SplitKLD * SplitTry, bool & AcceptanceDecision, SEG_PARAMETERS * segment_param){
    //    SplitKLD * SplitTry=this->GetToSplit();
    if (SplitTry==NULL) {
        return this;
    }
    // Updating of the checking
    cout<< "Trying split operation"<<endl;
    SplitTry->Parent->GetSplitCheck()[SplitTry->ChildToSplit]=1;
    // Copy of the current tree
    TreeEM * CopiedTree=this->CopyTree(NULL);
    (SplitTry->Parent)->SplitOperation(SplitTry->ChildToSplit,segment_param->choiceInitSplit,segment_param);
    this->ClearSMChecks();

    // Partial EM first
//    float PartCLL=0;
//    float PartOldCLL=0;
//    int PartIteration=0;
    //    (SplitTry->Parent->GetChild(SplitTry->ChildToSplit))->UpdateDistribution();
    //    (SplitTry->Parent->GetChild(SplitTry->ChildToSplit))->UpdateNonNormResp();
    //    (SplitTry->Parent->GetChild(SplitTry->ChildToSplit))->UpdateNormResp();
    //    (SplitTry->Parent->GetChild(SplitTry->ChildToSplit))->UpdateNormRespRoot();
    //    (SplitTry->Parent->GetChild(SplitTry->ChildToSplit))->UpdateNonNormWeights();
    //    (SplitTry->Parent->GetChild(SplitTry->ChildToSplit))->UpdateNormWeights();
    //    (SplitTry->Parent->GetChild(SplitTry->ChildToSplit))->RunFullEM(PartCLL, PartOldCLL, PartIteration);
    // Run EM
    float CompleteLogLikelihood=0;
    float OldCompleteLogLikelihood=0;
    int Iteration=0;
    //    this->UpdateDistribution();
    this->UpdateNonNormResp(segment_param);
    this->UpdateNormResp();
//    this->SaveAllClasses("/Users/Carole/Documents/PhD/TestSplitResult");
    this->UpdateNormRespRoot();
    if(segment_param->flag_MRF){
        this->ClearMRFModel();
        float * GMatrixToSet=NULL;
        if(segment_param->flag_GMatrixIn){
          GMatrixToSet=this->CreateGMatrixFromInfo(segment_param->flag_optMRFOut, segment_param->filename_GMatrix);
//          GMatrixToSet=this->PrepareGMatrixFromFile(segment_param->filename_GMatrix,segment_param->flag_optMRFOut);
        if(GMatrixToSet==NULL){
            cout<< "Pb in the preparation of GMatrix"<<endl;
            segment_param->flag_GMatrix=0;
        }
        }
        else{
            GMatrixToSet=this->MRFOptSolveLS(segment_param);
        }
        this->SetGMatrix(GMatrixToSet);
        if(GMatrixToSet!=NULL){
            delete [] GMatrixToSet;
            GMatrixToSet=NULL;
        }
        this->UpdateMRF(segment_param);
    }
//    this->UpdateNonNormWeights();
//    this->UpdateNormWeights();

    //this->RunFullEM(PartCLL, PartOldCLL, PartIteration);
    if(segment_param->flag_CEM){
        this->RunFullCEM(CompleteLogLikelihood, OldCompleteLogLikelihood,Iteration,segment_param);
    }
    else{
    this->RunFullEM(CompleteLogLikelihood, OldCompleteLogLikelihood,Iteration,segment_param);
    }
//    this->SaveAllClasses("/Users/Carole/Documents/PhD/TestSplitResult");
    // Test of the operation
    float OldCriterion=0;
    float NewCriterion=0;
    if(this->GetDPChildrenDirect()!=NULL){
        if(segment_param->flag_Countmod){
            OldCriterion=CopiedTree->CriterionCalculationSplitDP();
            NewCriterion=this->CriterionCalculationSplitDP();
        }
        else{
            if(segment_param->flag_DistClassInd){
         OldCriterion=CopiedTree->CriterionCalculationDPInd();
         NewCriterion=this->CriterionCalculationDPInd();
            }
            else{
                OldCriterion=CopiedTree->CriterionCalculationDPNonInd(SplitTry->Parent->GetChild(SplitTry->ChildToSplit)->FindGeneralClass());
                NewCriterion=this->CriterionCalculationDPNonInd(SplitTry->Parent->GetChild(SplitTry->ChildToSplit)->FindGeneralClass());
            }
        }
    }
    else{
     OldCriterion=CopiedTree->CriterionCalculation();
     NewCriterion=this->CriterionCalculation();
    }
    cout<< "The new criterion is "<<NewCriterion<<" and the old criterion is "<<OldCriterion<<endl;

    // Clear SplitTry
    if (SplitTry!=NULL) {
        delete SplitTry;
        SplitTry=NULL;
    }

    if (OldCriterion>=NewCriterion) { // Criterion of change not met, delete the modified tree and return the copied one
        delete this;
        AcceptanceDecision=0;
        cout<<"Split not accepted"<<endl;
        return CopiedTree;
    }
    else{ // Criterion of change met delete the not modified tree stored in CopiedTree and return the new model.
        delete CopiedTree;
        AcceptanceDecision=1;
        cout<<"Split accepted"<<endl;
//        int numbchild=this->GetNumberChildren();
//        for(int c=0;c<numbchild;c++){
//            this->GetChild(c)->PutAllLeavesToChildrenLevel();
//        }
        this->PutAllLeavesToMainNodesChildrenLevel(segment_param);
        this->ClearSMChecks();
        return this;
    }
}





/*************** METHODS FOR ATLAS ADAPTATION *******************/
float* TreeEM::AdaptPriors(SEG_PARAMETERS * segment_param){
    vector <int> Hierarchy = this->GetHierarchyVector();
    bool flag_comp_init=0;
    if (Hierarchy.size()>1){
        if(Hierarchy[1]==segment_param->class_keptpriorsmax){
            flag_comp_init=1;
            cout << "flag comp init on"<< endl;
        }
    }
    // Check if there are some priors to adapt
    if(this->GetPriors()==NULL){
        cout<<"No need for adaptation of statistical atlas since no atlas there"<<endl;
        return this->GetPriorsAdapted();
    }
    int numel=this->GetNumberElements();

    // Obtention of the needed dimensions to then blurr the responsabilities

    vector<int> DimImage;
    DimImage.push_back(this->GetPriors()->nx);
    DimImage.push_back(this->GetPriors()->ny);
    DimImage.push_back(this->GetPriors()->nz);

    // Temperation by the atlas with weight segment_param->AtlasWeight
    float * Priors_PTR=static_cast<float *>(this->GetPriors()->data);
    float * SmoothedPriors=new float[numel];
    float * InitPriors=new float[numel];
    int Level=this->GetLevel();
    int numbWeight=segment_param->AtlasWeight.size();
    float Weight;
    
    // Determination of Weight of temperation
    if (numbWeight==0){
        Weight=0;
    }
    else if (numbWeight==1){
        Weight=segment_param->AtlasWeight[0];
    }
    else if (Level<=numbWeight){
        Weight=segment_param->AtlasWeight[Level-1];
    }
    else {
        Weight=segment_param->AtlasWeight[0];
    }
    
    // Determination of smoothing strength
    int numbSmoothing=segment_param->AtlasSmoothing.size();
    float Smoothing;
    if (numbSmoothing==0){
        Smoothing=1;
    }
    else if (numbSmoothing==1){
        Smoothing=segment_param->AtlasSmoothing[0];
    }
    else if (Level<=numbSmoothing){
        Smoothing=segment_param->AtlasSmoothing[Level-1];
    }
    else {
        Smoothing=segment_param->AtlasSmoothing[0];
    }
//    float Weight=segment_param->AtlasWeight;
    Weight=Weight<=0?0:Weight;
    Weight=Weight>=1?1:Weight;
    cout<<"Priors_PTR " << GetMaxArray(Priors_PTR, numel)<<endl;
//    cout << " Adapting at level "<< Level <<" with AW "<<Weight<<" and AS "<<Smoothing;
    float NormalisedWeight=this->GetPartNormWeightAbovePriors();
    for(int i=0;i<numel;i++,Priors_PTR++){
//        SmoothedPriors[i]=NormalisedWeight*(1-Weight)*(*Priors_PTR);
        SmoothedPriors[i]=NormalisedWeight*(Weight)*(*Priors_PTR);
        InitPriors[i]=(*Priors_PTR);
    }

   cout<< "Smoothed Init range "<<GetMaxArray(SmoothedPriors, numel)<<endl;
    // Smoothing of the responsabilities (function developed in DirichletPriors) if there is some to do
    if(Weight>=1){
        return SmoothedPriors;
    }
    else {
        // Initialise float * such that contains values of NormResp on active voxels
        float * NormResp_PTR=this->GetNormResp();
        float * ImageResp=new float[numel];
        int * L2S_PTR=this->GetL2S();
        for(int i=0;i<numel;i++,L2S_PTR++){
            if(*L2S_PTR>=0){
                ImageResp[i]=*NormResp_PTR;
                NormResp_PTR++;
            }
            else{
                ImageResp[i]=0;
            }
        }
        cout << "Image resp range "<<GetMaxArray(ImageResp, numel)<<endl;
//    float * SmoothedPriors_tmp=GaussianBlurring(ImageResp, segment_param->AtlasSmoothing, DimImage);
    float * SmoothedPriors_tmp=GaussianBlurring(ImageResp, Smoothing, DimImage);
        cout << "Smoothed range "<<GetMaxArray(SmoothedPriors_tmp, numel)<<endl;
//    SaveTmpResult(SmoothedPriors_tmp,"/Users/Carole/Documents/PhD/SmoothResult.nii.gz");
    delete [] ImageResp;
    ImageResp=NULL;
    DimImage.clear();

    for(int i=0;i<numel;i++,Priors_PTR++){
//        SmoothedPriors[i]+=Weight*SmoothedPriors_tmp[i];
        SmoothedPriors[i]+=(1-Weight)*SmoothedPriors_tmp[i];
        if(flag_comp_init){
            SmoothedPriors[i]=max(InitPriors[i],SmoothedPriors[i]);
        }
    }
    Priors_PTR=static_cast<float *>(this->GetPriors()->data);
    delete [] SmoothedPriors_tmp;
    SmoothedPriors_tmp=NULL;

//    nifti_image * Result=nifti_copy_nim_info(this->GetDataImage());
//    Result->data = (void *) calloc(Result->nvox, sizeof(float));
//    float * Result_PTRtmp=static_cast<float *>(Result->data);
//    float * SmoothedPriors_PTR=SmoothedPriors;
//    for (int i=0; i<numel; i++, Result_PTRtmp++,SmoothedPriors_PTR++) {
//        *Result_PTRtmp=*SmoothedPriors_PTR;
//    }
//    nifti_set_filenames(Result, "/Users/Carole/Documents/PhD/TestAtlasSmooth.nii.gz", 0, 0);
//    nifti_image_write(Result);
//    nifti_image_free(Result);
    }

    return SmoothedPriors;
}

void TreeEM::AdaptPriorsAllLevels(SEG_PARAMETERS * segment_param){
    int numbchild=this->GetNumberChildren();
    for(int c=0;c<numbchild;c++){
        if (this->GetChild(c)->GetPriorsDirect()!=NULL) {
            nifti_image * NewPriors=this->GetChild(c)->TransformNormRespIntoPriors(segment_param);
            this->GetChild(c)->SetPriors(NewPriors);
            float * NewPriorsAdapted=static_cast<float *>(NewPriors->data);
//            SaveTmpResult(NewPriorsAdapted, "/Users/Carole/Documents/PhD/Testtmp.nii.gz");
            this->GetChild(c)->SetPriorsAdapted(NewPriorsAdapted);
        }
        this->GetChild(c)->AdaptPriorsAllLevels(segment_param);
    }
}

void TreeEM::AdaptPriorsChildren(SEG_PARAMETERS * segment_param){
    int numbchild=this->GetNumberChildren();
    for(int c=0;c<numbchild;c++){
        if (this->GetChild(c)->GetPriorsDirect()!=NULL) {
            nifti_image * NewPriors=this->GetChild(c)->TransformNormRespIntoPriors(segment_param);
            this->GetChild(c)->SetPriors(NewPriors);
            float * NewPriorsAdapted=static_cast<float *>(NewPriors->data);
            //            SaveTmpResult(NewPriorsAdapted, "/Users/Carole/Documents/PhD/Testtmp.nii.gz");
            this->GetChild(c)->SetPriorsAdapted(NewPriorsAdapted);
        }
    }
}

void TreeEM::AdaptPriorsOM7PK5(SEG_PARAMETERS * segment_param){
    if (this->GetFlagOutliers()!=7|| segment_param->PriorsKept!=5) {
        cout<<"Not adaptation as wanted";
        this->AdaptPriorsAllLevels(segment_param);
    }
    else{
        TreeEM * Root=this->FindRoot();
        int numbchild=Root->GetNumberChildren();
        for (int c=0; c<numbchild; c++) {
            if (Root->GetChild(c)->GetPriorsDirect()!=NULL) {
                nifti_image * NewPriors=Root->GetChild(c)->TransformNormRespIntoPriors(segment_param);
                Root->GetChild(c)->SetPriors(NewPriors);
                float * NewPriorsAdapted=static_cast<float *>(NewPriors->data);
                //            SaveTmpResult(NewPriorsAdapted, "/Users/Carole/Documents/PhD/Testtmp.nii.gz");
                Root->GetChild(c)->SetPriorsAdapted(NewPriorsAdapted);
            }
        }
        int numbGeneralClasses=Root->GetNumberGeneralClasses()/2; // the number of general classes is twice the number of tissues due to separation between brain and non brain part
        int numelmasked=Root->GetNumberMaskedElements();
        for (int c=0; c<numbGeneralClasses; c++) {
            // Initialisation of new seg to consider
            float * NewSeg=new float[numelmasked];
            for (int i=0; i<numelmasked; i++) {
                NewSeg[i]=0;
            }
            for (int l=0; l<2; l++) {
                for (int bnb=0; bnb<2; bnb++) {
                    float * NormRespToAdd=Root->GetChild(l)->GetChild(bnb)->GetChild(c)->GetNormResp();
                    for (int i=0; i<numelmasked; i++) {
                        NewSeg[i]+=NormRespToAdd[i];
                    }
                    nifti_image * NewPriors0=Root->GetChild(l)->GetChild(bnb)->GetChild(c)->TransformArrayIntoPriors(NewSeg,segment_param);
                    Root->GetChild(l)->GetChild(bnb)->GetChild(c)->SetPriors(NewPriors0);
                    float * NewPriorsAdapted0=static_cast<float *>(NewPriors0->data);
                    //            SaveTmpResult(NewPriorsAdapted, "/Users/Carole/Documents/PhD/Testtmp.nii.gz");
                    Root->GetChild(l)->GetChild(bnb)->GetChild(c)->SetPriorsAdapted(NewPriorsAdapted0);
                    Root->GetChild(l)->GetChild(bnb)->GetChild(c)->AdaptPriorsAllLevels(segment_param);
                    Root->GetChild(l)->GetChild(bnb)->GetChild(c)->AdaptPriorsAllLevels(segment_param);
                }
            }
            delete [] NewSeg;
            NewSeg=NULL;
        }
    }
}


void TreeEM::AdaptPriorsOM3PK8(SEG_PARAMETERS * segment_param){
    if (this->GetFlagOutliers()!=3 || (segment_param->PriorsKept!=8 && segment_param->PriorsKept!=5)) {
        this->AdaptPriorsAllLevels(segment_param);
    }
    else{
        if (segment_param->AtlasWeight.size()==1) {
            segment_param->AtlasWeight.push_back(0);
        }
        TreeEM * Root=this->FindRoot();
        int numbchild=Root->GetNumberChildren();
        for (int c=0; c<numbchild; c++) {
            if (Root->GetChild(c)->GetPriorsDirect()!=NULL) {
                float * UpdatedPriors = Root->GetChild(c)->AdaptPriors(segment_param);
                cout <<"Adaptation priors " << c << " "<< GetMaxArray(UpdatedPriors, Root->GetNumberElements())<<endl;
                Root->GetChild(c)->SetPriorsAdapted(UpdatedPriors);
                delete [] UpdatedPriors;
                UpdatedPriors=NULL;
                int numbChild2=Root->GetChild(c)->GetNumberChildren();
                for (int c2=0; c2<numbChild2; c2++) {
                    if (Root->GetChild(c)->GetChild(c2)->GetPriorsDirect()!=NULL) {
                        float * UpdatedPriors = Root->GetChild(c)->GetChild(c2)->AdaptPriors(segment_param);
                        Root->GetChild(c)->GetChild(c2)->SetPriorsAdapted(UpdatedPriors);
                        delete [] UpdatedPriors;
                        UpdatedPriors=NULL;
                    }
                }
            }
        }
    }
    this->NormalisePriorsAdapted();
    cout <<"Adaptation priors normalised "<< GetMaxArray(this->FindRoot()->GetChild(1)->GetPriorsAdaptedDirect(), this->GetNumberElements())<<endl;
}


void TreeEM::AdaptPriorsAllLevelsOM3PK5(SEG_PARAMETERS * segment_param){
    if (this->GetFlagOutliers()!=3 || segment_param->PriorsKept!=5) {
        this->AdaptPriorsAllLevels(segment_param);
    }
    else{
        TreeEM * Root=this->FindRoot();
        int numbchild=Root->GetNumberChildren();
        for (int c=0; c<numbchild; c++) {
            if (segment_param->flag_OutlierAtlas==3) {
                nifti_image * NewOutlierPriors=this->BuildOutliersPriors(segment_param);
                nifti_image * OppositePriors=this->CreateNormaliseOppositeImage(NewOutlierPriors);
                Root->GetChild(0)->SetPriors(OppositePriors);
                Root->GetChild(1)->SetPriors(NewOutlierPriors);
                float * PriorsAdaptedOutliers=static_cast<float *>(NewOutlierPriors->data);
                float * PriorsAdaptedInliers=static_cast<float *>(OppositePriors->data);
                Root->GetChild(0)->SetPriorsAdapted(PriorsAdaptedInliers);
                Root->GetChild(1)->SetPriorsAdapted(PriorsAdaptedOutliers);
            }
            else{
            if (Root->GetChild(c)->GetPriorsDirect()!=NULL) {
                nifti_image * NewPriors=Root->GetChild(c)->TransformNormRespIntoPriors(segment_param);
                Root->GetChild(c)->SetPriors(NewPriors);
                float * NewPriorsAdapted=static_cast<float *>(NewPriors->data);
                //            SaveTmpResult(NewPriorsAdapted, "/Users/Carole/Documents/PhD/Testtmp.nii.gz");
                Root->GetChild(c)->SetPriorsAdapted(NewPriorsAdapted);
            }
            }
        }
        int numbGeneralClasses=Root->GetNumberGeneralClasses();
        int numelmasked=Root->GetNumberMaskedElements();
        bool *BP;
        vector<nifti_image*>VectorBNBPriors;
        if (segment_param->flag_bnbComb) { // Case where OM 8 has been changed to OM3
            int numbBrainPriors=segment_param->vecBP.size();
            BP=new bool[segment_param->numb_classes]; // boolean array telling which prior should be considered under brain mask and therefore classified as it...
            for (int c=0; c<segment_param->numb_classes; c++) {
                BP[c]=0;
            }
            for (int nbp=0; nbp<numbBrainPriors; nbp++) {
                if (segment_param->vecBP[nbp]>segment_param->numb_classes) {
                    cout << "Impossible priors stated in bnb Comb"<<endl;
                    return;
                }
                BP[segment_param->vecBP[nbp]]=1;
                
            }
            VectorBNBPriors=ReadFromFilenamesVector(segment_param->filename_priors_bnb);
        }
        
        
        for (int c=0; c<numbGeneralClasses; c++) {
            float * SegInliers=Root->GetChild(0)->GetChild(c)->GetNormResp();
            float * SegOutliers=Root->GetChild(1)->GetChild(c)->GetNormResp();
//            int * Size=new int[2];
            int Size[2];
            Size[0]=numelmasked;
            Size[1]=1;
            float * NewSeg=Root->AddMatrix(SegInliers, SegOutliers, Size);
            nifti_image * NewPriors0=Root->GetChild(0)->GetChild(c)->TransformArrayIntoPriors(NewSeg,segment_param);
            nifti_image * NewPriors1=Root->GetChild(1)->GetChild(c)->TransformArrayIntoPriors(NewSeg,segment_param);
//            delete [] Size;
//            Size=NULL;
            if (segment_param->flag_bnbComb) {
                Root->MultiplyNii(NewPriors0, VectorBNBPriors[!BP[c]]);
                Root->MultiplyNii(NewPriors1, VectorBNBPriors[!BP[c]]);
            }
            
            Root->GetChild(0)->GetChild(c)->SetPriors(NewPriors0);
            float * NewPriorsAdapted0=static_cast<float *>(NewPriors0->data);
            Root->GetChild(0)->GetChild(c)->SetPriorsAdapted(NewPriorsAdapted0);

            Root->GetChild(1)->GetChild(c)->SetPriors(NewPriors1);
            float * NewPriorsAdapted1=static_cast<float *>(NewPriors1->data);
            Root->GetChild(1)->GetChild(c)->SetPriorsAdapted(NewPriorsAdapted1);
            delete [] NewSeg;
            NewSeg=NULL;
            Root->GetChild(0)->GetChild(c)->AdaptPriorsAllLevels(segment_param);
            Root->GetChild(1)->GetChild(c)->AdaptPriorsAllLevels(segment_param);
//            Root->GetChild(0)->GetChild(c)->SaveTmpResult(Root->GetChild(0)->GetChild(c)->GetPriorsAdapted(), "/Users/Carole/Documents/PhD/TestAdapt0.nii.gz");
//            Root->GetChild(1)->GetChild(c)->SaveTmpResult(Root->GetChild(1)->GetChild(c)->GetPriorsAdapted(), "/Users/Carole/Documents/PhD/TestAdapt1.nii.gz");
        }
    }
}

void TreeEM::FullAdaptPriors(SEG_PARAMETERS * segment_param){
    int numbchild=this->GetNumberChildren();
       if (segment_param->PriorsKept==0){
            for (int c=0;c<numbchild;c++){
                if(this->GetChild(c)->GetPriorsDirect()!=NULL){
                    nifti_image_free(this->GetChild(c)->GetPriorsDirect());
                    this->GetChild(c)->SetPriors(NULL);
                }
            }
            segment_param->BICFP=1; // if the priors are not kept, there is no question about the number of free parameters that has to take into account the mixing coefficients.
        }
    if(segment_param->PriorsKept>=2){
        if (segment_param->PriorsKept==5) {
            if (this->GetFlagOutliers()==7) {
                this->AdaptPriorsOM7PK5(segment_param);
            }
            else{
                this->AdaptPriorsOM3PK8(segment_param);
                //this->AdaptPriorsAllLevelsOM3PK5(segment_param);
            }
        }
        else if (segment_param->PriorsKept==6) {
            if (this->GetFlagOutliers()<5 && this->GetFlagOutliers()!=3) { //Case when there is only one level of adaptation
                this->AdaptPriorsAllLevels(segment_param);
            }
            else{
                this->AdaptPriorsChildren(segment_param);
                this->GetChild(0)->AdaptPriorsChildren(segment_param);
            }
        }
        else if (segment_param->PriorsKept==7){ // With choice PK7 : only adaptation at first level
            if (this->GetFlagOutliers()!=3 && this->GetFlagOutliers()<5){
                this->AdaptPriorsAllLevels(segment_param);
            }
            else{
                this->AdaptPriorsChildren(segment_param);
            }
        }
        else if(segment_param->PriorsKept==8&&segment_param->OutliersMod==3){
            this->AdaptPriorsOM3PK8(segment_param);
        }
        else{
            this->AdaptPriorsAllLevels(segment_param);
        }
        if(segment_param->flag_savePriors){
            this->SavePriorsAdapted(segment_param);
        }
        this->NormalisePriorsAdapted();
    }
}

nifti_image * TreeEM::BuildConstantPriors(float WeightInput){
    nifti_image * ConstantPriors=nifti_copy_nim_info(this->GetDataImage());
    ConstantPriors->dim[0]=3;
    ConstantPriors->dim[4]=1;
    int numel=this->GetNumberElements();
    nifti_update_dims_from_array(ConstantPriors);
    ConstantPriors->data = (void *) calloc(ConstantPriors->nvox, sizeof(float));
    float * ConstantPriors_PTRtmp=static_cast<float *>(ConstantPriors->data);
    for(int i=0;i<numel;i++,ConstantPriors_PTRtmp++){
        *ConstantPriors_PTRtmp=WeightInput;
    }
    return ConstantPriors;
}

// Create an atlas for the outliers threshold varying according to spatial knowledge and first update of parameters
nifti_image* TreeEM::BuildOutliersPriors( SEG_PARAMETERS * segment_param){
    float MahalDistance=segment_param->Mahal;
    int OutlierAtlasType=segment_param->flag_OutlierAtlas;
    nifti_image * OutlierAtlas=nifti_copy_nim_info(this->GetDataImage());
    OutlierAtlas->dim[0]=3;
    nifti_update_dims_from_array(OutlierAtlas);
    OutlierAtlas->data=(void *)calloc(OutlierAtlas->nvox, sizeof(float));
    float * OutlierAtlas_PTR=static_cast<float *>(OutlierAtlas->data);
    
    
    int numbclasses=this->GetNumberGeneralClasses();
    int numbmodal=this->GetNumberModalities();
    int numelmasked=this->GetNumberMaskedElements();
    int numel=this->GetNumberElements();
    vector<TreeEM*> GeneralClassesVector=this->GetGeneralClassesVector();
    switch (OutlierAtlasType) {
        case 0:{ // case where uniform value over whole image space
            for (int i=0; i<numel; i++) {
                OutlierAtlas_PTR[i]=MahalThreshold[numbmodal-1];
            }
        }
            break;
        case 1:{ //case where using only the ratio between squared covariance determinant
            vector<float *> PrimaryPriorsVector;
            vector<float> PrimaryDeterminant;
            vector<float *> PrimaryVarianceVector;
            // Check that Priors are well normalised before continuing otherwise needed normalisation
            if(!this->ArePriorsNormalised()){
                this->NormalisePriors();
                this->NormalisePriorsAdapted();
            }
            for (int g=0; g<numbclasses; g++) {
                if (GeneralClassesVector[g]->GetPriorsDirect()!=NULL) {
                    PrimaryPriorsVector.push_back(static_cast<float*>(GeneralClassesVector[g]->GetPriorsDirect()->data));
                    float * VariancePrimary=GeneralClassesVector[g]->GetVarianceDirect();
                    float Determinant=determinant(VariancePrimary, numbmodal);
                    PrimaryDeterminant.push_back(Determinant);
                    PrimaryVarianceVector.push_back(VariancePrimary);
                }
            }
            int numbp=PrimaryPriorsVector.size();
            if (numbp==0) {
                return this->BuildConstantPriors(0.01);
            }
            float * MeanVariance=GetMeanVarianceGeneralClasses();
            float DeterminantMean=determinant(MeanVariance, numbmodal);
            
            vector<float> NormalisationVector;
            //    for (int p=0; p<numbp; p++) {
            //        NormalisationVector.push_back(1.0/powf(pow_int(2*M_PI,numbmodal)*PrimaryDeterminant[p], 0.5)*expf(-0.5*MahalDistance*MahalDistance));
            //    }
            for (int p=0; p<numbp; p++) {
                NormalisationVector.push_back(sqrt(DeterminantMean/PrimaryDeterminant[p])*MahalThreshold[numbmodal-1]);
            }
            for (int i=0; i<numel; i++) {
                OutlierAtlas_PTR[i]=0;
            }
            for (int i=0; i<numel; i++) {
                for (int p=0; p<numbp; p++) {
                    OutlierAtlas_PTR[i]+=PrimaryPriorsVector[p][i]*NormalisationVector[p];
                }
            }
            delete [] MeanVariance;
            MeanVariance=NULL;
            for (int p=0; p<numbp; p++) {
                delete [] PrimaryVarianceVector[p];
                PrimaryVarianceVector[p]=NULL;
            }
    }
            break;
        case 2:{
            float * TypicalityMap=this->BuildAtypicalityMap(segment_param);
            // Creating Corresponding Image
            float * OutlierAtlas_PTR=static_cast<float *>(OutlierAtlas->data);
            for (int i=0; i<numel; i++) {
                OutlierAtlas_PTR[i]=0;
            }
            for (int i=0; i<numel; i++) {
                    OutlierAtlas_PTR[i]=TypicalityMap[i];

            }
            delete [] TypicalityMap;
            TypicalityMap=NULL;
        }
            break;
        case 3: { // case where the atypicality map is smoothed before becoming the outlier atlas
            float * TypicalityMap=this->BuildAtypicalityMap(segment_param);
            vector<int> Dim;
            for (int d=0; d<3; d++) {
                Dim.push_back(this->GetDataImage()->dim[d+1]);
            }
            float * BlurredTypicalityMap=this->GaussianBlurring(TypicalityMap, segment_param->AtlasSmoothing[0], Dim);
            // Creating Corresponding Image
            float * OutlierAtlas_PTR=static_cast<float *>(OutlierAtlas->data);
            for (int i=0; i<numel; i++) {
                OutlierAtlas_PTR[i]=0;
            }
//            int * L2S_PTR=this->GetL2S();
//            int j=0;
            for (int i=0; i<numel; i++) {
                OutlierAtlas_PTR[i]=BlurredTypicalityMap[i];
            }
            delete [] TypicalityMap;
            TypicalityMap=NULL;
            delete [] BlurredTypicalityMap;
            BlurredTypicalityMap=NULL;
            
        }
            break;
        default:{ // Case when we use the Typicality Map
            float * TypicalityMap=new float[numelmasked];
            for(int i=0;i<numelmasked;i++){
                TypicalityMap[i]=1;
            }
            // Populating TypicalityMap
            for (int c=0; c<numbclasses; c++) {
                float * Variance=GeneralClassesVector[c]->GetVarianceDirect();
                float NormalisationFactor=expf(-0.5*MahalDistance*MahalDistance)*1/(sqrt(pow_int(2*M_PI, numbmodal)*determinant(Variance , numbmodal)));
                float * DensityDist_tmp=new float[numelmasked];
                for (int i=0; i<numelmasked; i++) {
                    DensityDist_tmp[i]=0;
                }
                GeneralClassesVector[c]->MakeWeightedDist(DensityDist_tmp);
                //        float * NormRespToUse=GeneralClassesVector[c]->GetNormResp();
                float * NormRespToUse=GeneralClassesVector[c]->GetPriorsAdapted();
                int* S2L_PTR=this->GetS2L();
                for (int i=0; i<numelmasked; i++) {
                    TypicalityMap[i]-=NormRespToUse[S2L_PTR[i]]*(DensityDist_tmp[i]/(DensityDist_tmp[i]+NormalisationFactor));
                }
                delete [] DensityDist_tmp;
                DensityDist_tmp=NULL;
                delete [] Variance;
                Variance=NULL;
            }
            
            // Creating Corresponding Image
            float * OutlierAtlas_PTR=static_cast<float *>(OutlierAtlas->data);
            for (int i=0; i<numel; i++) {
                OutlierAtlas_PTR[i]=0;
            }
            int * L2S_PTR=this->GetL2S();
            int j=0;
            for (int i=0; i<numel; i++) {
                OutlierAtlas_PTR[i]=0;
                if (L2S_PTR[i]>=0) {
                    OutlierAtlas_PTR[i]=TypicalityMap[j];
                    j++;
                }
            }
            delete [] TypicalityMap;
            TypicalityMap=NULL;
        }
            break;
    }

    return OutlierAtlas;
}

// Return an array of size numel containing the atypicality Map based on Norm Resp and the parameters of the Gaussian Leaves. All voxels not in the mask are set to 0 as typical.
float * TreeEM::BuildAtypicalityMap(SEG_PARAMETERS * segment_param){
//    int numelmasked=this->GetNumberMaskedElements();
    int numel=this->GetNumberElements();
    vector<TreeEM *> GaussianLeaves=this->GetAllGaussianLeaves();
    int * L2S_PTR=this->GetL2S();
    // Initialisation of AtypicalityMap 0 outside of Mask, 1 inside
    float * AtypicalityMap=new float[numel];
    for (int i=0; i<numel; i++) {
        if (L2S_PTR[i]>=0) {
            AtypicalityMap[i]=1;
        }
        else {
            AtypicalityMap[i]=0;
        }
    }
    // Then populating map
    // Populating TypicalityMap
    int numbclasses=GaussianLeaves.size();
    float MahalDistance=segment_param->Mahal;
    int numbmodal=this->GetNumberModalities();
    for (int c=0; c<numbclasses; c++) {
        
        float * Variance=GaussianLeaves[c]->GetVarianceDirect();
        float NormalisationFactor=expf(-0.5*MahalDistance*MahalDistance)*1/(sqrt(pow_int(2*M_PI, numbmodal)*determinant(Variance , numbmodal)));
        float * DensityDist_tmp=GaussianLeaves[c]->MakeGaussianDistribution();
        //        float * NormRespToUse=GeneralClassesVector[c]->GetNormResp();
        float * NormRespToUse=GaussianLeaves[c]->GetNormResp();
        TreeEM * UniformComplement=GaussianLeaves[c]->GetCorrespondingUniform();
        float * NormRespUniformComplement=NULL;
        if(UniformComplement !=NULL){
            NormRespUniformComplement=UniformComplement->GetNormResp();
        }
        int anatClass=GaussianLeaves[c]->GetAnatClass();
        int NumberCorrespondingGaussianComponents=GetAllGaussianLeavesAnatomicalClass(anatClass).size();
        NumberCorrespondingGaussianComponents= NumberCorrespondingGaussianComponents==0?1:NumberCorrespondingGaussianComponents;
//        int* S2L_PTR=this->GetS2L();
        L2S_PTR=this->GetL2S();
        int j=0;
        for (int i=0; i<numel; i++) {
            if (L2S_PTR[i]>=0) {
                if (NormRespUniformComplement!=NULL) {
                    AtypicalityMap[i]-=(NormRespToUse[j]+NormRespUniformComplement[j]/NumberCorrespondingGaussianComponents)*(DensityDist_tmp[j]/(DensityDist_tmp[j]+NormalisationFactor));
                }
                else{
                  AtypicalityMap[i]-=(NormRespToUse[j])*(DensityDist_tmp[j]/(DensityDist_tmp[j]+NormalisationFactor));
                }
                j++;
            }
            
        }
        delete [] DensityDist_tmp;
        DensityDist_tmp=NULL;
        delete [] Variance;
        Variance=NULL;
    }
    return AtypicalityMap;
}

nifti_image * TreeEM::BuildOutliersPriors_bis(float MahalDistance){
    int numbclasses=this->GetNumberGeneralClasses();
    int numbmodal=this->GetNumberModalities();
    int numelmasked=this->GetNumberMaskedElements();
    int numel=this->GetNumberElements();
    vector<TreeEM*> GeneralClassesVector=this->GetGeneralClassesVector();
    float * TypicalityMap=new float[numelmasked];
    for(int i=0;i<numelmasked;i++){
        TypicalityMap[i]=1;
    }
      // Populating TypicalityMap
    for (int c=0; c<numbclasses; c++) {
        float * Variance=GeneralClassesVector[c]->GetVarianceDirect();
        float NormalisationFactor=expf(-0.5*MahalDistance*MahalDistance)*1/(sqrt(pow_int(2*M_PI, numbmodal)*determinant(Variance , numbmodal)));
        float * DensityDist_tmp=GeneralClassesVector[c]->MakeGaussianDistribution();
//        float * NormRespToUse=GeneralClassesVector[c]->GetNormResp();
        float * NormRespToUse=GeneralClassesVector[c]->GetPriorsAdapted();
        int* S2L_PTR=this->GetS2L();
        for (int i=0; i<numelmasked; i++) {
            TypicalityMap[i]-=NormRespToUse[S2L_PTR[i]]*(DensityDist_tmp[i]/(DensityDist_tmp[i]+NormalisationFactor));
        }
        delete [] DensityDist_tmp;
        DensityDist_tmp=NULL;
        delete [] Variance;
        Variance=NULL;
    }
    
    // Creating Corresponding Image
    nifti_image * OutlierAtlas=nifti_copy_nim_info(this->GetDataImage());
    OutlierAtlas->dim[0]=3;
    nifti_update_dims_from_array(OutlierAtlas);
    OutlierAtlas->data=(void *)calloc(OutlierAtlas->nvox, sizeof(float));
    float * OutlierAtlas_PTR=static_cast<float *>(OutlierAtlas->data);
    for (int i=0; i<numel; i++) {
        OutlierAtlas_PTR[i]=0;
    }
    int * L2S_PTR=this->GetL2S();
    int j=0;
    for (int i=0; i<numel; i++) {
        OutlierAtlas_PTR[i]=0;
        if (L2S_PTR[i]>=0) {
            OutlierAtlas_PTR[i]=TypicalityMap[j];
            j++;
        }
    }
    return OutlierAtlas;
}

nifti_image * TreeEM::CreateOutBrainPriors(SEG_PARAMETERS * segment_param){
    if (!segment_param->flag_manual_priors) {
        return NULL;
    }
    int numbclasses=this->GetNumberGeneralClasses();
    vector<TreeEM *> GeneralNodes=this->GetGeneralClassesVector();
    vector<float *> CurrentPriors;
    for (int c=0; c<numbclasses;c++) {
        CurrentPriors.push_back(static_cast<float*>(GeneralNodes[c]->GetPriorsDirect()->data));
    }
    if (GeneralNodes[0]->GetPriorsDirect()==NULL) {
        return NULL;
    }
    this->NormalisePriorsOverFlown();
    this->NormalisePriorsAdaptedOverFlown();
    nifti_image * OutBrainPriors=nifti_copy_nim_info(this->GetDataImage());
    OutBrainPriors->dim[0]=3;
    OutBrainPriors->dim[4]=1;
    nifti_update_dims_from_array(OutBrainPriors);
    OutBrainPriors->data=(void*)calloc(OutBrainPriors->nvox, sizeof(float));
    float * OutBrainPriors_PTR=static_cast<float *>(OutBrainPriors->data);
    float tmpSum=0;
    int numel=OutBrainPriors->nvox;
    for (int i=0; i<numel; i++,OutBrainPriors_PTR++) {
        tmpSum=0;
        for (int c=0; c<numbclasses; c++) {
            tmpSum+=(*CurrentPriors[c]);
            CurrentPriors[c]++;
        }
        *OutBrainPriors_PTR=1-tmpSum;
    }
//    string SavingPriors="/Users/Carole/Documents/PhD/PriorsOutBrain.nii.gz";
//    stringstream ss;
//    nifti_set_filenames(OutBrainPriors, SavingPriors.c_str(), 0, 0);
//    nifti_image_write(OutBrainPriors);
    return OutBrainPriors;
}

nifti_image * TreeEM::CreatePriorsFromAdaptedPriors(){
    float * PriorsAdaptedToUse=this->GetPriorsAdapted();
    if(PriorsAdaptedToUse==NULL){
        return NULL;
    }
    nifti_image * PriorsCreated=nifti_copy_nim_info(this->GetPriors());
    PriorsCreated->data=(void *) calloc(PriorsCreated->nvox,sizeof(float));
    float * PriorsCreated_PTR=static_cast<float *>(PriorsCreated->data);
    int numel=PriorsCreated->nvox;
    for(int i=0;i<numel;i++,PriorsCreated_PTR++,PriorsAdaptedToUse++){
        *PriorsCreated_PTR=*PriorsAdaptedToUse;
    }
    return PriorsCreated;
}

// Returns a pointer to a nifti image to be used as atlas for a gaussian stemming from a uniform in case 5 for SplittingUniform
vector<nifti_image *> TreeEM::CreatePriorsFromSplittingUniform(SEG_PARAMETERS * segment_param,int InitSplitUnif=0){
//    TreeEM * UnifNode=this->FindUnifDist(segment_param);
    vector<nifti_image *> PriorsSUG;
    TreeEM * UnifNode=this;
    if (UnifNode->GetDistributionType()!=2) {
        return PriorsSUG;
    }
    Parameters * ParamSU=UnifNode->ParametersForSplittingUniform3(segment_param,InitSplitUnif);
    UnifNode->CreateAndAddChildPriors(segment_param);
    UnifNode->GetChild(0)->SetParameters(ParamSU);
    
    delete ParamSU;
    ParamSU=NULL;
    
    float * LLGPriors=UnifNode->GetChild(0)->MakeGaussianDistribution();
    int * L2S_PTR=this->GetL2S();
    
    nifti_image * PriorsSUGG=nifti_copy_nim_info(this->GetDataImage());
    PriorsSUGG->dim[0]=3;
    PriorsSUGG->dim[4]=1;
    PriorsSUGG->dim[5]=1;
    nifti_update_dims_from_array(PriorsSUGG);
    nifti_image * PriorsSUGU=nifti_copy_nim_info(PriorsSUGG);
    PriorsSUGG->data=(void *)calloc(PriorsSUGG->nvox, sizeof(float));
    PriorsSUGU->data=(void *)calloc(PriorsSUGU->nvox, sizeof(float));
    float * PriorsSUGG_PTR=static_cast<float *>(PriorsSUGG->data);
    float * PriorsSUGU_PTR=static_cast<float *>(PriorsSUGU->data);
    int numel=PriorsSUGG->nvox;
    float minLLG=1;
    float maxLLG=0;
    for (int i=0; i<numel; i++,PriorsSUGG_PTR++,L2S_PTR++,PriorsSUGU_PTR++) {
        *PriorsSUGG_PTR=0;
        *PriorsSUGU_PTR=0;
        if (*L2S_PTR>=0) {
            *PriorsSUGG_PTR=*LLGPriors/(*LLGPriors+segment_param->OutliersWeight*10);
            if (*LLGPriors <minLLG) {
                minLLG=*LLGPriors;
            }
            if (*LLGPriors>maxLLG) {
                maxLLG=*LLGPriors;
            }
            *PriorsSUGU_PTR=segment_param->OutliersWeight*1/(*LLGPriors+segment_param->OutliersWeight*1);
            LLGPriors++;
        }
    }
//    nifti_set_filenames(PriorsSUGG, "/Users/Carole/Documents/PhD/TestGcase5.nii.gz", 0, 0);
//    nifti_image_write(PriorsSUGG);
//    nifti_set_filenames(PriorsSUGU, "/Users/Carole/Documents/PhD/TestUcase5.nii.gz", 0, 0);
//    nifti_image_write(PriorsSUGU);
    PriorsSUG.push_back(PriorsSUGG);
    PriorsSUG.push_back(PriorsSUGU);
    return PriorsSUG;
}

nifti_image * TreeEM::TransformArrayIntoPriors(float * NewSeg, SEG_PARAMETERS * segment_param){
    // NewSeg is assumed to be of size numelmasked
    nifti_image * PriorsResult = nifti_copy_nim_info(this->GetDataImage());
    //Make in only one time point 3D image
    PriorsResult->dim[0]=3;
    PriorsResult->dim[4]=1;
    PriorsResult->dim[5]=1;
    nifti_update_dims_from_array(PriorsResult);
    PriorsResult->data=(void *)calloc(PriorsResult->nvox,sizeof(float));
    float * PriorsResult_PTR=static_cast<float*>(PriorsResult->data);
    // Transform NormResp into float pointer of size of image
    int numel = this->GetNumberElements();
    float * NormRespImage=new float[numel];
    // Initialisation by 0
    for(int i=0;i<numel;i++){
        NormRespImage[i]=0;
    }
    float * NormResp_PTR=NewSeg;
    int * L2S_PTR=this->GetL2S();
    for(int i=0;i<numel;i++,L2S_PTR++){
        if(*L2S_PTR>=0){
            NormRespImage[i]=*NormResp_PTR;
            NormResp_PTR++;
        }
    }
    //    SaveTmpResult(NormRespImage, "/Users/Carole/Documents/PhD/TestNormResp.nii.gz");
    vector<int> Dim;
    for(int d=1;d<=3;d++){
        Dim.push_back(PriorsResult->dim[d]);
    }
    float * NormRespImageSmoothed=GaussianBlurring(NormRespImage,segment_param->AtlasSmoothing[0],Dim);
    //    SaveTmpResult(NormRespImageSmoothed, "/Users/Carole/Documents/PhD/TestNormResp.nii.gz");
    delete [] NormRespImage;
    NormRespImage=NULL;
    // Copy result into PriorsResultData
    for(int i=0;i<numel;i++,PriorsResult_PTR++){
        *PriorsResult_PTR=NormRespImageSmoothed[i];
    }
    //    SaveTmpResult(static_cast<float*>( PriorsResult->data), "/Users/Carole/Documents/PhD/TestNormResp.nii.gz");
    delete [] NormRespImageSmoothed;
    NormRespImageSmoothed=NULL;
    return PriorsResult;
}


nifti_image * TreeEM::TransformNormRespIntoPriors(SEG_PARAMETERS * segment_param){
    //Create image in which Priors will be stored.
//    nifti_image * PriorsResult=NULL;
//    if (this->GetPriors()!=NULL) {
//        PriorsResult = nifti_copy_nim_info(this->GetPriors());
//    }
//    else{
//        PriorsResult = nifti_copy_nim_info(this->GetDataImage());
//    }
    nifti_image * PriorsResult = nifti_copy_nim_info(this->GetDataImage());
    //Make in only one time point 3D image
    PriorsResult->dim[0]=3;
    PriorsResult->dim[4]=1;
    PriorsResult->dim[5]=1;
    nifti_update_dims_from_array(PriorsResult);
    PriorsResult->data=(void *)calloc(PriorsResult->nvox,sizeof(float));
    float * PriorsResult_PTR=static_cast<float*>(PriorsResult->data);
    // Transform NormResp into float pointer of size of image
    int numel = this->GetNumberElements();
    float * NormRespImage=new float[numel];
    // Initialisation by 0
    for(int i=0;i<numel;i++){
        NormRespImage[i]=0;
    }
    float * NormResp_PTR=this->GetNormResp();
    int * L2S_PTR=this->GetL2S();
    for(int i=0;i<numel;i++,L2S_PTR++){
        if(*L2S_PTR>=0){
            NormRespImage[i]=*NormResp_PTR;
            NormResp_PTR++;
        }
    }
//    SaveTmpResult(NormRespImage, "/Users/Carole/Documents/PhD/TestNormResp.nii.gz");
    vector<int> Dim;
    for(int d=1;d<=3;d++){
        Dim.push_back(PriorsResult->dim[d]);
    }
    float * NormRespImageSmoothed=GaussianBlurring(NormRespImage,segment_param->AtlasSmoothing[0],Dim);
//    SaveTmpResult(NormRespImageSmoothed, "/Users/Carole/Documents/PhD/TestNormResp.nii.gz");
    delete [] NormRespImage;
    NormRespImage=NULL;
    nifti_image * PriorsInit=NULL;
    float * PriorsInitData=NULL;
    float Weight=0;
    // Copy result into PriorsResultData
    if (segment_param->AtlasWeight[0]>0) {
        PriorsInit=this->GetPriors();
        Weight=segment_param->AtlasWeight[0];
        if (PriorsInit!=NULL) {
            PriorsInitData=static_cast<float*>(PriorsInit->data);
        }
    }
    if (PriorsInitData!=NULL) {
        for(int i=0;i<numel;i++,PriorsResult_PTR++){
            *PriorsResult_PTR=Weight*(PriorsInitData[i])+(1-Weight)*NormRespImageSmoothed[i];
        }
    }
    else{
        for(int i=0;i<numel;i++,PriorsResult_PTR++){
                *PriorsResult_PTR=NormRespImageSmoothed[i];
        }
    }
   
    
        
//    SaveTmpResult(static_cast<float*>( PriorsResult->data), "/Users/Carole/Documents/PhD/TestNormResp.nii.gz");
    delete [] NormRespImageSmoothed;
    NormRespImageSmoothed=NULL;
    return PriorsResult;
}


/***************** METHODS FOR BIAS FIELD CORRECTION *************/

// Returns a float array with all the basis functions to be used in the bias field correction
/** REMARK : To be thought again to see if we want to get it at each iteration and delete it afterwards or store it at the root as L2S or S2L **/
float * TreeEM::MakeBasisFunctions(){
    int numbFunctions=(int)((BForder+1)*(BForder+2)*(BForder+3))/6;
    int numelmasked=this->GetNumberMaskedElements();
    int sizeBasisFunctions=numbFunctions*numelmasked;
    float * BasisFunctions=new float[sizeBasisFunctions];//{0};
    for(int i=0;i<sizeBasisFunctions;i++){
        BasisFunctions[i]=0;
    }
    // Find the factors for the affine transformation of the indices so that the power functions are applied between 0 and 1
    float FactorX=(float)(2.0/(this->GetDataImage()->nx-1));
    float FactorY=(float)(2.0/(this->GetDataImage()->ny-1));
    float FactorZ=(float)(2.0/(this->GetDataImage()->nz-1));

    int SizePlane=this->GetDataImage()->nx*this->GetDataImage()->ny;
    int SizeColumn=this->GetDataImage()->nx;
    int zValue=0;
    int yValue=0;
    int xValue=0;

    int l=0;//Represent the index of the considered basis function
    for (int order=0; order<=BForder; order++) {
        for (int xorder=0; xorder<=order; xorder++) {
            for (int yorder=0; yorder<=order-xorder; yorder++) {
                int zorder=order-xorder-yorder; // the sum of the orders for the different directions must be at most BForder.
                // Reinitialisation of the pointers
                int * S2L_PTR=this->GetS2L();
                float * BasisFunctions_PTR=&BasisFunctions[numelmasked*l];
                for (int i=0; i<numelmasked; i++,S2L_PTR++,BasisFunctions_PTR++) {
                    // conversion of S2L value into x,y and z component
                    zValue=*S2L_PTR/SizePlane;
                    yValue=(*S2L_PTR-zValue*SizePlane)/SizeColumn;
                    xValue=(*S2L_PTR)-zValue*SizePlane-yValue*SizeColumn;

                    // Filling the BasisFunctions matrix with the proper values modified to be symmetric and between -1 and 1.
                    *BasisFunctions_PTR=pow_int(xValue*FactorX-1, xorder)*pow_int(yValue*FactorY-1, yorder)*pow_int(zValue*FactorZ-1, zorder);
                }
                l++;
            }
        }
    }
    return BasisFunctions;
}

// Returns the vector of numbmodal pointers to float array containing the values for the W matrix used in VL BF correction.
float * TreeEM::MakeWMatrixChildren(){
    int numbmodal=this->GetNumberModalities();
    int numelmasked=this->GetNumberMaskedElements();
    
    vector<TreeEM *> GeneralNodes=this->GetGeneralClassesVector();
    int numbchild=GeneralNodes.size();
    int OutliersType=this->GetFlagOutliers();
    float * WMatrix;
    if (OutliersType>0 && OutliersType!=4) { // in case where an outlier model is used, only the voxels not considered as outliers are used to compute the bias field coefficients
        bool * OutliersSeg=this->GetSegOutliers();
        int numelInliers=this->GetNumberInliers();
        WMatrix=new float[numelInliers*numbmodal];//{0};
        if(WMatrix==NULL){
            cout<<"Did not allocate Wmatrix properly"<<endl;
        }
        for(int i=0;i<numelInliers*numbmodal;i++){
            WMatrix[i]=0;
        }
        for(int m=0;m<numbmodal;m++){
            for (int c=0; c<numbchild; c++) {
                //Reinitialisation of the pointers
                float * WMatrix_PTR=&WMatrix[m*numelInliers];
                //            float * NormResp_PTR=this->GetChild(c)->GetNormResp();
                float * NormResp_PTR=GeneralNodes[c]->GetNormResp();
                //            float * DiagVarianceValue=this->GetChild(c)->GetDiagVarianceDirect();
                float * DiagVarianceValue=GeneralNodes[c]->GetDiagVarianceDirect_corr();
                float invVariance=DiagVarianceValue[m]>1E-6?1.0/DiagVarianceValue[m]:1E6;
                
                for (int i=0; i<numelmasked; i++,NormResp_PTR++) {
                    // Filling of the matrix as sum of normresp for the classes divided by the value of the diagonal in the covariance matrix.
                    if(!OutliersSeg[i]){ // Meaning that the considered voxel has to be taken into account since it is an inlier
                    *WMatrix_PTR+=(float)*NormResp_PTR*invVariance;
                        WMatrix_PTR++;
                    }
                }
                delete [] DiagVarianceValue;
            }
        }
        delete [] OutliersSeg;
        OutliersSeg=NULL;
        
        for(int m=0;m<numbmodal;m++){
            int  CountWMatrixZero=0;
            for(int i=0;i<numelInliers;i++){
                if(WMatrix[i+m*numelInliers]==0){
                    CountWMatrixZero++;
                }
            }
            if(CountWMatrixZero>0){
                cout<<"Pb with sum NormResp in calculation WMatrix for modality "<<m<<" is "<<CountWMatrixZero<<endl;
            }
        }

    }
    else{
        int sizeWMatrix=numbmodal*numelmasked;
    WMatrix=new float[sizeWMatrix];//{0};
    if(WMatrix==NULL){
        cout<<"Did not allocate Wmatrix properly"<<endl;
    }
    for(int i=0;i<sizeWMatrix;i++){
        WMatrix[i]=0;
    }
    for(int m=0;m<numbmodal;m++){
        for (int c=0; c<numbchild; c++) {
            //Reinitialisation of the pointers
            float * WMatrix_PTR=&WMatrix[m*numelmasked];
//            float * NormResp_PTR=this->GetChild(c)->GetNormResp();
            float * NormResp_PTR=GeneralNodes[c]->GetNormResp();
//            float * DiagVarianceValue=this->GetChild(c)->GetDiagVarianceDirect();
            float * DiagVarianceValue=GeneralNodes[c]->GetDiagVarianceDirect_corr();
            float invVariance=DiagVarianceValue[m]>1E-6?1.0/DiagVarianceValue[m]:1E6;
            if (OutliersType==4) {
                float * Typicality_PTR=&this->GetNormResp()[numelmasked];
                for (int i=0; i<numelmasked; i++,WMatrix_PTR++,NormResp_PTR++,Typicality_PTR++) {
                    // Filling of the matrix as sum of normresp for the classes divided by the value of the diagonal in the covariance matrix.
                    
                    *WMatrix_PTR+=(float)*NormResp_PTR*(*Typicality_PTR)*invVariance;
                }
            }
            else{
            for (int i=0; i<numelmasked; i++,WMatrix_PTR++,NormResp_PTR++) {
                // Filling of the matrix as sum of normresp for the classes divided by the value of the diagonal in the covariance matrix.

                *WMatrix_PTR+=(float)*NormResp_PTR*invVariance;
            }
            }
            delete [] DiagVarianceValue;
        }
    }

    for(int m=0;m<numbmodal;m++){
       int  CountWMatrixZero=0;
        for(int i=0;i<numelmasked;i++){
            if(WMatrix[i+m*numelmasked]==0){
                CountWMatrixZero++;
            }
        }
        if(CountWMatrixZero>0){
            cout<<"Pb with sum NormResp in calculation WMatrix for modality "<<m<<" is "<<CountWMatrixZero<<endl;
        }
    }
    }
    return WMatrix;
}

void TreeEM::PrintGMatrix(){
    if (this->GetGMatrix()==NULL) {
        cout << "No GMatrix to print"<<endl;
        return;
    }
    else {
        float * GMatrixToPrint=this->GetGMatrix();
        int numbLeaves=this->GetNumberAllLeaves();
        cout<< "Printing GMatrix ..."<<endl;
        for (int l1=0; l1<numbLeaves; l1++) {
            for (int l2=0; l2<numbLeaves; l2++) {
                cout << GMatrixToPrint[l1*numbLeaves +l2]<<" ";
            }
            cout<<endl;
        }
        cout<<endl;
    }
    return;
}

// Returns in a vector of pointers  the RMatrix needed for VL BF correction according to the different modalities.
float * TreeEM::MakeRMatrixChildren(){


    int numbmodal=this->GetNumberModalities();
    int numelmasked=this->GetNumberMaskedElements();
    vector<TreeEM *>GeneralNodes =this->GetGeneralClassesVector();
    //    int numbchild=this->GetNumberChildren();
    int numbchild=GeneralNodes.size();
    int numel=this->GetNumberElements();
    float * WMatrix=this->MakeWMatrixChildren();
    float * Data=static_cast<float*>(this->GetDataImage()->data);
    float * Data_PTR=Data;
    int * L2S_PTR=this->GetL2S();
    float * RMatrix;
    int OutlierType=this->GetFlagOutliers();
    if (OutlierType>0 && OutlierType!=4) {
        int numelInlier=this->GetNumberInliers();
        bool * OutlierSeg=this->GetSegOutliers();
        RMatrix=new float[numelInlier*numbmodal];
        
        for(int i=0;i<numelInlier*numbmodal;i++){
            RMatrix[i]=0;
        }
        int m=0;
//#ifdef _OPENMP
//#pragma omp parallel for shared(numbmodal,numelInlier,numbchild,numelmasked,OutlierSeg,RMatrix,WMatrix) private(m)
//#endif
        for( m=0;m<numbmodal;m++){
            L2S_PTR=this->GetL2S();
            Data_PTR=&Data[m*numel];
            float * RMatrix_PTR=&RMatrix[m*numelInlier];
            for (int c=0; c<numbchild; c++) {
                //Reinitialisation of the pointers
                RMatrix_PTR=&RMatrix[m*numelInlier];
                //            float * NormResp_PTR=this->GetChild(c)->GetNormResp();
                float * NormResp_PTR=GeneralNodes[c]->GetNormResp();
                float * WMatrix_PTR=&WMatrix[m*numelInlier];
                //            float *  Mean=this->GetChild(c)->GetMeanDirect();
                float * Mean=GeneralNodes[c]->GetMeanDirect();
                //            float * DiagVarianceValue=this->GetChild(c)->GetDiagVarianceDirect();
                float * DiagVarianceValue=GeneralNodes[c]->GetDiagVarianceDirect_corr();
                float invVariance=DiagVarianceValue[m]>1E-6?1.0/DiagVarianceValue[m]:1E6;
                for (int i=0; i<numelmasked; i++,NormResp_PTR++) {
                    // Filling of the matrix as normalised weighted sum of the means
                    if (!OutlierSeg[i]&& *WMatrix_PTR>0) { // Take care of case where WMatrix == 0 possible with outlier model
                        *RMatrix_PTR+=(float)(*NormResp_PTR*Mean[m]*invVariance)/(*WMatrix_PTR);
                        if (*RMatrix_PTR!=*RMatrix_PTR) {
                            cout<<"Nan pb for RMatrix"<<endl;
                        }
                        RMatrix_PTR++;
                        WMatrix_PTR++;
                    }
                }
                delete [] Mean;
                delete [] DiagVarianceValue;
            }
            RMatrix_PTR=&RMatrix[m*numelInlier];
            bool* OutlierSeg_PTR=OutlierSeg;
            for (int i=0; i<numel; i++, Data_PTR++,L2S_PTR++) {
                if (*L2S_PTR>=0) {
                    if (!*OutlierSeg_PTR) {
                        *RMatrix_PTR=*Data_PTR-*RMatrix_PTR;
                        RMatrix_PTR++;
                    }
                    OutlierSeg_PTR++;
                }
            }
        }
        delete[] OutlierSeg;
        OutlierSeg=NULL;
    }
    else{
        int sizeRMatrix=numelmasked*numbmodal;
    RMatrix=new float[sizeRMatrix];

    for(int i=0;i<sizeRMatrix;i++){
        RMatrix[i]=0;
    }
    for(int m=0;m<numbmodal;m++){
        L2S_PTR=this->GetL2S();
        Data_PTR=&Data[m*numel];
        float * RMatrix_PTR=&RMatrix[m*numelmasked];
        for (int c=0; c<numbchild; c++) {
            //Reinitialisation of the pointers
            RMatrix_PTR=&RMatrix[m*numelmasked];
//            float * NormResp_PTR=this->GetChild(c)->GetNormResp();
            float * NormResp_PTR=GeneralNodes[c]->GetNormResp();
            float * WMatrix_PTR=&WMatrix[m*numelmasked];
//            float *  Mean=this->GetChild(c)->GetMeanDirect();
            float * Mean=GeneralNodes[c]->GetMeanDirect();
//            float * DiagVarianceValue=this->GetChild(c)->GetDiagVarianceDirect();
            float * DiagVarianceValue=GeneralNodes[c]->GetDiagVarianceDirect_corr();
            float invVariance=DiagVarianceValue[m]>1E-6?1.0/DiagVarianceValue[m]:1E6;
            if (OutlierType==4) {
                float * Typicality_PTR=&this->GetNormResp()[numelmasked];
                for (int i=0; i<numelmasked; i++,WMatrix_PTR++,NormResp_PTR++,RMatrix_PTR++,Typicality_PTR++) {
                    // Filling of the matrix as normalised weighted sum of the means
                    if (*WMatrix_PTR>0) { // Take care of case where WMatrix == 0 possible with outlier model
                        *RMatrix_PTR+=(float)(*NormResp_PTR*(*Typicality_PTR)*Mean[m]*invVariance)/(*WMatrix_PTR);
                    }
                }
            }
            else{
            for (int i=0; i<numelmasked; i++,WMatrix_PTR++,NormResp_PTR++,RMatrix_PTR++) {
                // Filling of the matrix as normalised weighted sum of the means
                if (*WMatrix_PTR>0) { // Take care of case where WMatrix == 0 possible with outlier model
                    *RMatrix_PTR+=(float)(*NormResp_PTR*Mean[m]*invVariance)/(*WMatrix_PTR);
                    if(*NormResp_PTR!=*NormResp_PTR){
                        cout<<"nan problem with NormResp";
                    }
                    if (Mean[m]!=Mean[m]) {
                        cout<<"nan problem with Mean";
                    }
                    if (invVariance !=invVariance){
                        cout<<"nan problem with invVariance";
                    }
                }
            }
            }
            delete [] Mean;
            delete [] DiagVarianceValue;
        }
        RMatrix_PTR=&RMatrix[m*numelmasked];
        int CountNanInData=0;
        int CountNanInRMatrix=0;
        for (int i=0; i<numel; i++, Data_PTR++,L2S_PTR++) {
            if (*L2S_PTR>=0) {
                if (*Data_PTR!=*Data_PTR) {
                    CountNanInData++;
                }
                *RMatrix_PTR=*Data_PTR-*RMatrix_PTR;
                if (*RMatrix_PTR!=*RMatrix_PTR) {
                    CountNanInRMatrix++;
                }
                RMatrix_PTR++;
            }
        }
        if (CountNanInRMatrix>0) {
            cout<<CountNanInRMatrix<<" nan in RMatrix"<<endl;
        }
        if (CountNanInData>0) {
            cout<<CountNanInData<<" nan in Data"<<endl;
        }
    }
    }
    if(WMatrix!=NULL){
        delete [] WMatrix;
        WMatrix=NULL;
    }
    return RMatrix;
}

// Returns a vector of pointers to the AtWA matrices used for the BF correction. The obtained matrix will need to be inverted afterwards.
float * TreeEM::MakeAtWAMatrixChildren(){
    float * WMatrix=this->MakeWMatrixChildren();
    //    float * BFFunctions=this->MakeBasisFunctions();
    int numbmodal=this->GetNumberModalities();
    int numelmasked=this->GetNumberMaskedElements();
    int numbBF=((BForder+1)*(BForder+2)*(BForder+3))/6;

    float FactorX=(float)(2.0/(this->GetDataImage()->nx-1));
    float FactorY=(float)(2.0/(this->GetDataImage()->ny-1));
    float FactorZ=(float)(2.0/(this->GetDataImage()->nz-1));

    int SizePlane=this->GetDataImage()->nx*this->GetDataImage()->ny;
    int SizeColumn=this->GetDataImage()->nx;

    int XorderBF[MaxNumbBF];
    int YorderBF[MaxNumbBF];
    int ZorderBF[MaxNumbBF];
    int tmpnumbBF=0;
    for(int order=0;order<=BForder;order++){
        for(int zorder=0;zorder<=order;zorder++){
            for(int yorder=0;yorder<=order-zorder;yorder++){
                int xorder=order-zorder-yorder;
                XorderBF[tmpnumbBF]=xorder;
                YorderBF[tmpnumbBF]=yorder;
                ZorderBF[tmpnumbBF]=zorder;
                tmpnumbBF++;
            }
        }
    }
    float* AtWAMatrixResult=new float[numbBF*numbBF*numbmodal];
    for(int i=0;i<numbBF*numbBF*numbmodal;i++){
        AtWAMatrixResult[i]=0;
    }
    float AtWAMatrix[MaxNumbBF*MaxNumbBF];
    for(int i=0;i<MaxNumbBF*MaxNumbBF;i++){
        AtWAMatrix[i]=0;
    }
    int OutlierType=this->GetFlagOutliers();
    if (OutlierType>0 && OutlierType!=4) {
        bool * OutlierSeg=this->GetSegOutliers();
        int numelInliers=this->GetNumberInliers();
        for(int m=0;m<numbmodal;m++){
            
            int * S2L_PTR=this->GetS2L();
            int i2=0;
            for(int i=0;i<numelmasked;i++,S2L_PTR++){
                if (!OutlierSeg[i]) {
                    int zValue=*S2L_PTR/SizePlane;
                    int yValue=(*S2L_PTR-zValue*SizePlane)/SizeColumn;
                    int xValue=(*S2L_PTR)-zValue*SizePlane-yValue*SizeColumn;
                    
                    float xUsed=xValue*FactorX-1;
                    float yUsed=yValue*FactorY-1;
                    float zUsed=zValue*FactorZ-1;
                    
                    
                    for (int j1=0; j1<numbBF; j1++) {
                        float Value1=pow_int(xUsed,XorderBF[j1])*pow_int(yUsed,YorderBF[j1])*pow_int(zUsed,ZorderBF[j1]);
                        if(Value1>1||Value1<-1){
                            cout<<"Pb with Value1 "<<endl;
                        }
                        for (int j2=0; j2<numbBF; j2++) {
                            float Value2=pow_int(xUsed,XorderBF[j2])*pow_int(yUsed,YorderBF[j2])*pow_int(zUsed,ZorderBF[j2]);
                            if(Value2>1||Value2<-1){
                                cout<<"Pb with Value2 "<<endl;
                            }
                            float WMatrix_Val=WMatrix[m*numelInliers+i2];
                            AtWAMatrix[j1+numbBF*j2]+=(float)Value1*Value2*(WMatrix_Val);
                        }
                    }
                    i2++;
                }

            }
            for(int l=0;l<numbBF*numbBF;l++){
                AtWAMatrixResult[l+m*numbBF*numbBF]=AtWAMatrix[l];
            }
            for(int l=0;l<MaxNumbBF*MaxNumbBF;l++){
                AtWAMatrix[l]=0;
            }
        }
        delete []OutlierSeg;
        OutlierSeg=NULL;
    }
    else{
    // Not optimal since all calculated whereas symmetric matrix obtained
    for(int m=0;m<numbmodal;m++){

        int * S2L_PTR=this->GetS2L();
        for(int i=0;i<numelmasked;i++,S2L_PTR++){
            int zValue=*S2L_PTR/SizePlane;
            int yValue=(*S2L_PTR-zValue*SizePlane)/SizeColumn;
            int xValue=(*S2L_PTR)-zValue*SizePlane-yValue*SizeColumn;

            float xUsed=xValue*FactorX-1;
            float yUsed=yValue*FactorY-1;
            float zUsed=zValue*FactorZ-1;


            for (int j1=0; j1<numbBF; j1++) {
                float Value1=pow_int(xUsed,XorderBF[j1])*pow_int(yUsed,YorderBF[j1])*pow_int(zUsed,ZorderBF[j1]);
                if(Value1>1||Value1<-1){
                    cout<<"Pb with Value1 "<<endl;
                }
                for (int j2=0; j2<numbBF; j2++) {
                    float Value2=pow_int(xUsed,XorderBF[j2])*pow_int(yUsed,YorderBF[j2])*pow_int(zUsed,ZorderBF[j2]);
                    if(Value2>1||Value2<-1){
                        cout<<"Pb with Value2 "<<endl;
                    }
                    float WMatrix_Val=WMatrix[m*numelmasked+i];
                    AtWAMatrix[j1+numbBF*j2]+=(float)Value1*Value2*(WMatrix_Val);
                }
            }
        }
        for(int l=0;l<numbBF*numbBF;l++){
            AtWAMatrixResult[l+m*numbBF*numbBF]=AtWAMatrix[l];
        }
        for(int l=0;l<MaxNumbBF*MaxNumbBF;l++){
            AtWAMatrix[l]=0;
        }
    }
    }
    //clearing WMatrix
    if(WMatrix!=NULL){
        delete [] WMatrix;
        WMatrix=NULL;
    }
    cout<<"AtWAMatrix done"<<endl;
    return AtWAMatrixResult;
}

// Returns a vector of float pointers to the AtWR vectors needed for the VL BF correction
float * TreeEM::MakeAtWRVectorChildren(){
    // Initialisation and getting all needed presteps with other matrices (A, W and R)

    int numelmasked=this->GetNumberMaskedElements();
    int numbmodal=this->GetNumberModalities();
    //    float * BFFunctions=this->MakeBasisFunctions();
    int numbBF=((BForder+1)*(BForder+2)*(BForder+3))/6;
    float * WMatrix=this->MakeWMatrixChildren();
    float * RMatrix=this->MakeRMatrixChildren();


    float * AtWRVector=new float[numbBF*numbmodal];//{0};
    for(int i=0;i<numbBF*numbmodal;i++){
        AtWRVector[i]=0;
    }

    float FactorX=(float)(2.0/(this->GetDataImage()->nx-1));
    float FactorY=(float)(2.0/(this->GetDataImage()->ny-1));
    float FactorZ=(float)(2.0/(this->GetDataImage()->nz-1));

    int SizePlane=this->GetDataImage()->nx*this->GetDataImage()->ny;
    int SizeColumn=this->GetDataImage()->nx;

    int XorderBF[MaxNumbBF];
    int YorderBF[MaxNumbBF];
    int ZorderBF[MaxNumbBF];
    int tmpnumbBF=0;
    for(int order=0;order<=BForder;order++){
        for(int zorder=0;zorder<=order;zorder++){
            for(int yorder=0;yorder<=order-zorder;yorder++){
                int xorder=order-zorder-yorder;
                XorderBF[tmpnumbBF]=xorder;
                YorderBF[tmpnumbBF]=yorder;
                ZorderBF[tmpnumbBF]=zorder;
                tmpnumbBF++;
            }
        }
    }
    int * S2L_PTR=this->GetS2L();
    int OutlierType=this->GetFlagOutliers();
    if (OutlierType>0 && OutlierType!=4) {
        int numelInliers=this->GetNumberInliers();
        bool * OutlierSeg=this->GetSegOutliers();
        int i2=0;
        for(int i=0;i<numelmasked;i++,S2L_PTR++){
            if (!OutlierSeg[i]) {
                int zValue=*S2L_PTR/SizePlane;
                int yValue=(*S2L_PTR-zValue*SizePlane)/SizeColumn;
                int xValue=(*S2L_PTR)-zValue*SizePlane-yValue*SizeColumn;
                
                float xUsed=xValue*FactorX-1;
                float yUsed=yValue*FactorY-1;
                float zUsed=zValue*FactorZ-1;
                
                for (int j=0; j<numbBF; j++) {
                    for (int m=0; m<numbmodal; m++) {
                        //            float * BFFunctions_PTR=&BFFunctions[j*numelmasked];
                        //            float * WMatrix_PTR=&WMatrix[m*numelmasked];
                        //            float * RMatrix_PTR=&RMatrix[m*numelmasked];
                        float WMatrix_Val=WMatrix[m*numelInliers+i2];
                        float RMatrix_Val=RMatrix[m*numelInliers+i2];
                        float BFValue=pow_int(xUsed,XorderBF[j])*pow_int(yUsed,YorderBF[j])*pow_int(zUsed,ZorderBF[j]);
                        AtWRVector[j+m*numbBF]+=(float)BFValue*WMatrix_Val*RMatrix_Val;
                    }
                }
                i2++;
            }
            
            
        }
        delete [] OutlierSeg;
        OutlierSeg=NULL;
    }
    else{
    
    for(int i=0;i<numelmasked;i++,S2L_PTR++){


        int zValue=*S2L_PTR/SizePlane;
        int yValue=(*S2L_PTR-zValue*SizePlane)/SizeColumn;
        int xValue=(*S2L_PTR)-zValue*SizePlane-yValue*SizeColumn;

        float xUsed=xValue*FactorX-1;
        float yUsed=yValue*FactorY-1;
        float zUsed=zValue*FactorZ-1;

        for (int j=0; j<numbBF; j++) {
            for (int m=0; m<numbmodal; m++) {
                //            float * BFFunctions_PTR=&BFFunctions[j*numelmasked];
                //            float * WMatrix_PTR=&WMatrix[m*numelmasked];
                //            float * RMatrix_PTR=&RMatrix[m*numelmasked];
                float WMatrix_Val=WMatrix[m*numelmasked+i];
                float RMatrix_Val=RMatrix[m*numelmasked+i];
                float BFValue=pow_int(xUsed,XorderBF[j])*pow_int(yUsed,YorderBF[j])*pow_int(zUsed,ZorderBF[j]);
                AtWRVector[j+m*numbBF]+=(float)BFValue*WMatrix_Val*RMatrix_Val;
            }
        }
    }
    }
    // Clearing memory allocation
    delete [] WMatrix;
    WMatrix=NULL;
    delete [] RMatrix;
    RMatrix=NULL;
    //        delete [] BFFunctions;
    //        BFFunctions=NULL;

    return AtWRVector;
}

// Returns a vector of float pointers to the AtWR vectors needed for the VL BF correction
float * TreeEM::MakeBFCoeffsDirect(){
    // Initialisation and getting all needed presteps with other matrices (A, W and R)

    int numelmasked=this->GetNumberMaskedElements();
    int numbmodal=this->GetNumberModalities();
    //    float * BFFunctions=this->MakeBasisFunctions();
    int numbBF=((BForder+1)*(BForder+2)*(BForder+3))/6;
    int numbBFSq=numbBF*numbBF;
    int sizeAtWAR=numbBF*numbBF*numbmodal;
    float * WMatrix=this->MakeWMatrixChildren();
    float * RMatrix=this->MakeRMatrixChildren();
    float  AtWRResult[MaxNumbModal*MaxNumbBF];
    float * AtWAResult=new float[sizeAtWAR];
    for(int i=0;i<MaxNumbModal*MaxNumbBF;i++){
        AtWRResult[i]=0;
    }
    for(int i=0;i<sizeAtWAR;i++){
        AtWAResult[i]=0;
    }

    float FactorX=(float)(2.0/(this->GetDataImage()->nx-1));
    float FactorY=(float)(2.0/(this->GetDataImage()->ny-1));
    float FactorZ=(float)(2.0/(this->GetDataImage()->nz-1));

    int SizePlane=this->GetDataImage()->nx*this->GetDataImage()->ny;
    int SizeColumn=this->GetDataImage()->nx;

    int XorderBF[MaxNumbBF];
    int YorderBF[MaxNumbBF];
    int ZorderBF[MaxNumbBF];
    int tmpnumbBF=0;
    for(int order=0;order<=BForder;order++){
        for(int zorder=0;zorder<=order;zorder++){
            for(int yorder=0;yorder<=order-zorder;yorder++){
                int xorder=order-zorder-yorder;
                XorderBF[tmpnumbBF]=xorder;
                YorderBF[tmpnumbBF]=yorder;
                ZorderBF[tmpnumbBF]=zorder;
                tmpnumbBF++;
            }
        }
    }
    int * S2L_PTR=this->GetS2L();

    int CountNanRMatrix=0;
    int CountNanWMatrix=0;
    int OutlierType=this->GetFlagOutliers();
    if (OutlierType>0 && OutlierType!=4) {
        int numelInliers=this->GetNumberInliers();
        bool * OutlierSeg=this->GetSegOutliers();
        int i2=0;
        for(int i=0;i<numelmasked;i++,S2L_PTR++){
            if (!OutlierSeg[i]) {
                int zValue=*S2L_PTR/SizePlane;
                int yValue=(*S2L_PTR-zValue*SizePlane)/SizeColumn;
                int xValue=(*S2L_PTR)-zValue*SizePlane-yValue*SizeColumn;
                
                float xUsed=xValue*FactorX-1;
                float yUsed=yValue*FactorY-1;
                float zUsed=zValue*FactorZ-1;
                
                
                for (int j1=0; j1<numbBF; j1++) {
                    float BFValue1=pow_int(xUsed,XorderBF[j1])*pow_int(yUsed,YorderBF[j1])*pow_int(zUsed,ZorderBF[j1]);
                    for (int m=0; m<numbmodal; m++) {
                        float WMatrix_Val=WMatrix[m*numelInliers+i2];
                        float RMatrix_Val=RMatrix[m*numelInliers+i2];
                        // Checking non Nan of WMatrix and RMatrix
                        if(WMatrix_Val!=WMatrix_Val){
                            CountNanWMatrix++;
                        }
                        if(RMatrix_Val!=RMatrix_Val){
                            CountNanRMatrix++;
                        }
                        AtWRResult[j1+m*numbBF]+=(float)BFValue1*WMatrix_Val*RMatrix_Val;
                        for (int j2=0; j2<numbBF; j2++) {
                            float BFValue2=pow_int(xUsed,XorderBF[j2])*pow_int(yUsed,YorderBF[j2])*pow_int(zUsed,ZorderBF[j2]);
                            
                            AtWAResult[j1+numbBF*j2+m*numbBFSq]+=(float)BFValue1*BFValue2*(WMatrix_Val);
                        }
                    }
                }
                i2++;
            }
        }
        if(CountNanWMatrix >0 || CountNanRMatrix >0){
            cout<<"Nan Wmatrix is "<<CountNanWMatrix<<" and Nan RMatrix is "<<CountNanRMatrix<<endl;
        }
        delete [] OutlierSeg;
        OutlierSeg=NULL;
    }
    else{
    for(int i=0;i<numelmasked;i++,S2L_PTR++){


        int zValue=*S2L_PTR/SizePlane;
        int yValue=(*S2L_PTR-zValue*SizePlane)/SizeColumn;
        int xValue=(*S2L_PTR)-zValue*SizePlane-yValue*SizeColumn;

        float xUsed=xValue*FactorX-1;
        float yUsed=yValue*FactorY-1;
        float zUsed=zValue*FactorZ-1;


        for (int j1=0; j1<numbBF; j1++) {
            float BFValue1=pow_int(xUsed,XorderBF[j1])*pow_int(yUsed,YorderBF[j1])*pow_int(zUsed,ZorderBF[j1]);
            for (int m=0; m<numbmodal; m++) {
                float WMatrix_Val=WMatrix[m*numelmasked+i];
                float RMatrix_Val=RMatrix[m*numelmasked+i];
                // Checking non Nan of WMatrix and RMatrix
                if(WMatrix_Val!=WMatrix_Val){
                    CountNanWMatrix++;
                }
                if(RMatrix_Val!=RMatrix_Val){
                    CountNanRMatrix++;
                }
                AtWRResult[j1+m*numbBF]+=(float)BFValue1*WMatrix_Val*RMatrix_Val;
                for (int j2=0; j2<numbBF; j2++) {
                    float BFValue2=pow_int(xUsed,XorderBF[j2])*pow_int(yUsed,YorderBF[j2])*pow_int(zUsed,ZorderBF[j2]);

                    AtWAResult[j1+numbBF*j2+m*numbBFSq]+=(float)BFValue1*BFValue2*(WMatrix_Val);
                }
            }
        }

    }
    if(CountNanWMatrix >0 || CountNanRMatrix >0){
    cout<<"Nan Wmatrix is "<<CountNanWMatrix<<" and Nan RMatrix is "<<CountNanRMatrix<<endl;
    }
    }

//    for(int m=0;m<numbmodal;m++){
//        for(int j1=0;j1<numbBF;j1++){
//            for(int j2=0;j2<numbBF;j2++){
//                cout<< AtWAResult[j1+numbBF*j2+m*numbBF*numbBF]<<"  ";
//            }
//            cout<<endl;
//        }
//        cout<<endl;
//    }



    // Clearing memory allocation
    delete [] WMatrix;
    WMatrix=NULL;
    delete [] RMatrix;
    RMatrix=NULL;

    // Calculate Inverse of AtWAResult
    float * invAtWAMatrix=new float[sizeAtWAR];//{0};
    for(int i=0;i<sizeAtWAR;i++){
        invAtWAMatrix[i]=0;
    }
    // Allocation of the matrix
    for (int m=0; m<numbmodal; m++) {
//        matrix<float> AtWAMatrix_mat=matrix<float>(numbBF);
        float * AtWAMatrix_mat=new float[numbBFSq];
        float * AtWAMatrix_tmp=&AtWAResult[m*numbBFSq];
//        bool success=0;
        for (int j1=0; j1<numbBF; j1++) {
            for (int j2=0; j2<numbBF; j2++) {
//                AtWAMatrix_mat.setvalue(j1, j2, AtWAMatrix_tmp[j1+j2*numbBF]);
                AtWAMatrix_mat[j1+j2*numbBF]=AtWAMatrix_tmp[j1+j2*numbBF];
            }
        }
//        AtWAMatrix_mat.invert();
        invertMatrix(AtWAMatrix_mat,numbBF);
        int CountNanBF=0;
        for (int j1=0; j1<numbBF; j1++) {
            for (int j2=0; j2<numbBF; j2++) {
//                AtWAMatrix_mat.getvalue(j1, j2, invAtWAMatrix[j1+j2*numbBF+m*numbBF*numbBF], success);
                invAtWAMatrix[j1+j2*numbBF+m*numbBFSq]=AtWAMatrix_mat[j1+j2*numbBF];
                if(invAtWAMatrix[j1+j2*numbBF+m*numbBFSq]!=invAtWAMatrix[j1+j2*numbBF+m*numbBFSq]){
                    CountNanBF++;
                }
            }
        }
        if(CountNanBF!=0){
            cout<<"number of nans is "<<CountNanBF<<endl;
        }
        delete [] AtWAMatrix_mat;
        AtWAMatrix_mat=NULL;
    }
    // Clearing memory
    delete [] AtWAResult;
    AtWAResult=NULL;

    // Now InvAtWA is obtained and we also have AtWR so we can directly calculate the coeffs
    int sizeFinal=numbBF*numbmodal;
    float * FinalBFCoeffsResult=new float[sizeFinal];
    for(int l=0;l<sizeFinal;l++){
        FinalBFCoeffsResult[l]=0;
    }
    for (int m=0; m<numbmodal; m++) {
        float * invAtWA=&invAtWAMatrix[m*numbBFSq];
        float * AtWRV_PTR=&AtWRResult[m*numbBF];
        float * invAtWA_PTR=invAtWA;
        for (int j1=0; j1<numbBF; j1++) {
            invAtWA_PTR=&invAtWA[j1*numbBF];
            AtWRV_PTR=&AtWRResult[m*numbBF];
            float FinalBFCoeffsResult_tmp=0;
            for (int j2=0; j2<numbBF; j2++,AtWRV_PTR++,invAtWA_PTR++) {
                FinalBFCoeffsResult_tmp+=(PrecisionTYPE)(*AtWRV_PTR)*(*invAtWA_PTR);
            }
            if (FinalBFCoeffsResult_tmp>1) {
                cout<<"Possible pb in BF Correction !";
            }
            FinalBFCoeffsResult[j1+m*numbBF]=(float)FinalBFCoeffsResult_tmp;
        }

    }
    // Clearing memory
    delete [] invAtWAMatrix;
    invAtWAMatrix=NULL;
    //    delete [] AtWRVector;
    //    AtWRVector=NULL;
    return FinalBFCoeffsResult;

}

// Create the float array that will be used to set the new BFCoeffs knowing that only those of the last modality will be changed. The ones concerning the previous modalities are thus copied according to the BForder respectively used for each of them and only the ones concerning the last ones
float * TreeEM::MakeBFCoeffsSeparated(vector<int> BFOrderperModality, int IndexModalityTogether){
    int numbmodal=this->GetNumberModalities();
    vector<vector<int> > SimilarBFOrder;
    for (int m=0; m<numbmodal; m++) {
        vector<int> Simi;
        for (int m1=0; m1<numbmodal; m1++) {
            if (BFOrderperModality[m1]==BFOrderperModality[m]) {
                Simi.push_back(m1);
            }
        }
        SimilarBFOrder.push_back(Simi);
    }
    // Check if the ModifiedModalities vector is compatible
    if (IndexModalityTogether>numbmodal|| IndexModalityTogether<0){
        return NULL;
    }
    int sizeBFOrderperMod=BFOrderperModality.size();
    if (sizeBFOrderperMod!=numbmodal) {
        cout<<"Pb in correspondance between number of modalities and size of BFOrderperModality"<<endl;
        return NULL;
    }
    // Creating the needed array for the BF order and number of components
    int * numbBF=new int[numbmodal];
    int * sumnumbBF=new int[numbmodal];
    int numbTotBF=0;
    for (int m=0; m<numbmodal; m++) {
        numbBF[m]=(int)((BFOrderperModality[m]+1)*(BFOrderperModality[m]+2)*(BFOrderperModality[m]+3))/6;
        sumnumbBF[m]=numbTotBF;
        numbTotBF+=numbBF[m];
    }
    //Initialising the BFCoeffs float array with 0;
    float * BFCoeffsFinal = new float[numbTotBF];
    for (int j=0; j<numbTotBF; j++) {
        BFCoeffsFinal[j]=0;
    }
    float * ExistingBF=this->GetBFCoeffs();
    bool * ModalityTakenCare=new bool[numbmodal];
    for (int m=0; m<numbmodal; m++) {
        ModalityTakenCare[m]=0;
    }
    // Copying what is already existing and will not be changed according to ModifiedModalities for all but the ones that are not to be changed
    for (int m=0; m<IndexModalityTogether; m++) {
            for (int j=0; j<numbBF[m]; j++) {
                BFCoeffsFinal[sumnumbBF[m]+j]=ExistingBF[j+sumnumbBF[m]];
            }
        ModalityTakenCare[m]=1;
        }
    
    // Updating new coefficients and taking care of not redoing MakeBFCoeffsDirect if not needed (ie if BForder not different)
    for (int m=IndexModalityTogether; m<numbmodal; m++) {
        if (!ModalityTakenCare[m]) {
            BForder=BFOrderperModality[m];
            float * BFCoeffsNew=this->MakeBFCoeffsDirect();
            int numbSimilarBFOrder=SimilarBFOrder[m].size();
            for (int s=0; s<numbSimilarBFOrder; s++) {
                int LookedModality=SimilarBFOrder[m][s];
                if (LookedModality>=IndexModalityTogether && !ModalityTakenCare[LookedModality]) {
                    for (int j=0; j<numbBF[m]; j++) {
                        BFCoeffsFinal[sumnumbBF[LookedModality]+j]=BFCoeffsNew[numbBF[m]*LookedModality+j];
                    }
                                      ModalityTakenCare[LookedModality]=1;
                }
            }
            delete [] BFCoeffsNew;
            BFCoeffsNew=NULL;
        }
    }
    // Clearing memory and returning result
    delete [] ModalityTakenCare;
    ModalityTakenCare=NULL;
    delete [] numbBF;
    numbBF=NULL;
    delete [] sumnumbBF;
    sumnumbBF=NULL;
    return BFCoeffsFinal;
    
}

// Returns in a vector of pointers the inverted matrix AtWA for each modality.
float* TreeEM::MakeInvAtWAMatrixChildren(){
    float * AtWAMatrix=this->MakeAtWAMatrixChildren();
    int numbBF=(int)((BForder+1)*(BForder+2)*(BForder+3))/6;
    int numbmodal=this->GetNumberModalities();
    int numbBFSq=numbBF*numbBF;
    int sizeAtWA=numbBFSq*numbmodal;
    // float * invAtWAMatrixResult;
    float * invAtWAMatrix=new float[sizeAtWA];//{0};
    for(int i=0;i<sizeAtWA;i++){
        invAtWAMatrix[i]=0;
    }
    // Allocation of the matrix
    for (int m=0; m<numbmodal; m++) {
        matrix<float> AtWAMatrix_mat=matrix<float>(numbBF);

        float * AtWAMatrix_tmp=&AtWAMatrix[m*numbBFSq];
        bool success=0;
        for (int j1=0; j1<numbBF; j1++) {
            for (int j2=0; j2<numbBF; j2++) {
                AtWAMatrix_mat.setvalue(j1, j2, AtWAMatrix_tmp[j1+j2*numbBF]);
            }
        }
        AtWAMatrix_mat.invert();
        for (int j1=0; j1<numbBF; j1++) {
            for (int j2=0; j2<numbBF; j2++) {
                AtWAMatrix_mat.getvalue(j1, j2, invAtWAMatrix[j1+j2*numbBF+m*numbBFSq], success);
            }
        }
    }
    // Clearing memory
    delete [] AtWAMatrix;
    AtWAMatrix=NULL;
    return invAtWAMatrix;
}

// Returns in a vector of pointers the coefficients for the bias field
float * TreeEM::MakeFinalBFCoeffsChildren(){
    // Initialisation and obtention of the needed values

    int numbmodal=this->GetNumberModalities();
    int numbBF=((BForder+1)*(BForder+2)*(BForder+3))/6;
    int sizeFinal=numbBF*numbmodal;
    int numbBFSq=numbBF*numbBF;
    float * FinalBFCoeffsResult = new float[sizeFinal];
    for(int i=0;i<sizeFinal;i++){
        FinalBFCoeffsResult[i]=0;
    }
    float * invAtWAMatrixVector=this->MakeInvAtWAMatrixChildren();
    float * AtWRVector=this->MakeAtWRVectorChildren();
    for (int m=0; m<numbmodal; m++) {
        float * invAtWA=&invAtWAMatrixVector[m*numbBFSq];
        float * AtWRV_PTR=&AtWRVector[m*numbBF];
        float * invAtWA_PTR=invAtWA;
        for (int j1=0; j1<numbBF; j1++) {
            invAtWA_PTR=&invAtWA[j1*numbBF];
            AtWRV_PTR=&AtWRVector[m*numbBF];
            PrecisionTYPE FinalBFCoeffsResult_tmp=0;
            for (int j2=0; j2<numbBF; j2++,AtWRV_PTR++,invAtWA_PTR++) {
                FinalBFCoeffsResult_tmp+=(PrecisionTYPE)(*AtWRV_PTR)*(*invAtWA_PTR);
            }
            FinalBFCoeffsResult[j1+m*numbBF]=FinalBFCoeffsResult_tmp;
        }
    }
    // Clearing memory
    delete [] invAtWAMatrixVector;
    invAtWAMatrixVector=NULL;
    delete [] AtWRVector;
    AtWRVector=NULL;
//    float * FinalTestBFCoeffs=this->MakeBFCoeffsDirect();
    return FinalBFCoeffsResult;
}

// Returns the float array of DataBFCorrected according to the fact that not similar BF order has been used for each modality. Needed when one image has already been BF corrected at a previous stage with existing BF coefficients and that the image added afterwards is still not at this stage of correction when performing a progressive BF correction
float * TreeEM::MakeDataBFCorrectedSeparated(vector<int> BFOrderperModality){
    int numelmasked=this->GetNumberMaskedElements();
    int numel=this->GetNumberElements();
    int numbmodal=this->GetNumberModalities();
    int sizeDataBFCorrected=numbmodal*numelmasked;
    float * DataBFCorrected=new float[sizeDataBFCorrected];//{0};
    //    for(int i=0;i<numelmasked*numbmodal;i++){
    //        DataBFCorrected[i]=0;
    //    }
    float * DataBFCorrected_PTR=DataBFCorrected;
    float * DataInit=static_cast<float *>(this->GetDataImage()->data);
    float * DataInit_PTR=DataInit;
    int * L2S_PTR= this->GetL2S();
    //    int CountActive=0;
    //    for(int i=0;i<numel;i++,L2S_PTR++){
    //        if(*L2S_PTR>=0){
    //            CountActive++;
    //        }
    //    }
    float * BFCoeffsUsed=this->GetBFCoeffs();
    for (int m=0; m<numbmodal; m++) {
        L2S_PTR=this->GetL2S();
        //        CountActive=0;
        DataBFCorrected_PTR=&DataBFCorrected[m*numelmasked];
        DataInit_PTR=&DataInit[m*numel];
        for (int i=0; i<numel; i++,DataInit_PTR++,L2S_PTR++) {
            if(*L2S_PTR>=0){
                //                CountActive++;
                *DataBFCorrected_PTR=*DataInit_PTR;
                DataBFCorrected_PTR++;
            }
        }
    }
    if(BFCoeffsUsed!=NULL){
        // If there is a correction of the bias field to be done
        
        float * BFCorrection_new=this->MakeBFCorrectionSeparated(BFOrderperModality);
        for (int m=0; m<numbmodal; m++) {
            float * BFCorrection_PTR=&BFCorrection_new[m*numelmasked];
            //                    int * L2S_PTR=this->GetL2S();
            DataBFCorrected_PTR=&DataBFCorrected[m*numelmasked];
            for (int i=0; i<numelmasked; i++,DataBFCorrected_PTR++,BFCorrection_PTR++) {
                *DataBFCorrected_PTR-=(*BFCorrection_PTR);
            }
        }
        if(BFCorrection_new!=NULL){
            delete [] BFCorrection_new;
            BFCorrection_new=NULL;
        }
    }
    return DataBFCorrected;
}



float * TreeEM::MakeDataBFCorrected(){
    int numelmasked=this->GetNumberMaskedElements();
    int numel=this->GetNumberElements();
    int numbmodal=this->GetNumberModalities();
    float * DataBFCorrected=new float[numelmasked*numbmodal];//{0};
    //    for(int i=0;i<numelmasked*numbmodal;i++){
    //        DataBFCorrected[i]=0;
    //    }
    float * DataBFCorrected_PTR=DataBFCorrected;
    float * DataInit=static_cast<float *>(this->GetDataImage()->data);
    float * DataInit_PTR=DataInit;
    int * L2S_PTR= this->GetL2S();
    //    int CountActive=0;
    //    for(int i=0;i<numel;i++,L2S_PTR++){
    //        if(*L2S_PTR>=0){
    //            CountActive++;
    //        }
    //    }
    float * BFCoeffsUsed=this->GetBFCoeffs();
    for (int m=0; m<numbmodal; m++) {
        L2S_PTR=this->GetL2S();
        //        CountActive=0;
        DataBFCorrected_PTR=&DataBFCorrected[m*numelmasked];
        DataInit_PTR=&DataInit[m*numel];
        for (int i=0; i<numel; i++,DataInit_PTR++,L2S_PTR++) {
            if(*L2S_PTR>=0){
                //                CountActive++;
                *DataBFCorrected_PTR=*DataInit_PTR;
                DataBFCorrected_PTR++;
            }
        }
    }
    if(BFCoeffsUsed!=NULL){
        // If there is a correction of the bias field to be done

        float * BFCorrection_new=this->MakeBFCorrection(BForder);
        for (int m=0; m<numbmodal; m++) {
            float * BFCorrection_PTR=&BFCorrection_new[m*numelmasked];
            //                    int * L2S_PTR=this->GetL2S();
            DataBFCorrected_PTR=&DataBFCorrected[m*numelmasked];
            for (int i=0; i<numelmasked; i++,DataBFCorrected_PTR++,BFCorrection_PTR++) {
                *DataBFCorrected_PTR-=(*BFCorrection_PTR);
            }
        }
        if(BFCorrection_new!=NULL){
            delete [] BFCorrection_new;
            BFCorrection_new=NULL;
        }
    }
    //        int CountDataCorrectedZero=0;
    //        DataBFCorrected_PTR=DataBFCorrected;
    //        for(int i=0;i<numelmasked*numbmodal;i++,DataBFCorrected_PTR++){
    //            if(*DataBFCorrected_PTR==0){
    //                CountDataCorrectedZero++;
    //            }
    //        }
    return DataBFCorrected;
}


//float * TreeEM::MakeBFCorrection(){

//    float * BFCoeffs_newB=this->GetBFCoeffs();
//    if(BFCoeffs_newB==NULL){
//        return NULL;
//    }
//    float * BFBasisFunctions=this->MakeBasisFunctions();
//    int numelmasked=this->GetNumberMaskedElements();
//    int numbBF=((BForder+1)*(BForder+2)*(BForder+3))/6;
//    float BFCoeffs_new[numbBF*MaxNumbModal];
//    for(int i=0;i<numbBF*MaxNumbModal;i++){
//        BFCoeffs_new[i]=BFCoeffs_newB[i];
//    }
//    int numbmodal=this->GetNumberModalities();
//    float * BFCorrectionResult=new float[numbmodal*numelmasked];
//    for(int i=0;i<numbmodal*numelmasked;i++){
//        BFCorrectionResult[i]=0;
//    }
//    if(BFCoeffs_new!=NULL){
//    for(int m=0;m<numbmodal;m++){
//        for(int j=0;j<numbBF;j++){
//            float * BasisFunctions_PTR=&BFBasisFunctions[j*numelmasked];
////            float * BFCoeffs_PTR=&BFCoeffs_new[m*numbBF];
//            float * BFCorrectionResult_PTR=&BFCorrectionResult[m*numelmasked];
//            for(int i=0;i<numelmasked;i++,BFCorrectionResult_PTR++,BasisFunctions_PTR++){
//                *BFCorrectionResult_PTR+=BFCoeffs_new[j+m*numbBF]*(*BasisFunctions_PTR);
//            }
//        }
//    }
//    }
//    delete[] BFBasisFunctions;
//    BFBasisFunctions=NULL;
//    return BFCorrectionResult;
//}

void TreeEM::UncorrectData(int BForder){
    float * BFCorrection=this->MakeBFCorrection(BForder);
    int * L2S_PTR=this->GetL2S();
    float * DataCorrected_PTR=this->GetDataBFCorrected();
    float * DataToUncorrect=static_cast<float *>(this->GetDataImage()->data);
    int numel=this->GetNumberElements();
    int numelmasked=this->GetNumberMaskedElements();
    int numbmodal=this->GetNumberModalities();
    if(BFCorrection!=NULL){
    for (int m=0; m<numbmodal; m++) {
        int j=0;
        for (int i=0; i<numel; i++) {
            if (L2S_PTR[i]>=0) {
                DataToUncorrect[i+m*numel]=DataCorrected_PTR[j+m*numelmasked]+BFCorrection[j+m*numelmasked];
                j++;
                if(i==7894932){
                    cout<<"DataToUncorrect is "<<DataToUncorrect[i]<<" "<<DataToUncorrect[i+(numbmodal-1)*numel]<<endl;
                    cout<<"Testing uncorrection"<<endl;
                }
            }
        }
    }
    delete [] BFCorrection;
    BFCorrection=NULL;
}
    return;
}

float * TreeEM::MakeBFCorrectionSeparated(vector<int> BFOrderperModality){
    float * BFCoeffs_newB=this->GetBFCoeffs();
    int numbmodal=this->GetNumberModalities();
    //Check that size of BFOrderperModality is compatible with number of modalities considered
    int sizeBFOrderperMod=BFOrderperModality.size();
    if (sizeBFOrderperMod<numbmodal) {
        cout<<"Pb with BFOrderperModality vector"<<endl;
        return NULL;
    }
    if(BFCoeffs_newB==NULL){
        return NULL;
    }
    int * numbBF=new int[numbmodal];
    int * sumnumbBF=new int[numbmodal];
    int numbBFTot=0;
    int maxBFOrder=0;
    for (int m=0; m<numbmodal; m++) {
        numbBF[m]=((BFOrderperModality[m]+1)*(BFOrderperModality[m]+2)*(BFOrderperModality[m]+3))/6;
        sumnumbBF[m]=numbBFTot;
        numbBFTot+=numbBF[m];
        if (BFOrderperModality[m]>maxBFOrder) {
            maxBFOrder=BFOrderperModality[m];
        }
    }
    //    float * BFBasisFunctions=this->MakeBasisFunctions();
    int numelmasked=this->GetNumberMaskedElements();
    
    float BFCoeffs_new[MaxNumbBF*MaxNumbModal];
    
    for(int i=0;i<MaxNumbBF*MaxNumbModal;i++){
        if(i<numbBFTot){
            BFCoeffs_new[i]=BFCoeffs_newB[i];
        }
        else{
            BFCoeffs_new[i]=0;
        }
    }
    int sizeCorrectionResult=numbmodal*numelmasked;
    float * BFCorrectionResult=new float[sizeCorrectionResult];
    for(int i=0;i<sizeCorrectionResult;i++){
        BFCorrectionResult[i]=0;
    }
    if(BFCoeffs_newB!=NULL){
        float FactorX=(float)(2.0/(this->GetDataImage()->nx-1));
        float FactorY=(float)(2.0/(this->GetDataImage()->ny-1));
        float FactorZ=(float)(2.0/(this->GetDataImage()->nz-1));
        
        int SizePlane=this->GetDataImage()->nx*this->GetDataImage()->ny;
        int SizeColumn=this->GetDataImage()->nx;
        
        int XorderBF[MaxNumbBF];
        int YorderBF[MaxNumbBF];
        int ZorderBF[MaxNumbBF];
        int tmpnumbBF=0;
        for(int order=0;order<=maxBFOrder;order++){
            for(int zorder=0;zorder<=order;zorder++){
                for(int yorder=0;yorder<=order-zorder;yorder++){
                    int xorder=order-zorder-yorder;
                    XorderBF[tmpnumbBF]=xorder;
                    YorderBF[tmpnumbBF]=yorder;
                    ZorderBF[tmpnumbBF]=zorder;
                    tmpnumbBF++;
                }
            }
        }
        int * S2L_PTR=this->GetS2L();
        for(int i=0;i<numelmasked;i++,S2L_PTR++){
            
            
            int zValue=*S2L_PTR/SizePlane;
            int yValue=(*S2L_PTR-zValue*SizePlane)/SizeColumn;
            int xValue=(*S2L_PTR)-zValue*SizePlane-yValue*SizeColumn;
            
            float xUsed=xValue*FactorX-1;
            float yUsed=yValue*FactorY-1;
            float zUsed=zValue*FactorZ-1;
            for(int m=0;m<numbmodal;m++){
                for(int j=0;j<numbBF[m];j++){
                    float BFValue=pow_int(xUsed,XorderBF[j])*pow_int(yUsed,YorderBF[j])*pow_int(zUsed,ZorderBF[j]);
                    BFCorrectionResult[i+m*numelmasked]+=BFCoeffs_new[j+sumnumbBF[m]]*BFValue;
                    
                }
            }
        }
    }
    // Clearing memory related to the variation in numbBF per modality
    delete [] sumnumbBF;
    sumnumbBF=NULL;
    delete [] numbBF;
    numbBF=NULL;
    return BFCorrectionResult;
}

float * TreeEM::MakeBFCorrection(int BForder){

    float * BFCoeffs_newB=this->GetBFCoeffs();
    if(BFCoeffs_newB==NULL){
        return NULL;
    }
    //    float * BFBasisFunctions=this->MakeBasisFunctions();
    int numelmasked=this->GetNumberMaskedElements();
    int numbBF=((BForder+1)*(BForder+2)*(BForder+3))/6;
    int numbmodal=this->GetNumberModalities();
    int sizeBFCoeffs=numbBF*numbmodal;
    float BFCoeffs_new[MaxNumbBF*MaxNumbModal];
    for(int i=0;i<MaxNumbBF*MaxNumbModal;i++){
        if(i<sizeBFCoeffs){
            BFCoeffs_new[i]=BFCoeffs_newB[i];
        }
        else{
            BFCoeffs_new[i]=0;
        }
    }
    int sizeBFCorrectionResult=numbmodal*numelmasked;
    float * BFCorrectionResult=new float[sizeBFCorrectionResult];
    for(int i=0;i<sizeBFCorrectionResult;i++){
        BFCorrectionResult[i]=0;
    }
    if(BFCoeffs_newB!=NULL){
        float FactorX=(float)(2.0/(this->GetDataImage()->nx-1));
        float FactorY=(float)(2.0/(this->GetDataImage()->ny-1));
        float FactorZ=(float)(2.0/(this->GetDataImage()->nz-1));

        int SizePlane=this->GetDataImage()->nx*this->GetDataImage()->ny;
        int SizeColumn=this->GetDataImage()->nx;

        int XorderBF[MaxNumbBF];
        int YorderBF[MaxNumbBF];
        int ZorderBF[MaxNumbBF];
        int tmpnumbBF=0;
        for(int order=0;order<=BForder;order++){
            for(int zorder=0;zorder<=order;zorder++){
                for(int yorder=0;yorder<=order-zorder;yorder++){
                    int xorder=order-zorder-yorder;
                    XorderBF[tmpnumbBF]=xorder;
                    YorderBF[tmpnumbBF]=yorder;
                    ZorderBF[tmpnumbBF]=zorder;
                    tmpnumbBF++;
                }
            }
        }
        int * S2L_PTR=this->GetS2L();
        for(int i=0;i<numelmasked;i++,S2L_PTR++){


            int zValue=*S2L_PTR/SizePlane;
            int yValue=(*S2L_PTR-zValue*SizePlane)/SizeColumn;
            int xValue=(*S2L_PTR)-zValue*SizePlane-yValue*SizeColumn;

            float xUsed=xValue*FactorX-1;
            float yUsed=yValue*FactorY-1;
            float zUsed=zValue*FactorZ-1;
            for(int m=0;m<numbmodal;m++){
                for(int j=0;j<numbBF;j++){
                    float BFValue=pow_int(xUsed,XorderBF[j])*pow_int(yUsed,YorderBF[j])*pow_int(zUsed,ZorderBF[j]);
                    BFCorrectionResult[i+m*numelmasked]+=BFCoeffs_new[j+m*numbBF]*BFValue;

                }
            }
        }
    }

    return BFCorrectionResult;
}


float * TreeEM::GenerateBFCorrection(int BForder, int numbmodal, float * BFCoeffs_newB, nifti_image * DataRef){
    if(DataRef == NULL){
        DataRef = this->GetDataImage();
    }
//    float * BFCoeffs_newB=this->GetBFCoeffs();
    if(BFCoeffs_newB==NULL){
        return NULL;
    }
    //    float * BFBasisFunctions=this->MakeBasisFunctions();
    int numel=DataRef->nx*DataRef->ny*DataRef->nz;
    int numbBF=((BForder+1)*(BForder+2)*(BForder+3))/6;
//    int numbmodal=this->GetNumberModalities();
    int sizeBFCoeffs=numbBF*numbmodal;
    float BFCoeffs_new[MaxNumbBF*MaxNumbModal];
    for(int i=0;i<MaxNumbBF*MaxNumbModal;i++){
        if(i<sizeBFCoeffs){
            BFCoeffs_new[i]=BFCoeffs_newB[i];
        }
        else{
            BFCoeffs_new[i]=0;
        }
    }
    int sizeBFCorrectionResult=numbmodal*numel;
    float * BFCorrectionResult=new float[sizeBFCorrectionResult];
    for(int i=0;i<sizeBFCorrectionResult;i++){
        BFCorrectionResult[i]=0;
    }
    if(BFCoeffs_newB!=NULL){
        float FactorX=(float)(2.0/(DataRef->nx-1));
        float FactorY=(float)(2.0/(DataRef->ny-1));
        float FactorZ=(float)(2.0/(DataRef->nz-1));
        
        int SizePlane=DataRef->nx*DataRef->ny;
        int SizeColumn=DataRef->nx;
        
        int XorderBF[MaxNumbBF];
        int YorderBF[MaxNumbBF];
        int ZorderBF[MaxNumbBF];
        int tmpnumbBF=0;
        for(int order=0;order<=BForder;order++){
            for(int zorder=0;zorder<=order;zorder++){
                for(int yorder=0;yorder<=order-zorder;yorder++){
                    int xorder=order-zorder-yorder;
                    XorderBF[tmpnumbBF]=xorder;
                    YorderBF[tmpnumbBF]=yorder;
                    ZorderBF[tmpnumbBF]=zorder;
                    tmpnumbBF++;
                }
            }
        }
//        int * S2L_PTR=this->GetS2L();
//        for(int i=0;i<numelmasked;i++,S2L_PTR++){
         for(int i=0;i<numel;i++){
            
            int zValue=i/SizePlane;
            int yValue=(i-zValue*SizePlane)/SizeColumn;
            int xValue=(i)-zValue*SizePlane-yValue*SizeColumn;
            
            float xUsed=xValue*FactorX-1;
            float yUsed=yValue*FactorY-1;
            float zUsed=zValue*FactorZ-1;
            for(int m=0;m<numbmodal;m++){
                for(int j=0;j<numbBF;j++){
                    float BFValue=pow_int(xUsed,XorderBF[j])*pow_int(yUsed,YorderBF[j])*pow_int(zUsed,ZorderBF[j]);
                    BFCorrectionResult[i+m*numel]+=BFCoeffs_new[j+m*numbBF]*BFValue;
                    
                }
            }
        }
    }
    
    return BFCorrectionResult;
}



/******************* SAVING RESULTS ******************************/
void TreeEM::SaveAllClasses(string filenameOut,SEG_PARAMETERS * segment_param){
    int numbTotalClasses=0;
    //this->GetNumberLeaves(numbTotalClasses);
    numbTotalClasses=this->GetNumberAllLeaves();
    vector<TreeEM *> LeavesVector;
    //this->GetLeaves(LeavesVector);
    LeavesVector=this->GetAllLeaves();
    nifti_image * Result=nifti_copy_nim_info(this->GetDataImage());
    Result->dim[0]=4;
    Result->dim[4]=numbTotalClasses;
    Result->dim[5]=1;
    nifti_update_dims_from_array(Result);
    Result->data = (void *) calloc(Result->nvox, sizeof(float));
    int numel=this->GetNumberElements();
    float * Result_PTR=static_cast<float *>(Result->data);
    float * Result_PTRtmp=Result_PTR;
    //float * Input_PTR=LeavesVector[0]->GetPartialResult(NORMRESP);
    for (int c=0; c<numbTotalClasses; c++) {
        Result_PTRtmp=&Result_PTR[c*numel];
        float * Input=LeavesVector[c]->GetPartialResult(NORMRESP,segment_param);
        float * Input_PTR=Input;
        if (Input !=NULL) {
            for (int i=0; i<numel; i++, Result_PTRtmp++,Input_PTR++) {
                *Result_PTRtmp=*Input_PTR;
            }
            if(Input!=NULL){
                delete[]Input;
                Input=NULL;
            }
        }
        else{
            cout<< "Input for saving is NULL.."<<endl;
        }

    }
    nifti_set_filenames(Result, filenameOut.c_str(), 0, 0);
    nifti_image_write(Result);
    nifti_image_free(Result);
//    LeavesVector.clear();
}

void TreeEM::SaveGeneralClasses(string filenameOut,SEG_PARAMETERS * segment_param){
    vector<TreeEM *> ChildrenVector;
    int numbGeneralClasses;
    nifti_image * Result=nifti_copy_nim_info(this->GetDataImage());
    
    if(segment_param->OutliersMod!=3 && segment_param->OutliersMod<5){
    numbGeneralClasses=this->GetNumberChildren();
    ChildrenVector=this->GetChildren();
    Result->dim[0]=4;
    Result->dim[4]=numbGeneralClasses;
    Result->dim[5]=1;
    nifti_update_dims_from_array(Result);
    Result->data = (void *) calloc(Result->nvox, sizeof(float));
    int numel=this->GetNumberElements();
    float * Result_PTR=static_cast<float *>(Result->data);
    float * Result_PTRtmp=Result_PTR;
    //float * Input_PTR=ChildrenVector[0]->GetPartialResult(NORMRESP);
    for (int c=0; c<numbGeneralClasses; c++) {
        Result_PTRtmp=&Result_PTR[c*numel];
        float *Input=ChildrenVector[c]->GetPartialResult(NORMRESP,segment_param);
        float * Input_PTR=Input;
        for (int i=0; i<numel; i++, Result_PTRtmp++,Input_PTR++) {
            *Result_PTRtmp=*Input_PTR;
        }
        if(Input!=NULL){
            delete [] Input;
            Input=NULL;
        }
    }
    nifti_set_filenames(Result, filenameOut.c_str(), 0, 0);
    nifti_image_write(Result);
    nifti_image_free(Result);
    ChildrenVector.clear();
    }
    else{ //special case where there has to be more than one BiASM General output (outlierMod == 3)
        // Taking first care of the only number of priors case (Concatenate all subclasses concerning each general class without any difference between inlier and outliers)
        // Check before if same number of children for Inliers and outliers.
        string FilenameBC;
        int Index;
        string FilenameBC_b;
        string FilenameBC_e;
        if (this->FindRoot()->GetChild(0)->GetNumberChildren()==this->FindRoot()->GetChild(1)->GetNumberChildren()) {
            FilenameBC=nifti_makebasename(segment_param->filename_out[0].c_str());
            Index=FilenameBC.find_last_of('/');
            FilenameBC_b=FilenameBC.substr(0,Index+1);
            FilenameBC_e=FilenameBC.substr(Index+1,FilenameBC.length());
            FilenameBC=FilenameBC_b+"BG0_"+FilenameBC_e+".nii.gz";
            // the considered classes correspond to level 2 that are paired through their initial priors
            vector<TreeEM*> ChildrenVector0=this->FindRoot()->GetChild(0)->GetChildren();
            vector<TreeEM*> ChildrenVector1=this->FindRoot()->GetChild(1)->GetChildren();
            numbGeneralClasses=ChildrenVector0.size();
            Result=nifti_copy_nim_info(this->GetDataImage());
            Result->dim[0]=4;
            Result->dim[4]=numbGeneralClasses;
            Result->dim[5]=1;
            nifti_update_dims_from_array(Result);
            Result->data = (void *) calloc(Result->nvox, sizeof(float));
            int numel=this->GetNumberElements();
            float * Result_PTR=static_cast<float *>(Result->data);
            float * Result_PTRtmp=Result_PTR;
            for (int c=0; c<numbGeneralClasses; c++) {
                Result_PTRtmp=&Result_PTR[c*numel];
                float *Input0=ChildrenVector0[c]->GetPartialResult(NORMRESP,segment_param);
                float *Input1=ChildrenVector1[c]->GetPartialResult(NORMRESP, segment_param);
                float * Input0_PTR=Input0;
                float * Input1_PTR=Input1;
                for (int i=0; i<numel; i++, Result_PTRtmp++,Input0_PTR++,Input1_PTR++) {
                    *Result_PTRtmp=(*Input0_PTR)+(*Input1_PTR);
                }
                if(Input0!=NULL){
                    delete [] Input0;
                    Input0=NULL;
                }
                if(Input1!=NULL){
                    delete [] Input1;
                    Input1=NULL;
                }
            }
            nifti_set_filenames(Result, FilenameBC.c_str(), 0, 0);
            nifti_image_write(Result);
            nifti_image_free(Result);
            Result=NULL;
            ChildrenVector0.clear();
            ChildrenVector1.clear();
        }
        
        // Saving into another image the file with 2 * number of priors : first the concatenated normal anatomical classes then the concatenated outliers for each anatomical class
        // the considered classes correspond to level 2
        FilenameBC=nifti_makebasename(segment_param->filename_out[0].c_str());
        Index=FilenameBC.find_last_of('/');
        FilenameBC_b=FilenameBC.substr(0,Index+1);
        FilenameBC_e=FilenameBC.substr(Index+1,FilenameBC.length());
        FilenameBC=FilenameBC_b+"BG1_"+FilenameBC_e+".nii.gz";
        ChildrenVector=this->FindRoot()->GetAllTreesFromLevel(2);
        numbGeneralClasses=ChildrenVector.size();
        Result=nifti_copy_nim_info(this->GetDataImage());
        Result->dim[0]=4;
        Result->dim[4]=numbGeneralClasses;
        Result->dim[5]=1;
        nifti_update_dims_from_array(Result);
        Result->data = (void *) calloc(Result->nvox, sizeof(float));
        int numel=this->GetNumberElements();
        float * Result_PTR=static_cast<float *>(Result->data);
        float * Result_PTRtmp=Result_PTR;
        for (int c=0; c<numbGeneralClasses; c++) {
            Result_PTRtmp=&Result_PTR[c*numel];
            float *Input=ChildrenVector[c]->GetPartialResult(NORMRESP,segment_param);
            float * Input_PTR=Input;
            for (int i=0; i<numel; i++, Result_PTRtmp++,Input_PTR++) {
                *Result_PTRtmp=*Input_PTR;
            }
            if(Input!=NULL){
                delete [] Input;
                Input=NULL;
            }
            
        }
        nifti_set_filenames(Result, FilenameBC.c_str(), 0, 0);
        nifti_image_write(Result);
        nifti_image_free(Result);
        Result=NULL;
        ChildrenVector.clear();
        
        // At last saving an image with only one class concerning all outliers (all leaves concatenated under only node outlier) Correspond to children of Child0 and to node outlier
        FilenameBC=nifti_makebasename(segment_param->filename_out[0].c_str());
        Index=FilenameBC.find_last_of('/');
        FilenameBC_b=FilenameBC.substr(0,Index+1);
        FilenameBC_e=FilenameBC.substr(Index+1,FilenameBC.length());
        FilenameBC=FilenameBC_b+"BG2_"+FilenameBC_e+".nii.gz";
        ChildrenVector=this->FindRoot()->GetChild(0)->GetChildren();
        ChildrenVector.push_back(this->GetNodeOutlier());
        numbGeneralClasses=ChildrenVector.size();
        Result=nifti_copy_nim_info(this->GetDataImage());
        Result->dim[0]=4;
        Result->dim[4]=numbGeneralClasses;
        Result->dim[5]=1;
        nifti_update_dims_from_array(Result);
        Result->data = (void *) calloc(Result->nvox, sizeof(float));
        numel=this->GetNumberElements();
        Result_PTR=static_cast<float *>(Result->data);
        Result_PTRtmp=Result_PTR;
        for (int c=0; c<numbGeneralClasses; c++) {
            Result_PTRtmp=&Result_PTR[c*numel];
            float *Input=ChildrenVector[c]->GetPartialResult(NORMRESP,segment_param);
            float * Input_PTR=Input;
            for (int i=0; i<numel; i++, Result_PTRtmp++,Input_PTR++) {
                *Result_PTRtmp=*Input_PTR;
            }
            if(Input!=NULL){
                delete [] Input;
                Input=NULL;
            }
            
        }
        nifti_set_filenames(Result, FilenameBC.c_str(), 0, 0);
        nifti_image_write(Result);
        nifti_image_free(Result);
        Result=NULL;
        ChildrenVector.clear();
    }
}

void TreeEM::SaveBFBasisFunctions(string filenameBF){
    int numelmasked=this->GetNumberMaskedElements();
    int numbBF=((BForder+1)*(BForder+2)*(BForder+3))/6;
    float * BasisFunctionsToSave=this->MakeBasisFunctions();
    nifti_image * Result=nifti_copy_nim_info(this->GetDataImage());
    Result->dim[0]=4;
    Result->dim[4]=numbBF;
    Result->dim[5]=1;
    nifti_update_dims_from_array(Result);
    Result->data = (void *) calloc(Result->nvox, sizeof(float));
    int numel=this->GetNumberElements();
    float * Result_PTR=static_cast<float *>(Result->data);
    float * Result_PTRtmp=Result_PTR;
    float * Input_PTR=BasisFunctionsToSave;
    int * L2S_PTR=this->GetL2S();
    for (int j=0; j<numbBF; j++) {
        Result_PTRtmp=&Result_PTR[j*numel];
        Input_PTR=&BasisFunctionsToSave[j*numelmasked];
        L2S_PTR=this->GetL2S();
        for (int i=0; i<numel; i++, Result_PTRtmp++,L2S_PTR++) {
            if (*L2S_PTR>=0) {
                *Result_PTRtmp=*Input_PTR;
                Input_PTR++;
            }
            else{
                *Result_PTRtmp=0;
            }

        }
    }
    if(BasisFunctionsToSave!=NULL){
        delete[] BasisFunctionsToSave;
        BasisFunctionsToSave=NULL;
    }
    nifti_set_filenames(Result, filenameBF.c_str(), 0, 0);
    nifti_image_write(Result);
    nifti_image_free(Result);
}

void TreeEM::SaveBFBasisFunctions(int BFnumb,string filenameBF){
    int numelmasked=this->GetNumberMaskedElements();
    int numbBF=((BForder+1)*(BForder+2)*(BForder+3))/6;
    if (BFnumb>=numbBF) {
        return;
    }
    float * BasisFunctionsToSave=this->MakeBasisFunctions();
    nifti_image * Result=nifti_copy_nim_info(this->GetDataImage());
    Result->dim[0]=3;
    Result->dim[4]=1;
    Result->dim[5]=1;
    nifti_update_dims_from_array(Result);
    Result->data = (void *) calloc(Result->nvox, sizeof(float));
    int numel=this->GetNumberElements();
    float * Result_PTR=static_cast<float *>(Result->data);
    float * Result_PTRtmp=Result_PTR;
    float * Input_PTR=&BasisFunctionsToSave[BFnumb*numelmasked];
    int * L2S_PTR=this->GetL2S();


    for (int i=0; i<numel; i++, Result_PTRtmp++,L2S_PTR++) {
        if (*L2S_PTR>=0) {
            *Result_PTRtmp=*Input_PTR;
            Input_PTR++;
        }
        else{
            *Result_PTRtmp=0;
        }

    }
    if(BasisFunctionsToSave!=NULL){
        delete[]BasisFunctionsToSave;
        BasisFunctionsToSave=NULL;
    }
    nifti_set_filenames(Result, filenameBF.c_str(), 0, 0);
    nifti_image_write(Result);
    nifti_image_free(Result);
}

void TreeEM::SaveBFCorrection(string filenameBF){
    int numelmasked=this->GetNumberMaskedElements();
    //    int numbBF=((BForder+1)*(BForder+2)*(BForder+3))/6;
    int numbmodal=this->GetNumberModalities();

        if (this->AreBFCoeffsDirectUseable()) {
            //                float * BFCoeffs_tmp=BFCoeffsToSave;
            float * BFCorrection=this->MakeBFCorrection(BForder);
            nifti_image * Result=nifti_copy_nim_info(this->GetDataImage());
            Result->dim[0]=4;
            Result->dim[4]=numbmodal;
            Result->dim[5]=1;
            nifti_update_dims_from_array(Result);
            Result->data = (void *) calloc(Result->nvox, sizeof(float));
            int numel=this->GetNumberElements();
            int numbBF=((BForder+1)*(BForder+2)*(BForder+3))/6;
            float * Result_PTR=static_cast<float *>(Result->data);
            float * Result_PTRtmp=Result_PTR;
            for (int i=0; i<numel; i++, Result_PTRtmp++) {
                *Result_PTRtmp=0;
            }
            //                float * Input_PTR=BasisFunctionsToSave;
            int * L2S_PTR=this->GetL2S();

            for (int m=0; m<numbmodal; m++) {
                for (int j=0; j<numbBF; j++) {
                    float * BFCorrection_PTR=&BFCorrection[m*numelmasked];
                    Result_PTRtmp=&Result_PTR[m*numel];
                    //                        Input_PTR=&BasisFunctionsToSave[j*numelmasked];
                    L2S_PTR=this->GetL2S();
                    for (int i=0; i<numel; i++, Result_PTRtmp++,L2S_PTR++) {
                        if (*L2S_PTR>=0) {
                            *Result_PTRtmp=*BFCorrection_PTR;
                            BFCorrection_PTR++;
                        }
                        else{
                            *Result_PTRtmp=0;
                        }

                    }

                }
            }
            nifti_set_filenames(Result, filenameBF.c_str(), 0, 0);
            nifti_image_write(Result);
            nifti_image_free(Result);
            if(BFCorrection!=NULL){
                delete[] BFCorrection;
                BFCorrection=NULL;
            }
        }



}

void TreeEM::SaveBFCorrectedData(string filenameBF){
    //    int numelmasked=this->GetNumberMaskedElements();
    //    int numbBF=((BForder+1)*(BForder+2)*(BForder+3))/6;
    int numbmodal=this->GetNumberModalities();
    int numelmasked=this->GetNumberMaskedElements();
    if (this->AreBFCoeffsDirectUseable() || !this->AreBFCoeffsDirectUseable()) {
        nifti_image * Result=nifti_copy_nim_info(this->GetDataImage());
        Result->dim[0]=4;
        Result->dim[4]=numbmodal;
        Result->dim[5]=1;
        nifti_update_dims_from_array(Result);
        Result->data = (void *) calloc(Result->nvox, sizeof(float));
        int numel=this->GetNumberElements();
        float * Result_PTR=static_cast<float *>(Result->data);
        float * Result_PTRtmp=Result_PTR;
        for (int i=0; i<numel; i++, Result_PTRtmp++) {
            *Result_PTRtmp=0;
        }
        float * Input=this->GetDataBFCorrected();
        float * Input_PTR=Input;
        int * L2S_PTR=this->GetL2S();

        for (int m=0; m<numbmodal; m++) {
            L2S_PTR=this->GetL2S();
            Result_PTRtmp=&Result_PTR[m*numel];
            Input_PTR=&Input[m*numelmasked];

            for (int i=0; i<numel; i++, Result_PTRtmp++,L2S_PTR++) {
                if(*L2S_PTR>=0){
                    *Result_PTRtmp=*Input_PTR;
                    Input_PTR++;
                }


            }

        }

        nifti_set_filenames(Result, filenameBF.c_str(), 0, 0);
        nifti_image_write(Result);
        nifti_image_free(Result);
    }

}

//void TreeEM::SaveTreeInTextFile(string filenameOut){
//    std::ofstream fs(filenameOut);

//    if(!fs)
//    {
//        std::cout<<"Cannot open the output file."<<std::endl;
//        return;
//    }
//    int numbchild=this->GetNumberChildren();
//    int numbmodal=this->GetNumberModalities();
//    float indFactor=this->GetIndFactor();
//    fs<<"There are "<<numbchild<<" general classes \n";
//    fs<<"The studied data contains "<<numbmodal<<" modalities\n";
//    fs<<"The factor for independence is "<<indFactor<<" \n";
//    // Writing BF coefficients if exist
//    if (this->AreBFCoeffsDirectUseable()) {
//        int numbBF=((BForder+1)*(BForder+2)*(BForder+3))/6;
//        float * BFCoeffs_new=this->GetBFCoeffs();
//        fs<<" The BF coefficients are : \n";
//        for (int m=0; m<numbmodal; m++) {
//            float * BFCoeffs_PTR=&BFCoeffs_new[m*numbBF];
//            fs << "For modality "<<m<<" \n";
//            for (int l=0; l<numbBF; l++,BFCoeffs_PTR++) {
//                fs<<*BFCoeffs_PTR<<"   -    ";
//            }
//            fs<<"\n";
//        }
//    }
//    // Writing parameters and weights of the different classes
//    for (int c=0; c<numbchild; c++) {
//        int numbLeaves=this->GetChild(c)->GetNumberAllLeaves();
//        vector<TreeEM *> LeavesVector=this->GetChild(c)->GetAllLeaves();
//        fs<<"General class "<<c<<" contains "<<numbLeaves<<" subclasses and its weight is "<<this->GetChild(c)->GetNormWeight()<<" \n";
//        if (numbLeaves==0) {
//            fs<<"The general class "<<c<<" is not a mixture and its parameters are : \n Mean :\n";
//            float * Mean=this->GetChild(c)->GetMean();
//            float * Variance=this->GetChild(c)->GetVariance();
//            for (int m=0; m<numbmodal; m++) {
//                fs<<Mean[m]<<"    ";
//            }
//            fs<<"\n Variance \n";
//            for (int m1=0; m1<numbmodal; m1++) {
//                for (int m2=0; m2<numbmodal; m2++) {
//                    fs<<Variance[m1+m2*numbmodal]<<"     ";
//                }
//                fs<<"\n";
//            }

//        }
//        else{
//            for (int l=0; l<numbLeaves; l++) {
//                fs<<"The subclass "<<l<<" of general class "<<c<<" is of weight "<<LeavesVector[l]->GetNormWeight()<<" \n";
//                fs<<"The parameters of the distribution are : \n Mean \n";
//                float * Mean=LeavesVector[l]->GetMean();
//                float * Variance=LeavesVector[l]->GetVariance();
//                for (int m=0; m<numbmodal; m++) {
//                    fs<<Mean[m]<<"    ";
//                }
//                fs<<"\n Variance \n";
//                for (int m1=0; m1<numbmodal; m1++) {
//                    for (int m2=0; m2<numbmodal; m2++) {
//                        fs<<Variance[m1+m2*numbmodal]<<"     ";
//                    }
//                    fs<<"\n";
//                }
//            }
//        }
//    }
//    //fs<<"ghgh";
//    fs.close();
//    return;
//}
vector<TreeEM*> TreeEM::GetAllTreesFromLevel(int l){
    vector<TreeEM*> LevelElements;
    // First check if requested level is available
    if(l>this->GetNumberLevels()){
        cout<< "Requested level more than possible depth"<<endl;
        return LevelElements;
    }
    if(l==0){
        LevelElements.push_back(this);

    }
    else{
    int numbchild=this->GetNumberChildren();
    for(int c=0;c<numbchild;c++){
        vector<TreeEM *> LevelElements_child=this->GetChild(c)->GetAllTreesFromLevel(l-1);
        int numbLEC=LevelElements_child.size();
        for(int c1=0;c1<numbLEC;c1++){
            LevelElements.push_back(LevelElements_child[c1]);
        }
    }
    }
    return LevelElements;
}

int TreeEM::GetNumberLevels(){
      int MaxLevel=0;
      int numbchild=this->GetNumberChildren();
//      cout<< "considered numbchild is "<<numbchild<<endl;
      for(int c=0;c<numbchild;c++){
//          cout << "the child looked is "<< c<<endl;
          int Level=(this->GetChild(c))->GetNumberLevels();
//          cout<< "Number of levels of child "<<c<<" is "<<Level<<endl;
          if (Level>MaxLevel){
              MaxLevel=Level;
          }
      }
//      cout<<"Number of levels is "<<MaxLevel+1<<" for "<<this<<endl;
      return MaxLevel+1;
    }

int TreeEM::GetLevel(){
    int Level=0;
    if(!(this->IsRoot()||this->WhatTypeOfTreeComponent()==INITIALNODE)){
        return 1+this->GetParent()->GetLevel();
    }
    return Level;
}

int * TreeEM::GetHierarchy(){
    int numbLevel=this->GetLevel();
    int * Hierarchy=NULL;
    if(numbLevel>0){
    Hierarchy=new int[numbLevel];
    int * Hierarchy_bef=this->GetParent()->GetHierarchy();
    int Level_bef=this->GetParent()->GetLevel();
    for(int l=0;l<Level_bef;l++){
        Hierarchy[l]=Hierarchy_bef[l];
    }
    Hierarchy[Level_bef]=this->GetParent()->FindIndex(this);
    if(Hierarchy_bef!=NULL){
        delete [] Hierarchy_bef;
        Hierarchy_bef=NULL;
    }
    }
    else{
        Hierarchy=NULL;
    }
    return Hierarchy;
}

vector<int> TreeEM::GetHierarchyVector(){
    int numbLevel=this->GetLevel();
    vector<int> HierarchyVector;
    if(numbLevel>0){
        vector<int> Hierarchy_bef=this->GetParent()->GetHierarchyVector();
        int Level_bef=this->GetParent()->GetLevel();
        for(int l=0;l<Level_bef;l++){
            HierarchyVector.push_back(Hierarchy_bef[l]);
        }
        HierarchyVector.push_back(this->GetParent()->FindIndex(this));
        if(Hierarchy_bef.size()!=0){
            Hierarchy_bef.clear();
        }
    }
    return HierarchyVector;
}

TreeEM* TreeEM::FindFromHierarchy(vector<int> HierarchyVector){
    // Check that the search begins at the Root
    TreeEM * RootForSearch=this->FindRoot();
    TreeEM * TreeTmp=RootForSearch;
    int LengthHierarchy=HierarchyVector.size();
    for (int i=0; i<LengthHierarchy; i++) {
        TreeTmp=TreeTmp->GetChild(HierarchyVector[i]);
    }
    return TreeTmp;
}

int TreeEM::FindIndex(TreeEM* ChildToFind){
    int numbchild=this->GetNumberChildren();
    for(int c=0;c<numbchild;c++){
        if(this->GetChild(c)==ChildToFind){
            return c;
        }
    }
    return -1;
}

int TreeEM::FindGeneralClass(){
    // Check if Root or initial node
    if(this->IsRoot()){
        return -1;
    }
    else{
        if (this->GetParent()->IsRoot()){
            return this->GetParent()->FindIndex(this);
        }
        else{
            return this->GetParent()->FindGeneralClass();
        }
    }
}

TreeEM* TreeEM::FindGeneralClassPriors(){
    // Check if truly has upwards some priors
    if(this->GetPriors()==NULL){
        return NULL;
    }
    else{
        if(this->GetPriorsDirect()!=NULL){
            return this;
        }
        else{
            return this->GetParent()->FindGeneralClassPriors();
        }
    }
}

TreeEM * TreeEM::GetCorrespondingUniform(){
    int AnatClass=this->GetAnatClass();
    if (AnatClass<0) {
        cout<<"The observed tree is not related to a specific anatomical class"<<endl;
        return NULL;
    }
    if (this->GetFlagOutliers()!=3 && this->GetFlagOutliers()!=8) {
        cout<<"No anatomical symmetry between the inlier and the outlier part"<<endl;
        return NULL;
    }
    return this->GetUniformLeavesVector()[AnatClass];
}

// Return the index of the corresponding anatomical class. -1 by default if does not correspond to any anatomical class for construction reason.
int TreeEM::GetAnatClass(){
    if (this->IsRoot()) {
        cout<<"Root no anatomical"<<endl;
        return -1;
    }
    if (this->GetNodeOutlier()==this) {
        cout<<"Outlier no anatomical"<<endl;
        return -1;
    }
    if (this->GetNodeInlier()==this) {
        cout<<"Inlier no anatomical"<<endl;
        return -1;
    }
    if (this->GetParent()==this->GetNodeOutlier() ) {
        if (this->GetFlagOutliers()!=3 && this->GetFlagOutliers() !=8) {
            cout<<"outlier configuration not allowing for anatomical determination"<<endl;
            return -1;
        }
    }
    if (this->GetFlagOutliers()==3 || this->GetFlagOutliers()==8) {
        return this->GetHierarchyVector()[1];
    }
    else return this->GetHierarchyVector()[0];
}

TreeEM* TreeEM::FindUnifDist(SEG_PARAMETERS * segment_param){
    if (segment_param->OutliersMod==0) { // when no outlier model, no unif dist
        return NULL;
    }
    else{
        TreeEM * OutlierNode=this->GetNodeOutlier();
        if (OutlierNode->GetDistributionType()==1) { // the general outlier node is a Gaussian now (case 1 or 2 of uniformTC)
            return NULL;
        }
        else if (OutlierNode->GetDistributionType()==2){ // the general outlier node is unif dist itself
            return OutlierNode;
        }
        else{
            vector<TreeEM*> ChildrenOutlier=OutlierNode->GetChildren();
            int numbOutSubclasses=ChildrenOutlier.size();
            for (int c=0; c<numbOutSubclasses; c++) {
                if (ChildrenOutlier[c]->GetDistributionType()==2) {
                    return ChildrenOutlier[c];
                }
            }
            return NULL; // means that there is no uniform dist anymore in the model. Cannot occur with uniformTC more than 2
        }
    }
}

vector<vector<int> > TreeEM::FindAllUniformDistHierarchies(SEG_PARAMETERS * segment_param){
    vector<vector<int> > UnifDistHierarchyVector;
    if (segment_param->OutliersMod==0) { // when no outlier model, no unif dist
        return UnifDistHierarchyVector;
    }
    else{
        TreeEM * OutlierNode=this->GetNodeOutlier();
        if (OutlierNode->GetDistributionType()==1) { // the general outlier node is a Gaussian now (case 1 or 2 of uniformTC)
            return UnifDistHierarchyVector;
        }
        else if (OutlierNode->GetDistributionType()==2){ // the general outlier node is unif dist itself
            UnifDistHierarchyVector.push_back(OutlierNode->GetHierarchyVector());
            return UnifDistHierarchyVector;
        }
        else{
            vector<TreeEM*> LeavesOutlier=OutlierNode->GetAllLeaves();
            int numbOutSubclassesLeaves=LeavesOutlier.size();
            for (int c=0; c<numbOutSubclassesLeaves; c++) {
                if (LeavesOutlier[c]->GetDistributionType()==2) {
                    UnifDistHierarchyVector.push_back(LeavesOutlier[c]->GetHierarchyVector());
                }
            }
            return UnifDistHierarchyVector; // means that there is no uniform dist anymore in the model. Cannot occur with uniformTC more than 2
        }
    }
}

vector<TreeEM *> TreeEM::GetUniformLeavesVector(){
    vector<TreeEM *> VectorUniform;
    if (this->GetFlagOutliers()==0) {
        return VectorUniform;
    }
    else{
        TreeEM * OutlierNode=this->GetNodeOutlier();
        if (OutlierNode->GetDistributionType()==1) { // the general outlier node is a Gaussian now (case 1 or 2 of uniformTC)
            return VectorUniform;
        }
        else if (OutlierNode->GetDistributionType()==2){ // the general outlier node is unif dist itself
            VectorUniform.push_back(OutlierNode);
            return VectorUniform;
        }
        else{
            vector<TreeEM*> LeavesOutlier=OutlierNode->GetAllLeaves();
            int numbOutSubclassesLeaves=LeavesOutlier.size();
            for (int c=0; c<numbOutSubclassesLeaves; c++) {
                if (LeavesOutlier[c]->GetDistributionType()==2) {
                    VectorUniform.push_back(LeavesOutlier[c]);
                }
            }
            return VectorUniform; // means that there is no uniform dist anymore in the model. Cannot occur with uniformTC more than 2
        }

    }
}

TreeEM* TreeEM::FindMainNode(){
    // if at Root returns NULL
    vector<int> Hierarchy=this->GetHierarchyVector();
    TreeEM * MainNodeResult=NULL;
    if (Hierarchy.size()==0) {
        return NULL;
    }
//    int * Hierarchy=this->GetHierarchy();
//    if(Hierarchy==NULL){ // => we are considering the root
//        return NULL;
//    }
    switch (this->GetFlagOutliers()) {
        case 1:
            if(this->GetLevel()==1 && this!=this->GetNodeOutlier()) { // level 1 above main classes
                return NULL;
            }
            else if(this==this->GetNodeOutlier()){ // level 1 at node outlier
                MainNodeResult= this;
                return MainNodeResult;
            }
            else{ // under main node follow hierarchy : main node at level 2
                MainNodeResult=this->FindRoot()->GetChild(Hierarchy[0])->GetChild(Hierarchy[1]);
                return MainNodeResult;
            }
            break;
        case 3:{
            if(this->GetLevel()==1) { // level 1 above main classes
                return NULL;
            }
            else{ // under main node follow hierarchy : main node at level 2
                MainNodeResult=this->FindRoot()->GetChild(Hierarchy[0])->GetChild(Hierarchy[1]);
                return MainNodeResult;
            }
        }
            break;
        case 5:{
            if(this->GetLevel()==1) { // level 1 above main classes
                return NULL;
            }
            else{ // under main node follow hierarchy : main node at level 2
                MainNodeResult=this->FindRoot()->GetChild(Hierarchy[0])->GetChild(Hierarchy[1]);
                return MainNodeResult;
            }
        }
            break;
            
        case 6:{
            if(this->GetLevel()==1) { // level 1 above main classes
                return NULL;
            }
            else{ // under main node follow hierarchy : main node at level 2
                
                MainNodeResult= this->FindRoot()->GetChild(Hierarchy[0])->GetChild(Hierarchy[1]);
                return MainNodeResult;
            }
        }
            break;
            case 7:{
                if(this->GetLevel()<=2) { // level 1  and 2 above main classes
                    return NULL;
                }
                else{ // under main node follow hierarchy : main node at level 2
                    MainNodeResult=this->FindRoot()->GetChild(Hierarchy[0])->GetChild(Hierarchy[1])->GetChild(Hierarchy[2]);
                    return MainNodeResult;
                }
            }
    break;
        default:{// no outlier model or model not trilayered with main class at first level
            MainNodeResult=this->FindRoot()->GetChild(Hierarchy[0]);
            return MainNodeResult;
        }
            break;
    }
    return MainNodeResult;
}


void TreeEM::SaveTreeInTextFile(string filenameOut,SEG_PARAMETERS * segment_param){
    std::ofstream fs(filenameOut.c_str());
    cout<< filenameOut<< " to save tree in text file"<<endl;
    if(!fs.is_open())
    {
        std::cout<<"Cannot open the output file."<<std::endl;
        return;
    }
    int numbLevels=this->GetNumberLevels();
    int numbchild=this->GetNumberChildren();
    int numbmodal=this->GetNumberModalities();
    fs << "Level 0 1"<<endl;
    fs << "ResultLL "<< this->GetLogLikelihood()<<endl;
    float * KLDModel=this->GetKLDModel();
    float * SSDModel=this->GetSSDModel();
    fs<< "KLD "<<KLDModel[0];
    for (int m=0; m<numbmodal; m++) {
        fs<<" "<<KLDModel[m+1];
    }
    fs<<endl;
    fs<<"SSD is "<<SSDModel[0];
    for (int m=0; m<numbmodal; m++) {
        fs<<" "<<SSDModel[m+1];
    }
    fs<<endl;
    delete [] KLDModel;
    KLDModel=NULL;
    delete [] SSDModel;
    SSDModel=NULL;
    fs << "Images "<<numbmodal<<endl;
    if(segment_param->flag_inDCFile){
        if(segment_param->filename_input.size()>0){
            for(int m=0;m<numbmodal;m++){
                string filename=segment_param->filename_input[m];
                string str(filename);
                fs<<filename<<endl;
            }
            int * ModalityTypes = this->GetModalities(segment_param);
            fs << "Modalities ";
            for (int m=0; m<numbmodal; m++) {
                fs<<PossibleModalities[ModalityTypes[m]]<<" ";
            }
            fs<<endl;
            fs<<"Data Corrected "<<segment_param->filename_inDC<<endl;
        }
        else{
        string filename=segment_param->filename_inDC;
        string str(filename);
        for (int m=0; m<numbmodal; m++) {
            fs<<filename<<endl;
        }
        int * ModalityTypes = this->GetModalities(segment_param);
        fs << "Modalities ";
        for (int m=0; m<numbmodal; m++) {
            fs<<PossibleModalities[ModalityTypes[m]]<<" ";
        }
        fs<<endl;
        delete [] ModalityTypes;
        ModalityTypes=NULL;
        fs<<"Data Corrected "<<filename<<endl;
        }
    }
    else{
    for(int m=0;m<numbmodal;m++){
        string filename=segment_param->filename_input[m];
        string str(filename);
        fs<<filename<<endl;
    }
    int * ModalityTypes = this->GetModalities(segment_param);
        cout<<"Modalities gotten"<<endl;
    fs << "Modalities ";
    for (int m=0; m<numbmodal; m++) {
        fs<<PossibleModalities[ModalityTypes[m]]<<" ";
    }
    fs<<endl;
    delete [] ModalityTypes;
    ModalityTypes=NULL;
    fs<<"DataCorrected "<<segment_param->filename_datacorrected<<endl;
    }
    if(segment_param->flag_mask && this->GetMask()!=NULL){
        fs<<"Mask "<<this->GetMask()->iname<<endl;
    }
    if(segment_param->bias_order>0){
        fs<<"BFImage "<<segment_param->filename_correction<<endl;
    }
    if(segment_param->flag_MRFOut){
        fs << "MRFImage "<<segment_param->filename_MRFOut<<endl;
    }
    if(segment_param->flag_GMatrixIn){
        fs<< "GMatrixIn "<<segment_param->filename_GMatrix<<endl;
    }
    if(segment_param->flag_GMatrixPost){
        fs<< "GMatrixPost "<<segment_param->filename_GMatrixPost<<endl;
    }
    if(segment_param->flag_Outliers){
        fs<<"OutliersMode "<<segment_param->OutliersMod<<endl;
        if(this->GetFlagOutliers()==4){
            fs << "VLkappa "<<segment_param->VLkappa<<endl;
        }
        
        else{
        fs<<"OutliersWeight "<<segment_param->OutliersWeight<<endl;
        }
        fs<<"OutlierAtlas "<<segment_param->flag_OutlierAtlas<<endl;
    }
    else{
        fs<<"NoOutlier"<<endl;
    }
    fs<<"CovPriors "<<segment_param->CovPriorsType<<endl;
    fs<<"PriorsKept "<<segment_param->PriorsKept<<endl;
    fs<<"AcceptanceType "<<segment_param->AcceptanceType<<endl;
    fs<<"BICFP "<<segment_param->BICFP<<endl;
    fs<<"AtlasWeight ";
    int numbWeight=segment_param->AtlasWeight.size();
    for(int w=0;w<numbWeight;w++){
        fs<<segment_param->AtlasWeight[w]<<" ";
    }fs<<endl;
    
    fs<<"AtlasSmoothing ";
    int numbSmoothing=segment_param->AtlasSmoothing.size();
    for(int w=0; w < numbSmoothing;w++){
        fs<<segment_param->AtlasSmoothing[w]<<" ";
    }fs<<endl;
    fs<<"KernelSize "<<segment_param->KernelSize<<endl;
    fs<<"MiniPartWeight "<<segment_param->WeightMini<<endl;
    fs<<"SplitAccept "<<segment_param->SplitAccept<<endl;
    if (segment_param->flag_Outliers && segment_param->uniformTypeChange >2) {
        fs<<"VarianceInitUnif "<<segment_param->VarianceInitUnif << endl;
        fs<<"InitSplitUnifKM "<<segment_param->choiceInitSplitUnifKMeans<<endl;
        fs<<"UnifSplitWeight "<<segment_param->UnifSplitWeight<< endl;
        fs<<"UniformTC "<<segment_param->uniformTypeChange<<endl;
        fs<<"DistInitUnif "<<segment_param->DistInitUnif<<endl;
    }
    if(segment_param->bias_order > 0){
        fs<<"BF "<<segment_param->bias_order<<endl;
        int numbBF=(int)((BForder+1)*(BForder+2)*(BForder+3))/6;
        float * BFCoeffs_toprint=this->GetBFCoeffs();
        for(int m=0;m<numbmodal;m++){
            for(int j=0;j<numbBF;j++){
                fs<<BFCoeffs_toprint[m*numbBF+j]<<"     ";
            }
            fs<<endl;
        }
    }

    if(segment_param->flag_DP){
        float * DPChildrenToPrint=this->GetDPChildren();
        if(segment_param->flag_DistClassInd){
        for(int c=0;c<numbchild;c++){

            fs<<"CP "<<c<<endl;
            for(int i=0;i<MaxSupport;i++){
                fs<<DPChildrenToPrint[i+c*MaxSupport]<< "   ";
            }
            fs<<endl;
        }
        }
    }
    fs<<"IF "<<this->GetIndFactor()<<endl;
    fs<<endl;
    int pa=0;
    for(int l=1;l<numbLevels;l++){
        vector<TreeEM*> LevelsElement=this->GetAllTreesFromLevel(l);
        int numbElements=LevelsElement.size();
        fs<<"Level "<<l<<" "<<numbElements<<endl;
        fs<<endl;
        for(int c=0;c<numbElements;c++){
            TreeEM * ElementToPrint=LevelsElement[c];
            int * Hierarchy=ElementToPrint->GetHierarchy();
            fs<<"Class ";
            for(int i=0;i<l;i++){
                fs<<Hierarchy[i]<<" ";
            }
            fs<<endl;
            if(Hierarchy!=NULL){
                delete [] Hierarchy;
                Hierarchy=NULL;
            }
            if(ElementToPrint->GetPriorsDirect()!=NULL){
                fs<<"Prior "<<ElementToPrint->GetPriorsDirect()->iname<<endl;
            }
            if(ElementToPrint->GetPriorsAdaptedDirect()!=NULL ){// && pa<segment_param->filename_PriorsAdaptedOut.size()){
                vector<int> HierarchyVector=ElementToPrint->GetHierarchyVector();
                int numbHierarchy=HierarchyVector.size();
                string FilenameBC=nifti_makebasename(segment_param->filename_out[0].c_str());
                int Index=FilenameBC.find_last_of('/');
                string FilenameBC_b=FilenameBC.substr(0,Index+1);
                string FilenameBC_e=FilenameBC.substr(Index+1,FilenameBC.length());
                string FilenameBC_m="PriorsAdapted_";
                for (int h=0; h<numbHierarchy; h++) {
                    stringstream ss;
                    ss<<HierarchyVector[h];
                    string cs=ss.str();
                    FilenameBC_m+=cs;
                }
                    FilenameBC=FilenameBC_b+FilenameBC_m+FilenameBC_e+".nii.gz";
                fs<<"AdaptedPriors "<<FilenameBC<<endl;
//                fs<<"AdaptedPriors"<<segment_param->filename_PriorsAdaptedOut[pa]<<endl;
                pa++;
            }
            fs << "Weight "<<ElementToPrint->GetNormWeight()<<endl;
            int DistributionType=ElementToPrint->GetDistributionType();
            switch(DistributionType){
            case 0 :
                fs<<"Mixture"<<endl;
                break;
            case 2:{
                fs<<"UniformDist"<<endl;
                float * MeanToPrint=ElementToPrint->GetMeanDirect();
                float * VarianceToPrint=ElementToPrint->GetVarianceDirect();
                fs<<"MeanD ";
                for (int m=0; m<numbmodal; m++) {
                    fs<<MeanToPrint[m]<<" ";
                }
                fs<<endl;
                fs<<"VarianceD ";
                for (int m1=0; m1<numbmodal; m1++) {
                    for (int m2=0; m2<numbmodal; m2++) {
                        fs<<VarianceToPrint[m1+m2*numbmodal]<<" ";
                    }
                }
                fs<<endl;
                if (MeanToPrint!=NULL) {
                    delete [] MeanToPrint;
                    MeanToPrint=NULL;
                }
                if(VarianceToPrint!=NULL){
                    delete [] VarianceToPrint;
                    VarianceToPrint=NULL;
                }
                }
                break;
            default:{
                fs<<"Leaf "<<DistributionType<<endl;
                float * ValueToPrint=ElementToPrint->GetParametersValue();
                fs<<"Mean ";
                for(int m=0;m<numbmodal;m++){
                    fs<<ValueToPrint[m]<<" ";
                }
                fs<<endl;
                fs<<"Variance ";
                for(int m=0;m<numbmodal*numbmodal;m++){
                    fs<<ValueToPrint[numbmodal+m]<<" ";
                }
                fs<<endl;
            }
            }
            fs<<endl;
        }
    }
    cout<<"Finished saving"<<endl;
    fs.close();
    return;
}

void TreeEM::ModifyCountFiles(vector<string> CountFiles){
    int numbchild=this->GetNumberChildren();
    int numbFiles=CountFiles.size();
    if(numbchild!=numbFiles){
        cout<<"Pb in the number of count files and general classes"<<endl;
        return;
    }
    else{
        int numbchild=this->GetNumberChildren();
        for(int c=0;c<numbchild;c++){
            int numbLeaves=(this->GetChild(c)->GetNumberAllLeaves()>0?this->GetChild(c)->GetNumberAllLeaves():1);

            ifstream CountFile(CountFiles[c].c_str());
            ofstream TempCount("/Users/Carole/Documents/PhD/temporaryCount.txt");
            if(!CountFile || !TempCount){
                cout<<"Pb in opening files"<<endl;
            }
            int valueFile;
            int line=0;
            while(CountFile >> valueFile){
                if(line==numbLeaves-1){
                    valueFile+=1;
                }
                TempCount << valueFile<<"\n";
                line++;
            }
            rename("/Users/Carole/Documents/PhD/temporaryCount.txt",CountFiles[c].c_str());
        }
    }
}

float * TreeEM::GaussianBlurring(float * CountHistogram, float gauss_std, vector<int> dim){
    if (gauss_std>0) {
        int numbDim=dim.size();
        int kernelsizemin=(int)floorf(gauss_std*KernelSize);
        int kernelsizemax=(int)ceilf(gauss_std*KernelSize);
        int kernelsize=0;
        (kernelsizemin/2)*2==kernelsizemin?kernelsize=kernelsizemax:kernelsize=kernelsizemin;
        // To do filtering, kernel must be at least of size 2.
        kernelsize=kernelsize<3?3:kernelsize;
        
        // Construction of the kernel
        float * Kernel=new float[kernelsize];
        int kernelradius=kernelsize/2;
        for(int i =0;i<kernelsize;i++){
            Kernel[i]=1.0/(sqrt(2.0*M_PI)*gauss_std)*expf(-0.5*pow((i-kernelradius)/gauss_std,2));
        }
        //Normalisation of the kernel
        float SumKernel=0;
        for(int i=0;i<kernelsize;i++){
            SumKernel+=Kernel[i];
        }
        if(SumKernel>0){
            for(int i=0;i<kernelsize;i++){
                Kernel[i]/=SumKernel;
            }
        }
        
        // Construction of the Shift array
        int * Shift=new int[numbDim];
        for(int c=0;c<numbDim;c++){
            if(c>0){
                Shift[c]=Shift[c-1]*dim[c-1];
            }
            else{
                Shift[c]=1;
            }
        }
        
        // Copying the initial array to blur
        int SizeHistogram=Shift[numbDim-1]*dim[numbDim-1];
        float * Gaussian_tmp=new float[SizeHistogram];
        float * Gaussian_tmp2=new float[SizeHistogram];
        for (int i=0; i<SizeHistogram; i++) {
            Gaussian_tmp[i]=0;
            Gaussian_tmp2[i]=0;
        }
//        int CountNonZero=0;
//        int CountZeroB=0;
        for(int i=0;i<SizeHistogram;i++){
            Gaussian_tmp[i]=CountHistogram[i];
//            if(Gaussian_tmp[i]>0){
//                CountNonZero++;
//            }
        }
        
        for(int c=0;c<numbDim;c++){ // To do the blurring in each direction
            for(int j=0;j<SizeHistogram/(dim[c]);j++){
                int i=0;
                //            int RemainDim[numbDim-1];
                //            int IndRemainDim[numbDim-1];
                //            int RemainShift[numbDim-1];
                //            int FinalShift[numbDim-1];
                int * RemainDim=new int[numbDim-1];
                int * IndRemainDim=new int[numbDim-1];
                int * RemainShift=new int[numbDim-1];
                int * FinalShift=new int[numbDim-1];
                for(int i=0;i<numbDim-1;i++){
                    RemainShift[i]=1;
                    FinalShift[i]=1;
                }
                for(int d=0;d<numbDim;d++){
                    if(d!=c){
                        RemainDim[i]=dim[d];
                        IndRemainDim[i]=d;
                        i++;
                    }
                }
                for(int i=0;i<numbDim-1;i++){
                    if(i>0){
                        RemainShift[i]=RemainShift[i-1]*RemainDim[i-1];
                    }
                }
                int t=j;
                int tmp=0;
                int * Index=new int[numbDim-1];
                for(int i=numbDim-2;i>=0;i--){
                    tmp=t/RemainShift[i];
                    t=t-tmp*RemainShift[i];
                    Index[i]=tmp;
                }
                for(int i=0;i<numbDim-1;i++){
                    if(c<IndRemainDim[i]){
                        FinalShift[i]=dim[c]*RemainShift[i];
                    }
                    else{
                        FinalShift[i]=RemainShift[i];
                    }
                }
                int FinalIndex=0;
                for(int i=0;i<numbDim-1;i++){
                    FinalIndex+=Index[i]*FinalShift[i];
                }
                for(int i=0;i<dim[c];i++){
                    float tmpkernel=0;
                    int FinalIndexB=FinalIndex+i*Shift[c];
                    float SumKernelTmp=0;
                    int StableIndex=FinalIndexB-kernelsize/2*Shift[c];
                    for(int k=0;k<kernelsize;k++){
                        if(i-kernelsize/2+k>=0 && i-kernelsize/2+k<dim[c]){ // Only when remains in image considered for kernel. Main pb is that the kernel is then not normalised anymore
                            int IndexToUse=StableIndex+k*Shift[c];
//                            tmpkernel+=Kernel[k]*Gaussian_tmp[FinalIndexB+(-kernelsize/2+k)*Shift[c]];
                            // Convolution operation
                            tmpkernel+=Kernel[k]*Gaussian_tmp[IndexToUse];
                            SumKernelTmp+=Kernel[k];
                        }
                    }
                    if (SumKernelTmp<1 && SumKernelTmp>0) {
                        tmpkernel/=SumKernelTmp;
                    }
                    Gaussian_tmp2[FinalIndexB]=tmpkernel;
                }
                delete [] Index;
                Index=NULL;
                if(RemainShift!=NULL){
                    delete [] RemainShift;
                    RemainShift=NULL;
                }
                if(RemainDim!=NULL){
                    delete [] RemainDim;
                    RemainDim=NULL;
                }
                if(IndRemainDim!=NULL){
                    delete [] IndRemainDim;
                    IndRemainDim=NULL;
                }
                if(FinalShift!=NULL){
                    delete [] FinalShift;
                    FinalShift=NULL;
                }
            }
            float sumNorm=0;
            
            for(int l=0;l<SizeHistogram;l++){
//                if(Gaussian_tmp2[l]>0){
//                    CountZeroB++;
//                }
                sumNorm+=Gaussian_tmp2[l];
                Gaussian_tmp[l]=Gaussian_tmp2[l];
            }
            //        for(int l=0;l<SizeHistogram;l++){
            //            Gaussian_tmp[l]/=sumNorm;
            //        }
            
        }
        delete [] Gaussian_tmp2;
        Gaussian_tmp2=NULL;
        delete [] Kernel;
        Kernel=NULL;
        delete [] Shift;
        Shift=NULL;
        return Gaussian_tmp;
    }
    else{ // if gauss_std is 0, means that there is actually no adaptation to be done and we only copy the result before returning it
        int numbDim=dim.size();
        // Construction of the Shift array
        int * Shift=new int[numbDim];
        for(int c=0;c<numbDim;c++){
            if(c>0){
                Shift[c]=Shift[c-1]*dim[c-1];
            }
            else{
                Shift[c]=1;
            }
        }
        
        // Copying the initial array to blur
        int SizeHistogram=Shift[numbDim-1]*dim[numbDim-1];
        float * Gaussian_tmp=new float[SizeHistogram];
        for (int i=0; i<SizeHistogram; i++) {
            Gaussian_tmp[i]=CountHistogram[i];
        }
        delete [] Shift;
        Shift=NULL;
        return Gaussian_tmp;
    }
}


/******************** METHODS RELATED TO MRF CALCULATION *******************/

float * TreeEM::GetNormRespShifted(int dim, int dir,SEG_PARAMETERS * segment_param){
    // First make sure that the input values are ok or change them accordingly
    if(dir!=0){
    dir=dir>0?1:-1;
    }
    dim=dim>2?2:dim;
    dim=dim<0?0:dim;

    // Initialisation of the needed values
//    int Dimensions[3];
//    Dimensions[0]=this->GetDataImage()->nx;
//    Dimensions[1]=this->GetDataImage()->ny;
//    Dimensions[2]=this->GetDataImage()->nz;
    int Shift[3];
    Shift[0]=1;
    Shift[1]=this->GetDataImage()->nx;
    Shift[2]=this->GetDataImage()->nx*this->GetDataImage()->ny;
    int numbx=this->GetDataImage()->nx;
    int numby=this->GetDataImage()->ny;
    int numbz=this->GetDataImage()->nz;
    int indexShift=Shift[dim]*dir;
//    int numbmodal=this->GetNumberModalities();
    int numel=this->GetNumberElements();
//    int nvox=this->GetDataImage()->nvox;
//    int numelmasked=this->GetNumberMaskedElements();
    int newIndex=0;
    int oldIndex=0;
    // Allocation of memory for shifted matrix
    float * NormRespShifted= new float[numel];//{0};
    int * L2S_PTR=this->GetL2S();
    float * NormRespPointedNC=this->GetNormResp();
    float * NormRespPointed = new float[numel];
        L2S_PTR=this->GetL2S();
        float * NormRespPointedNC_PTR = NormRespPointedNC;
    
    if (this->GetFlagOutliers()==4) {
        int numelmasked=this->GetNumberMaskedElements();
        float * Typicality_PTR=&this->GetNormResp()[numelmasked];
        float * MSOutlierBeliefs=this->GetMSOutlierBeliefs(segment_param);
        float * MSOutlierBeliefs_PTR=MSOutlierBeliefs;
        vector<int> Hierarchy =this->GetHierarchyVector();
        bool WMBool=(Hierarchy[0]==1);
        for (int i=0; i<numel; i++,L2S_PTR++) {
            
            NormRespPointed[i]=0;
            if(*L2S_PTR>=0){
                NormRespPointed[i]=*NormRespPointedNC_PTR*(*Typicality_PTR)+WMBool*(*MSOutlierBeliefs_PTR);
                NormRespPointedNC_PTR++;
                Typicality_PTR++;
                MSOutlierBeliefs_PTR++;
            }
            NormRespShifted[i]=0;
        }
        delete [] MSOutlierBeliefs;
        MSOutlierBeliefs=NULL;
    }
    else{
        for (int i=0; i<numel; i++,L2S_PTR++) {

                NormRespPointed[i]=0;
                if(*L2S_PTR>=0){
                    NormRespPointed[i]=*NormRespPointedNC_PTR;
                    NormRespPointedNC_PTR++;
                }
                NormRespShifted[i]=0;
        }
    }

        for (int i=0; i<numbx; i++) {
            for (int j=0; j<numby; j++) {
                for (int k=0; k<numbz; k++) {
                    newIndex=i+j*Shift[1]+k*Shift[2]+indexShift;
                    oldIndex=i+j*Shift[1]+k*Shift[2];
                    if (newIndex>0 && newIndex<numel) {
                        NormRespShifted[newIndex]=NormRespPointed[oldIndex];
                    }
                }
            }
        }
        

//    delete [] Dimensions;
//    Dimensions=NULL;
//    delete [] Shift;
//    Shift = NULL;
    delete [] NormRespPointed;
    NormRespPointed = NULL;
    return NormRespShifted;
}

float * TreeEM::GetNormRespShiftedSumN(){
    
    // Initialisation of the needed values
//    int Dimensions[3];
//    Dimensions[0]=this->GetDataImage()->nx;
//    Dimensions[1]=this->GetDataImage()->ny;
//    Dimensions[2]=this->GetDataImage()->nz;
    int Shift[3];
    Shift[0]=1;
    Shift[1]=this->GetDataImage()->nx;
    Shift[2]=this->GetDataImage()->nx*this->GetDataImage()->ny;
    int numbx=this->GetDataImage()->nx;
    int numby=this->GetDataImage()->ny;
    int numbz=this->GetDataImage()->nz;
//    int indexShift=Shift[dim]*dir;
    //    int numbmodal=this->GetNumberModalities();
    int numel=this->GetNumberElements();
    int numelmasked=this->GetNumberMaskedElements();
    
    //    int nvox=this->GetDataImage()->nvox;
    //    int numelmasked=this->GetNumberMaskedElements();
    int newIndex=0;
    int oldIndex=0;
    // Allocation of memory for shifted matrix
    float * NormRespShifted= new float[numelmasked];//{0};
    int * L2S_PTR=this->GetL2S();
    float * NormRespPointedNC=this->GetNormResp();
    float * NormRespPointed = new float[numel];
    L2S_PTR=this->GetL2S();
    int j=0;
    float * NormRespPointedNC_PTR = NormRespPointedNC;
    for (int i=0; i<numel; i++,L2S_PTR++) {
        NormRespPointed[i]=0;
        if(*L2S_PTR>=0){
            NormRespPointed[i]=*NormRespPointedNC_PTR;
            NormRespPointedNC_PTR++;
            NormRespShifted[j]=0;
            j++;
        }
        
    }
    L2S_PTR=this->GetL2S();
    for (int dim=0; dim<3; dim++) {
        for (int dir=-1; dir<=1; dir=dir+2) {
            for (int i=0; i<numbx; i++) {
                for (int j=0; j<numby; j++) {
                    for (int k=0; k<numbz; k++) {
                        newIndex=i+j*Shift[1]+k*Shift[2]+Shift[dim]*dir;
                        oldIndex=i+j*Shift[1]+k*Shift[2];
                        if (newIndex>0 && newIndex<numel && L2S_PTR[newIndex]>=0) {
                            NormRespShifted[L2S_PTR[newIndex]]+=NormRespPointed[oldIndex];
                        }
                    }
                }
            }
        }
    }

    
    //    delete [] Dimensions;
    //    Dimensions=NULL;
    //    delete [] Shift;
    //    Shift = NULL;
    delete [] NormRespPointed;
    NormRespPointed = NULL;
    return NormRespShifted;
}

float * TreeEM::GetSumNeighboursNormResp_bis(){
    // First initialisation of the final NormResp obtained
//    int numel=this->GetNumberElements();
    int numelmasked=this->GetNumberMaskedElements();
    float * SumNeighboursNormResp=new float[numelmasked];
    for(int i=0;i<numelmasked;i++){
        SumNeighboursNormResp[i]=0;
    }
    int Dim[3];
    Dim[0]=this->GetDataImage()->nx;
    Dim[1]=this->GetDataImage()->ny;
    Dim[2]=this->GetDataImage()->nz;
    
    int Shift[3];
    Shift[0]=1;
    Shift[1]=Dim[0];
    Shift[2]=Shift[1]*Dim[1];
    
    int NeighbourShift[6];
    for (int d=0; d<3; d++) {
        for (int l=0; l<2; l++) {
            NeighbourShift[2*d+l]=Shift[d]*pow_int(-1, l+1);
        }
    }
    float DistanceFactor[6];
    float * PixDim=this->GetDataImage()->pixdim;
    for (int d=0; d<3; d++) {
        DistanceFactor[2*d]=PixDim[d+1];
        DistanceFactor[2*d+1]=PixDim[d+1];
    }
    
    int * L2S_PTR=this->GetL2S();
    int * S2L_PTR=this->GetS2L();
    
    int NeighbourTrans[6];
    for (int d=0; d<3; d++) {
        NeighbourTrans[2*d]=-1;
        NeighbourTrans[2*d+1]=1;
    }
    
    for (int i=0; i<numelmasked; i++, S2L_PTR++) {
        int IndexL=*S2L_PTR;
        int Coord[3];
//        for (int d=0; d<3; d++) {
//            Coord[d]=0;
//        }
        int tmp=IndexL;
        for (int d=2; d>=0; d--) {
            Coord[d]=tmp/Shift[d];
            tmp-=Coord[d]*Shift[d];
        }
//        int * Coord=this->CorrespondingCoord(IndexL,Shift);
//        int NeighbourTrans[6];
//        for (int d=0; d<3; d++) {
//            NeighbourTrans[2*d]=-1;
//            NeighbourTrans[2*d+1]=1;
//        }
        
        for (int n=0; n<6; n++) {
            int dimn=n/2;
//            int CoordTest=Coord[dimn]+NeighbourShift[n]/Shift[dimn];
            int CoordTest=Coord[dimn]+NeighbourTrans[n];
            if (CoordTest>0 && CoordTest<=Dim[dimn]-1) {
                int IndexN=IndexL+NeighbourShift[n];
//                if (IndexN<0) {
//                    cout<<"Pb with index when MRF neighbour"<<endl;
//                }
                int shortIndexN=L2S_PTR[IndexN];
                float * NormRespToUse=this->GetNormResp();
//                if (L2S_PTR[IndexN]>=0) {
//                    SumNeighboursNormResp[L2S_PTR[IndexN]]+=this->NormResp[L2S_PTR[IndexN]]/DistanceFactor[dimn];
//                }
                if (shortIndexN>=0) {
                    SumNeighboursNormResp[shortIndexN]+=NormRespToUse[shortIndexN]/DistanceFactor[dimn];
                }
            }
        }
//        delete [] Coord;
//        Coord=NULL;
    }
    
    return SumNeighboursNormResp;
}

int * TreeEM::CorrespondingCoord(int Index, int * Shift){
    if(Index<0 || Index>=this->GetNumberElements() ){
        return NULL;
    }
    else{
        int tmp=Index;
        int * Coord=new int[3];
        for (int d=0; d<3; d++) {
            Coord[d]=0;
        }
        for (int d=2; d>=0; d--) {
            Coord[d]=tmp/Shift[d];
            tmp-=Coord[d]*Shift[d];
        }
        return Coord;
    }
}

float * TreeEM::GetSumNeighboursNormResp(SEG_PARAMETERS * segment_param){
    // First initialisation of the final NormResp obtained
    int numel=this->GetNumberElements();
    int numelmasked=this->GetNumberMaskedElements();
    float * SumNeighboursNormResp=new float[numelmasked];
    for(int i=0;i<numelmasked;i++){
        SumNeighboursNormResp[i]=0;
    }

    // Assuming that it is a 3D image
    for(int dim = 0;dim<3;dim++){
        for(int dir = -1;dir<=1;dir=dir+2){
            float DistanceMRFFactor=1.0f;
            if (!this->IsDataIsotropic()) {
                DistanceMRFFactor=this->DistanceFactor(dim);
//                cout<< "DistanceFactor is "<<DistanceMRFFactor;
            }
            // Calculation of the corresponding NormRespShifted
            float * TmpShiftedNormResp=this->GetNormRespShifted(dim,dir,segment_param);
//            SaveTmpResult(TmpShiftedNormResp,"/Users/Carole/Documents/PhD/TestShifted.nii.gz");
            float * SumNeighboursNormResp_PTR=SumNeighboursNormResp;
            int * L2S_PTR=this->GetL2S();
            // Then Summed in the final result
            for(int i=0;i<numel;i++,L2S_PTR++){
                if (*L2S_PTR>=0){
                    *SumNeighboursNormResp_PTR+=DistanceMRFFactor*TmpShiftedNormResp[i];
                    SumNeighboursNormResp_PTR++;
                }

            }
            // Clearing memory allocated temporarily
            delete [] TmpShiftedNormResp;
            TmpShiftedNormResp=NULL;
        }
    }
//SaveTmpResultMasked(SumNeighboursNormResp,"/Users/Carole/Documents/PhD/TestShifted.nii.gz");
    return SumNeighboursNormResp;
}

float * TreeEM::GMulSumNeighbNormRespExp(SEG_PARAMETERS * segment_param){
    // Initialisation of result
    int numelmasked=this->GetNumberMaskedElements();
    int numbLeaves=this->GetNumberAllLeaves();
    int sizeResultMul=numelmasked*numbLeaves;
    vector<TreeEM *> LeavesVector=this->GetAllLeaves();
    float * LeavesSumNeighbour = new float[sizeResultMul];

    // Filling LeavesSumNeighbour
    for(int l=0;l<numbLeaves;l++){
//        int CountPbInequalitySumNormShift=0;
//       float * tmpLeavesSumNeighbour = LeavesVector[l]->GetSumNeighboursNormResp(segment_param);
        float * tmpLeavesSumNeighbour=LeavesVector[l]->GetSumNeighboursNormResp_bis();
//        float * tmpLeavesSumNeighbour = LeavesVector[l]->GetNormRespShiftedSumN();
        for(int i=0;i<numelmasked;i++){
//            if (tmpLeavesSumNeighbour_bis[i]!=tmpLeavesSumNeighbour[i]) {
//                CountPbInequalitySumNormShift++;
//            }
            LeavesSumNeighbour[i+l*numelmasked]=tmpLeavesSumNeighbour[i];
        }
//        cout<< CountPbInequalitySumNormShift<<endl;

        delete [] tmpLeavesSumNeighbour;
        tmpLeavesSumNeighbour=NULL;

    }



   // Initialising before multiplication

    float * Gmatrix=this->GetGMatrix();
    
    float * ResultMul=new float[sizeResultMul];
    for(int i=0;i<sizeResultMul;i++){
        ResultMul[i]=0;
    }
    
    int l=0;
    #ifdef _OPENMP
    #pragma omp parallel for shared(numbLeaves,numelmasked,Gmatrix,LeavesSumNeighbour,ResultMul) private(l)
    #endif
    for(l=0;l<numbLeaves;l++){
            for(int i=0;i<numelmasked;i++){
                for(int l2=0;l2<numbLeaves;l2++){
                    ResultMul[i+l*numelmasked]+=Gmatrix[l*numbLeaves+l2]*LeavesSumNeighbour[i+l2*numelmasked];
            }
        }
    }
//    int CountNan=0;
//    int i=0;
//#ifdef _OPENMP
//#pragma omp parallel for shared(numbLeaves,numelmasked,Gmatrix,LeavesSumNeighbour,ResultMul) private(i) schedule(dynamic) reduction(+:CountNan)
//#endif
//    for(i=0;i<numelmasked;i++){
//        for(int l=0;l<numbLeaves;l++){
//            if(LeavesSumNeighbour[i+l*numelmasked]!=LeavesSumNeighbour[i+l*numelmasked]){
//                CountNan++;
//            }
//        }
//    }
    delete [] LeavesSumNeighbour;
    LeavesSumNeighbour=NULL;

    int i=0;
#ifdef _OPENMP
#pragma omp parallel for shared(numbLeaves,numelmasked,ResultMul) private(l,i)
#endif
    for( l=0;l<numbLeaves;l++){
        for(i=0;i<numelmasked;i++){
            ResultMul[i+l*numelmasked]=expf(-ResultMul[i+l*numelmasked]);
//            if(ResultMul[i+l*numelmasked]!=ResultMul[i+l*numelmasked]){
//                CountNan++;
//            }
        }
    }

    return ResultMul;

}

//float * TreeEM::SumExpUmrf(){
//    // Check if you are at root level to make this request
//    if(!this->IsRoot()){
//        cout<<"Sum Umrf can only be asked at root"<<endl;
//        return NULL;
//    }
//    int numbLeaves=this->GetNumberAllLeaves();
//    int numelmasked=this->GetNumberMaskedElements();
//    vector<TreeEM *> LeavesVector=this->GetAllLeaves();
//    float * SumExpUmrfResult=new float[numelmasked];
//    for(int i=0;i<numelmasked;i++){
//        SumExpUmrfResult[i]=0;
//    }

//    for(int l=0;l<numbLeaves;l++){
//        float * PartExpUmrfResult=LeavesVector[l]->GetMRF();
//        for(int i=0;i<numelmasked;i++){
//            SumExpUmrfResult[i]+=PartExpUmrfResult[i];
//        }
//    }

//    return SumExpUmrfResult;
//}

void TreeEM::UpdateMRF(SEG_PARAMETERS * segment_param){

    float * tmpGMulSumNeigh=this->FindRoot()->GMulSumNeighbNormRespExp(segment_param);
    int numelmasked=this->GetNumberMaskedElements();
    int numbLeaves=this->FindRoot()->GetNumberAllLeaves();
    vector<TreeEM*> LeavesVector=this->FindRoot()->GetAllLeaves();
    
    // If not doing the normalisation, the part of normalisation is not needed.
    for (int l=0; l<numbLeaves; l++) {
        LeavesVector[l]->SetMRF(&tmpGMulSumNeigh[l*numelmasked]);
    }
    delete [] tmpGMulSumNeigh;
    tmpGMulSumNeigh=NULL;
    
//    float * SumMRF= new float[numelmasked];
//    for(int i=0;i<numelmasked;i++){
//        SumMRF[i]=0;
//    }
//    // Creating the normalisation factor for each active voxel
//    int CountNegativePB=0;
//    int CountNan=0;
//    for(int l=0;l<numbLeaves;l++){
//    for(int i=0;i<numelmasked;i++){
//        if(tmpGMulSumNeigh[i+l*numelmasked]<0){
//            CountNegativePB++;
//        }
//        if(tmpGMulSumNeigh[i+l*numelmasked]!=tmpGMulSumNeigh[i+l*numelmasked]){
//            CountNan++;
//        }
//        SumMRF[i]+=tmpGMulSumNeigh[i+l*numelmasked];
//    }
//    }
////    cout<<"Number of negative pb in sum MRF are "<<CountNegativePB<<" and Nan "<<CountNan<<endl;
//
//    // For each leave, creating the MRF value, normalising it and set it
//    for(int l=0;l<numbLeaves;l++){
//        float * MRFToUpdate= new float[numelmasked];
//        int CountMRFNormPb=0;
//        for(int i=0;i<numelmasked;i++){
//            if(SumMRF[i]>-10E-6){
//            MRFToUpdate[i]=tmpGMulSumNeigh[i+l*numelmasked]/SumMRF[i];
//            }
//            else{
//                CountMRFNormPb++;
////                cout<<"Pb with normalisation factor of MRF"<<endl;
//                MRFToUpdate[i]=1.0/numbLeaves;
//            }
//        }
//        if(CountMRFNormPb>0){
//            cout<< "MRF Norm Pb is "<<CountMRFNormPb<<" at leave "<<l<<endl;
//        }
//        LeavesVector[l]->SetMRF(MRFToUpdate);
//        delete [] MRFToUpdate;
//        MRFToUpdate=NULL;
//    }
//
//    // Clearing memory
//    delete [] SumMRF;
//    SumMRF=NULL;
//    delete [] tmpGMulSumNeigh;
//    tmpGMulSumNeigh=NULL;
}

void TreeEM::SetMRF(float * MRFToUpdate){
    // Check if MRF to update is on a leaf
    if(!this->IsLeaf()){
//        cout<<"MRF is only set on leaves"<<endl;
        if(this->MRF!=NULL){
            delete [] this->MRF;
            this->MRF=NULL;
        }
        return;
    }
    // prepare by deleting already present MRF and creating memory for new one
    if(this->GetMRF()!=NULL){
        delete [] this->GetMRF();
        this->MRF=NULL;
    }
    if(MRFToUpdate!=NULL){
    int numelmasked=this->GetNumberMaskedElements();
    this->MRF=new float[numelmasked];
    for(int i=0;i<numelmasked;i++){
        this->MRF[i]=MRFToUpdate[i];
    }
    }
    return;
}

float * TreeEM::GetMRF(){
    if(this->IsLeaf()){
        return this->MRF;
    }
    else{
        if(this->MRF!=NULL){
            cout<<"There should not be any MRF at this stage"<<endl;
            this->SetMRF(NULL);
        }
        return NULL;
    }
}

float * TreeEM::CopyMRF(){
    float *MRFToCopy=this->GetMRF();
    if(MRFToCopy==NULL){
        return NULL;
    }
    else {
        int numelmasked=this->GetNumberMaskedElements();
        float * MRFCopied = new float[numelmasked];
        for(int i=0;i<numelmasked;i++){
            MRFCopied[i]=MRFToCopy[i];
        }
        return MRFCopied;
    }
}

bool TreeEM::PrepareGInfoFromFile(string GMatrixFilename){
    // No preparation of GMatrix if not at root
    if(!this->IsRoot()){
        cout<<"No preparation of GMatrix if not at root"<<endl;
        return 0;
    }
    
    // First reading and taking all needed information from file
    ifstream text (GMatrixFilename.c_str());
    //    text.open(TreeTextFile,ios::in);
    if(!text){
        std::cout<<"could not open the text file properly ! for text file "<< GMatrixFilename<<endl;
        return 0;
    }
    else{ // Checked before that we are at the root so no worry on this side
        cout<<"Able to open "<<GMatrixFilename<<endl;
        
        std::string line;
        //        int numbchild = this->GetNumberChildren();
        vector<TreeEM*> NodesVector=this->GetGeneralClassesVector();
        //        cout<<"numbchild is "<<NodesVector.size()<<endl;
        int numbchild=NodesVector.size();
        int FlagOutliers=this->GetFlagOutliers();

        if (FlagOutliers==3 || FlagOutliers>=5 ) {
            int numbtemp=NodesVector.size()+this->GetNodeOutlier()->GetNumberChildren();
            //            if (numbtemp==2*numbchild) {
            //                numbchild=numbtemp;
            //            }
            if (FlagOutliers==6) {
                numbchild=numbtemp;
            }
        }
        //        cout<< numbchild<<" general anatomical classes"<<endl;
        if(this->GetPriorsNodeVector().size()==0){
            numbchild=0;
        }
//        vector< vector<int> > NeighborhoodSummary;
//        vector<vector<int> > OutlierSummary;
//        float GValues[3];
        //        float * GValues = new float[3];
        GValues[0]=1;
        GValues[1]=0;
        GValues[2]=0;
        numbClasses=0;
        while(getline(text,line)){
            istringstream in(line);
            std:: string type;
            in >> type;
            if (type == "GClasses"){
                //                int numbClasses=0;
                in >> numbClasses;
                if(numbClasses!=numbchild && this->GetFlagOutliers()==0){
                    cout<< "Incompatibility of general classes number with Gfile"<<endl;
                    return 0;
                }
            }
            if(type == "Neighborhood"){
                int CurrentClass=0;
                int NeighborhoodClass=0;
                vector<int> NeighboursCount;
                in >> CurrentClass;
                if(CurrentClass >= numbchild){
                    cout<< "Impossible class neighborhood offered"<<endl;
                    return 0;
                }
                while(in >> NeighborhoodClass){
                    //                    in >> NeighborhoodClass;
                    if(NeighborhoodClass >= numbchild){
                        cout<< "Impossible class neighborhood offered"<<endl;
                        return 0;
                    }
                    NeighboursCount.push_back(NeighborhoodClass);
                }
                NeighborhoodSummary.push_back(NeighboursCount);
            }
            if (FlagOutliers==5) {
                int numbchildOut=this->GetNodeOutlier()->GetChildren().size();
                if(type=="Out"){
                    int CurrentClassOut=0;
                    int OutBelongingClass=0;
                    vector<int> OutBelongClass;
                    in >> CurrentClassOut;
                    if(CurrentClassOut >= numbchildOut){
                        cout<< "Impossible class outliers offered"<<endl;
                        return 0;
                    }
                    while(in >> OutBelongingClass){
                        //                    in >> NeighborhoodClass;
                        if(OutBelongingClass >= numbchild){
                            cout<< "Impossible class belonging for outliers offered"<<endl;
                            return 0;
                        }
                        OutBelongClass.push_back(OutBelongingClass);
                    }
                    OutlierSummary.push_back(OutBelongClass);
                    
                }
            }
            
            if(type == "GValue"){
                int Level=0;
                float Value=0;
                in >> Level;
                in >> Value;
                // Checking if Value between 0 and 1 and thresholding if necessary
                //                Value=Value>1?1:Value;
                Value=Value<0?0:Value;
                if(Level<=2){
                    GValues[Level]=Value;
                }
            }
        }
        
        cout<<"OM "<<FlagOutliers<<" NC "<<numbchild<<" NS "<<NeighborhoodSummary.size()<<endl;
        int sizeNeighSumm=NeighborhoodSummary.size();
        if(sizeNeighSumm!=numbClasses && this->GetFlagOutliers()!=6){
            cout<< "Incompatibility between number of classes and neighborhood information"<<endl;
            cout<<"OM "<<FlagOutliers<<" NC "<<numbClasses<<" NS "<<sizeNeighSumm<<endl;
            return 0;
        }
        else if(FlagOutliers==6 && sizeNeighSumm!=numbchild){
            cout<< "Incompatibility between number of classes and neighborhood information"<<endl;
            cout<<"OM "<<FlagOutliers<<" NC "<<numbchild<<" NS "<<sizeNeighSumm<<endl;
            return 0;
        }
        
        return 1;
    }
}

float * TreeEM::CreateGMatrixFromInfo(bool optMRFOut,string GMatrixFilename){
    if (ValidGInfo==0) {
        cout<<"Info not available for GMatrix"<<endl;
        ValidGInfo=PrepareGInfoFromFile(GMatrixFilename);
        if (!ValidGInfo) {
            return NULL;
        }
    }
    if(ValidGInfo){
        cout<<"Info already available for GMatrix !"<<endl;
    }
    // No preparation of GMatrix if not at root
    if(!this->IsRoot()){
        cout<<"No preparation of GMatrix if not at root"<<endl;
        return NULL;
    }
//    int numbClasses=NeighborhoodSummary.size();
            int numbLeaves = this->GetNumberAllLeaves();
    vector<nifti_image *> PriorsVectorForSize=this->GetPriorsVector();
    vector<TreeEM*> NodesVector=this->GetGeneralClassesVector();
    //        cout<<"numbchild is "<<NodesVector.size()<<endl;
    int numbchild=NodesVector.size();
    int FlagOutliers=this->GetFlagOutliers();
    int numbPriors=PriorsVectorForSize.size();
    if (FlagOutliers==3 || FlagOutliers>=5 ) {
        int numbtemp=NodesVector.size()+this->GetNodeOutlier()->GetNumberChildren();
        //            if (numbtemp==2*numbchild) {
        //                numbchild=numbtemp;
        //            }
        if (FlagOutliers==6) {
            numbchild=numbtemp;
        }
    }
    //        cout<< numbchild<<" general anatomical classes"<<endl;
    if(this->GetPriorsNodeVector().size()==0){
        numbchild=0;
    }

            // Construction of GMatrix
            int numbLeavesSq=numbLeaves*numbLeaves;
            float * GMatrixResult = new float[numbLeavesSq];
            for (int i=0;i<numbLeavesSq;i++){
                GMatrixResult[i]=GValues[0];
            }
            if(numbchild==0){ // case where numbchild != numbClasses in particular when there are no priors and we cannot say anything about neighborhood properties
                for(int l1=0;l1<numbLeaves;l1++){
                    for(int l2=0;l2<numbLeaves;l2++){
                        if(l1!=l2){
                            GMatrixResult[l1*numbLeaves+l2]=GValues[2];
                        }
                    }
                }
                for(int c=0;c<numbchild;c++){
                    NeighborhoodSummary[c].clear();
                }
                return GMatrixResult;
            }
            else{
                int * NumberLeavesPerChild = new int[numbchild];
                int * IndexChangeChild=new int [numbchild+1];
                for(int i=0;i<numbchild+1;i++){
                    IndexChangeChild[i]=0;
                }
                // Once the node vector defined, obtention of the index changes from child to child.
                if(FlagOutliers!=6){
                    for(int c=0;c<numbchild;c++){ //or c < numbClasses
                        
                        NumberLeavesPerChild[c]=NodesVector[c]->GetNumberAllLeaves();
                        // If no Leaves detected means that the general class is no mixture but a leaf in itself
                        NumberLeavesPerChild[c]=NumberLeavesPerChild[c]==0?1:NumberLeavesPerChild[c];
                        
                        IndexChangeChild[c+1]=NumberLeavesPerChild[c]+IndexChangeChild[c];
                        
                    }
                }
                else{
                    int numbchildIn=NodesVector.size();
//                    int numbchildOutliers=numbchild-numbchildIn;
                    vector<TreeEM *> OutliersNodeVector=this->GetNodeOutlier()->GetChildren();
                    for (int c=0; c<numbchild; c++) {
                        if(c<numbchildIn){
                            NumberLeavesPerChild[c]=NodesVector[c]->GetNumberAllLeaves();
                        }
                        else{
                            NumberLeavesPerChild[c]=OutliersNodeVector[c-numbchildIn]->GetNumberAllLeaves();
                        }
                        NumberLeavesPerChild[c]=NumberLeavesPerChild[c]==0?1:NumberLeavesPerChild[c];
                        
                        IndexChangeChild[c+1]=NumberLeavesPerChild[c]+IndexChangeChild[c];
                    }
                }
                if (FlagOutliers!=3 && FlagOutliers!=5 && FlagOutliers!=7 ) {
                    // First filling blocks of second level
                    
                    for(int l1=0;l1<numbLeaves;l1++){
                        for(int l2=0;l2<numbLeaves;l2++){
                            // Determining at which general class each leaf corresponds
                            int Child1=0;
                            int Child2=0;
                            int test1=0;
                            int test2=0;
                            for(int c=0;c<numbchild;c++){
                                test1=IndexChangeChild[c];
                                test2=IndexChangeChild[c+1];
                                if (l1>=test1 && l1 <test2){
                                    Child1=c;
                                    break;
                                }
                            }
                            if(l1>=test2 && Child1==0){ // case where no child found and l1 correspond to out of the normal children => outlier
                                Child1=numbClasses;
                            }
                            test1=0;
                            test2=0;
                            for(int c=0;c<numbchild;c++){
                                test1=IndexChangeChild[c];
                                test2=IndexChangeChild[c+1];
                                if (l2>=test1 && l2 <test2){
                                    Child2=c;
                                    break;
                                }
                            }
                            if(l2>=test2 && Child2==0){ // same as with l1 => outlier
                                Child2=numbClasses;
                            }
                            // 1 on the diagonal
                            if(l2==l1){
                                GMatrixResult[l1+l2*numbLeaves]=0;
                            }
                            // if leaves considered belong to same general class
                            else if(Child1==Child2){
                                GMatrixResult[l1+l2*numbLeaves]=GValues[2];
                            }
                            else if(Child1>=numbClasses || Child2>=numbClasses){ // case where one of the leaves is considered as outlier : can be neighbour to everything so GValue[1] chosen
                                GMatrixResult[l1+l2*numbLeaves]=GValues[1];
                            }
                            else if(numbPriors>0){
                                // if leaves considered belong to neighbouring general class
                                int NumberOfNeighboursChild1=NeighborhoodSummary[Child1].size();
                                bool NeighC1C2=0;
                                for(int c=0;c<NumberOfNeighboursChild1;c++){
                                    if(NeighborhoodSummary[Child1][c]==Child2){
                                        NeighC1C2=1;
                                        break;
                                    }
                                }
                                if(NeighC1C2){
                                    GMatrixResult[l1+l2*numbLeaves]=GValues[1];
                                }
                            }
                            
                        }
                    }
                }
                else {
                    
                    
                    vector<TreeEM *> OutlierNodesVector;
                    if(FlagOutliers!=7){
                        OutlierNodesVector=this->GetNodeOutlier()->GetChildren();
                    }
                    else {
                        OutlierNodesVector=this->GetOutliersMainNodesVector();
                    }
                    
                    
                    int numbchildOut=OutlierNodesVector.size();
                    if (OutlierSummary.size()==0) {
                        for (int c=0; c<numbchildOut; c++) {
                            vector<int> NewOutliersBelong;
                            for (int c2=0; c2<numbchild; c2++) {
                                NewOutliersBelong.push_back(c2);
                            }
                            OutlierSummary.push_back(NewOutliersBelong);
                        }
                    }
                    int * NumberLeavesPerChildOut = new int[numbchildOut];
                    int * IndexChangeChildOut=new int [numbchildOut+1];
                    int numbLeavesGen=0;
                    for (int c=0; c<numbchild; c++) {
                        numbLeavesGen+=NumberLeavesPerChild[c];
                    }
                    for(int i=0;i<numbchildOut+1;i++){
                        IndexChangeChildOut[i]=numbLeavesGen;
                    }
                    
                    for(int c=0;c<numbchildOut;c++){ //or c < numbClasses
                        
                        NumberLeavesPerChildOut[c]=OutlierNodesVector[c]->GetNumberAllLeaves();
                        // If no Leaves detected means that the general class is no mixture but a leaf in itself
                        NumberLeavesPerChildOut[c]=NumberLeavesPerChildOut[c]==0?1:NumberLeavesPerChildOut[c];
                        
                        IndexChangeChildOut[c+1]=NumberLeavesPerChildOut[c]+IndexChangeChildOut[c];
                        
                    }
                    if(optMRFOut){
                        // First filling blocks of second level
                        if (numbchild==numbchildOut) {
                            for(int l1=0;l1<numbLeaves;l1++){
                                for(int l2=0;l2<numbLeaves;l2++){
                                    // Determining at which general class each leaf corresponds
                                    int Child1=0;
                                    int Child2=0;
                                    int test1=0;
                                    int test2=0;
                                    bool outFlag1=0;
                                    bool outFlag2=0;
                                    for(int c=0;c<numbchild;c++){
                                        if (l1<numbLeavesGen) {
                                            test1=IndexChangeChild[c];
                                            test2=IndexChangeChild[c+1];
                                        }
                                        else{
                                            outFlag1=1;
                                            test1=IndexChangeChildOut[c];
                                            test2=IndexChangeChildOut[c+1];
                                        }
                                        
                                        if (l1>=test1 && l1 <test2){
                                            Child1=c;
                                            break;
                                        }
                                    }
                                    if(l1>=test2 && Child1==0){ // case where no child found and l1 correspond to out of the normal children => outlier
                                        cout<<"Outlier not declared"<<endl;
                                        Child1=numbClasses;
                                    }
                                    test1=0;
                                    test2=0;
                                    for(int c=0;c<numbchild;c++){
                                        if (l2<numbLeavesGen) {
                                            test1=IndexChangeChild[c];
                                            test2=IndexChangeChild[c+1];
                                        }
                                        else{
                                            outFlag2=1;
                                            test1=IndexChangeChildOut[c];
                                            test2=IndexChangeChildOut[c+1];
                                        }
                                        if (l2>=test1 && l2 <test2){
                                            Child2=c;
                                            break;
                                        }
                                    }
                                    if(l2>=test2 && Child2==0){ // same as with l1 => outlier
                                        Child2=numbClasses;
                                    }
                                    // 0 on the diagonal
                                    if(l2==l1 && outFlag1==outFlag2){
                                        GMatrixResult[l1+l2*numbLeaves]=0;
                                    }
                                    // if leaves considered belong to same general class
                                    else if(Child1==Child2){
                                        if( l1<numbLeavesGen && l2<numbLeavesGen){
                                            GMatrixResult[l1+l2*numbLeaves]=GValues[2];
                                        }
                                        else{
                                            if (numbchild==numbchildOut) {
                                                GMatrixResult[l1+l2*numbLeaves]=0;
                                            }
                                            
                                        }
                                    }
                                    
                                    else if(Child1>=numbClasses || Child2>=numbClasses){ // case where one of the leaves is considered as outlier : can be neighbour to everything so GValue[1] chosen
                                        GMatrixResult[l1+l2*numbLeaves]=GValues[2];
                                    }
                                    else if(numbPriors>0){
                                        // if leaves considered belong to neighbouring general class
                                        int NumberOfNeighboursChild1=NeighborhoodSummary[Child1].size();
                                        bool NeighC1C2=0;
                                        for(int c=0;c<NumberOfNeighboursChild1;c++){
                                            if (numbchildOut==numbchild) {
                                                if(NeighborhoodSummary[Child1][c]==Child2){
                                                    NeighC1C2=1;
                                                    break;
                                                }
                                            }
                                        }
                                        if(NeighC1C2){
                                            if(l1<numbLeavesGen && l2<numbLeavesGen){
                                                GMatrixResult[l1+l2*numbLeaves]=GValues[1];
                                            }
                                            else{
                                                GMatrixResult[l1+l2*numbLeaves]=GValues[2];
                                            }
                                        }
                                    }
                                }
                            }
                            
                        }
                    }
                    else{ //  case where the same rules apply for the outliers MRF
                        // First filling blocks of second level
                        for(int l1=0;l1<numbLeaves;l1++){
                            for(int l2=0;l2<numbLeaves;l2++){
                                // Determining at which general class each leaf corresponds
                                int Child1=0;
                                int Child2=0;
                                int test1=0;
                                int test2=0;
                                bool outFlag1=0;
                                bool outFlag2=0;
                                for(int c=0;c<numbchild;c++){
                                    if (l1<numbLeavesGen) {
                                        test1=IndexChangeChild[c];
                                        test2=IndexChangeChild[c+1];
                                    }
                                    else{
                                        if (c<numbchildOut) {
                                            test1=IndexChangeChildOut[c];
                                            test2=IndexChangeChildOut[c+1];
                                        }
                                    }
                                    
                                    if (l1>=test1 && l1 <test2){
                                        Child1=c;
                                        break;
                                    }
                                }
                                if(l1>=test2 && Child1==0){ // case where no child found and l1 correspond to out of the normal children => outlier
                                    cout<<"Outlier not declared"<<endl;
                                    Child1=numbClasses;
                                }
                                test1=0;
                                test2=0;
                                for(int c=0;c<numbchild;c++){
                                    if (l2<numbLeavesGen) {
                                        test1=IndexChangeChild[c];
                                        test2=IndexChangeChild[c+1];
                                    }
                                    else{
                                        if (c<numbchildOut) {
                                            test1=IndexChangeChildOut[c];
                                            test2=IndexChangeChildOut[c+1];
                                        }
                                    }
                                    if (l2>=test1 && l2 <test2){
                                        Child2=c;
                                        break;
                                    }
                                }
                                if(l2>=test2 && Child2==0){ // same as with l1 => outlier
                                    Child2=numbClasses;
                                }
                                // 0 on the diagonal
                                if(l2==l1){
                                    GMatrixResult[l1+l2*numbLeaves]=0;
                                }
                                // if leaves considered belong to same general class
                                else if(Child1==Child2 && (outFlag2==outFlag1 || numbchild==numbchildOut)){
                                    GMatrixResult[l1+l2*numbLeaves]=GValues[2];
                                }
                                
                                else if(Child1>=numbClasses || Child2>=numbClasses){ // case where one of the leaves is considered as outlier : can be neighbour to everything so GValue[1] chosen
                                    GMatrixResult[l1+l2*numbLeaves]=GValues[1];
                                }
                                else if(this->GetPriorsVector().size()>0){
                                    bool NeighC1C2=0;
                                    if (((outFlag1==outFlag2)&& outFlag1==0) || numbchildOut==numbchild) {
                                        // if leaves considered belong to neighbouring general class
                                        int NumberOfNeighboursChild1=NeighborhoodSummary[Child1].size();
                                        for(int c=0;c<NumberOfNeighboursChild1;c++){
                                            if(NeighborhoodSummary[Child1][c]==Child2){
                                                NeighC1C2=1;
                                                break;
                                            }
                                        }
                                    }
                                    else{
                                        if (outFlag1) {
                                            int NumberOutliersChild1=OutlierSummary[Child1].size();
                                            for (int c=0; c<NumberOutliersChild1; c++) {
                                                if (OutlierSummary[Child1][c]==Child2) {
                                                    NeighC1C2=1;
                                                    break;
                                                }
                                            }
                                        }
                                        if (outFlag2) {
                                            int NumberOutliersChild2=OutlierSummary[Child2].size();
                                            for (int c=0; c<NumberOutliersChild2; c++) {
                                                if (OutlierSummary[Child2][c]==Child1) {
                                                    NeighC1C2=1;
                                                    break;
                                                }
                                            }
                                        }
                                    }
                                    if(NeighC1C2){
                                        GMatrixResult[l1+l2*numbLeaves]=GValues[1];
                                    }
                                }
                            }
                        }
                    }
                    delete [] IndexChangeChildOut;
                    IndexChangeChildOut=NULL;
                    delete [] NumberLeavesPerChildOut;
                    NumberLeavesPerChildOut=NULL;
                }
                
                
                
                //cleaning memory for GValues
                //            if (GValues!=NULL){
                //                delete [] GValues;
                //                GValues=NULL;
                //            }
//                for(int c=0;c<numbClasses;c++){
//                    NeighborhoodSummary[c].clear();
//                }
                if(NumberLeavesPerChild !=NULL){
                    delete [] NumberLeavesPerChild;
                    NumberLeavesPerChild=NULL;
                }
                if(IndexChangeChild !=NULL){
                    delete [] IndexChangeChild;
                    IndexChangeChild=NULL;
                }            }
    
                return GMatrixResult;
            }

       






float * TreeEM::PrepareGMatrixFromFile(string GMatrixFilename,bool optMRFOut){
    // No preparation of GMatrix if not at root
    if(!this->IsRoot()){
        cout<<"No preparation of GMatrix if not at root"<<endl;
        return NULL;
    }
    
    // First reading and taking all needed information from file
    ifstream text (GMatrixFilename.c_str());
    //    text.open(TreeTextFile,ios::in);
    if(!text){
        std::cout<<"could not open the text file properly ! for GMatrix "<<GMatrixFilename<<endl;
        return NULL;
    }
    else{ // Checked before that we are at the root so no worry on this side
        cout<<"Able to open "<<GMatrixFilename<<endl;
        int numbLeaves = this->GetNumberAllLeaves();
        std::string line;
        //        int numbchild = this->GetNumberChildren();
        vector<TreeEM*> NodesVector=this->GetGeneralClassesVector();
        //        cout<<"numbchild is "<<NodesVector.size()<<endl;
        int numbchild=NodesVector.size();
        int FlagOutliers=this->GetFlagOutliers();
        vector<nifti_image *> PriorsVectorForSize=this->GetPriorsVector();
        int numbPriors=PriorsVectorForSize.size();
        if (FlagOutliers==3 || FlagOutliers>=5 ) {
            int numbtemp=NodesVector.size()+this->GetNodeOutlier()->GetNumberChildren();
            //            if (numbtemp==2*numbchild) {
            //                numbchild=numbtemp;
            //            }
            if (FlagOutliers==6) {
                numbchild=numbtemp;
            }
        }
        //        cout<< numbchild<<" general anatomical classes"<<endl;
        if(this->GetPriorsNodeVector().size()==0){
            numbchild=0;
        }
        //        if(this->FlagOutliers>0){ // Case we are considering an outlier model and already checked beforehand that there are some pb
        //            numbchild=this->GetPriorsNodeVector().size();
        //            if(numbchild==0){ // means that no priors is put on the "normal classes"
        //                numbchild=this->GetChild(0)->GetNumberChildren(); // In this case the number of anatomical classes must be at second level
        //            }
        //        }
        //        else{
        //            numbchild=this->GetNumberChildren();
        //        }
        
//        vector< vector<int> > NeighborhoodSummary;
        
//        vector<vector<int> > OutlierSummary;
//        float GValues[3];
//        float * GValues = new float[3];
        GValues[0]=1;
        GValues[1]=0;
        GValues[2]=0;
        numbClasses=0;
        while(getline(text,line)){
            istringstream in(line);
            std:: string type;
            in >> type;
            if (type == "GClasses"){
                //                int numbClasses=0;
                in >> numbClasses;
                if(numbClasses!=numbchild && this->GetFlagOutliers()==0){
                    cout<< "Incompatibility of general classes number with Gfile"<<endl;
                    return NULL;
                }
            }
            if(type == "Neighborhood"){
                int CurrentClass=0;
                int NeighborhoodClass=0;
                vector<int> NeighboursCount;
                in >> CurrentClass;
                if(CurrentClass >= numbchild){
                    cout<< "Impossible class neighborhood offered"<<endl;
                    return NULL;
                }
                while(in >> NeighborhoodClass){
                    //                    in >> NeighborhoodClass;
                    if(NeighborhoodClass >= numbchild){
                        cout<< "Impossible class neighborhood offered"<<endl;
                        return NULL;
                    }
                    NeighboursCount.push_back(NeighborhoodClass);
                }
                NeighborhoodSummary.push_back(NeighboursCount);
            }
            if (FlagOutliers==5) {
                int numbchildOut=this->GetNodeOutlier()->GetChildren().size();
                if(type=="Out"){
                    int CurrentClassOut=0;
                    int OutBelongingClass=0;
                    vector<int> OutBelongClass;
                    in >> CurrentClassOut;
                    if(CurrentClassOut >= numbchildOut){
                        cout<< "Impossible class outliers offered"<<endl;
                        return NULL;
                    }
                    while(in >> OutBelongingClass){
                        //                    in >> NeighborhoodClass;
                        if(OutBelongingClass >= numbchild){
                            cout<< "Impossible class belonging for outliers offered"<<endl;
                            return NULL;
                        }
                        OutBelongClass.push_back(OutBelongingClass);
                    }
                    OutlierSummary.push_back(OutBelongClass);
                    
                }
            }
            
            if(type == "GValue"){
                int Level=0;
                float Value=0;
                in >> Level;
                in >> Value;
                // Checking if Value between 0 and 1 and thresholding if necessary
                //                Value=Value>1?1:Value;
                Value=Value<0?0:Value;
                if(Level<=2){
                    GValues[Level]=Value;
                }
            }
        }
        //
        //        cout<<"GValues are ";
        for(int i=0;i<=2;i++){
            //            cout<<GValues[i]<<" "; // At some point need to check that values ordered in GMatrix
        }
        //        cout<<endl;
        // Checking if obtained informations coherent with preexistent data
//        cout<<"OM "<<FlagOutliers<<" NC "<<numbchild<<" NS "<<NeighborhoodSummary.size()<<endl;
        int sizeNeighSumm=NeighborhoodSummary.size();
        if(sizeNeighSumm!=numbClasses && this->GetFlagOutliers()!=6){
            cout<< "Incompatibility between number of classes and neighborhood information"<<endl;
//            cout<<"OM "<<FlagOutliers<<" NC "<<numbClasses<<" NS "<<NeighborhoodSummary.size()<<endl;
            return NULL;
        }
        else if(FlagOutliers==6 && sizeNeighSumm!=numbchild){
            cout<< "Incompatibility between number of classes and neighborhood information"<<endl;
            cout<<"OM "<<FlagOutliers<<" NC "<<numbchild<<" NS "<<sizeNeighSumm<<endl;
            return NULL;
        }
        
        // Construction of GMatrix
        int numbLeavesSq=numbLeaves*numbLeaves;
        float * GMatrixResult = new float[numbLeavesSq];
        for (int i=0;i<numbLeavesSq;i++){
            GMatrixResult[i]=GValues[0];
        }
        if(numbchild==0){ // case where numbchild != numbClasses in particular when there are no priors and we cannot say anything about neighborhood properties
            for(int l1=0;l1<numbLeaves;l1++){
                for(int l2=0;l2<numbLeaves;l2++){
                    if(l1!=l2){
                        GMatrixResult[l1*numbLeaves+l2]=GValues[2];
                    }
                }
            }
//            if (GValues!=NULL){
//                delete [] GValues;
//                GValues=NULL;
//            }
            for(int c=0;c<numbchild;c++){
                NeighborhoodSummary[c].clear();
            }
            return GMatrixResult;
        }
        else{
            int * NumberLeavesPerChild = new int[numbchild];
            int * IndexChangeChild=new int [numbchild+1];
            for(int i=0;i<numbchild+1;i++){
                IndexChangeChild[i]=0;
            }
            //        vector<TreeEM*> NodesVector; // give the vector of nodes vector not counting the outlier node if exists
            //        if(this->FlagOutliers==1){
            //            NodesVector=this->GetPriorsNodeVector();
            //            if (NodesVector.size()==0){ // case no priors are used
            //                NodesVector=this->GetChild(0)->GetChildren();
            //            }
            //        }
            //        else if(this->FlagOutliers==0){
            //               NodesVector=this->GetChildren();
            //            }
            // Once the node vector defined, obtention of the index changes from child to child.
            if(FlagOutliers!=6){
            for(int c=0;c<numbchild;c++){ //or c < numbClasses
                
                NumberLeavesPerChild[c]=NodesVector[c]->GetNumberAllLeaves();
                // If no Leaves detected means that the general class is no mixture but a leaf in itself
                NumberLeavesPerChild[c]=NumberLeavesPerChild[c]==0?1:NumberLeavesPerChild[c];
                
                IndexChangeChild[c+1]=NumberLeavesPerChild[c]+IndexChangeChild[c];
                
            }
        }
        else{
            int numbchildIn=NodesVector.size();
//            int numbchildOutliers=numbchild-numbchildIn;
            vector<TreeEM *> OutliersNodeVector=this->GetNodeOutlier()->GetChildren();
            for (int c=0; c<numbchild; c++) {
                if(c<numbchildIn){
                NumberLeavesPerChild[c]=NodesVector[c]->GetNumberAllLeaves();
                }
                else{
                    NumberLeavesPerChild[c]=OutliersNodeVector[c-numbchildIn]->GetNumberAllLeaves();
                }
                NumberLeavesPerChild[c]=NumberLeavesPerChild[c]==0?1:NumberLeavesPerChild[c];
                
                IndexChangeChild[c+1]=NumberLeavesPerChild[c]+IndexChangeChild[c];
            }
        }
            if (FlagOutliers!=3 && FlagOutliers!=5 && FlagOutliers!=7 ) {
                // First filling blocks of second level
                
                for(int l1=0;l1<numbLeaves;l1++){
                    for(int l2=0;l2<numbLeaves;l2++){
                        // Determining at which general class each leaf corresponds
                        int Child1=0;
                        int Child2=0;
                        int test1=0;
                        int test2=0;
                        for(int c=0;c<numbchild;c++){
                            test1=IndexChangeChild[c];
                            test2=IndexChangeChild[c+1];
                            if (l1>=test1 && l1 <test2){
                                Child1=c;
                                break;
                            }
                        }
                        if(l1>=test2 && Child1==0){ // case where no child found and l1 correspond to out of the normal children => outlier
                            Child1=numbClasses;
                        }
                        test1=0;
                        test2=0;
                        for(int c=0;c<numbchild;c++){
                            test1=IndexChangeChild[c];
                            test2=IndexChangeChild[c+1];
                            if (l2>=test1 && l2 <test2){
                                Child2=c;
                                break;
                            }
                        }
                        if(l2>=test2 && Child2==0){ // same as with l1 => outlier
                            Child2=numbClasses;
                        }
                        // 1 on the diagonal
                        if(l2==l1){
                            GMatrixResult[l1+l2*numbLeaves]=0;
                        }
                        // if leaves considered belong to same general class
                        else if(Child1==Child2){
                            GMatrixResult[l1+l2*numbLeaves]=GValues[2];
                        }
                        else if(Child1>=numbClasses || Child2>=numbClasses){ // case where one of the leaves is considered as outlier : can be neighbour to everything so GValue[1] chosen
                            GMatrixResult[l1+l2*numbLeaves]=GValues[1];
                        }
                        else if(numbPriors>0){
                            // if leaves considered belong to neighbouring general class
                            int NumberOfNeighboursChild1=NeighborhoodSummary[Child1].size();
                            bool NeighC1C2=0;
                            for(int c=0;c<NumberOfNeighboursChild1;c++){
                                if(NeighborhoodSummary[Child1][c]==Child2){
                                    NeighC1C2=1;
                                    break;
                                }
                            }
                            if(NeighC1C2){
                                GMatrixResult[l1+l2*numbLeaves]=GValues[1];
                            }
                        }
                        
                    }
                }
            }
            else {
                
                
                vector<TreeEM *> OutlierNodesVector;
                if(FlagOutliers!=7){
                OutlierNodesVector=this->GetNodeOutlier()->GetChildren();
                }
                else {
                    OutlierNodesVector=this->GetOutliersMainNodesVector();
                }
                
                
                int numbchildOut=OutlierNodesVector.size();
                if (OutlierSummary.size()==0) {
                    for (int c=0; c<numbchildOut; c++) {
                        vector<int> NewOutliersBelong;
                        for (int c2=0; c2<numbchild; c2++) {
                            NewOutliersBelong.push_back(c2);
                        }
                        OutlierSummary.push_back(NewOutliersBelong);
                    }
                }
                int * NumberLeavesPerChildOut = new int[numbchildOut];
                int * IndexChangeChildOut=new int [numbchildOut+1];
                int numbLeavesGen=0;
                for (int c=0; c<numbchild; c++) {
                    numbLeavesGen+=NumberLeavesPerChild[c];
                }
                for(int i=0;i<numbchildOut+1;i++){
                    IndexChangeChildOut[i]=numbLeavesGen;
                }
                
                for(int c=0;c<numbchildOut;c++){ //or c < numbClasses
                    
                    NumberLeavesPerChildOut[c]=OutlierNodesVector[c]->GetNumberAllLeaves();
                    // If no Leaves detected means that the general class is no mixture but a leaf in itself
                    NumberLeavesPerChildOut[c]=NumberLeavesPerChildOut[c]==0?1:NumberLeavesPerChildOut[c];
                    
                    IndexChangeChildOut[c+1]=NumberLeavesPerChildOut[c]+IndexChangeChildOut[c];
                    
                }
                if(optMRFOut){
                    // First filling blocks of second level
                    if (numbchild==numbchildOut) {
                        for(int l1=0;l1<numbLeaves;l1++){
                            for(int l2=0;l2<numbLeaves;l2++){
                                // Determining at which general class each leaf corresponds
                                int Child1=0;
                                int Child2=0;
                                int test1=0;
                                int test2=0;
                                bool outFlag1=0;
                                bool outFlag2=0;
                                for(int c=0;c<numbchild;c++){
                                    if (l1<numbLeavesGen) {
                                        test1=IndexChangeChild[c];
                                        test2=IndexChangeChild[c+1];
                                    }
                                    else{
                                        outFlag1=1;
                                        test1=IndexChangeChildOut[c];
                                        test2=IndexChangeChildOut[c+1];
                                    }
                                    
                                    if (l1>=test1 && l1 <test2){
                                        Child1=c;
                                        break;
                                    }
                                }
                                if(l1>=test2 && Child1==0){ // case where no child found and l1 correspond to out of the normal children => outlier
                                    cout<<"Outlier not declared"<<endl;
                                    Child1=numbClasses;
                                }
                                test1=0;
                                test2=0;
                                for(int c=0;c<numbchild;c++){
                                    if (l2<numbLeavesGen) {
                                        test1=IndexChangeChild[c];
                                        test2=IndexChangeChild[c+1];
                                    }
                                    else{
                                        outFlag2=1;
                                        test1=IndexChangeChildOut[c];
                                        test2=IndexChangeChildOut[c+1];
                                    }
                                    if (l2>=test1 && l2 <test2){
                                        Child2=c;
                                        break;
                                    }
                                }
                                if(l2>=test2 && Child2==0){ // same as with l1 => outlier
                                    Child2=numbClasses;
                                }
                                // 0 on the diagonal
                                if(l2==l1 && outFlag1==outFlag2){
                                    GMatrixResult[l1+l2*numbLeaves]=0;
                                }
                                // if leaves considered belong to same general class
                                else if(Child1==Child2){
                                    if( l1<numbLeavesGen && l2<numbLeavesGen){
                                        GMatrixResult[l1+l2*numbLeaves]=GValues[2];
                                    }
                                    else{
                                        if (numbchild==numbchildOut) {
                                            GMatrixResult[l1+l2*numbLeaves]=0;
                                        }
                                        
                                    }
                                }
                                
                                else if(Child1>=numbClasses || Child2>=numbClasses){ // case where one of the leaves is considered as outlier : can be neighbour to everything so GValue[1] chosen
                                    GMatrixResult[l1+l2*numbLeaves]=GValues[2];
                                }
                                else if(numbPriors>0){
                                    // if leaves considered belong to neighbouring general class
                                    int NumberOfNeighboursChild1=NeighborhoodSummary[Child1].size();
                                    bool NeighC1C2=0;
                                    for(int c=0;c<NumberOfNeighboursChild1;c++){
                                        if (numbchildOut==numbchild) {
                                            if(NeighborhoodSummary[Child1][c]==Child2){
                                                NeighC1C2=1;
                                                break;
                                            }
                                        }
                                    }
                                    if(NeighC1C2){
                                        if(l1<numbLeavesGen && l2<numbLeavesGen){
                                            GMatrixResult[l1+l2*numbLeaves]=GValues[1];
                                        }
                                        else{
                                            GMatrixResult[l1+l2*numbLeaves]=GValues[2];
                                        }
                                    }
                                }
                            }
                        }
                        
                    }
                }
                else{ //  case where the same rules apply for the outliers MRF
                    // First filling blocks of second level
                    for(int l1=0;l1<numbLeaves;l1++){
                        for(int l2=0;l2<numbLeaves;l2++){
                            // Determining at which general class each leaf corresponds
                            int Child1=0;
                            int Child2=0;
                            int test1=0;
                            int test2=0;
                            bool outFlag1=0;
                            bool outFlag2=0;
                            for(int c=0;c<numbchild;c++){
                                if (l1<numbLeavesGen) {
                                    test1=IndexChangeChild[c];
                                    test2=IndexChangeChild[c+1];
                                }
                                else{
                                    if (c<numbchildOut) {
                                        test1=IndexChangeChildOut[c];
                                        test2=IndexChangeChildOut[c+1];
                                    }
                                }
                                
                                if (l1>=test1 && l1 <test2){
                                    Child1=c;
                                    break;
                                }
                            }
                            if(l1>=test2 && Child1==0){ // case where no child found and l1 correspond to out of the normal children => outlier
                                cout<<"Outlier not declared"<<endl;
                                Child1=numbClasses;
                            }
                            test1=0;
                            test2=0;
                            for(int c=0;c<numbchild;c++){
                                if (l2<numbLeavesGen) {
                                    test1=IndexChangeChild[c];
                                    test2=IndexChangeChild[c+1];
                                }
                                else{
                                    if (c<numbchildOut) {
                                        test1=IndexChangeChildOut[c];
                                        test2=IndexChangeChildOut[c+1];
                                    }
                                }
                                if (l2>=test1 && l2 <test2){
                                    Child2=c;
                                    break;
                                }
                            }
                            if(l2>=test2 && Child2==0){ // same as with l1 => outlier
                                Child2=numbClasses;
                            }
                            // 0 on the diagonal
                            if(l2==l1){
                                GMatrixResult[l1+l2*numbLeaves]=0;
                            }
                            // if leaves considered belong to same general class
                            else if(Child1==Child2 && (outFlag2==outFlag1 || numbchild==numbchildOut)){
                                GMatrixResult[l1+l2*numbLeaves]=GValues[2];
                            }
                            
                            else if(Child1>=numbClasses || Child2>=numbClasses){ // case where one of the leaves is considered as outlier : can be neighbour to everything so GValue[1] chosen
                                GMatrixResult[l1+l2*numbLeaves]=GValues[1];
                            }
                            else if(this->GetPriorsVector().size()>0){
                                bool NeighC1C2=0;
                                if (((outFlag1==outFlag2) && (outFlag1==0)) || numbchildOut==numbchild) {
                                    // if leaves considered belong to neighbouring general class
                                    int NumberOfNeighboursChild1=NeighborhoodSummary[Child1].size();
                                    for(int c=0;c<NumberOfNeighboursChild1;c++){
                                        if(NeighborhoodSummary[Child1][c]==Child2){
                                            NeighC1C2=1;
                                            break;
                                        }
                                    }
                                }
                                else{
                                    if (outFlag1) {
                                        int NumberOutliersChild1=OutlierSummary[Child1].size();
                                        for (int c=0; c<NumberOutliersChild1; c++) {
                                            if (OutlierSummary[Child1][c]==Child2) {
                                                NeighC1C2=1;
                                                break;
                                            }
                                        }
                                    }
                                    if (outFlag2) {
                                        int NumberOutliersChild2=OutlierSummary[Child2].size();
                                        for (int c=0; c<NumberOutliersChild2; c++) {
                                            if (OutlierSummary[Child2][c]==Child1) {
                                                NeighC1C2=1;
                                                break;
                                            }
                                        }
                                    }
                                }
                                if(NeighC1C2){
                                    GMatrixResult[l1+l2*numbLeaves]=GValues[1];
                                }
                            }
                        }
                    }
                }
                delete [] IndexChangeChildOut;
                IndexChangeChildOut=NULL;
                delete [] NumberLeavesPerChildOut;
                NumberLeavesPerChildOut=NULL;
            }
            
            
            
            //cleaning memory for GValues
//            if (GValues!=NULL){
//                delete [] GValues;
//                GValues=NULL;
//            }
            for(int c=0;c<numbClasses;c++){
                NeighborhoodSummary[c].clear();
            }
            if(NumberLeavesPerChild !=NULL){
                delete [] NumberLeavesPerChild;
                NumberLeavesPerChild=NULL;
            }
            if(IndexChangeChild !=NULL){
                delete [] IndexChangeChild;
                IndexChangeChild=NULL;
            }
            //        NeighborhoodSummary.clear();
            //            cout<<endl;
            //            for (int i1=0; i1<numbLeaves; i1++) {
            //                for (int i2=0; i2<numbLeaves; i2++) {
            //                    cout<<GMatrixResult[i1+i2*numbLeaves]<<" ";
            //                }
            //                cout<<endl;
            //            }
            ValidGInfo=1;
            return GMatrixResult;
        }
    }
}

void TreeEM::SetGMatrix(float * GMatrixToSet){
    // Gmatrix only set not NULL at Root
    if(!this->IsRoot()){
        cout<<"GMatrix can only be set at root"<<endl;
        if(this->GetGMatrixDirect()!=NULL){
            delete [] this->GetGMatrixDirect();
            this->GMatrix=NULL;
        }
        return;
    }
    // delete current GMatrix if there is one existing
    if(this->GetGMatrixDirect()!=NULL){
        delete [] this->GetGMatrixDirect();
//        delete [] this->GMatrix;
        this->GMatrix=NULL;
        this->FindRoot()->GMatrix=NULL;
    }
    // allocate memory for new GMatrix
    int numbLeaves=this->GetNumberAllLeaves();
    int numbLeavesSq=numbLeaves*numbLeaves;
    this->GMatrix=new float [numbLeavesSq];
    for(int l=0;l<numbLeavesSq;l++){
        this->GMatrix[l]=GMatrixToSet[l];
    }
    return;
}

float * TreeEM::GetGMatrix(){
    if(!this->IsRoot()){
        return this->GetParent()->GetGMatrix();
    }
    else{
        return this->GMatrix;
    }
}

float * TreeEM::GetGMatrixDirect(){
    return this->GMatrix;
}

float * TreeEM::CopyGMatrix(){
    float * GMatrixToCopy=this->GetGMatrixDirect();
    if(GMatrixToCopy==NULL){
        return NULL;
    }

        int numbLeaves=this->FindRoot()->GetNumberAllLeaves();
        int numbLeavesSq=numbLeaves*numbLeaves;
        float * CopiedGMatrix=new float[numbLeavesSq];
        for(int i=0;i<numbLeavesSq;i++){
            CopiedGMatrix[i]=GMatrixToCopy[i];
        }

    return CopiedGMatrix;
}

void TreeEM::ClearMRFModel(){
    if(this->GetMRF()!=NULL){
        if(!this->IsLeaf()){
            delete [] this->GetMRF();
            this->SetMRF(NULL);
        }
    }
    // recursive part
    int numbchild=this->GetNumberChildren();
    for(int c=0;c<numbchild;c++){
        this->GetChild(c)->ClearMRFModel();
    }
}

/*** METHODS FOR OPTIMIZATION OF G MATRIX IN MRF ****/

// Return as an array of integers the result of the hard segmentation on the leaves
int * TreeEM::MakeHardSegLeaves(){
    int numbLeaves=this->GetNumberAllLeaves();
    int numelmasked=this->GetNumberMaskedElements();
    vector<TreeEM*> LeavesVector=this->GetAllLeaves();
    vector<float *> NormRespVector;
    for(int l=0;l<numbLeaves;l++){
        NormRespVector.push_back(LeavesVector[l]->GetNormResp());
    }
    int * HardSegLeavesResult=new int[numelmasked];
    for(int i=0;i<numelmasked;i++){
        HardSegLeavesResult[i]=0;
        float maxNormResp=-1;
        int maxClass=0;
        for(int l=0;l<numbLeaves;l++){
            if(NormRespVector[l][i]>maxNormResp){
                maxNormResp=NormRespVector[l][i];
                maxClass=l;
            }
        }
        HardSegLeavesResult[i]=maxClass;
    }
    return HardSegLeavesResult;
}

// Returns the binary segmentation between inliers and outliers : value 0 if inlier, 1 if outlier
bool * TreeEM::GetSegOutliers(){
    int numelmasked=this->GetNumberMaskedElements();
    // Initialisation as if everything would be inlier
    bool * OutlierSeg=new bool[numelmasked];
    for (int i=0; i<numelmasked; i++) {
        OutlierSeg[i]=0;
    }
    if (this->GetFlagOutliers()==0) { // return directly when no outlier model in place
        return OutlierSeg;
    }
    else{
        float * NormRespOutliers=this->GetNodeOutlier()->GetNormResp();
        // Consider as outlier if value above 0.5
        for (int i=0; i<numelmasked; i++) {
            if (NormRespOutliers[i]>0.5) {
                OutlierSeg[i]=1;
            }
        }

    }
    return OutlierSeg;
}

// Returns the number of voxels considered as inliers
int TreeEM::GetNumberInliers(){
    int numelmasked=this->GetNumberMaskedElements();
    if (this->GetFlagOutliers()==0) {
        return numelmasked;
    }
    else{
        int numelInliers=0;
        bool * OutlierSeg=this->GetSegOutliers();
        for (int i=0; i<numelmasked; i++) {
            if (!OutlierSeg[i]) {
                numelInliers++;
            }
        }
        delete [] OutlierSeg;
        OutlierSeg=NULL;
        return numelInliers;
    }
}

// Return the HardSeg on the leaves shifted according to dimension or direction Size is these of image (numel)
int * TreeEM::HardSegLeavesShifted(int dim, int dir){
    // First make sure that the input values are ok or change them accordingly
    if(dir!=0){
    dir=dir>0?1:-1;
    }
    dim=dim>2?2:dim;
    dim=dim<0?0:dim;

    // Initialisation of the needed values
//    int Dimensions[3];
//    Dimensions[0]=this->GetDataImage()->nx;
//    Dimensions[1]=this->GetDataImage()->ny;
//    Dimensions[2]=this->GetDataImage()->nz;
    int Shift[3];
    Shift[0]=1;
    Shift[1]=this->GetDataImage()->nx;
    Shift[2]=this->GetDataImage()->nx*this->GetDataImage()->ny;
    int numbx=this->GetDataImage()->nx;
    int numby=this->GetDataImage()->ny;
    int numbz=this->GetDataImage()->nz;
    int indexShift=Shift[dim]*dir;
    int numel=this->GetNumberElements();
    int newIndex=0;
    int oldIndex=0;
    // Allocation of memory for shifted matrix
    int * HardSegLeavesShifted= new int[numel];//{0};
    int * L2S_PTR=this->GetL2S();
    int * HardSegLeavesPointedNC=this->MakeHardSegLeaves();
    int * HardSegLeavesPointed = new int[numel];
        L2S_PTR=this->GetL2S();
        int * HardSegLeavesPointedNC_PTR = HardSegLeavesPointedNC;
        for (int i=0; i<numel; i++,L2S_PTR++) {

                HardSegLeavesPointed[i]=0;
                if(*L2S_PTR>=0){
                    HardSegLeavesPointed[i]=*HardSegLeavesPointedNC_PTR;
                    HardSegLeavesPointedNC_PTR++;
                }
                HardSegLeavesShifted[i]=0;
        }

        for (int i=0; i<numbx; i++) {
            for (int j=0; j<numby; j++) {
                for (int k=0; k<numbz; k++) {
                    newIndex=i+j*Shift[1]+k*Shift[2]+indexShift;
                    oldIndex=i+j*Shift[1]+k*Shift[2];
                    if (newIndex>0 && newIndex<numel) {
                        HardSegLeavesShifted[newIndex]=HardSegLeavesPointed[oldIndex];
                    }
                }
            }
        }
// Clearing memory before returning result
//    delete [] Dimensions;
//    Dimensions=NULL;
//    delete [] Shift;
//    Shift = NULL;
    delete [] HardSegLeavesPointed;
    HardSegLeavesPointed = NULL;
    delete [] HardSegLeavesPointedNC;
    HardSegLeavesPointedNC=NULL;
    return HardSegLeavesShifted;
}

// Summation of the result of the HardSeg on the 6 next neighbours of size numelmasked * numbLeaves (gives the gi vector)
int * TreeEM::SumHardSegNeighboursLeaves(){
    int numbLeaves=this->GetNumberAllLeaves();
    int numelmasked=this->GetNumberMaskedElements();
    int sizeSumHardSeg=numbLeaves*numelmasked;
    int * SumHardSegLeavesNeighbours=new int[sizeSumHardSeg];
    for(int i=0;i<sizeSumHardSeg;i++){
        SumHardSegLeavesNeighbours[i]=0;
    }

    for(int dim =0;dim<3;dim++){
        for (int dir =-1;dir<=1;dir=dir+2){
            int * tmpHardSegLeaves=this->HardSegLeavesShifted(dim,dir);
            for(int i=0;i<numelmasked;i++){
                SumHardSegLeavesNeighbours[i+tmpHardSegLeaves[i]*numelmasked]++;
            }
            delete [] tmpHardSegLeaves;
            tmpHardSegLeaves = NULL;
        }

    }
    return SumHardSegLeavesNeighbours;
}

float * TreeEM::MakeHistogramHardSegLeaves(){
    int numbLeaves=this->GetNumberAllLeaves();
    int numelmasked=this->GetNumberMaskedElements();
    int * HardSegLeaves=this->MakeHardSegLeaves();
    int * SumHardSegLeavesNeighbours=this->SumHardSegNeighboursLeaves();
    int SizeHist=(int)pow_int(numbLeaves,7);
    float * HistogramFinal=new float [SizeHist];
//    int * Shift = new int[7];
    int Shift[7];
    for(int i=0;i<7;i++){
        Shift[i]=(int)pow_int(numbLeaves,i);
    }
    for(int i=0;i<numelmasked;i++){
        int Index=HardSegLeaves[i];
        for(int l=0;l<numbLeaves;l++){
            Index+=l*Shift[SumHardSegLeavesNeighbours[i]+1];
        }
        HistogramFinal[Index]++;
    }
    int sizeHistFin=(int)pow_int(numbLeaves, 7);
    for(int i=0;i<sizeHistFin;i++){
        HistogramFinal[i]/=(float)numelmasked;
    }
    return HistogramFinal;
}

// Using current Softseg, fill the histogram of the possible configurations for each voxel and its 6 neighbours. The only non zero elements are those such that index correspond to sum of 6
float * TreeEM::HistogramSoftSegMRF(SEG_PARAMETERS * segment_param){
    int numbLeaves=this->GetNumberAllLeaves();
//    bool test=this->IsNormRespValidLeaves();
    // Obtention of the possible combinations for the segmentation
//    int * TabSize = new int[7];
    int TabSize[7];
    for(int i=0;i<7;i++){
        TabSize[i]=numbLeaves;
    }
    int * Combination=CombinationBis(TabSize,7);
//    int * Shift = new int[7];
//    for(int i=0;i<7;i++){
//        Shift[i]=pow_int(numbLeaves,i);
//    }
    int * Shift = new int [numbLeaves+1];
    Shift[0]=1;
    Shift[1]=numbLeaves;
    for(int i=2;i<=numbLeaves;i++){
        Shift[i]=Shift[i-1]*7;
    }

    int numelmasked=this->GetNumberMaskedElements();
    // Storage of the shifted NormResp for all leaves
    vector<TreeEM*> LeavesVector=this->GetAllLeaves();
    vector<float *> NormRespLeaves;
    for(int l=0;l<numbLeaves;l++){
        for(int dim=0;dim<3;dim++){
            for(int dir =-1;dir<=1;dir=dir+2){
               NormRespLeaves.push_back(LeavesVector[l]->GetNormRespShifted(dim,dir,segment_param));
            }
        }
    }

//    SaveTmpResult(NormRespLeaves[0],"/Users/Carole/Documents/PhD/NormRespLeavesShifted.nii.gz");
//    SaveTmpResultMasked(LeavesVector[0]->GetNormResp(),"/Users/Carole/Documents/PhD/NormRespNonShifted.nii.gz");

    // Allocation and initialisation of the Histogram
    int SizeHist=(int)pow_int(7,numbLeaves)*numbLeaves;
    PrecisionTYPE * HistogramFinal = new PrecisionTYPE[SizeHist];
    for(int i=0;i<SizeHist;i++){
        HistogramFinal[i]=0;
    }
int numberCombi=(int)pow_int(numbLeaves,7);
    // Convert Combination into gi vector
    int sizeGiVecConv=numbLeaves*numberCombi;
    int * GiVectorConverted = new int[sizeGiVecConv];
    for(int i=0;i<sizeGiVecConv;i++){
        GiVectorConverted[i]=0;
    }
//    int CountImpossibleCombination=0;
//    int CountPbIndexRecovery=0;

    for(int i=0;i<numberCombi;i++){
        int Ind=7*i;
        // First element in each session of combination corresponds to z and not g therefore omitted when reconstructing g vector
        // Ultimately in gi as a vector count of neighbours allocated to a special leaf for all leaves (Norm1 of each gi must be 6)
        for(int j=1;j<7;j++){
            GiVectorConverted[i*numbLeaves+Combination[Ind+j]]++;
        }
//        // Check if sum of GiVectorConverted is equal to 6
        int CheckSum=0;
        for(int l=0;l<numbLeaves;l++){
            CheckSum+=GiVectorConverted[i*numbLeaves+l];
        }


        // Find corresponding index in the histogram
//        int Index=Combination[i*numbLeaves];
        int Index=Combination[Ind];
        for(int l=0;l<numbLeaves;l++){
            Index+=GiVectorConverted[i*numbLeaves+l]*Shift[l+1];
//            Index+=l*Shift[GiVectorConverted[i*numbLeaves+l]+1];
        }


//        // Check if Index corresponds to proper sum
//        int tmp=Index;
//        int tmp2=0;
//        int sumTry=0;
//        for(int l=numbLeaves;l>0;l--){
//            tmp2=tmp/Shift[l];
//            sumTry+=tmp2;
//            tmp=tmp-tmp2*Shift[l];
//        }
//        if(sumTry!=6){
//            cout<< "Pb with index recovery at index "<<Ind<<" with value "<<sumTry<<endl;
//            CountPbIndexRecovery++;
//        }

        // Determine corresponding value to add
        int * S2L_PTR=this->GetS2L();

        for(int e=0;e<numelmasked;e++){
            PrecisionTYPE Value=LeavesVector[Combination[Ind]]->GetNormResp()[e]; // Value of norm resp corresponding to ze
            for(int j=1;j<7;j++){
                Value*=(PrecisionTYPE)NormRespLeaves[Combination[Ind+j]*6+j-1][S2L_PTR[e]];
//                // Check sum of normresp equal to 1 for all shifted leaves at all masked voxels
//                float testSumNormRespLeaves=0;
//                for(int l=0;l<numbLeaves;l++){
//                    testSumNormRespLeaves+=NormRespLeaves[l*6+j-1][S2L_PTR[e]];
//                }
//                if(testSumNormRespLeaves>1+10E-6){
//                    cout<<"SumNormRespLeaves shifted more than 1 for j "<<j<<" at index "<<e<<" with value "<<testSumNormRespLeaves<<endl;
//                }
//                if(testSumNormRespLeaves<1-10E-6){
//                    cout<<"SumNormRespLeaves shifted less than 1 for j "<<j<<" at index "<<e<<" with value "<<testSumNormRespLeaves<<endl;
//                }
//                if(Value==0){
////                    cout<< "Impossible combination at index "<<e<<endl;
//                    CountImpossibleCombination++;
//                }
            }
            if(Value/numelmasked>1){
                cout<<"Pb with value more than 1"<<endl;
            }
            HistogramFinal[Index]+=(PrecisionTYPE)Value;
        }
    }
    //Normalising Histogram
    float * HistogramReturn=new float[SizeHist];
    for(int i=0;i<SizeHist;i++){
        HistogramReturn[i]=HistogramFinal[i]/(float)numelmasked;
    }
    delete [] GiVectorConverted;
    GiVectorConverted=NULL;
    delete [] HistogramFinal;
    HistogramFinal=NULL;
    //Checking sum over Histogram Final
    PrecisionTYPE SumCheck=0;
    for(int i=0;i<SizeHist;i++){
        SumCheck+=(PrecisionTYPE)HistogramReturn[i];
        if (HistogramReturn[i]!=0){
            cout << "Histogram non zero at "<<i<<" with value "<<HistogramReturn[i]<<endl;
        }
    }
    for(int i=0;i<SizeHist;i++){
        HistogramReturn[i]/=SumCheck;
    }
    // Clearing memory
    for(int i=0;i<6*numbLeaves;i++){
        delete[] NormRespLeaves[i];
        NormRespLeaves[i]=NULL;
    }
    NormRespLeaves.clear();
    delete[] Shift;
    Shift=NULL;
//    delete [] TabSize;
//    TabSize=NULL;
    delete[] Combination;
    Combination=NULL;
    return HistogramReturn;
}

// return as a float array the log ratio described in equation 7 of VanLeemput 98
// When 0 value, put at -1E32 as default value. Will be discarded farther in the process
float * TreeEM::MRFOptMakeLogRatio(SEG_PARAMETERS * segment_param){
    int numbLeaves=this->GetNumberAllLeaves();
//    int SizeHist=pow_int(numbLeaves,7);
    int SizeHist=numbLeaves*(int)pow_int(7,numbLeaves);
    float * HistogramFinal=this->HistogramSoftSegMRF(segment_param);


    // check on non zero values of HistogramFinal
    int CountNonZero=0;
    float SumHistogram=0;
    for(int i=0;i<SizeHist;i++){
        if(HistogramFinal[i]>0){
            cout<<"Histogram non zero at "<< i << " with value "<<HistogramFinal[i]<<endl;
            CountNonZero++;
            SumHistogram+=HistogramFinal[i];
        }
    }

    // Initialisation of the result
    int SizeLogRatio=(int)(SizeHist*(numbLeaves-1))/2;
    float * LogRatio=new float[SizeLogRatio];

    for(int i=0;i<SizeLogRatio;i++){
        LogRatio[i]=0;
    }

    int SizeGCombi=SizeHist/numbLeaves;
    int CountPbLogRatio=0;
    for(int j=0;j<SizeGCombi;j++){
        int i1=0;
        int i2=0;

        for(int i=0;i<numbLeaves*(numbLeaves-1)/2;i++){
            i2++;
            if(i2==numbLeaves){
                i1++;
                i2=i1+1;
            }
                if(HistogramFinal[i2+j*numbLeaves]>1E-6 && HistogramFinal[i1+j*numbLeaves]>1E-6){
                LogRatio[i+j*(numbLeaves*(numbLeaves-1))/2]=logf(HistogramFinal[i1+j*numbLeaves]/HistogramFinal[i2+j*numbLeaves]);
                }
                else{
                    CountPbLogRatio++;
                    LogRatio[i+j*(numbLeaves*(numbLeaves-1))/2]=-10E32;
                }
            }
        }
    //Clearing memory before returning result
    delete [] HistogramFinal;
    HistogramFinal=NULL;
    cout<<"LogRatio calculated"<<endl;
    return LogRatio;

}

// return the integer array containing all the differences of int vectors obtained as possible configurations of one voxel and its 6 neighbours
int * TreeEM::MRFOptAMatrix(){
    int numbLeaves=this->GetNumberAllLeaves();
//    int SizeHist=pow_int(numbLeaves,7);
    int SizeHist=numbLeaves*(int)pow_int(7,numbLeaves);
    int SizeAMatrix=(int)(SizeHist*(numbLeaves-1)*pow_int(numbLeaves,2))/2;
//    int SizeAMatrix=pow_int(numbLeaves,6)*(numbLeaves)*(numbLeaves-1)/2*pow_int(numbLeaves,2);
    int * AMatrixResult=new int[SizeAMatrix];
    for(int i=0;i<SizeAMatrix;i++){
        AMatrixResult[i]=0;
    }

//    int * ShiftGOnly=new int[6];
//    for(int i=0;i<6;i++){
//        ShiftGOnly[i]=pow_int(numbLeaves,i);
//    }

    int * ShiftGOnly=new int[numbLeaves];
    for(int i=0;i<numbLeaves;i++){
        ShiftGOnly[i]=(int)pow_int(7,i);
    }
    int SizeGCombi=SizeHist/numbLeaves;
    int * VMatrix=new int[SizeHist * numbLeaves*numbLeaves];
    for(int i=0;i<SizeHist*numbLeaves*numbLeaves;i++){
        VMatrix[i]=0;
    }
//    int CountPbAMatrix=0;
    for(int j=0;j<SizeGCombi;j++){
//        int i1=0;
//        int i2=0;
//        int Index[numbLeaves];
        int * Index=new int[numbLeaves];
        int tmp=j;
        for(int l=numbLeaves-1;l>=0;l--){
            Index[l]=tmp/ShiftGOnly[l];
            tmp=tmp-Index[l]*ShiftGOnly[l];
        }
        // Conversion of Index into gi Vector
//        int Gi[numbLeaves];
        int * Gi=new int[numbLeaves];
        for(int l=0;l<numbLeaves;l++){
            Gi[l]=0;
        }
int CheckGiSum=0;
        for(int l=0;l<numbLeaves;l++){
//            Gi[Index[l]]++;
            Gi[l]=Index[l];
            CheckGiSum+=Gi[l];
        }

        for(int l=0;l<numbLeaves;l++){
//            int Zi[numbLeaves];
            int * Zi=new int[numbLeaves];
            for(int kl=0;kl<numbLeaves;kl++){
                Zi[kl]=0;
            }
            Zi[l]=1;

            for(int l1=0;l1<numbLeaves;l1++){
                for(int l2=0;l2<numbLeaves;l2++){
                    VMatrix[j*numbLeaves*numbLeaves*numbLeaves+l*numbLeaves*numbLeaves+l1*numbLeaves+l2]=Zi[l1]*(VMatrix[j*numbLeaves*numbLeaves*numbLeaves+l*numbLeaves*numbLeaves+l1*numbLeaves+l2]+Gi[l2]);
                }
            }
            if(Zi!=NULL){
                delete [] Zi;
                Zi=NULL;
            }
        }
        if(Gi!=NULL){
            delete [] Gi;
            Gi=NULL;
        }




//        for(int i=0;i<numbLeaves*(numbLeaves-1)/2;i++){
//            i2++;
//            if(i2==numbLeaves){
//                i1++;
//                i2=i1+1;
//            }
//            for(int l=0;l<numbLeaves;l++){
//                AMatrixResult[j*(numbLeaves)*(numbLeaves-1)/2+i1*numbLeaves+l]=AMatrixResult[j*(numbLeaves)*(numbLeaves-1)/2+i1*numbLeaves+l]+Gi[l];
//                AMatrixResult[j*(numbLeaves)*(numbLeaves-1)/2+i2*numbLeaves+l]=AMatrixResult[j*(numbLeaves)*(numbLeaves-1)/2+i2*numbLeaves+l]-Gi[l];
//            }
//        }
    }

//    // printing V result
//    cout<< "Printing VResult"<<endl;
//    int SizeLogRatio=SizeHist*(numbLeaves-1)/2;
//    int LengthMatrixG=pow_int(numbLeaves,2);
//    for(int i=0;i<SizeHist;i++){
//        for(int j=0;j<LengthMatrixG;j++){
//            cout<<VMatrix[i*LengthMatrixG+j]<<"  ";
//        }
//        cout<<endl;
//    }

    for(int j=0;j<SizeGCombi;j++){
        int i1=0;
        int i2=0;
                for(int i=0;i<numbLeaves*(numbLeaves-1)/2;i++){
                    i2++;
                    if(i2==numbLeaves){
                        i1++;
                        i2=i1+1;
                    }
                    for(int l=0;l<numbLeaves*numbLeaves;l++){
                        AMatrixResult[j*numbLeaves*numbLeaves*(numbLeaves)*(numbLeaves-1)/2+i*numbLeaves*numbLeaves+l]=AMatrixResult[j*numbLeaves*numbLeaves*(numbLeaves)*(numbLeaves-1)/2+i*numbLeaves*numbLeaves+l]+VMatrix[j*numbLeaves*numbLeaves*numbLeaves+i1*numbLeaves*numbLeaves+l];
                        AMatrixResult[j*numbLeaves*numbLeaves*(numbLeaves)*(numbLeaves-1)/2+i*numbLeaves*numbLeaves+l]=AMatrixResult[j*numbLeaves*numbLeaves*(numbLeaves)*(numbLeaves-1)/2+i*numbLeaves*numbLeaves+l]-VMatrix[j*numbLeaves*numbLeaves*numbLeaves+i2*numbLeaves*numbLeaves+l];
                    }
                }
    }
//    // printing A result
//    cout<< "Printing AResult"<<endl;
//    for(int i=0;i<SizeLogRatio;i++){
//        for(int j=0;j<LengthMatrixG;j++){
//            cout<<AMatrixResult[i*LengthMatrixG+j]<<"  ";
//        }
//        cout<<endl;
//    }

    delete [] ShiftGOnly;
    ShiftGOnly=NULL;
    delete [] VMatrix;
    VMatrix=NULL;
    cout<<"AMatrixCalculated"<<endl;
    return AMatrixResult;
}

// Solving the LS problem and returning the obtained result that will form the G matrix for the 6 neighbours
float * TreeEM::MRFOptSolveLS(SEG_PARAMETERS * segment_param){
    float * LogRatio=this->MRFOptMakeLogRatio(segment_param);
    int * AMatrix=this->MRFOptAMatrix();
    int numbLeaves=this->GetNumberAllLeaves();
//    int SizeLogRatio=pow_int(numbLeaves,6)*(numbLeaves)*(numbLeaves-1)/2;
    int SizeLogRatio=(int)pow_int(7,numbLeaves)*(numbLeaves)*(numbLeaves-1)/2;
    int SizeAMatrix=(int)(SizeLogRatio*pow_int(numbLeaves,2));
    // find indices not to use in the solution
    int * AuthorisedIndices=new int[SizeLogRatio];
    int SizeNonValid=0;
//    float minLogRatio=10E32;
    for(int i=0;i<SizeLogRatio;i++){
        AuthorisedIndices[i]=0;
//        if(LogRatio[i]<minLogRatio){
//            minLogRatio=LogRatio[i];
//        }
        if(LogRatio[i]<=-9E32){
            AuthorisedIndices[i]=-1;
            SizeNonValid++;
        }
    }

    // Obtain the reduced Matrices to use instead
    float * LogRatioReduced=new float[SizeLogRatio-SizeNonValid];
    int SizeLogRatioReduced=SizeLogRatio-SizeNonValid;
    int SizeAMatrixReduced=(int)(SizeAMatrix-SizeNonValid*pow_int(numbLeaves,2));
    float * AMatrixReduced=new float[SizeAMatrixReduced];
    int LengthMatrixG=(int)pow_int(numbLeaves,2);
    int j=0;
//    int CountNanAMatrix=0;
    int CountNanLogRatio=0;
    for(int i=0;i<SizeLogRatio;i++){
        if(AuthorisedIndices[i]>=0){
            cout<< i<<"  ";
            LogRatioReduced[j]=LogRatio[i];
            if(LogRatioReduced[j]!=LogRatioReduced[j]){
                CountNanLogRatio++;
            }
            for(int l=0;l<LengthMatrixG;l++){
                AMatrixReduced[j*LengthMatrixG+l]=AMatrix[i*LengthMatrixG+l];
            }
            j++;
        }
    }
    cout<<endl;
    delete [] AuthorisedIndices;
    AuthorisedIndices=NULL;
    delete [] LogRatio;
    LogRatio=NULL;
    delete [] AMatrix;
    AMatrix=NULL;
    // Using SVD to solve LS linear problem


//    SVD SVDforMRF=SVD(AMatrixReduced,SizeLogRatio-SizeNonValid,LengthMatrixG);
//    float * VforMRF=SVDforMRF.getV();
//    float * UforMRF=SVDforMRF.getU();
//    float * SforMRF=SVDforMRF.getS();


//    int SizeSUT[4];
////    SizeSUT[0]=SizeLogRatio-SizeNonValid;
//    SizeSUT[0]=SizeSUT[1]=SizeSUT[2]=LengthMatrixG;
//    SizeSUT[3]=SizeLogRatio-SizeNonValid;
//    int un=(SizeLogRatio-SizeNonValid)>=LengthMatrixG?LengthMatrixG:(SizeLogRatio-SizeNonValid);
//    float * UT=TransposeMatrix(UforMRF,SizeLogRatio-SizeNonValid,un);


//    float * SUT=ProductMatrix(SforMRF,UT,SizeSUT);
//    delete[]UT;
//    UT=NULL;

//    int SizeVSUT[4];
//    SizeVSUT[0]=SizeVSUT[1]=SizeVSUT[2]=LengthMatrixG;
//    SizeVSUT[3]=SizeLogRatio-SizeNonValid;

//    float * VSUT=ProductMatrix(VforMRF,SUT,SizeVSUT);
//    delete [] SUT;
//    SUT=NULL;

//    int SizeFinal[4];
//    SizeFinal[0]=LengthMatrixG;
//    SizeFinal[1]=SizeFinal[2]=SizeLogRatio-SizeNonValid;
//    SizeFinal[3]=1;

//    float * FinalThetaResult=ProductMatrix(VSUT,LogRatioReduced,SizeFinal);
//    delete [] VSUT;
//    VSUT=NULL;


    float * AMatrixReducedT=TransposeMatrix(AMatrixReduced,SizeLogRatioReduced,LengthMatrixG);
//    // printing AT
//    for(int i=0;i<SizeLogRatioReduced;i++){
//        for(int j=0;j<LengthMatrixG;j++){
//            cout<<AMatrixReducedT[j*SizeLogRatioReduced+i]<<"  ";
//        }
//        cout<<endl;
//    }
    int SizeATA[4]={LengthMatrixG,SizeLogRatioReduced,SizeLogRatioReduced,LengthMatrixG};
    float * ATA=ProductMatrix(AMatrixReducedT,AMatrixReduced,SizeATA);
//    //printing ATA
//    for (int i=0;i<LengthMatrixG;i++){
//        for(int j=0;j<LengthMatrixG;j++){
//            cout<<ATA[i*LengthMatrixG+j]<<"  ";
//        }
//        cout<<endl;
//    }

    int CountNanATA=0;
    for(int i=0;i<LengthMatrixG*LengthMatrixG;i++){
        if(ATA[i]!=ATA[i]){
            CountNanATA++;
        }
    }
    cout<<CountNanATA<<" nan in the calculation of ATA"<<endl;
    invertMatrix(ATA,LengthMatrixG);
    int CountNanInvertATA=0;
    for(int i=0;i<LengthMatrixG*LengthMatrixG;i++){
        if(ATA[i]!=ATA[i]){
            CountNanInvertATA++;
        }
    }
//    cout<<"Printing inv ATA"<<endl;
//    for (int i=0;i<LengthMatrixG;i++){
//        for(int j=0;j<LengthMatrixG;j++){
//            cout<<ATA[i*LengthMatrixG+j]<<"  ";
//        }
//        cout<<endl;
//    }
    cout<<CountNanInvertATA<<" nan in the inversion of ATA"<<endl;
    int SizeATLR[4]={LengthMatrixG,SizeLogRatioReduced,SizeLogRatioReduced,1};
    float * ATLR=ProductMatrix(AMatrixReducedT,LogRatioReduced,SizeATLR);
    delete [] AMatrixReduced;
    AMatrixReduced=NULL;
    delete [] AMatrixReducedT;
    AMatrixReducedT=NULL;
    int SizeinvATAATLR[4]={LengthMatrixG,LengthMatrixG,LengthMatrixG,1};
    float * FinalResultBis=ProductMatrix(ATA,ATLR,SizeinvATAATLR);

    delete [] AMatrixReduced;
    AMatrixReduced=NULL;
    delete [] LogRatioReduced;
    LogRatioReduced=NULL;

    return FinalResultBis;
}

void TreeEM::SaveTmpResultMasked(float * ResultToSave,string filename){
            nifti_image * Result=nifti_copy_nim_info(this->GetDataImage());
    Result->dim[0]=3;
    Result->dim[4]=Result->dim[5]=1;
    nifti_update_dims_from_array(Result);
            Result->data = (void *) calloc(Result->nvox, sizeof(float));
            float * Result_PTRtmp=static_cast<float *>(Result->data);
            float * ToSave_PTR=ResultToSave;
            int * L2S_PTR =this->GetL2S();
            int numel=this->GetNumberElements();
            for (int i=0; i<numel; i++, Result_PTRtmp++,L2S_PTR++) {
                *Result_PTRtmp=0;
                if(*L2S_PTR>=0){
                *Result_PTRtmp=*ToSave_PTR;
                    ToSave_PTR++;
                }
            }
            nifti_set_filenames(Result, filename.c_str(), 0, 0);
            nifti_image_write(Result);
            nifti_image_free(Result);
}

void TreeEM::SaveTmpResult(float * ResultToSave,string filename){
            nifti_image * Result=nifti_copy_nim_info(this->GetDataImage());
    Result->dim[0]=3;
    Result->dim[4]=Result->dim[5]=1;
    nifti_update_dims_from_array(Result);
            Result->data = (void *) calloc(Result->nvox, sizeof(float));
            float * Result_PTRtmp=static_cast<float *>(Result->data);
            float * ToSave_PTR=ResultToSave;
            int numel=this->GetNumberElements();
            for (int i=0; i<numel; i++, Result_PTRtmp++,ToSave_PTR++) {
                *Result_PTRtmp=0;
                *Result_PTRtmp=*ToSave_PTR;

            }
            nifti_set_filenames(Result, filename.c_str(), 0, 0);
            nifti_image_write(Result);
            nifti_image_free(Result);
}

void TreeEM::SavePriorsAdaptedHierarchy(SEG_PARAMETERS * segment_param){
    vector<TreeEM *> AllPriorsAdaptedVector;
    this->FindRoot()->GetAllPriorsNodeVector(AllPriorsAdaptedVector);
    int numbPriorsToSave=AllPriorsAdaptedVector.size();
    
    // Preliminary creation of string needed to build
    string FilenameBC=nifti_makebasename(segment_param->filename_out[0].c_str());
    int Index=FilenameBC.find_last_of('/');
    string FilenameBC_b=FilenameBC.substr(0,Index+1);
    string FilenameBC_e=FilenameBC.substr(Index+1,FilenameBC.length());
    cout<<numbPriorsToSave<<" priors adapted to save"<<endl;
    for (int p=0; p<numbPriorsToSave; p++) {
        //First create string from hierarchy
        vector<int> HierarchyTree=AllPriorsAdaptedVector[p]->GetHierarchyVector();
        string HierarchyString="";
        int Hsize=HierarchyTree.size();
        for (int h=0; h<Hsize; h++) {
            stringstream ss;
            ss << HierarchyTree[h];
            HierarchyString+=ss.str();
        }
        // Then copy image of adapted priors
        nifti_image * Result=nifti_copy_nim_info(this->GetDataImage());
        Result->dim[4]=1;
        nifti_update_dims_from_array(Result);
        Result->data = (void *) calloc(Result->nvox, sizeof(float));
        int numel=Result->nx*Result->ny*Result->nz;
        float * PriorsAdapted_PTR=AllPriorsAdaptedVector[p]->GetPriorsAdaptedDirect();
        if(PriorsAdapted_PTR!=NULL){
            float * Result_PTRtmp=static_cast<float *>(Result->data);
            for(int i=0;i<numel;i++,Result_PTRtmp++,PriorsAdapted_PTR++){
                *Result_PTRtmp=*PriorsAdapted_PTR;
            }
        }
        int numbmodal=this->GetNumberModalities();
        stringstream mm;
        mm<<numbmodal;
        string modalstr=mm.str();
        string FilenameBC=FilenameBC_b+"PriorsAdapted_"+HierarchyString+FilenameBC_e+"_"+modalstr+".nii.gz";
        nifti_set_filenames(Result, FilenameBC.c_str(), 0, 0);
        nifti_image_write(Result);
        nifti_image_free(Result);

    }
}

void TreeEM::SavePriorsAdapted(SEG_PARAMETERS* segment_param){
//    if(segment_param->AtlasWeight==0){
//        return;
//    }
    vector<float *> PriorsAdaptedVector=this->GetPriorsAdaptedVectorParent();
    int numbGclasses=PriorsAdaptedVector.size();

    for(int c=0;c<numbGclasses;c++){
        nifti_image * Result=nifti_copy_nim_info(this->GetDataImage());
        Result->dim[4]=1;
        nifti_update_dims_from_array(Result);
        Result->data = (void *) calloc(Result->nvox, sizeof(float));
        int numel=Result->nx*Result->ny*Result->nz;
        float * PriorsAdapted_PTR=PriorsAdaptedVector[c];
        if(PriorsAdapted_PTR!=NULL){
        float * Result_PTRtmp=static_cast<float *>(Result->data);
        for(int i=0;i<numel;i++,Result_PTRtmp++,PriorsAdapted_PTR++){
            *Result_PTRtmp=*PriorsAdapted_PTR;
        }
        }
        cout<<"First level"<< c << " "<<GetMaxArray(static_cast<float *>(Result->data), numel);
        nifti_set_filenames(Result, segment_param->filename_PriorsAdaptedOut[c].c_str(), 0, 0);
        nifti_image_write(Result);
        nifti_image_free(Result);
    }
    if (this->GetFlagOutliers()==1 ||this->GetFlagOutliers()==3 || this->GetFlagOutliers()>=5) {
        vector<float *> PriorsVectorSecond0=this->GetChild(0)->GetPriorsAdaptedVectorParent();
        vector<float *> PriorsVectorSecond1=this->GetChild(1)->GetPriorsAdaptedVectorParent();
        int numbGclasses0=PriorsVectorSecond0.size();
        int numbGclasses1=PriorsVectorSecond1.size();
        string FilenameBC=nifti_makebasename(segment_param->filename_out[0].c_str());
        int Index=FilenameBC.find_last_of('/');
        string FilenameBC_b=FilenameBC.substr(0,Index+1);
        string FilenameBC_e=FilenameBC.substr(Index+1,FilenameBC.length());
        
        for(int c=0;c<numbGclasses0;c++){
            nifti_image * Result=nifti_copy_nim_info(this->GetDataImage());
            Result->dim[4]=1;
            nifti_update_dims_from_array(Result);
            Result->data = (void *) calloc(Result->nvox, sizeof(float));
            int numel=Result->nx*Result->ny*Result->nz;
            float * PriorsAdapted_PTR=PriorsVectorSecond0[c];
            if(PriorsAdapted_PTR!=NULL){
                float * Result_PTRtmp=static_cast<float *>(Result->data);
                for(int i=0;i<numel;i++,Result_PTRtmp++,PriorsAdapted_PTR++){
                    *Result_PTRtmp=*PriorsAdapted_PTR;
                }
            }
            stringstream ss;
            ss << c;
            stringstream s0;
            s0 << 0;
            string cb=ss.str();
            string c0=s0.str();
            FilenameBC=FilenameBC_b+"PriorsAdapted_"+c0+cb+FilenameBC_e+".nii.gz";
            nifti_set_filenames(Result, FilenameBC.c_str(), 0, 0);
            nifti_image_write(Result);
            nifti_image_free(Result);
        }
        for(int c=0;c<numbGclasses1;c++){
            nifti_image * Result=nifti_copy_nim_info(this->GetDataImage());
            Result->dim[4]=1;
            nifti_update_dims_from_array(Result);
            Result->data = (void *) calloc(Result->nvox, sizeof(float));
            int numel=Result->nx*Result->ny*Result->nz;
            float * PriorsAdapted_PTR=PriorsVectorSecond1[c];
            if(PriorsAdapted_PTR!=NULL){
                float * Result_PTRtmp=static_cast<float *>(Result->data);
                for(int i=0;i<numel;i++,Result_PTRtmp++,PriorsAdapted_PTR++){
                    *Result_PTRtmp=*PriorsAdapted_PTR;
                }
            }
            stringstream ss;
            ss << c;
            stringstream s1;
            s1 << 1;
            string cb=ss.str();
            string c1=s1.str();
            FilenameBC=FilenameBC_b+"PriorsAdapted_"+c1+cb+FilenameBC_e+".nii.gz";
            nifti_set_filenames(Result, FilenameBC.c_str(), 0, 0);
            nifti_image_write(Result);
            nifti_image_free(Result);
        }
    }


}

bool * TreeEM::GetMSLesIndicVL(SEG_PARAMETERS * segment_param){
    int * Modalities=this->GetModalities(segment_param);
    int numbmodal=this->GetNumberModalities();
    int numelmasked=this->GetNumberMaskedElements();
    float * DataCorrected_PTR=this->GetDataBFCorrected();
    bool * MSLesClassif=new bool[numelmasked];
    for (int i=0; i<numelmasked; i++) {
        MSLesClassif[i]=1;
    }
    // Get all means for general classes
    vector<TreeEM*> GeneralClasses=this->GetGeneralClassesVector();
    int numbclasses=GeneralClasses.size();
    vector<float *> MeanGeneralClasses;
    for (int c=0; c<numbclasses; c++) {
        float * MeanGenClass=GeneralClasses[c]->GetMeanDirect();
        MeanGeneralClasses.push_back(MeanGenClass);
    }
    
    switch (numbclasses) {
        case 3: {// 3 classical tissues GM WM CSF
            //Testing according to the modality
            for (int m=0 ; m<numbmodal; m++) {
                switch (Modalities[m]) {
                    case 0:
                        
                        break;
                    case 1:
                        
                        break;
                    case 2:
                        for (int i=0; i<numelmasked; i++) {
                            if (DataCorrected_PTR[i+m*numelmasked]>MeanGeneralClasses[1][m]) {
                                MSLesClassif[i]*=1;
                            }
                            else{
                                MSLesClassif[i]*=0;
                            }
                        }
                        break;
                    case 3:
                        for (int i=0; i<numelmasked; i++) {
                            if (DataCorrected_PTR[i+m*numelmasked]>MeanGeneralClasses[1][m]) {//&& DataCorrected_PTR[i+m*numelmasked]>MeanGeneralClasses[2][m]) {
                                MSLesClassif[i]*=1;
                            }
                            else{
                                MSLesClassif[i]*=0;
                            }
                        }
                        break;
                    default:
                        break;
                }
            }
        }

            break;
        case 4:{ // case of 4 priors GM WM ECSF ICSF
                //Testing according to the modality
                for (int m=0 ; m<numbmodal; m++) {
                    switch (Modalities[m]) {
                        case 0:
                            
                            break;
                        case 1:
                            
                            break;
                        case 2:
                            for (int i=0; i<numelmasked; i++) {
                                if (DataCorrected_PTR[i+m*numelmasked]>MeanGeneralClasses[1][m]) {
                                    MSLesClassif[i]*=1;
                                }
                                else{
                                    MSLesClassif[i]*=0;
                                }
                            }
                            break;
                        case 3:
                            for (int i=0; i<numelmasked; i++) {
                                if (DataCorrected_PTR[i+m*numelmasked]>MeanGeneralClasses[1][m]) {//&& DataCorrected_PTR[i+m*numelmasked]>MeanGeneralClasses[2][m]) {
                                    MSLesClassif[i]*=1;
                                }
                                else{
                                    MSLesClassif[i]*=0;
                                }
                            }
                            break;
                        default:
                            break;
                    }
                }
        }
            break;
        case 5:{ // case where priors are GM DGM WM ECSF ICSF
                    //Testing according to the modality
                    for (int m=0 ; m<numbmodal; m++) {
                        switch (Modalities[m]) {
                            case 0:
                                
                                break;
                            case 1:
                                
                                break;
                            case 2:
                                for (int i=0; i<numelmasked; i++) {
                                    if (DataCorrected_PTR[i+m*numelmasked]>MeanGeneralClasses[2][m]) {
                                        MSLesClassif[i]*=1;
                                    }
                                    else{
                                        MSLesClassif[i]*=0;
                                    }
                                }
                                break;
                            case 3:
                                for (int i=0; i<numelmasked; i++) {
                                    if (DataCorrected_PTR[i+m*numelmasked]>MeanGeneralClasses[2][m]) {//&& DataCorrected_PTR[i+m*numelmasked]>MeanGeneralClasses[2][m]) {
                                        MSLesClassif[i]*=1;
                                    }
                                    else{
                                        MSLesClassif[i]*=0;
                                    }
                                }
                                break;
                            default:
                                break;
                        }
                    }
        }

            break;
        default:
            break;
    }
    
//    for (int i=0; i<numelmasked; i++) {
//        if (DataCorrected_PTR[i]>MeanGeneralClasses[0][0]) {
//            MSLesClassif[i]*=1;
//        }
//        else{
//            MSLesClassif[i]*=0;
//        }
//    }
//    for (int i=0; i<numelmasked; i++) {
//        if (DataCorrected_PTR[i+numelmasked]>MeanGeneralClasses[0][1]) {
//            MSLesClassif[i]*=1;
//        }
//        else{
//            MSLesClassif[i]*=0;
//        }
//    }
    // clear memory for mean
    for (int c=0; c<numbclasses; c++) {
        delete [] MeanGeneralClasses[c];
        MeanGeneralClasses[c]=NULL;
    }
    // returning boolean
    return MSLesClassif;
}

// From the case of outlier 3 Create a typicality map for a specific tissue
float * TreeEM::MakeTypicalityFloatClass(int IndexClass, SEG_PARAMETERS * segment_param){
//    First, get relevant class and covariance matrix of either parameters or according to observations
    float * MeanToUse=this->GetNodeInlier()->GetChild(IndexClass)->GetMeanDirect();
    float * VarianceToUse=this->GetNodeInlier()->GetChild(IndexClass)->GetVarianceDirect(MeanToUse);
    int numelmasked=this->GetNumberMaskedElements();
    int numbmodal=this->GetNumberModalities();
    float DeterminantVariance=this->determinant(VarianceToUse, numbmodal);
    float * InvertedVariance=this->InvertMatrix(VarianceToUse, numbmodal);
    float * Typicality=new float[numelmasked];
    float DistanceValue=1/sqrt(pow_int(2*3.14, numbmodal)*DeterminantVariance)*exp(-0.5*segment_param->VLkappa*segment_param->VLkappa);
    float * DataIntensity=this->GetDataBFCorrected();
    float Normalisation=1/(pow(2*3.14, numbmodal/2)*sqrt(DeterminantVariance));
    for (int i=0;i<numelmasked; i++) {
        float Value=0;
        for (int m1=0; m1<numbmodal; m1++) {
            for (int m2=0; m2<numbmodal; m2++) {
                Value+=(DataIntensity[m1*numelmasked+i]-MeanToUse[m1])*InvertedVariance[m1+m2*numbmodal]*(DataIntensity[m2*numelmasked+i]-MeanToUse[m2]);
            }
        }
        Value=Normalisation*exp(-0.5*Value);
        Typicality[i]=Value/(Value+DistanceValue);
    }
    return Typicality;
}

nifti_image * TreeEM::CreateTypicalityAtlas4D(SEG_PARAMETERS * segment_param){
//    Initialisation of the result
    int numbmodal=this->GetNumberModalities();
    int numbclasses=this->GetNodeInlier()->GetNumberChildren();
    int numel=this->GetNumberElements();
    nifti_image * FinalTypicality=nifti_copy_nim_info(this->GetDataImage());
    FinalTypicality->dim[0]=4;
    FinalTypicality->dim[4]=numbclasses;
    nifti_update_dims_from_array(FinalTypicality);
    FinalTypicality->data=(void *)calloc(FinalTypicality->nvox, sizeof(float));
    float * DataFinal=static_cast<float*>(FinalTypicality->data);
//    First get the typicality maps for all the tissue classes
//    Then weight them according to the corresponding NormResp (Inliers+Outliers
    vector<float *> TypicalityAtlasVector;
    int * L2S=this->GetL2S();
    for (int c=0; c<numbclasses; c++) {
        float * TypicalityToPush=MakeTypicalityFloatClass(c, segment_param);
        TypicalityAtlasVector.push_back(TypicalityToPush);
    }
    for (int c=0; c<numbclasses; c++) {
        float * NormRespInliers=this->GetNodeInlier()->GetChild(c)->GetNormResp();
        float * NormRespOutliers=this->GetNodeOutlier()->GetChild(c)->GetNormResp();
        for (int i=0; i<numel; i++) {
            if (L2S[i]<0) {
                DataFinal[c*numel+i]=0;
            }
            else{
                DataFinal[c*numel+i]=(NormRespInliers[L2S[i]]+NormRespOutliers[L2S[i]])*TypicalityAtlasVector[c][L2S[i]];
            }
        }
    }
    for (int c=0; c<numbclasses; c++) {
        delete [] TypicalityAtlasVector[c];
        TypicalityAtlasVector[c]=NULL;
    }
    return FinalTypicality;
}

nifti_image * TreeEM::CreateTypicalityAtlas(SEG_PARAMETERS * segment_param){
    nifti_image * Atlas4D=this->CreateTypicalityAtlas4D(segment_param);
    nifti_image * TypicalityAtlas=this->Sum4DNii(Atlas4D);
    nifti_image_free(Atlas4D);
    return TypicalityAtlas;
}

nifti_image * TreeEM::Sum4DNii(nifti_image * Image4D){
    if (Image4D==NULL) {
        return NULL;
    }
    nifti_image * Result=nifti_copy_nim_info(Image4D);
    Result->dim[0]=3;
    Result->dim[4]=1;
    nifti_update_dims_from_array(Result);
    Result->data=(void*)calloc(Result->nvox, sizeof(float));
    float * DataResult=static_cast<float*>(Result->data);
    float * Data4D=static_cast<float*>(Image4D->data);
//    Initialisation of Result to 0
    int numel=Result->nvox;
    int numbdim=Image4D->dim[4];
    for (int i=0; i<numel; i++) {
        DataResult[i]=0;
    }
    for(int d=0;d<numbdim;d++){
        for (int i=0; i<numel; i++) {
            DataResult[i]+=Data4D[i+d*numel];
        }
    }
    return Result;
}

float * TreeEM::MakeTypicalityWeight(SEG_PARAMETERS * segment_param){
    if (this->GetFlagOutliers()!=4) { // the VL method is not used when not using an outlier model under 4
        return NULL;
    }
    float kappa =segment_param->VLkappa;
    int numelmasked=this->GetNumberMaskedElements();
    int numbmodal=this->GetNumberModalities();
    float * Distribution= new float[numelmasked];
    this->MakeWeightedDist(Distribution);
    float * VarianceDirect=this->GetVarianceDirect();
    float Determinant=determinant(VarianceDirect, numbmodal);
    float TypicalityValue=1/(pow(2*3.14, numbmodal*0.5)*pow(Determinant,0.5))*exp(-0.5*kappa*kappa);
    float * Typicality=new float [numelmasked];
    bool * LesClassif=this->GetMSLesIndicVL(segment_param);
    bool * CSFOutClassif=this->GetCSFOutIndicVL(segment_param);
    float * MRF_PTR=this->GetMRF();
    float * WM_PTR=this->FindRoot()->GetChild(1)->GetMRF();
    float * CSF_PTR=this->FindRoot()->GetChild(2)->GetMRF();
    for (int i=0; i<numelmasked; i++) {
        if (LesClassif[i]+CSFOutClassif[i]==0) {
            Typicality[i]=1;
        }
        else{
            if (MRF_PTR!=NULL) {
                Typicality[i]=Distribution[i]*MRF_PTR[i]/(Distribution[i]*MRF_PTR[i]+TypicalityValue*(LesClassif[i]*WM_PTR[i]+CSFOutClassif[i]*CSF_PTR[i]));
            }
            else{
        Typicality[i]=Distribution[i]/(Distribution[i]+TypicalityValue*(LesClassif[i]+CSFOutClassif[i]));
            }
        }
    }
//    for (int i=0; i<numelmasked; i++) {
//        Typicality[i]=Distribution[i]/(Distribution[i]+TypicalityValue);
//    }
    //clear memory allocated and not needed anymore.
    delete [] Distribution;
    delete [] VarianceDirect;
    Distribution=NULL;
    VarianceDirect=NULL;
    return Typicality;
}

float * TreeEM::GetMSOutlierBeliefs(SEG_PARAMETERS * segment_param){
    if (this->GetFlagOutliers()!=4) {
        return NULL;
    }
    else{
        int numelmasked = this->GetNumberMaskedElements();
        TreeEM * Root=this->FindRoot();
        int numbchild=Root->GetNumberChildren();
        float * MSOutliersBeliefs=new float[numelmasked];
        for (int i=0; i<numelmasked; i++) {
            MSOutliersBeliefs[i]=1;
        }
        for (int c=0; c<numbchild; c++) {
            float * Typicality_PTR=&Root->GetChild(c)->GetNormResp()[numelmasked];
            float * NormResp_PTR=Root->GetChild(c)->GetNormResp();
            for (int i=0; i<numelmasked; i++) {
                MSOutliersBeliefs[i]-=Typicality_PTR[i]*NormResp_PTR[i];
            }
        }
        bool * MSLesClassif=this->GetMSLesIndicVL(segment_param);
        for (int i=0; i<numelmasked; i++) {
            MSOutliersBeliefs[i]*=MSLesClassif[i];
        }
        delete [] MSLesClassif;
        MSLesClassif=NULL;
        return MSOutliersBeliefs;
    }

}

float * TreeEM::GetOutlierBeliefs(SEG_PARAMETERS * segment_param){
    if (this->GetFlagOutliers()!=4) {
        return NULL;
    }
    else{
        int numelmasked = this->GetNumberMaskedElements();
        TreeEM * Root=this->FindRoot();
        int numbchild=Root->GetNumberChildren();
        float * MSOutliersBeliefs=new float[numelmasked];
        for (int i=0; i<numelmasked; i++) {
            MSOutliersBeliefs[i]=1;
        }
        for (int c=0; c<numbchild; c++) {
            float * Typicality_PTR=&Root->GetChild(c)->GetNormResp()[numelmasked];
            float * NormResp_PTR=Root->GetChild(c)->GetNormResp();
            for (int i=0; i<numelmasked; i++) {
                MSOutliersBeliefs[i]-=Typicality_PTR[i]*NormResp_PTR[i];
            }
        }

        return MSOutliersBeliefs;
    }
    
}

float * TreeEM::GetCSFOutlierBeliefs(SEG_PARAMETERS * segment_param){
    if (this->GetFlagOutliers()!=4) {
        return NULL;
    }
    else{
        int numelmasked = this->GetNumberMaskedElements();
        TreeEM * Root=this->FindRoot();
        int numbchild=Root->GetNumberChildren();
        float * CSFOutliersBeliefs=new float[numelmasked];
        for (int i=0; i<numelmasked; i++) {
            CSFOutliersBeliefs[i]=1;
        }
        for (int c=0; c<numbchild; c++) {
            float * Typicality_PTR=&Root->GetChild(c)->GetNormResp()[numelmasked];
            float * NormResp_PTR=Root->GetChild(c)->GetNormResp();
            for (int i=0; i<numelmasked; i++) {
                CSFOutliersBeliefs[i]-=Typicality_PTR[i]*NormResp_PTR[i];
            }
        }
        bool * CSFOutClassif=this->GetCSFOutIndicVL(segment_param);
        for (int i=0; i<numelmasked; i++) {
            CSFOutliersBeliefs[i]*=CSFOutClassif[i];
        }
        delete [] CSFOutClassif;
        CSFOutClassif=NULL;
        return CSFOutliersBeliefs;
    }
    
}

bool * TreeEM::GetCSFOutIndicVL(SEG_PARAMETERS * segment_param){
//    int * Modalities=this->GetModalities(segment_param);
//    int numbmodal=this->GetNumberModalities();
    int numelmasked=this->GetNumberMaskedElements();
//    float * DataCorrected_PTR=this->GetDataBFCorrected();
    bool * CSFOutClassif=new bool[numelmasked];
    for (int i=0; i<numelmasked; i++) {
        CSFOutClassif[i]=1;
    }
    // Get all means for general classes
    vector<TreeEM*> GeneralClasses=this->GetGeneralClassesVector();
    int numbclasses=GeneralClasses.size();
    vector<float *> MeanGeneralClasses;
    for (int c=0; c<numbclasses; c++) {
        float * MeanGenClass=GeneralClasses[c]->GetMeanDirect();
        MeanGeneralClasses.push_back(MeanGenClass);
    }
    
//    //Testing according to the modality
//    for (int m=0 ; m<numbmodal; m++) {
//        switch (Modalities[m]) {
//            case 0:
//                
//                break;
//            case 1:
//                
//                break;
//            case 2:
//                for (int i=0; i<numelmasked; i++) {
//                    if (DataCorrected_PTR[i+m*numelmasked]<MeanGeneralClasses[0][m]) {
//                        CSFOutClassif[i]*=1;
//                    }
//                    else{
//                        CSFOutClassif[i]*=0;
//                    }
//                }
//                break;
//            case 3:
//                for (int i=0; i<numelmasked; i++) {
//                    if (DataCorrected_PTR[i+m*numelmasked]>MeanGeneralClasses[0][m]) {
//                        CSFOutClassif[i]*=1;
//                    }
//                    else{
//                        CSFOutClassif[i]*=0;
//                    }
//                }
//                break;
//            default:
//                break;
//        }
//    }
//                    for (int i=0; i<numelmasked; i++) {
//                        if (DataCorrected_PTR[i]<MeanGeneralClasses[0][0]) {
//                            CSFOutClassif[i]*=1;
//                        }
//                        else{
//                            CSFOutClassif[i]*=0;
//                        }
//                    }
//                    for (int i=0; i<numelmasked; i++) {
//                        if (DataCorrected_PTR[i+numelmasked]>MeanGeneralClasses[0][1]) {
//                            CSFOutClassif[i]*=1;
//                        }
//                        else{
//                            CSFOutClassif[i]*=0;
//                        }
//                    }
    for (int i=0;i<numelmasked; i++) {
        CSFOutClassif[i]=0;
    }
    
    
    // clear memory for mean
    for (int c=0; c<numbclasses; c++) {
        delete [] MeanGeneralClasses[c];
        MeanGeneralClasses[c]=NULL;
    }
    // returning boolean
    return CSFOutClassif;
}

vector<float *> TreeEM::GetMeanGeneralClassesVector(){
    vector<TreeEM *> GeneralNodesVector=this->GetGeneralClassesVector();
    int numbGenClasses=GeneralNodesVector.size();
    vector<float *> MeanGeneralClassesVector;
    for (int c=0; c<numbGenClasses; c++) {
        float * MeanDirect=GeneralNodesVector[c]->GetMeanDirect();
        MeanGeneralClassesVector.push_back(MeanDirect);
    }
    return MeanGeneralClassesVector;
}

vector<float *> TreeEM::GetVarianceGeneralClassesVector(){
    vector<TreeEM *> GeneralNodesVector=this->GetGeneralClassesVector();
    int numbGenClasses=GeneralNodesVector.size();
    vector<float *> VarianceGeneralClassesVector;
    for (int c=0; c<numbGenClasses; c++) {
        float * VarianceDirect=GeneralNodesVector[c]->GetVarianceDirect();
        VarianceGeneralClassesVector.push_back(VarianceDirect);
    }
    return VarianceGeneralClassesVector;
}

vector<TreeEM *> TreeEM::GetWMLesions(SEG_PARAMETERS * segment_param){
    vector<TreeEM *> GeneralNodes=this->GetGeneralClassesVector();
    vector<TreeEM *> LesionVector;
    int numbmodal=this->GetNumberModalities();
    int * ModalityTypes=this->GetModalities(segment_param);
    // Get all means for general classes
    vector<TreeEM*> GeneralClasses=this->GetGeneralClassesVector();
    int numbclasses=GeneralClasses.size();
    vector<float *> MeanGeneralClasses;
    for (int c=0; c<numbclasses; c++) {
        float * MeanGenClass=GeneralClasses[c]->GetMeanDirect();
        MeanGeneralClasses.push_back(MeanGenClass);
    }
    // For all outlier subclasses define those that answer the criterion over the lesion classification
    if (this->FlagOutliers==0) {
        cout<<"no lesion vector since no outlier model"<<endl;
        return LesionVector;
    }
    else{
        vector<TreeEM *> LeavesOutlier=this->GetNodeOutlier()->GetAllLeaves();
        int numboutleaves=LeavesOutlier.size();
        for (int l=0; l<numboutleaves; l++) {
            float * MeanLeave=LeavesOutlier[l]->GetMeanDirect(); // Have to consider that lesion class might still be partially under uniform distribution
            bool flagLesion=1;
            for (int m=0; m<numbmodal; m++) {
                int Modality=ModalityTypes[m];
                switch (Modality) {
                    case 1:{ // T1 to be considered as lesion must be hypointense compared to WM
                        if (MeanGeneralClasses[1][m]<MeanLeave[m]) {
                            flagLesion*=0;
                        }
                        else{
                            flagLesion*=1;
                        }
                    }
                        break;
                    case 2:{ // T2 to be considered as lesion must be hyperintense compared to WM
                        if (MeanGeneralClasses[1][m]>MeanLeave[m]) {
                            flagLesion*=0;
                        }
                        else{
                            flagLesion*=1;
                        }
                    }
                        break;
                    case 3:{ // FLAIR to be considered as lesion must be hyperintense compared to all classes
                        if (MeanGeneralClasses[1][m]>MeanLeave[m] ) {//|| MeanGeneralClasses[0][m]>MeanLeave[m] || MeanGeneralClasses[2][m]>MeanLeave[m]) {
                            flagLesion*=0;
                        }
                        else{
                            flagLesion*=1;
                        }
                    }
                        break;
                    case 4:{ // case of PD
                        if (MeanGeneralClasses[1][m]>MeanLeave[m] ) {//|| MeanGeneralClasses[0][m]>MeanLeave[m] || MeanGeneralClasses[2][m]>MeanLeave[m]) {
                            flagLesion*=0;
                        }
                        else{
                            flagLesion*=1;
                        }

                    }
                        break;
                    default:{ // no modality defined so cannot be considered as lesion anymore
                        flagLesion*=0;
                    }
                        break;
                }
            }
            if (flagLesion==1) {
                LesionVector.push_back(LeavesOutlier[l]);
            }
            delete [] MeanLeave;
            MeanLeave=NULL;
        }
    }
    for(int c=0;c<numbclasses;c++){
        delete [] MeanGeneralClasses[c];
        MeanGeneralClasses[c]=NULL;
    }
    delete [] ModalityTypes;
    ModalityTypes=NULL;
    cout<<LesionVector.size()<<" classes corresponding to WM lesion rules"<<endl;
    return LesionVector;
}

int * TreeEM::GetModalities(SEG_PARAMETERS * segment_param){
    int numbmodal=this->GetNumberModalities();
    int * ModalityTypes=new int[numbmodal];
    for (int m=0; m<numbmodal; m++) {
        ModalityTypes[m]=0;
    }
    // First Find possible modalities potentially present and their order by using segment_param. Note that using filename out will work because it contains in the right order the name of the used modalities
    if(segment_param->flag_out || segment_param->flag_inDCFile){
        cout<< "Out or DCfile known..."<<endl;
        
        string FilenameToUse;
        int Index;
        if (segment_param->flag_inDCFile) {
            FilenameToUse=segment_param->filename_inDC;
            Index=FilenameToUse.find("DataCorrected_");
            Index=Index+13;
        }
        else{
            FilenameToUse=segment_param->filename_out[0];
            Index=FilenameToUse.find_last_of('/');
        }
    cout<<FilenameToUse<<endl;
    string FilenameOut_e=FilenameToUse.substr(Index+1,FilenameToUse.length());
    int IndexUS=FilenameOut_e.find_first_of('_');
    string ModalitiesString=FilenameOut_e.substr(0,IndexUS);
    size_t found = ModalitiesString.find("T1");
    cout<<"T1 found at "<< found<<endl;
    typedef multimap<size_t, int> MapModal;
    typedef pair<size_t, int> ModalPair;
    MapModal::iterator first_element;
    MapModal MapModalities;
    MapModalities.insert(ModalPair(ModalitiesString.find("T1"),1));
    MapModalities.insert(ModalPair(ModalitiesString.find("T2"),2));
    MapModalities.insert(ModalPair(ModalitiesString.find("FLAIR"),3));
    MapModalities.insert(ModalPair(ModalitiesString.find("PD"),4));
    for (int m=0; m<numbmodal; m++) {
        first_element=MapModalities.begin();
        if (first_element->first!=string::npos) {
            ModalityTypes[m]=first_element->second;
            MapModalities.erase(first_element);
        }
        else{
            break;
        }
    }
//    // First try to get them using the filename
//    for (int m=0; m<numbmodal; m++) {
//        string FilenameToTest=segment_param->filename_input[m];
//        if (FilenameToTest.find("T1")!=string::npos) {
//            ModalityTypes[m]=1;
//        }
//        if (FilenameToTest.find("T2")!=string::npos) {
//            ModalityTypes[m]=2;
//        }
//        if (FilenameToTest.find("FLAIR")!=string::npos) {
//            ModalityTypes[m]=3;
//        }
//        if (FilenameToTest.find("PD")!=string::npos) {
//            ModalityTypes[m]=4;
//        }
//    }
    }
    int sizeModa=segment_param->Modalities.size();
    if(sizeModa!=0){
        for (int m=0; m<sizeModa; m++) {
            ModalityTypes[m]=segment_param->Modalities[m];
        }
    }
    // Check if one of the Modality Types has not been found;
    bool ModNotFound=0;
    for (int m=0; m<numbmodal; m++) {
        if (ModalityTypes[m]==0) {
            ModNotFound=1;
            break;
        }
    }
    
    // Go to second way of finding modality
    if (ModNotFound) {
    // Get all means for general classes
    vector<TreeEM*> GeneralClasses=this->GetGeneralClassesVector();
    int numbclasses=GeneralClasses.size();
    vector<float *> MeanGeneralClasses;
    for (int c=0; c<numbclasses; c++) {
        float * MeanGenClass=GeneralClasses[c]->GetMeanDirect();
        MeanGeneralClasses.push_back(MeanGenClass);
    }
    // From values of means get modalities
    // Assume that there are at least 3 general classes
    if (numbclasses<3) {
        cout<<"Not enough general classes considered"<<endl;
        return ModalityTypes;
    }
    else{
        switch (numbclasses) {
            case 3:
            {
                for (int m=0; m<numbmodal; m++) {
                    if (ModalityTypes[m]==0) {
                        
//                    float * MeanModal=new float[3];
                        float MeanModal[3];
                    for (int c=0; c<3; c++) {
                        MeanModal[c]=MeanGeneralClasses[c][m];
                    }
                    if (MeanModal[2]<=MeanModal[0] && MeanModal[2]<=MeanModal[1] && MeanModal[0]<=MeanModal[1]) { // definition of a T1 contrast
                        ModalityTypes[m]=1;
                    }
                    else if(MeanModal[2]>=MeanModal[0] && MeanModal[2]>=MeanModal[1] && MeanModal[0]>=MeanModal[1]){// definition of a T2 contrast
                        ModalityTypes[m]=2;
                    }
                    else if(MeanModal[2]<=MeanModal[0] && MeanModal[2]<=MeanModal[1] && MeanModal[0]>=MeanModal[1]){ // definition of FLAIR contrast
                        ModalityTypes[m]=3;
                    }
                    else{
                        cout<<"Impossible to define this modality"<<endl;
                        ModalityTypes[m]=0;
                    }
//                    delete [] MeanModal;
//                    MeanModal=NULL;
                }
            }
            }
                break;
            case 4: // case of 4 classes considered namely GM WM ECSF ICSF
        {
            for (int m=0; m<numbmodal; m++) {
                if (ModalityTypes[m]==0) {
//                float * MeanModal=new float[3];
                    float MeanModal[4];
                for (int c=0; c<4; c++) {
                    MeanModal[c]=MeanGeneralClasses[c][m];
                }
                if (MeanModal[3]<=MeanModal[0] && MeanModal[3]<=MeanModal[1] && MeanModal[0]<=MeanModal[1]) { // definition of a T1 contrast
                    ModalityTypes[m]=1;
                }
                else if(MeanModal[3]>=MeanModal[0] && MeanModal[3]>=MeanModal[1] && MeanModal[0]>=MeanModal[1]){// definition of a T2 contrast
                    ModalityTypes[m]=2;
                }
                else if(MeanModal[3]<=MeanModal[0] && MeanModal[3]<=MeanModal[1] && MeanModal[0]>=MeanModal[1]){ // definition of FLAIR contrast
                    ModalityTypes[m]=3;
                }
                else{
                    cout<<"Impossible to define this modality"<<endl;
                    ModalityTypes[m]=0;
                }
//                delete [] MeanModal;
//                MeanModal=NULL;
            }
        }
        }
                break;
            case 5: // case of 5 priors to consider : GM DGM WM ECSF ICSF
        {
            for (int m=0; m<numbmodal; m++) {
                if (ModalityTypes[m]==0) {
//                float * MeanModal=new float[3];
                    float MeanModal[5];
                for (int c=0; c<4; c++) {
                    MeanModal[c]=MeanGeneralClasses[c][m];
                }
                if (MeanModal[4]<=MeanModal[0] && (MeanModal[4]<=MeanModal[2]) && (MeanModal[0]<=MeanModal[2])) { // definition of a T1 contrast
                    ModalityTypes[m]=1;
                }
                else if(MeanModal[4]>=MeanModal[0] && MeanModal[4]>=MeanModal[2] && MeanModal[0]>=MeanModal[1]){// definition of a T2 contrast
                    ModalityTypes[m]=2;
                }
                else if(MeanModal[4]<=MeanModal[0] && MeanModal[4]<=MeanModal[2] && MeanModal[0]>=MeanModal[2]){ // definition of FLAIR contrast
                    ModalityTypes[m]=3;
                }
                else{
                    cout<<"Impossible to define this modality"<<endl;
                    ModalityTypes[m]=0;
                }
//                delete [] MeanModal;
//                MeanModal=NULL;
            }
        }
        }
                break;
            default:
                break;
        }
for (int c=0; c<numbclasses; c++) {
    delete [] MeanGeneralClasses[c];
    MeanGeneralClasses[c]=NULL;
}
MeanGeneralClasses.clear();

}
    }
//    cout<<"Modalities used are ";
//    for (int m=0; m<numbmodal; m++) {
//        cout<<PossibleModalities[ModalityTypes[m]]<<" ";
//    }
//    cout<<endl;
    return ModalityTypes;
}

void TreeEM::SaveAllLesionClasses(SEG_PARAMETERS * segment_param){
    vector<TreeEM *> LesionClasses=this->GetWMLesions(segment_param);
    int numbLeaves=LesionClasses.size();
    if (numbLeaves==0) {
        cout<<"no lesion class to save"<<endl;
        return;
    }
    string FilenameBC=nifti_makebasename(segment_param->filename_out[0].c_str());
    int Index=FilenameBC.find_last_of('/');
    string FilenameBC_b=FilenameBC.substr(0,Index+1);
    string FilenameBC_e=FilenameBC.substr(Index+1,FilenameBC.length());
    FilenameBC=FilenameBC_b+"LesionAll_"+FilenameBC_e+".nii.gz";
    nifti_image * Result=nifti_copy_nim_info(this->GetDataImage());
    Result->dim[0]=4;
    Result->dim[4]=numbLeaves;
    nifti_update_dims_from_array(Result);
    Result->data = (void *) calloc(Result->nvox, sizeof(float));
    float *Result_PTR=static_cast<float*>(Result->data);
    int numel=this->GetNumberElements();
    for (int c=0; c<numbLeaves; c++) {
        float * Result_PTRtmp=&Result_PTR[c*numel];
        float *Input=LesionClasses[c]->GetPartialResult(NORMRESP,segment_param);
        float * Input_PTR=Input;
        for (int i=0; i<numel; i++, Result_PTRtmp++,Input_PTR++) {
            *Result_PTRtmp=*Input_PTR;
        }
        if(Input!=NULL){
            delete [] Input;
            Input=NULL;
        }
    }
    nifti_set_filenames(Result, FilenameBC.c_str(), 0, 0);
    nifti_image_write(Result);
    nifti_image_free(Result);
}

void TreeEM::SaveLesionClass(SEG_PARAMETERS * segment_param){
    vector<TreeEM *> LesionClasses=this->GetWMLesions(segment_param);
    int numbLeaves=LesionClasses.size();
    if (numbLeaves==0) {
        cout<<"no lesion class to save"<<endl;
    }
    string FilenameBC=nifti_makebasename(segment_param->filename_out[0].c_str());
    int Index=FilenameBC.find_last_of('/');
    string FilenameBC_b=FilenameBC.substr(0,Index+1);
    string FilenameBC_e=FilenameBC.substr(Index+1,FilenameBC.length());
    FilenameBC=FilenameBC_b+"LesionTot_"+FilenameBC_e+".nii.gz";
    nifti_image * Result=nifti_copy_nim_info(this->GetDataImage());
    Result->dim[0]=3;
    Result->dim[4]=1;
    nifti_update_dims_from_array(Result);
    Result->data = (void *) calloc(Result->nvox, sizeof(float));
    float *Result_PTR=static_cast<float*>(Result->data);
    int numel=this->GetNumberElements();
    // Initialisation of Result to 0 everywhere
    for (int i=0; i<numel; i++) {
        Result_PTR[i]=0;
    }
    for (int c=0; c<numbLeaves; c++) {
        float * Result_PTRtmp=Result_PTR;
        float *Input=LesionClasses[c]->GetPartialResult(NORMRESP,segment_param);
        float * Input_PTR=Input;
        for (int i=0; i<numel; i++, Result_PTRtmp++,Input_PTR++) {
            *Result_PTRtmp+=*Input_PTR;
        }
        if(Input!=NULL){
            delete [] Input;
            Input=NULL;
        }
    }
    nifti_set_filenames(Result, FilenameBC.c_str(), 0, 0);
    nifti_image_write(Result);
    nifti_image_free(Result);
}

void TreeEM::SaveMRFImage(SEG_PARAMETERS * segment_param){
    vector<TreeEM*> LeavesVector=this->GetAllLeaves();
    int numbLeaves=LeavesVector.size();
    if(LeavesVector[0]->GetMRF()==NULL){ // if no MRF, nothing to save, change segment_param so that nothing will appear in txt file
        segment_param->flag_MRFOut=0;
        return;
    }
    nifti_image * Result=nifti_copy_nim_info(this->GetDataImage());
    Result->dim[0]=4;
    Result->dim[4]=numbLeaves;
    nifti_update_dims_from_array(Result);
    Result->data = (void *) calloc(Result->nvox, sizeof(float));
    float *Result_PTR=static_cast<float*>(Result->data);
    int numel=this->GetNumberElements();
    for(int l=0;l<numbLeaves;l++){
        float *Result_PTRtmp=&Result_PTR[l*numel];
        int * L2S_PTR=this->GetL2S();
        float * MRFToSave_PTR=LeavesVector[l]->GetMRF();
        for(int i=0;i<numel;i++,Result_PTRtmp++,L2S_PTR++){
            *Result_PTRtmp=0;
            if(*L2S_PTR>=0){
                *Result_PTRtmp=*MRFToSave_PTR;
                MRFToSave_PTR++;
            }
        }
    }
    nifti_set_filenames(Result, segment_param->filename_MRFOut.c_str(), 0, 0);
    nifti_image_write(Result);
    nifti_image_free(Result);

}

nifti_image * TreeEM::ReadFromFilename(string Filename){
    //    std::cout<<Filename<<endl;
    return nifti_image_read(Filename.c_str(),true);
}


vector<nifti_image *> TreeEM::ReadFromFilenamesVector(vector<string> FilenamesVector){
    int sizeVector=FilenamesVector.size();
    std::cout<< "Number of Filenames is "<<sizeVector<<endl;
    vector<nifti_image*> ImagesVector;
    for (int f=0; f<sizeVector; f++) {
        ImagesVector.push_back(nifti_image_read(FilenamesVector[f].c_str(), true));
        //cout<< "Size of dimension x in image "<< nifti_image_read(FilenamesVector[f], true)->nx<<endl;
    }
    return ImagesVector;
}

// Reallocation of memory for all array whose size change when increasing memory
void TreeEM::ReinitialisationForModalityChange(){
    // Special case of the root
    if (this->IsRoot()) {
        // Need to change memory space for BF Corrected: initially consider no BF Coefficients
        this->SetBFCoeffs(NULL);
        float * DataBFCorrectedToSet=this->MakeDataBFCorrected();
        this->SetDataBFCorrected(DataBFCorrectedToSet);
        delete [] DataBFCorrectedToSet;
        DataBFCorrectedToSet=NULL;
    }
    int DistributionTypeToInitialise=this->GetDistributionType();
    if(DistributionTypeToInitialise==1){
        this->CreateAllocateAndInitializeParameters(DistributionTypeToInitialise);
    }
    int numbchild=this->GetNumberChildren();
    for (int c=0; c<numbchild; c++) {
        this->GetChild(c)->ReinitialisationForModalityChange();
    }
}

bool TreeEM::HaveSimilarStructure(TreeEM * ExistingTree){
    bool flagSimiStruct=1;
    if (this->GetNumberChildren()==0) {
        if(ExistingTree->GetNumberChildren()==0){
            return flagSimiStruct;
        }
        else{
            flagSimiStruct=0;
            return flagSimiStruct;
        }
    }
    else{
        if (this->GetNumberChildren()!=ExistingTree->GetNumberChildren()) {
            flagSimiStruct=0;
            return flagSimiStruct;
        }
        else{
            int numbchild=this->GetNumberChildren();
            for (int c=0; c<numbchild; c++) {
                flagSimiStruct*=this->GetChild(c)->HaveSimilarStructure(ExistingTree->GetChild(c));
            }
        }
        return flagSimiStruct;
    }
}

void TreeEM::ResuscitateUniform(SEG_PARAMETERS * segment_param){
    vector<TreeEM *> VectorUniformDistNode=this->GetUniformLeavesVector();
    int numbunif=VectorUniformDistNode.size();
    bool flagUnifResuscitated=0;
    for (int u=0; u<numbunif; u++) {
        if (VectorUniformDistNode[u]->GetNormWeight()<=1E-10) {
            flagUnifResuscitated=1;
            cout<< "Unif "<<u<<"has to be resuscitated"<<endl;
            TreeEM * ParentUnif=VectorUniformDistNode[u]->GetParent();
            vector<TreeEM *> ParentUnifChildren=ParentUnif->GetChildren();
            int numbchild=ParentUnifChildren.size();
            for (int c=0; c<numbchild; c++) {
                ParentUnifChildren[c]->SetNormWeight(ParentUnifChildren[c]->GetNormWeight()*(1-10E-4));
            }
            VectorUniformDistNode[u]->SetNormWeight(10E-4);
        }
    }
    if (flagUnifResuscitated) {
        this->UpdateNonNormResp(segment_param);
        this->UpdateNormResp();
        this->UpdateNormRespRoot();
    }
    
}

void TreeEM::RepopulateNormResp(TreeEM * ExistingTree){
    // First check if both have similar structure
    if (!this->HaveSimilarStructure(ExistingTree)) {
        cout<<"There is nothing to repopulate since it is not the same structure"<<endl;
        return;
    }
    vector<TreeEM *> AllNodesExisting=ExistingTree->GetAllNodes();
    vector<TreeEM *> AllNodes=this->GetAllNodes();
    int numbExistingNodes=AllNodesExisting.size();
    int numbAllNodes=AllNodes.size();
    if (numbExistingNodes!=numbAllNodes) {
        cout<<"Pb in the repopulation"<<endl;
        return;
    }
    for (int n=0; n<numbExistingNodes; n++) {
        AllNodes[n]->SetNormResp(AllNodesExisting[n]->GetNormResp());
    }
}



void TreeEM::ProgressivePriorsAdaptation(SEG_PARAMETERS * segment_param){
    switch (segment_param->ProgressivePriors) {
        case 0:{ // case where we use the already adapted priors for the anatomical level and the new outlier priors brought by the new dimensionality
            if(this->GetFlagOutliers()>0 ){
                this->FullAdaptPriors(segment_param);
                if(this->GetNodeOutlier()->GetPriorsDirect()!=NULL){
                    float * NewOutliersAdapted=static_cast<float *>(this->GetNodeOutlier()->GetPriors()->data);
                    this->GetNodeOutlier()->SetPriorsAdapted(NewOutliersAdapted);
                    if (this->GetFlagOutliers()==3 || this->GetFlagOutliers()>=5) {
                        float * NewInliersAdapted=static_cast<float *>(this->GetNodeInlier()->GetPriorsDirect()->data); // If there are priors on node outliers, there must be priors on node inliers = reason why not checked for
                        this->GetNodeInlier()->SetPriorsAdapted(NewInliersAdapted);
                    }
            }
                this->UpdatePartPriorsAdapted();
        }
        }
            break;
        case 1:{ // case where we use the initial priors without any type of adaptation for the anatomical part and the new outlier atlases for the outlier level
            vector<TreeEM *> VectorNodeswithPriors=this->GetPriorsNodeVector();
            int numbNodeswithPriors=VectorNodeswithPriors.size();
            for (int p=0; p<numbNodeswithPriors; p++) {
                float * PriorsAdaptedToSet=static_cast<float *>( VectorNodeswithPriors[p]->GetPriorsDirect()->data);
                VectorNodeswithPriors[p]->SetPriorsAdapted(PriorsAdaptedToSet);
            }
            this->UpdatePartPriorsAdapted();
        }
            break;
        case 2:{ // case where we adapt the obtained segmentation in order to provide the new atlases
            this->FullAdaptPriors(segment_param);
            this->UpdatePartPriorsAdapted();
        }
            break;
        case 3:{ // case where we adapt the outliers and inliers priors but use the initial anatomical segmentation
            this->FullAdaptPriors(segment_param);
            vector<TreeEM *> VectorNodeswithPriors=this->GetPriorsNodeVector();
            int numbNodeswithPriors=VectorNodeswithPriors.size();
            for (int p=0; p<numbNodeswithPriors; p++) {
                if (VectorNodeswithPriors[p]->GetLevel()>1) {
                    float * PriorsAdaptedToSet=static_cast<float *>( VectorNodeswithPriors[p]->GetPriorsDirect()->data);
                    VectorNodeswithPriors[p]->SetPriorsAdapted(PriorsAdaptedToSet);
                }
            }
            this->UpdatePartPriorsAdapted();
        }
            break;
        default:
            break;
    }
}

TreeEM * TreeEM::BuildTreeWithAddedModalityFromExistingModel(TreeEM * ExistingTree, SEG_PARAMETERS * segment_param){
    TreeEM * NewBuiltTree=ExistingTree->CopyTree(NULL);
    int numbTotalImages=segment_param->filename_input.size();
    int numbUsedModalities=ExistingTree->GetNumberModalities();
    // Possibility to have step size in terms of number of channels different. Allow in particular to first consider 1 modality then consider the addition of the other 1 by 1 or 2 at the same time.
    int numberAddedModalities=segment_param->NumberAddedModalities[numbUsedModalities];
    if (numbTotalImages<=numbUsedModalities) {
        cout<<"No complexification needed : already all images used"<<endl;
        if(segment_param->PriorsKept!=3 && segment_param->PriorsKept!=4){
            segment_param->AtlasWeight.clear();
            segment_param->AtlasWeight.push_back(0);
            float Smoothing=1;
            if(segment_param->AtlasSmoothing.size()>0){
                Smoothing=segment_param->AtlasSmoothing[0];
                segment_param->AtlasSmoothing.clear();
                segment_param->AtlasSmoothing.push_back(Smoothing);
            }
        }
        NewBuiltTree->ProgressivePriorsAdaptation(segment_param);
        return NewBuiltTree;
    }
    
    
    
    int newNumbUsedModalities=numbUsedModalities+numberAddedModalities;
    if (numbUsedModalities+numberAddedModalities>numbTotalImages) {
        newNumbUsedModalities=numbTotalImages;
    }
    NormMask=segment_param->flag_NormMask;
    vector<nifti_image *> ReadImages=ReadFromFilenamesVectorProgressive(segment_param->filename_input, newNumbUsedModalities);
    nifti_image * NewImageToUse=CreateDataImage(ReadImages);
    int numbImages=ReadImages.size();
    for(int i=0;i<numbImages;i++){
        nifti_image_free(ReadImages[i]);
        ReadImages[i]=NULL;
    }
    nifti_set_filenames(NewImageToUse, "/Users/Carole/Documents/PhD/TemporaryFiles/NewData.nii.gz", 0, 0);
//    nifti_image_write(NewImageToUse);
    NewBuiltTree->SetData(NewImageToUse);
    if(!segment_param->flag_inDC){
    NewBuiltTree->NormaliseDataImage();
    }
    NewBuiltTree->ReinitialisationForModalityChange();
    
    // Build Temporary Tree to perform BF if needed
 // Meaning that there is need for some BF correction on new added modality
        // First copy Existing Tree
        TreeEM * TreeForBF=ExistingTree->CopyTree(NULL);
    TreeForBF->SaveAllClasses("/Users/Carole/Documents/PhD/TestClassesCopy.nii.gz ", segment_param);
        vector<nifti_image *> ReadImagesToBF=ReadFromFilenamesVectorProgressive(segment_param->filename_input,numberAddedModalities,numbUsedModalities);
        nifti_image* NewImageToBF=CreateDataImage(ReadImagesToBF);
    nifti_set_filenames(NewImageToBF, "/Users/Carole/Documents/PhD/TemporaryFiles/NewData.nii.gz", 0, 0);
//    nifti_image_write(NewImageToBF);
        int numbImagesBF=ReadImagesToBF.size();
        for (int i=0; i<numbImagesBF; i++) {
            nifti_image_free(ReadImagesToBF[i]);
            ReadImagesToBF[i]=NULL;
        }
    if (NewImageToBF==NULL) {
        delete TreeForBF;
        TreeForBF=NULL;
    }
    
    else{
        BForder=0;
        TreeForBF->SetData(NewImageToBF);
        if(!segment_param->flag_inDC){
        TreeForBF->NormaliseDataImage();
        }
        TreeForBF->MakeTreeBasic();
        
        
        TreeForBF->ReinitialisationForModalityChange();
//        TreeForBF->SavePriorsAdapted(segment_param);
        // Delete all children of main nodes
        //TreeForBF->InitialiseNormRespWithPriors();
        TreeForBF->InitialiseBasicTree(segment_param);
//        TreeForBF->SaveAllClasses("/Users/Carole/Documents/PhD/TestClasses.nii.gz", segment_param);
//        TreeForBF->SaveTmpResultMasked(TreeForBF->GetChild(0)->GetChild(0)->GetNormResp(), "/Users/Carole/Documents/PhD/Check.nii.gz");
        float CompleteLogLikelihood=0;
        float OldCompleteLogLikelihood=0;
        int Iteration=0;
        TreeForBF->RunFullEM(CompleteLogLikelihood, OldCompleteLogLikelihood, Iteration, segment_param);
    }
    
    if(segment_param->bias_order>0){
    // Create BFCoefficients from existing and TreeForBF
    int numbBF=(segment_param->bias_order+1)*(segment_param->bias_order+2)*(segment_param->bias_order+3)/6;
    int numbmodal=NewBuiltTree->GetNumberModalities();
    int sizeBFCoeffs=numbmodal*numbBF;
    float * BFCoeffsExisting=NULL;
    float * BFCoeffsTreeBF=NULL;
    BFCoeffsExisting=ExistingTree->GetBFCoeffs();
    if (TreeForBF!=NULL) {
        BFCoeffsTreeBF=TreeForBF->GetBFCoeffs();
    }
    
    
    float * BFCoeffsToSet=new float[sizeBFCoeffs];
    for (int j=0; j<newNumbUsedModalities*numbBF; j++) {
        BFCoeffsToSet[j]=0;
    }
    if (BFCoeffsExisting!=NULL) {
        for (int j=0; j<numbUsedModalities*numbBF; j++) {
            BFCoeffsToSet[j]=BFCoeffsExisting[j];
        }
    }
    if (BFCoeffsTreeBF!=NULL) {
        for (int j=0; j<numberAddedModalities*numbBF; j++) {
            BFCoeffsToSet[j+numbUsedModalities*numbBF]=BFCoeffsTreeBF[j];
        }
    }

    
//    // Recopy BF Coefficients and initialise DataBFCorrected
//    vector<int> BFOrderperModality;
//    for (int m=0; m<numbUsedModalities; m++) { // Careful must be sure that this order is truly attained when performing EM before and prevent EM from stopping before reaching the maximum number...
//        BFOrderperModality.push_back(segment_param->bias_order);
//    }
//    int numbTrulyAddedModalities=newNumbUsedModalities-numbUsedModalities;
//    for (int m=0; m<numbTrulyAddedModalities; m++) { // Initially no coeffs available for newly added modalities
//        BFOrderperModality.push_back(-1);
//    }
//    NewBuiltTree->SetBFCoeffsSeparated(ExistingTree->GetBFCoeffs(), BFOrderperModality);
//    float * NewDataBFCorrected=NewBuiltTree->MakeDataBFCorrectedSeparated(BFOrderperModality);
    NewBuiltTree->SetBFCoeffs(BFCoeffsToSet);
    if(BFCoeffsToSet!=NULL){
    delete [] BFCoeffsToSet;
    BFCoeffsToSet=NULL;
    }
        
    }
    if (TreeForBF!=NULL) {
        delete TreeForBF;
        TreeForBF=NULL;
    }
    BForder=segment_param->bias_order;
    float * DataBFCorrectedToUse=NewBuiltTree->MakeDataBFCorrected();
    NewBuiltTree->SetDataBFCorrected(DataBFCorrectedToUse);
    delete [] DataBFCorrectedToUse;
//    int numelmasked=NewBuiltTree->GetNumberMaskedElements();
//    NewBuiltTree->SaveTmpResultMasked(&NewDataBFCorrected[numelmasked],"/Users/Carole/Documents/PhD/TemporaryFiles/Mod2.nii.gz");
//    NewBuiltTree->SaveTmpResultMasked(NewDataBFCorrected,"/Users/Carole/Documents/PhD/TemporaryFiles/Mod1.nii.gz");
//    NewBuiltTree->SetDataBFCorrected(NewDataBFCorrected);
//    delete [] NewDataBFCorrected;
//    NewDataBFCorrected=NULL;
    NewBuiltTree->SaveBFCorrectedData("/Users/Carole/Documents/PhD/TemporaryFiles/TestDataCorrected2.nii.gz");
    // Copy again NormResp that has been suppressed with the reinitialisation
    NewBuiltTree->RepopulateNormResp(ExistingTree);
    cout<<"NewBuiltTree repopulated"<<endl;
    NewBuiltTree->UpdateParameters();
    // Change of outlier priors if need be associated to new dimensionality.
    bool ValidityNewTree=NewBuiltTree->CheckForTreeValidity();
    if (ValidityNewTree==0) {
        cout<<"NewBuiltTree appears to be invalid..."<<endl;
    }
    cout<<"Parameters updated"<<endl;
    if (NewBuiltTree->GetFlagOutliers()>0) {
        nifti_image * NewOutliersPriors=NewBuiltTree->BuildOutliersPriors(segment_param);
        nifti_image * NewInliersPriors=NewBuiltTree->CreateNormaliseOppositeImage(NewOutliersPriors);
        NewBuiltTree->GetNodeInlier()->SetPriors(NewInliersPriors);
        NewBuiltTree->GetNodeOutlier()->SetPriors(NewOutliersPriors);
    }
    // Change of Priors Adapted according to segment_param->ProgressivePriors and using AtlasWeight and AtlasSmoothing if need be
    NewBuiltTree->ProgressivePriorsAdaptation(segment_param);
    NewBuiltTree->ResuscitateUniform(segment_param);
    cout<<"Needed uniform resuscitated"<<endl;
    NewBuiltTree->UpdateNonNormResp(segment_param);
    cout<<"New update for non norm resp"<<endl;
    NewBuiltTree->UpdateNormResp();
    NewBuiltTree->UpdateNormRespRoot();
    
    if(segment_param->flag_MRF){
        float * GMatrixToSet=NULL;
        if(segment_param->flag_GMatrixIn){
//            GMatrixToSet =NewBuiltTree->PrepareGMatrixFromFile(segment_param->filename_GMatrix,segment_param->flag_optMRFOut);
            GMatrixToSet=NewBuiltTree->CreateGMatrixFromInfo(segment_param->flag_optMRFOut, segment_param->filename_GMatrix);
            NewBuiltTree->SetGMatrix(GMatrixToSet);
            if(GMatrixToSet==NULL){
                segment_param->flag_GMatrix=0;
            }
            else{
                delete [] GMatrixToSet;
                GMatrixToSet=NULL;
            }
        }
        else {
            GMatrixToSet=NewBuiltTree->MRFOptSolveLS(segment_param);
            if(GMatrixToSet!=NULL){
                delete [] GMatrixToSet;
                GMatrixToSet=NULL;
            }
        }
    }
    if(segment_param->flag_MRF){
        NewBuiltTree->UpdateMRF(segment_param);
    }
    
    NewBuiltTree->UpdateNonNormWeights();
    NewBuiltTree->UpdateNormWeights();
    NewBuiltTree->UpdateParameters();
    BFFlag=0;
    cout<<"New modality completely added "<<endl;
    return NewBuiltTree;
}

// Returns the index of the first non NULL pointer in the ImagesVector considered
int TreeEM::FirstNotNULL(vector<nifti_image *> ImagesVector){
    if (ImagesVector.size()==0){
        std::cout<< "No image in vector"<<endl;
        return -1;
    }
    int finn = ImagesVector.size();
    for (int i=ImagesVector.size()-1; i>=0; i--) {
        if (ImagesVector[i]!=NULL){
            finn=i;
        }
    }
    return finn;
}

// Returns the index of the last non NULL pointer to a nifti_image in the ImageVector considered
int TreeEM::LastNotNULL(vector<nifti_image *> ImagesVector){
    if (ImagesVector.size()==0) {
        return -2;
    }
    int linn=0;
    int sizeVector=ImagesVector.size();
    for (int i=0; i<sizeVector; i++) {
        if (ImagesVector[i]!=NULL) {
            linn=i;
        }
    }
    return linn;
}

nifti_image * TreeEM::CreateDataImage(vector<nifti_image*> ImagesToSegment){
    int finn=FirstNotNULL(ImagesToSegment);
    int linn=LastNotNULL(ImagesToSegment);
    std::cout<< "First not Null is "<<finn<< " and last is "<< linn<<endl;
    if (linn-finn<0) {
        std::cout<<"No Images To Segment"<<endl;
        return NULL;
    }
    int nx=ImagesToSegment[finn]->nx;
    int ny=ImagesToSegment[finn]->ny;
    int nz=ImagesToSegment[finn]->nz;
    nifti_image * CreatedImage=NULL;
    if ((linn-finn)<0) { // no image in the vector
        std::cout<<"no image in the vector"<<endl;
        return CreatedImage;
    }
    else if((finn-linn)==0){ // only one image in the vector but can already be multimodal
        std::cout<<"only one image in the vector"<<endl;
        if (ImagesToSegment[finn]->datatype!=NIFTI_TYPE_FLOAT32){
            seg_changeDatatype<float>(ImagesToSegment[finn]);
        }
        CreatedImage =nifti_copy_nim_info(ImagesToSegment[finn]);
        float * ImageDataPtr=static_cast<float *>(ImagesToSegment[finn]->data);
        CreatedImage->data = (void *) calloc(CreatedImage->nvox, sizeof(float));
        
        float * CreatedImage_PTR_start=static_cast<float *>(CreatedImage->data);
        
        float * CreatedImage_PTR=CreatedImage_PTR_start;
        int numbvoxCreated=CreatedImage->nvox;
        for (int i=0; i<numbvoxCreated; i++ ,CreatedImage_PTR++, ImageDataPtr++) {
            (*CreatedImage_PTR)=(*ImageDataPtr);
        }
        return CreatedImage;
    }
    else{ // for the moment only handle images with only 3 D and not 4D
        std::cout<<"There are "<<linn-finn+1<<" images to consider"<<endl;
        
        int numbmulti=0;
        for (int i=finn; i<=linn; i++) {
            if(ImagesToSegment[i]!=NULL){
                
                if (ImagesToSegment[finn]->datatype!=NIFTI_TYPE_FLOAT32){
                    seg_changeDatatype<float>(ImagesToSegment[i]);
                }
                //                numbmulti+=ImagesToSegment[i]->nu*ImagesToSegment[i]->nt;
                numbmulti++;
            }
        }
        CreatedImage =nifti_copy_nim_info(ImagesToSegment[finn]);
        CreatedImage->dim[0]=4;
        CreatedImage->dim[4]=numbmulti;
        CreatedImage->dim[5]=1;
        nifti_update_dims_from_array(CreatedImage);
        CreatedImage->data = (void *) calloc(CreatedImage->nvox, sizeof(float));
        float * CreatedImage_PTR_start=static_cast<float *>(CreatedImage->data);
        float * ImageDataPtr;
        float * CreatedImage_PTR=CreatedImage_PTR_start;
        for (int m=finn; m<=linn; m++) {
            if (ImagesToSegment[m]!=NULL) {
                if( ImagesToSegment[m]->nx!=nx || ImagesToSegment[m]->ny!=ny || ImagesToSegment[m]->nz!=nz){
                    std::cout<<"Not compatible dimensions"<<endl;
                }
                else{
                    int numel=ImagesToSegment[m]->nx*ImagesToSegment[m]->ny*ImagesToSegment[m]->nz;
                    std::cout<<"Compatible dimensions"<<endl;
                    seg_changeDatatype<float>(ImagesToSegment[m]);
                    ImageDataPtr=static_cast<float *>(ImagesToSegment[m]->data);
                    //                    for (int i=0; i<ImagesToSegment[m]->nvox; i++) {
                    for(int i=0;i<numel;i++){
                        (*CreatedImage_PTR)=(*ImageDataPtr);
                        CreatedImage_PTR++;
                        ImageDataPtr++;
                    }
                }
            }
        }
        //        for (int i=finn; i<=linn; i++) {
        //            nifti_image_free(ImagesToSegment[i]);
        //        }
        //        ImagesToSegment.clear();
        //        nifti_set_filenames(CreatedImage,"/Users/Carole/Documents/PhD/CreatedImage.nii.gz",0,0);
        //        nifti_image_write(CreatedImage);
        return CreatedImage;
    }
}



vector<nifti_image *> TreeEM::ReadFromFilenamesVectorProgressive(vector<string> Filenames, int numbElementsToRead, int begin){
    vector<nifti_image *> VectorImages;
    int numbMaxFilenames=Filenames.size();
    if (numbElementsToRead<=0) {
        return VectorImages;
    }
    if (numbMaxFilenames<numbElementsToRead+begin) {
        VectorImages=ReadFromFilenamesVector(Filenames);
        return VectorImages;
    }
    vector<string> PartVectorFilenames;
    for (int i=begin; i<numbElementsToRead+begin; i++) {
        PartVectorFilenames.push_back(Filenames[i]);
    }
    VectorImages=ReadFromFilenamesVector(PartVectorFilenames);
    return VectorImages;
    
}

float TreeEM::GetMahalDist(float * ValueArray, float * MeanArray, float * InvertVarianceArray, int numbmodal){
    float ResultMahal=0;
    
    for (int m1=0; m1<numbmodal; m1++) {
        float tmp=0;
        for (int m2=0; m2<numbmodal; m2++) {
            tmp+=InvertVarianceArray[m1*numbmodal+m2]*(ValueArray[m2]-MeanArray[m2]);
        }
        ResultMahal+=tmp*(ValueArray[m1]-MeanArray[m1]);
    }
    ResultMahal=sqrtf(ResultMahal);
    return ResultMahal;
}


/************************************** METHODS TO AVOID ISLANDS / HOLES in WM ****************************************************/

/* Methods for component labeling and related to obtained the main component elements */
int * TreeEM::ComponentLabeling(float * ImageToLabel, int Neigh, int * Dim, int * Shift, float thresh){
 int numel=Dim[0]*Dim[1]*Dim[2];
 int Label=0;
 //Initialisation of looked elements and labels
 int * PositionTmp=new int[numel];
 int * ComponentsLabel=new int[numel];
 for (int i=0;i<numel;i++){
 PositionTmp[i]=0;
 ComponentsLabel[i]=0;
 }
 for(int x=0;x<Dim[0];x++){
 for(int y=0;y<Dim[1];y++){
 for(int z=0;z<Dim[2];z++){
 int CurrentIndex=x*Shift[0]+y*Shift[1]+z*Shift[2];
 if(ImageToLabel[CurrentIndex]>thresh && PositionTmp[CurrentIndex]==0 && ComponentsLabel[CurrentIndex]==0){
 PositionTmp[CurrentIndex]=1;
 ComponentsLabel[CurrentIndex]=Label++;
 //                    cout<<"Changing to label "<<Label<<endl;
 int Times=0;
 RecurseCompLabel(ImageToLabel,PositionTmp,Label,ComponentsLabel,Neigh,Dim,Shift,thresh,Times);
 //                    cout<<"out of loop Now Times is "<<endl;
 }
 }
 }
 }
 //    cout<<"Final label is "<<Label<<endl;
 
 //    nifti_image * ImageBorderCSF=nifti_copy_nim_info(SegToAnalyse);
 //    ImageBorderCSF->data=(void *) calloc(SegToAnalyse->nvox, sizeof(float));
 //    float * ImageBorderCSF_PTR=static_cast<float *>(ImageBorderCSF->data);
 //    for (int i=0; i<numel; i++) {
 //        ImageBorderCSF_PTR[i]=(float)ComponentsLabel[i];
 //    }
 //    nifti_set_filenames(ImageBorderCSF, "/Users/Carole/Documents/PhD/TemporaryFiles/SABRE09/BorderComponent.nii.gz", 0, 0);
 //    nifti_image_write(ImageBorderCSF);
 
 RepassComponentsLabel(ComponentsLabel, Neigh,Dim,Shift);
// RefineNeighbourhood(ComponentsLabel,Dim,Shift);
 RelabelComponents(ComponentsLabel,Dim);
 delete [] PositionTmp;
 PositionTmp=NULL;
 int maxLabel=-1;
 for(int i=0;i<numel;i++){
 if(ComponentsLabel[i]>maxLabel){
 maxLabel=ComponentsLabel[i];
 }
 }
 //    cout<<"Number of components is "<<maxLabel;
 return ComponentsLabel;
 }

// Recursive function allowing for the building of connected components given the soft segmentation, binarised with thresh.
void TreeEM::RecurseCompLabel(float * Data, int * PositionTmp, int Label, int * ComponentsLabel,int Neigh,int * Dim,int * Shift, float thresh,int& Times){
    int numel=Dim[0]*Dim[1]*Dim[2];
    if(Times==1000){
        cout<<"Have to go out"<<endl;
        return;
    }
    else{
        for(int i=0;i<numel;i++){
            if(PositionTmp[i]==1 && Times<1000){
                //            int * NeighboursToLook=GetListNeighboursToLook(i, Dim,Shift);
                int * NeighboursToLook=GetListNeighbours(i, Dim, Shift, Neigh);
                int CountNeighboursBelongingToSame=0;
                for(int n=0;n<Neigh;n++){
                    if(Data[NeighboursToLook[n]]>=thresh && ComponentsLabel[NeighboursToLook[n]]==0){
                        PositionTmp[NeighboursToLook[n]]=1;
                        ComponentsLabel[NeighboursToLook[n]]=Label;
                        CountNeighboursBelongingToSame++;
                    }
                }
                // cout<<CountNeighboursBelongingToSame<<" neighbours in same lesion"<<endl;
                delete [] NeighboursToLook;
                NeighboursToLook=NULL;
                PositionTmp[i]=2;
                //Times++;
                //            RecurseCompLabel(Data, PositionTmp, Label, ComponentsLabel, Dim, Shift, thresh,Times);
            }
        }
        Times++;
    }
    //    cout<<"Times is "<<Times<<endl;
    bool flag_pos1=0;
    for (int i=0; i<numel; i++) {
        if (PositionTmp[i]==1) {
            flag_pos1=1;
            //            cout<<"Still something in Position...";
            break;
        }
    }
    
    //    Times=0;
    if (flag_pos1) { // Recursive call on RecurseCompLabel, given the updated positionTmp and ComponentsLabel. Performed if there is still one voxel that has to be considered but has not been treated.
        RecurseCompLabel(Data, PositionTmp, Label, ComponentsLabel,Neigh, Dim, Shift,thresh,Times);
    }
    return;
    //
}

// Given the current ComponentLabel integer array of labels for the connected components of lesion, modify the labelling so that there is no gap in the labeling (consecutive label integers). Note that discontinuity can occurr when suppressing lesion components due to incoherence or size limitation. Processed in a recursive way until no gap anymore
void TreeEM::RelabelComponents(int * ComponentsLabel, int * Dim){
    int numel=Dim[0]*Dim[1]*Dim[2];
    int maxLabel=GetMaxArray(ComponentsLabel, numel);
    bool flag_change=0;
    for (int l=0 ; l<maxLabel; l++) {
        int Size=GetLabelSize(l+1, ComponentsLabel, numel);
        if (Size==0) {
            flag_change=1;
            for (int i=0; i<numel; i++) {
                if (ComponentsLabel[i]>l+1) {
                    ComponentsLabel[i]--;
                }
            }
        }
    }
    if (flag_change) { // Recursive call to RelabelComponents.
        cout<<"Again change... "<<endl;
        RelabelComponents(ComponentsLabel, Dim);
    }
    
}

// Recursive functions on the labeling integer array making sure that it only one label is used for neighborhing regions. To avoid connected regions to be labelled differently.
void TreeEM::RepassComponentsLabel(int * ComponentsLabel, int Neigh,int * Dim,int * Shift){
    int numel=Dim[0]*Dim[1]*Dim[2];
//    int maxLabel=GetMaxArray(ComponentsLabel, numel);
    int CountChange=0;
    for (int i=0; i<numel; i++) {
        if (ComponentsLabel[i]>0) {
            //            int * ListNeighboursToLook=GetListNeighboursToLook(i, Dim,Shift);
            int * ListNeighboursToLook=GetListNeighbours(i, Dim, Shift, Neigh);
            int LabelTmp=ComponentsLabel[i];
            for (int n=0; n<Neigh; n++) {
                int LabelNeigh=ComponentsLabel[ListNeighboursToLook[n]];
                if (LabelNeigh>0 && LabelNeigh!=LabelTmp) {
                    if (LabelTmp>LabelNeigh) {
                        ComponentsLabel[i]=LabelNeigh;
                    }
                    else{
                        ComponentsLabel[ListNeighboursToLook[n]]=LabelTmp;
                    }
                    CountChange ++;
                }
            }
            delete [] ListNeighboursToLook;
            ListNeighboursToLook=NULL;
        }
    }
    //    cout<<CountChange<<" changes after repass"<<endl;
    if(CountChange>0){ // Recursive call to RepassComponentsLabel
        RepassComponentsLabel(ComponentsLabel, Neigh,Dim,Shift);
    }
}


void TreeEM::GetListNeighbours_bis(int * ListNeighbours, int CurrentIndex, int * Dim, int * Shift,int NeighbouringType){
    //    int * CorrespondingIndex=new int[3];
    int CorrespondingIndex[3];
    int tmp=CurrentIndex;
    for(int i=2;i>=0;i--){
        CorrespondingIndex[i]=(int)tmp/Shift[i];
        tmp-=CorrespondingIndex[i]*Shift[i];
    }
    int numel=Dim[0]*Dim[1]*Dim[2];
    int neigh=0;
    
    switch (NeighbouringType) {
        case 6:{
            for (int n=0; n<6; n++) {
                ListNeighbours[n]=0;
            }
            for(int x=-1;x<=1;x++){
                for(int y=-1;y<=1;y++){
                    for(int z=-1;z<=1;z++){
                        if((abs(z)+abs(x)+abs(y))==1){ // the voxel itself is not part of its list of neighbours
                            //                            int * newIndex=new int[3];
                            int newIndex[3];
                            newIndex[0]=CorrespondingIndex[0]+x;
                            newIndex[1]=CorrespondingIndex[1]+y;
                            newIndex[2]=CorrespondingIndex[2]+z;
                            bool outBorder=0;
                            for(int d=0;d<3;d++){
                                if(newIndex[d]<0 || newIndex[d]>Dim[d]-1){
                                    outBorder=1;
                                    break;
                                }
                            }
                            neigh=abs(x)*0 + abs(y)*2 + abs(z)*4; // Simply to be sure that in list first 2 correspond to WE, then NS then TB
                            if(x+y+z>0){
                                neigh++;
                            }
                            if(!outBorder){
                                ListNeighbours[neigh]=newIndex[0]*Shift[0]+newIndex[1]*Shift[1]+newIndex[2]*Shift[2];
                                if(ListNeighbours[neigh]>numel || ListNeighbours[neigh]<0){
                                    cout<<"Pb with neigh "<<neigh;
                                }
                            }
                            else{
                                ListNeighbours[neigh]=(CurrentIndex);
                            }
                            //                            delete [] newIndex;
                            //                            newIndex=NULL;
                        }
                    }
                }
            }
        }
            break;
        case 18:{
            for (int n=0; n<18; n++) {
                ListNeighbours[n]=0;
            }
            for(int x=-1;x<=1;x++){
                for(int y=-1;y<=1;y++){
                    for(int z=-1;z<=1;z++){
                        int SumNeigh=abs(x)+abs(y)+abs(z);
                        if(SumNeigh>=1 && SumNeigh<=2){ // the voxel itself is not part of its list of neighbours
                            //                            int * newIndex=new int[3];
                            int newIndex[3];
                            newIndex[0]=CorrespondingIndex[0]+x;
                            newIndex[1]=CorrespondingIndex[1]+y;
                            newIndex[2]=CorrespondingIndex[2]+z;
                            
                            bool outBorder=0;
                            for(int d=0;d<3;d++){
                                if(newIndex[d]<0 || newIndex[d]>Dim[d]-1){
                                    outBorder=1;
                                    break;
                                }
                            }
                            if(!outBorder){
                                ListNeighbours[neigh]=(newIndex[0]*Shift[0]+newIndex[1]*Shift[1]+newIndex[2]*Shift[2]);
                                if(ListNeighbours[neigh]>numel || ListNeighbours[neigh]<0){
                                    cout<<"Pb with neigh "<<neigh;
                                }
                            }
                            else{
                                ListNeighbours[neigh]=(CurrentIndex);
                            }
                            neigh++;
                        }
                    }
                }
            }
            
        }
            break;
        case 26:{
            for (int n=0; n<26; n++) {
                ListNeighbours[n]=0;
            }
            for(int x=-1;x<=1;x++){
                for(int y=-1;y<=1;y++){
                    for(int z=-1;z<=1;z++){
                        if((abs(z)||abs(x)||abs(y))){ // the voxel itself is not part of its list of neighbours
                            //                            int * newIndex=new int[3];
                            int newIndex[3];
                            newIndex[0]=CorrespondingIndex[0]+x;
                            newIndex[1]=CorrespondingIndex[1]+y;
                            newIndex[2]=CorrespondingIndex[2]+z;
                            
                            bool outBorder=0;
                            for(int d=0;d<3;d++){
                                if(newIndex[d]<0 || newIndex[d]>Dim[d]-1){
                                    outBorder=1;
                                    break;
                                }
                            }
                            if(!outBorder){
                                ListNeighbours[neigh]=(newIndex[0]*Shift[0]+newIndex[1]*Shift[1]+newIndex[2]*Shift[2]);
                                if(ListNeighbours[neigh]>numel || ListNeighbours[neigh]<0){
                                    cout<<"Pb with neigh "<<neigh;
                                }
                            }
                            else{
                                ListNeighbours[neigh]=(CurrentIndex);
                            }
                            neigh++;
                        }
                    }
                }
            }
            
        }
            break;
        default:
            break;
    }
}




// Returns in a array of integers the indices of the neighbours of the CurrentIndex given information of the dimensions of the image and the type of adjacency chosen (6 - 18 - 26)
int * TreeEM::GetListNeighbours(int CurrentIndex, int * Dim, int * Shift, int NeighbourhingType){
    int *ListNeighbours=NULL;
    //    int * CorrespondingIndex=new int[3];
    int CorrespondingIndex[3];
    int tmp=CurrentIndex;
    for(int i=2;i>=0;i--){
        CorrespondingIndex[i]=(int)tmp/Shift[i];
        tmp-=CorrespondingIndex[i]*Shift[i];
    }
    int numel=Dim[0]*Dim[1]*Dim[2];
    int neigh=0;
    
    switch (NeighbourhingType) {
        case 6:{
            ListNeighbours=new int[6];
            for (int n=0; n<6; n++) {
                ListNeighbours[n]=0;
            }
            for(int x=-1;x<=1;x++){
                for(int y=-1;y<=1;y++){
                    for(int z=-1;z<=1;z++){
                        if((abs(z)+abs(x)+abs(y))==1){ // the voxel itself is not part of its list of neighbours
                            //                            int * newIndex=new int[3];
                            int newIndex[3];
                            newIndex[0]=CorrespondingIndex[0]+x;
                            newIndex[1]=CorrespondingIndex[1]+y;
                            newIndex[2]=CorrespondingIndex[2]+z;
                            bool outBorder=0;
                            for(int d=0;d<3;d++){
                                if(newIndex[d]<0 || newIndex[d]>Dim[d]-1){
                                    outBorder=1;
                                    break;
                                }
                            }
                            neigh=abs(x)*0 + abs(y)*2 + abs(z)*4; // Simply to be sure that in list first 2 correspond to WE, then NS then TB
                            if(x+y+z>0){
                                neigh++;
                            }
                            if(!outBorder){
                                ListNeighbours[neigh]=newIndex[0]*Shift[0]+newIndex[1]*Shift[1]+newIndex[2]*Shift[2];
                                if(ListNeighbours[neigh]>numel || ListNeighbours[neigh]<0){
                                    cout<<"Pb with neigh "<<neigh;
                                }
                            }
                            else{
                                ListNeighbours[neigh]=(CurrentIndex);
                            }
                            //                            delete [] newIndex;
                            //                            newIndex=NULL;
                        }
                    }
                }
            }
        }
            break;
        case 18:{
            ListNeighbours=new int[18];
            for (int n=0; n<18; n++) {
                ListNeighbours[n]=0;
            }
            for(int x=-1;x<=1;x++){
                for(int y=-1;y<=1;y++){
                    for(int z=-1;z<=1;z++){
                        int SumNeigh=abs(x)+abs(y)+abs(z);
                        if(SumNeigh>=1 && SumNeigh<=2){ // the voxel itself is not part of its list of neighbours
                            //                            int * newIndex=new int[3];
                            int newIndex[3];
                            newIndex[0]=CorrespondingIndex[0]+x;
                            newIndex[1]=CorrespondingIndex[1]+y;
                            newIndex[2]=CorrespondingIndex[2]+z;
                            
                            bool outBorder=0;
                            for(int d=0;d<3;d++){
                                if(newIndex[d]<0 || newIndex[d]>Dim[d]-1){
                                    outBorder=1;
                                    break;
                                }
                            }
                            if(!outBorder){
                                ListNeighbours[neigh]=(newIndex[0]*Shift[0]+newIndex[1]*Shift[1]+newIndex[2]*Shift[2]);
                                if(ListNeighbours[neigh]>numel || ListNeighbours[neigh]<0){
                                    cout<<"Pb with neigh "<<neigh;
                                }
                            }
                            else{
                                ListNeighbours[neigh]=(CurrentIndex);
                            }
                            neigh++;
                            //                            delete [] newIndex;
                            //                            newIndex=NULL;
                        }
                    }
                }
            }
            
        }
            break;
        case 26:{
            ListNeighbours=new int[26];
            for (int n=0; n<26; n++) {
                ListNeighbours[n]=0;
            }
            for(int x=-1;x<=1;x++){
                for(int y=-1;y<=1;y++){
                    for(int z=-1;z<=1;z++){
                        if((abs(z)||abs(x)||abs(y))){ // the voxel itself is not part of its list of neighbours
                            //                            int * newIndex=new int[3];
                            int newIndex[3];
                            newIndex[0]=CorrespondingIndex[0]+x;
                            newIndex[1]=CorrespondingIndex[1]+y;
                            newIndex[2]=CorrespondingIndex[2]+z;
                            
                            bool outBorder=0;
                            for(int d=0;d<3;d++){
                                if(newIndex[d]<0 || newIndex[d]>Dim[d]-1){
                                    outBorder=1;
                                    break;
                                }
                            }
                            if(!outBorder){
                                ListNeighbours[neigh]=(newIndex[0]*Shift[0]+newIndex[1]*Shift[1]+newIndex[2]*Shift[2]);
                                if(ListNeighbours[neigh]>numel || ListNeighbours[neigh]<0){
                                    cout<<"Pb with neigh "<<neigh;
                                }
                            }
                            else{
                                ListNeighbours[neigh]=(CurrentIndex);
                            }
                            neigh++;
                            //                            delete [] newIndex;
                            //                            newIndex=NULL;
                        }
                    }
                }
            }
            
        }
            break;
        default:
            break;
    }
    //    delete [] CorrespondingIndex;
    //    CorrespondingIndex=NULL;
    return ListNeighbours;
}


/* Returns in a array of size all possible modalities available their presence or absence with the index in the modality sequence if available. -1 when the given modality is not part of the used ones. The indices of the array follow the rules:
 0=T1 ; 1=T2 ; 2=FLAIR ; 3=PD ; 4=SWI;
 */

int * TreeEM::GetCorrespondingModality(SEG_PARAMETERS * segment_param){
    int * CorrespondingModalities=new int [5];
    for (int i=0;i<5;i++){
        CorrespondingModalities[i]=-1;
    }
    int * Modalities=this->GetModalities(segment_param);
    int numbmodal=this->GetNumberModalities();
    for(int m=0;m<numbmodal;m++){
        CorrespondingModalities[Modalities[m]-1]=m;
    }
    delete [] Modalities;
    return CorrespondingModalities;
}

void TreeEM::CorrectWMOforCSFInclusion(SEG_PARAMETERS * segment_param){
    int * HardSeg=this->GetHardSeg();
    int * Modalities=this->GetModalities(segment_param);
    int * ModIndexTable= this->GetCorrespondingModality(segment_param);
    int IndexCSF=segment_param->IndexCSF;
    int IndexWM=segment_param->IndexWM;
    int IndexGM=segment_param->IndexGM;
    vector<float *> MeanGeneralClasses=this->GetMeanGeneralClassesVector();
    float * WMONormResp=this->GetNodeOutlier()->GetChild(IndexWM)->GetNormResp();
    float * CSFNormResp=this->GetNodeInlier()->GetChild(IndexCSF)->GetNormResp();
    int numbclasses=MeanGeneralClasses.size();
    float * DataBFCorrected=this->GetDataBFCorrected();
//    At the beginning make it so that everything that looks like CSF is classified as such. Will be corrected for lacune problems when avoiding holes afterwards
    int numelmasked=this->GetNumberMaskedElements();
    for(int i=0;i<numelmasked;i++){
        if(HardSeg[i]==numbclasses){
            float * MeanToCompareCSF=MeanGeneralClasses[IndexCSF];
            float * MeanToCompareGM=MeanGeneralClasses[IndexGM];
            bool flag_CSFToChange=1;
            if(ModIndexTable[0]>=0){
                if(!(DataBFCorrected[i+numelmasked*ModIndexTable[0]]<MeanToCompareGM[ModIndexTable[0]])){
                    flag_CSFToChange=0;
                }
            }
            if(ModIndexTable[2]>=0) { //
                if(! (DataBFCorrected[i+numelmasked*ModIndexTable[2]] <=MeanToCompareCSF[ModIndexTable[2]])){
                    flag_CSFToChange=0;
                }
            }
            if(flag_CSFToChange){ // Putting back the WMO into CSF
                CSFNormResp[i]+=WMONormResp[i];
                WMONormResp[i]=0;
            }
            }
        }
    delete [] Modalities;
    delete [] ModIndexTable;
    Modalities=NULL;
    ModIndexTable=NULL;
    }

float * TreeEM::GetLesionGMCSFSeg(int * HardSeg, int IndexClass, SEG_PARAMETERS * segment_param){
    float * NormRespOutlierLeave=this->GetNodeOutlier()->GetChild(IndexClass)->GetNormResp();
    int * ModIndexTable=this->GetCorrespondingModality(segment_param);
    int numelmasked=this->GetNumberMaskedElements();
    int numel=this->GetNumberElements();
    int IndexWM=segment_param->IndexWM;
    int IndexGM=segment_param->IndexGM;
    int IndexCSF=segment_param->IndexCSF;
    int IndexOut=segment_param->IndexOut;
//    int * S2L=this->GetS2L();
    int * L2S=this->GetL2S();
    float * LesionSegSpec=new float[numelmasked];
    float * DataCorrected=this->GetDataBFCorrected();
    int numbchild=this->GetNumberGeneralClasses();
    nifti_image * BasisImage=this->GetDataImage();
    int Dim[3];
    int Shift[3];
    for(int d=0;d<3;d++){
        Dim[d]=BasisImage->dim[d+1];
    }
    Shift[0]=1;
    Shift[1]=Dim[0];
    Shift[2]=Shift[1]*Dim[2];
    vector<float *> MeanGeneralClasses=this->GetMeanGeneralClassesVector();
    // First get all the elements that satisfy the lesion rules of hyperintensity compared to WM
    for(int i=0;i<numelmasked;i++){
        LesionSegSpec[i]=0;
        if(HardSeg[i]==numbchild){ // meaning that the considered voxel is classified as outlier
    if (ModIndexTable[2]>=0){ // meaning that the FLAIR modality is used in our case
        int IndexFLAIR=ModIndexTable[2];
        if(DataCorrected[i+numelmasked*IndexFLAIR]>MeanGeneralClasses[IndexWM][IndexFLAIR]){
            LesionSegSpec[i]=NormRespOutlierLeave[i];
        }
    }
    else if(ModIndexTable[1]>=0){ // we have only a T2 to base the lesion segmentation rule
        int IndexT2=ModIndexTable[1];
        if(DataCorrected[i+numelmasked*IndexT2]>MeanGeneralClasses[IndexWM][IndexT2]){
            LesionSegSpec[i]=NormRespOutlierLeave[i];
        }
    }
    }
    }
    // Secondly retrieve from there the connected components the proportion of neighbours for each individual element
        float * LesionLong=MakeLong(LesionSegSpec, L2S, numel);
        int * HardSegLong=MakeLongPad(HardSeg, -1,L2S,numel);
        int * LesionSegTempConnected=ComponentLabeling(LesionLong, 26, Dim , Shift, 0.1);
        int MaxLabel=GetMaxArray(LesionSegTempConnected, numel);
    
//    If the proportion of WM + Outlier elements in neighborhood is higher than the other, reclassify as lesion and set the final result at the value of the corresponding NormResp
        for(int l=0;l<MaxLabel;l++){
            float * ProportionNeighTemp=this->ProportionNeighboursLesion(LesionSegTempConnected, l+1, HardSegLong, segment_param);
            if(ProportionNeighTemp[IndexWM]+ProportionNeighTemp[numbchild]<ProportionNeighTemp[IndexGM] || ProportionNeighTemp[IndexWM]+ProportionNeighTemp[numbchild]<ProportionNeighTemp[IndexCSF] || ProportionNeighTemp[IndexWM]+ProportionNeighTemp[numbchild]<ProportionNeighTemp[IndexOut]   ){
                vector<int> LesionIndices=this->GetIndicesValue(LesionSegTempConnected,l+1,numel);
                int SizeIndices=LesionIndices.size();
                for(int s=0;s<SizeIndices;s++){
                    LesionSegSpec[L2S[LesionIndices[s]]]=0;
                }
            }
            if(ProportionNeighTemp!=NULL){
                delete [] ProportionNeighTemp;
                ProportionNeighTemp=NULL;
            }
        }
//    Clearing memory before returning result
    for(int c=0;c<numbchild;c++){
        if(MeanGeneralClasses[c] !=NULL){
            delete [] MeanGeneralClasses[c];
            MeanGeneralClasses[c]=NULL;
        }
    }
    if(ModIndexTable!=NULL){
        delete [] ModIndexTable;
    }
    if(LesionLong!=NULL){
        delete [] LesionLong;
        LesionLong=NULL;
    }
    if(HardSegLong!=NULL){
        delete [] HardSegLong;
        HardSegLong=NULL;
    }
    if(LesionSegTempConnected!=NULL){
        delete [] LesionSegTempConnected;
        LesionSegTempConnected=NULL;
    }
    
    return LesionSegSpec;
}


// For all the Labels in the integer array containing the Labels, return in an integer array of size numbLabels the number of voxels of each lesion label
int * TreeEM::GetVolumeLabels(int * ComponentLabel, int numel){
    int maxLabel=-1;
    for(int i=0;i<numel;i++){
        if(ComponentLabel[i]>maxLabel){
            maxLabel=ComponentLabel[i];
        }
    }
    if(maxLabel==0){
        return NULL;
    }
    int * VolumeLabels=new int [maxLabel];
    for(int l=0;l<maxLabel;l++){
        VolumeLabels[l]=0;
    }
    for(int l=1;l<=maxLabel;l++){
        int TmpVolume=0;
        for(int i=0;i<numel;i++){
            if(ComponentLabel[i]==l){
                TmpVolume++;
            }
        }
        VolumeLabels[l-1]=TmpVolume;
    }
    return VolumeLabels;
}

// Returns the modified array of integer of size numel containing the initial labels into the labels by ordered volume
int * TreeEM::OrderedVolumeLabel(int * ComponentLabels, int MiniSize, int numel){
    int maxLabel=GetMaxArray(ComponentLabels, numel);
    int * VolumeLabels=GetVolumeLabels(ComponentLabels, numel);
    int * OldVolumeLabels=new int [maxLabel];
    for (int l=0; l<maxLabel; l++) {
        OldVolumeLabels[l]=VolumeLabels[l];
    }
    int * OrderedLabels=GetCorrespondanceOrderedVolume(VolumeLabels, maxLabel);
    int * NewComponentsOrderedLabel=new int[numel];
    for(int i=0;i<numel;i++){
        NewComponentsOrderedLabel[i]=ComponentLabels[i];
        if(ComponentLabels[i]!=0){
            NewComponentsOrderedLabel[i]=OrderedLabels[ComponentLabels[i]-1];
        }
        if(ComponentLabels[i]>0 && OldVolumeLabels[ComponentLabels[i]-1]<MiniSize){
            cout<<"Discarding because below mini size of "<<MiniSize<<endl;
            NewComponentsOrderedLabel[i]=0;
        }
    }
    cout<<" new max Label is "<<GetMaxArray(NewComponentsOrderedLabel, numel);
    delete [] VolumeLabels;
    delete [] OrderedLabels;
    delete [] OldVolumeLabels;
    VolumeLabels=NULL;
    OrderedLabels=NULL;
    OldVolumeLabels=NULL;
    return NewComponentsOrderedLabel;
}


// Correspondance between Label as it is obtained initially and index in term of decreasing volume
int * TreeEM::GetCorrespondanceOrderedVolume(int * VolumeLabels, int maxLabel){
    int * CorrespondingOrderedLabels=new int[maxLabel];
    int * CorrespondanceOrderedLabels=new int[maxLabel];
    for(int l=0;l<maxLabel;l++){
        CorrespondingOrderedLabels[l]=l+1;
        CorrespondanceOrderedLabels[l]=l+1;
    }
    bool flag_swap=1;
    while(flag_swap==1){
        flag_swap=0;
        for(int l=0;l<maxLabel-1;l++){
            if(VolumeLabels[l]<VolumeLabels[l+1]){
                int tmp1=VolumeLabels[l];
                int tmp2=VolumeLabels[l+1];
                int indTmp1=CorrespondingOrderedLabels[l];
                int indTmp2=CorrespondingOrderedLabels[l+1];
                VolumeLabels[l]=tmp2;
                VolumeLabels[l+1]=tmp1;
                CorrespondingOrderedLabels[l]=indTmp2;
                CorrespondingOrderedLabels[l+1]=indTmp1;
                flag_swap=1;
            }
        }
    }
    for(int l1=0;l1<maxLabel;l1++){
        for(int l2=1;l2<maxLabel+1;l2++){
            if(CorrespondingOrderedLabels[l1]==l2){
                CorrespondanceOrderedLabels[l2-1]=l1+1;
            }
        }
    }
    delete [] CorrespondingOrderedLabels;
    CorrespondingOrderedLabels=NULL;
    return CorrespondanceOrderedLabels;
}

    
    //Returns for the given lesion Label the proportion of voxels on its border belonging to either one of the given segmentation tissues
    float * TreeEM::ProportionNeighboursLesion(int * LesionLabeling, int Label, int * HardSegLong,SEG_PARAMETERS * segment_param){
        if(HardSegLong==NULL){
            return NULL;
        }
//        int BorderType=1;
        int Dim[3];
        int Shift[3];
        nifti_image * BasicImage=this->GetDataImage();
        for(int d=0;d<3;d++){
            Dim[d]=BasicImage->dim[d+1];
        }
        Shift[0]=1;
        Shift[1]=Dim[0];
        Shift[2]=Shift[1]*Dim[1];
        int numel=this->GetNumberElements();
        int numbclasses = this->GetNumberGeneralClasses();
//        int IndexOut=segment_param->IndexOut;
        //    Create the oppose bool array to the one corresponding to the lesion and create indices border for this one
        bool * LesionBool=this->CreateLesionBool(LesionLabeling,Label, numel);
        bool * OpposeLesion=OpposeBoolArray(LesionBool, numel);
        int * OpposeLesionInt=TranscribeArray<bool, int>(OpposeLesion, numel);
        vector<int> VectorIndicesBorderLesion=GetIndicesBorderLesion(OpposeLesionInt, 1, Dim, Shift);
        int numbBorder=VectorIndicesBorderLesion.size();
        if (numbBorder==0) {
            return NULL;
        }
        
        //    Create and fill the proportion array
        float * ResultProportion=new float[numbclasses+1];
        for (int i=0; i<=numbclasses; i++) {
            ResultProportion[i]=0;
        }
        for (int i=0; i<numbBorder; i++) {
            if(HardSegLong[VectorIndicesBorderLesion[i]]>-1){
                ResultProportion[HardSegLong[VectorIndicesBorderLesion[i]]]++;
            }
            else{
                ResultProportion[numbclasses]++;
            }
        }
        for (int c=0; c<=numbclasses; c++) {
            ResultProportion[c]/=1.0*numbBorder;
        }
        //    Clearing before returning
        if(LesionBool !=NULL){
            delete [] LesionBool;
            LesionBool=NULL;
        }
        if(OpposeLesion!=NULL){
            delete [] OpposeLesion;
            OpposeLesion=NULL;
        }
        if (OpposeLesionInt!=NULL) {
            delete [] OpposeLesionInt;
            OpposeLesionInt=NULL;
        }
        
        return ResultProportion;
    }

// Returns in a vector of indices the list of indices of voxels belonging to lesion that are at the border with another tissue.
vector<int> TreeEM::GetIndicesBorderLesion (int * OrderedLabels, int Label, int * Dim, int * Shift){
    int numel=Dim[0]*Dim[1]*Dim[2];
    vector<int>VectorIndicesBorderLesion;
    int maxLabel=GetMaxArray(OrderedLabels, numel);
    if (Label<1 || Label>maxLabel) {
        cout<<"No appropriate label value for indices of border lesion"<<endl;
        return VectorIndicesBorderLesion;
    }
    for(int i=0;i<numel;i++){
        if(OrderedLabels[i]==Label){
            bool flag_border=0;
            //            int * List6Neighbours=Get6Neighbours(i, Dim,Shift);
            int List6Neighbours[6];
            GetListNeighbours_bis(List6Neighbours, i, Dim, Shift, 6);
            //            int * List6Neighbours=GetListNeighbours(i, Dim, Shift, 6);
            for(int n=0;n<6;n++){
                if(OrderedLabels[List6Neighbours[n]]!=Label){
                    flag_border=1;
                }
            }
            if (flag_border) {
                VectorIndicesBorderLesion.push_back(i);
            }
            //            delete [] List6Neighbours;
            //            List6Neighbours=NULL;
        }
    }
    return VectorIndicesBorderLesion;
}



//Returns the binary segmentation of a given lesion given its label and the number of elements considered
bool * TreeEM::CreateLesionBool(int * LesionLabeling, int Label,int numel ){
    //    Check if Label is compatible
    int maxLabel=GetMaxArray(LesionLabeling, numel);
    if (maxLabel<Label) {
        return NULL;
    }
    bool * LesionBool=new bool[numel];
    for (int i=0; i<numel; i++) {
        if (LesionLabeling[i]==Label) {
            LesionBool[i]=1;
        }
        else{
            LesionBool[i]=0;
        }
    }
    return LesionBool;
}


void TreeEM::CorrectNormRespToUniform(float * Correction, int GeneralInit, int UniformFin, int CorrectionType){
    vector<TreeEM *> ClassesToMinus;
    vector<TreeEM *> ClassesToPlus=this->GetUniformLeavesVector();
    float * ClassToPlusNormResp=ClassesToPlus[UniformFin]->GetNormResp();
    int numelmasked=this->GetNumberMaskedElements();
    switch (CorrectionType){
        case 0: {// from outlier to outlier
            ClassesToMinus=this->GetNodeOutlier()->GetChild(GeneralInit)->GetAllDirectLeaves();
            if(ClassesToMinus.size()==0){
                ClassesToMinus.push_back(this->GetNodeOutlier()->GetChild(GeneralInit));
            }
        }
            break;
        case 1:{ //from inlier to outlier
            ClassesToMinus=this->GetNodeInlier()->GetChild(GeneralInit)->GetAllDirectLeaves();
            if(ClassesToMinus.size()==0){
                ClassesToMinus.push_back(this->GetNodeInlier()->GetChild(GeneralInit));
            }
        }
            break;
        default:{ // outlier to outlier as case 0
            ClassesToMinus=this->GetNodeOutlier()->GetChild(GeneralInit)->GetAllDirectLeaves();
            if(ClassesToMinus.size()==0){
                ClassesToMinus.push_back(this->GetNodeOutlier()->GetChild(GeneralInit));
            }
        }
    }
    
    //    Once the ClassToMinus and ClassToPlus have been found, do the proper change in the class
    int SizeMinus=ClassesToMinus.size();
    for (int c=0; c<SizeMinus; c++) {
        float * ClassToMinusNormResp=ClassesToMinus[c]->GetNormResp();
    for (int i=0;i<numelmasked;i++){
        if(Correction[i]>0){
            ClassToPlusNormResp[i]+=ClassToMinusNormResp[i];
            ClassToMinusNormResp[i]=0;
        }
    }
    }
}

// WARNING Can only be done on a basic tree otherwise does not make much sense
void TreeEM::CorrectNormResp(float * Correction, int InitialClass, int FinalClass, int CorrectionType){
    float * ClassToMinus;
    float * ClassToPlus;
    int numelmasked=this->GetNumberMaskedElements();
    switch (CorrectionType){
        case 0: {// from outlier to outlier
            ClassToMinus=this->GetNodeOutlier()->GetChild(InitialClass)->GetNormResp();
            ClassToPlus=this->GetNodeOutlier()->GetChild(FinalClass)->GetNormResp();
        }
            break;
        case 1:{ //from inlier to inlier
            ClassToMinus=this->GetNodeInlier()->GetChild(InitialClass)->GetNormResp();
            ClassToPlus=this->GetNodeInlier()->GetChild(FinalClass)->GetNormResp();
        }
            break;
        case 2:{ // from outlier to inlier
            ClassToMinus=this->GetNodeOutlier()->GetChild(InitialClass)->GetNormResp();
            ClassToPlus=this->GetNodeInlier()->GetChild(FinalClass)->GetNormResp();
        }
            break;
        case 3:{ // from inlier to outlier
            ClassToMinus=this->GetNodeInlier()->GetChild(InitialClass)->GetNormResp();
            ClassToPlus=this->GetNodeOutlier()->GetChild(FinalClass)->GetNormResp();
        }
            break;
        default:{ // outlier to outlier as case 0
            ClassToMinus=this->GetNodeOutlier()->GetChild(InitialClass)->GetNormResp();
            ClassToPlus=this->GetNodeOutlier()->GetChild(FinalClass)->GetNormResp();
        }
    }
    
    //    Once the ClassToMinus and ClassToPlus have been found, do the proper change in the class
    for (int i=0;i<numelmasked;i++){
        ClassToMinus[i]-=Correction[i];
        ClassToPlus[i]+=Correction[i];
    }
    
}

//Returns the binary Parenchymal segmentation using the maximum segmentation (8 possible choices)
bool * TreeEM::GetWMDGMSegBool(int * HardSegLeaves,SEG_PARAMETERS* segment_param){
    int numelmasked=this->GetNumberMaskedElements();
    int * S2L=this->GetS2L();
//    First try to find DGM segmentation based on filename in segment_param;
    nifti_image * DGMPrior=NULL;
    float * DGMPotential=NULL;
    if(!segment_param->flag_DGMPrior){
        cout<<"No DGM prior read through segment_param"<<endl;
        DGMPotential=new float[numelmasked];
//        need to create something to use as DGM potential afterwards
        for(int i=0;i<numelmasked;i++){
            DGMPotential[i]=0;
        }
    }
    else{
        DGMPrior=ReadFromFilename(segment_param->filename_DGMPrior);
        float * DGMData=static_cast<float *>(DGMPrior->data);
        DGMPotential=MakeSmall(DGMData, S2L, numelmasked);
    }
//    Initialise the Parenchymal segmentation
    
    bool * WMDGMSeg=new bool[numelmasked];
    int IndexWM=segment_param->IndexWM;
    int IndexGM=segment_param->IndexGM;
    int numbclasses=this->GetNumberGeneralClasses();
//    Combine the WM+WMO+(GM+GMO)restricted to DGM
    for(int i=0;i<numelmasked;i++){
        WMDGMSeg[i]=0;
        if(HardSegLeaves[i]==IndexWM || HardSegLeaves[i]==IndexWM+numbclasses){
            WMDGMSeg[i]=1;
        }
        if(HardSegLeaves[i]==IndexGM || HardSegLeaves[i]==IndexGM+numbclasses){
            if(DGMPotential[i]>0.3){
                WMDGMSeg[i]=1;
            }
        }

    }
    if(DGMPotential!=NULL){
        delete [] DGMPotential;
        DGMPotential=NULL;
    }
    if(DGMPrior!=NULL){
        nifti_image_free(DGMPrior);
        DGMPrior=NULL;
    }
    return WMDGMSeg;
}


bool TreeEM::IsOutsideMask(vector<int> ListIndices){
    bool Result=0;
    int * L2S_PTR=this->GetL2S();
//    int numel=this->GetNumberElements();
    int sizeInd=ListIndices.size();
    for (int i=0; i<sizeInd; i++) {
        if (L2S_PTR[ListIndices[i]]<0) {
            Result=1;
            break;
        }
    }
    return Result;
}








nifti_image * TreeEM::CorrectInitialEMResultForWrongWMHoles(SEG_PARAMETERS * segment_param){
//First get the modalities in the used system in order to avoid
    int * Modalities=this->GetModalities(segment_param);
    int numel=this->GetNumberElements();
    int * L2S=this->GetL2S();
//    int IndexCSF=segment_param->IndexCSF;
    int IndexWM=segment_param->IndexWM;
//    int IndexGM=segment_param->IndexGM;
    int Dim[3];
    int Shift[3];
    nifti_image * BasicImage=this->GetDataImage();
    for(int d=0;d<3;d++){
        Dim[d]=BasicImage->dim[d+1];
    }
    Shift[0]=1;
    Shift[1]=Dim[0];
    Shift[2]=Dim[1]*Shift[1];
// Need to get the initial outlier + separated segmentation
int * HardSeg=this->GetHardSeg();


//    Initialise Image result
   nifti_image * ResultOpposedComponents=nifti_copy_nim_info(this->GetDataImage());
    ResultOpposedComponents->dim[0]=3;
    ResultOpposedComponents->dim[4]=1;
    ResultOpposedComponents->dim[5]=1;
    nifti_update_dims_from_array(ResultOpposedComponents);
    ResultOpposedComponents->data=(void *) calloc(ResultOpposedComponents->nvox, sizeof(float));
    float * ResultData=static_cast<float *>(ResultOpposedComponents->data);
    for(int i=0;i<numel;i++){
        ResultData[i]=0;
    }
// Need to correct for CSF in WMO if extended
    if(this->IsBasicTree()){
    this->CorrectWMOforCSFInclusion(segment_param);
        this->RebuildNormRespFromLeaves();
    }
    cout<<"Check NormResp after WMO CSF correction "<<this->AreNormRespValid()<<endl;

    
    this->UpdateHardSeg();
    HardSeg=this->GetHardSeg();
    int numelmasked=this->GetNumberMaskedElements();
    float * HardSegFloat=TranscribeArray<int, float>(HardSeg, numelmasked);
//    SaveTmpResultMasked(HardSegFloat, "/Users/Carole/Documents/PhD/SABRE_80/TestJuxta/HardSegInit.nii.gz");
    delete [] HardSegFloat;
    HardSegFloat=NULL;
    

    
////    Get LesionSegmentation of elements in CSFO or GMO
//float * LesAlternateGM=this->GetLesionGMCSFSeg(HardSeg,1,segment_param);
//    SaveTmpResultMasked(LesAlternateGM, "/Users/Carole/Documents/PhD/ISBI/TestStrange/AlternateGMLes.nii.gz");
//float * LesAlternateCSF=this->GetLesionGMCSFSeg(HardSeg,2,segment_param);
//     SaveTmpResultMasked(LesAlternateCSF, "/Users/Carole/Documents/PhD/ISBI/TestStrange/AlternateCSFLes.nii.gz");
//
//    
///* The obtained LesAlternateGM and LesAlternateCSF reclassified into WMO. With option 0, the transfer is done from outlier to another outlier region */
//    if (this->IsBasicTree()) {
//        this->CorrectNormResp(LesAlternateCSF,IndexCSF,IndexWM,0);
//        //    Same as before but with LesAlternateGM
//        this->CorrectNormResp(LesAlternateGM,IndexGM,IndexWM,0);
//    }
//    else{
//        this->CorrectNormRespToUniform(LesAlternateCSF,IndexCSF,IndexWM,0);
//        //    Same as before but with LesAlternateGM
//        this->CorrectNormRespToUniform(LesAlternateGM,IndexGM,IndexWM,0);
//    }

    

//    Need to obtain the parenchymal segmentation : for that need also DGM prior and corresponding segmentation
    this->RebuildNormRespFromLeaves();
    cout<<"Check NormResp after GMO CSFO correction "<<this->AreNormRespValid()<<endl;
    this->UpdateHardSeg();
    HardSeg=this->GetHardSeg();
    HardSegFloat=TranscribeArray<int, float>(HardSeg, numelmasked);
//    SaveTmpResultMasked(HardSegFloat, "/Users/Carole/Documents/PhD/ISBI/TestStrange/HardSegAfter.nii.gz");
    delete [] HardSegFloat;
    HardSegFloat=NULL;
    
//    int * HardSegLeaves=this->MakeHardSegLeaves(); // As applied on initial 8 leaves problem ,will get directly the WM+WMO as result of HardSeg of value IndexWM and IndexWM+numbclasses
    int * HardSegCombined=this->MakeHardSegCombined();
    HardSegFloat=TranscribeArray<int, float>(HardSeg, numelmasked);
//    SaveTmpResultMasked(HardSegFloat, "/Users/Carole/Documents/PhD/ISBI/TestStrange/HardSegAfter.nii.gz");
    delete [] HardSegFloat;
    HardSegFloat=NULL;
    
    bool * ParenchymalSegBool=this->GetWMDGMSegBool(HardSegCombined,segment_param);
    
    float * ParenchymaFloat=TranscribeArray<bool, float>(ParenchymalSegBool, numelmasked);
//    SaveTmpResultMasked(ParenchymaFloat, "/Users/Carole/Documents/PhD/ISBI/TestStrange/WMDGM.nii.gz");
    delete [] ParenchymaFloat;
    ParenchymaFloat=NULL;


// Need to get the connected components of the WMO part
// Need first to get everything in the long format instead of the short one
    bool * Parenchyma_long=MakeLong(ParenchymalSegBool, L2S, numel);
    int * HardSegCombinedLong=MakeLongPad(HardSegCombined, -1, L2S, numel);
//    int * HardSegLong=MakeLongPad(HardSeg, -1, L2S, numel);
    float* OpposedParenchymal_long=new float[numel];
    int numbclasses=this->GetNumberGeneralClasses();
    for(int i=0;i<numel;i++){
        OpposedParenchymal_long[i]=!Parenchyma_long[i];
    }
    int * ComponentOpposedParenchyma=ComponentLabeling(OpposedParenchymal_long, 6, Dim, Shift, 0.5);
    int * OrderedComponentsOppPar=OrderedVolumeLabel(ComponentOpposedParenchyma, 1, numel);
    float * ComponentOpposedFloat=TranscribeArray<int, float>(OrderedComponentsOppPar, numel);
//    this->SaveTmpResult(ComponentOpposedFloat, "/Users/Carole/Documents/PhD/ISBI/TestStrange/OpposedComponents.nii.gz");
    
//    For each of the elements that could be actually the filling of holes the WM, check the proportion of neighbours  and how far it is from border of mask. If not close to Out and none of its elements is outside of the mask, need to reclassify as WM. For that purpose, add norm resp of all leaves for this voxel to the WMO class.
    int OpposedParLabelMax=GetMaxArray(ComponentOpposedParenchyma, numel);
    float * NormRespWMO=NULL;
    vector<TreeEM *> UniformLeaves=this->GetUniformLeavesVector();
    int sizeUniform=UniformLeaves.size();
    if (sizeUniform>1) {
        NormRespWMO=UniformLeaves[IndexWM]->GetNormResp();
    }
    else if(sizeUniform>0){
        NormRespWMO=UniformLeaves[0]->GetNormResp();
    }
    vector<TreeEM *> LeavesTreeVector=this->GetAllLeaves();
    int numbLeaves=LeavesTreeVector.size();
    int CountNotAccepted=0;
    int CountSup1Pb=0;
    for(int o=0;o<OpposedParLabelMax;o++){
        float * ProportionTemp=this->ProportionNeighboursLesion(OrderedComponentsOppPar, o+1, HardSegCombinedLong, segment_param);
        vector<int> IndicesToPushToWMO=this->GetIndicesValue(ComponentOpposedParenchyma, o+1, numel);
        if(ProportionTemp[numbclasses-1]+ProportionTemp[numbClasses]<=0.0001 && !this->IsOutsideMask(IndicesToPushToWMO)){ // if not close or in exterior of mask.
            
            int SizeComponent=IndicesToPushToWMO.size();
                for(int c=0;c<numbLeaves;c++){
                    vector<int> HierarchyLeave=LeavesTreeVector[c]->GetHierarchyVector();
                    if(HierarchyLeave[1]!=IndexWM){
                        
                        float * NormRespToCorrect=LeavesTreeVector[c]->GetNormResp();
                        for(int s=0;s<SizeComponent;s++){
                            NormRespWMO[L2S[IndicesToPushToWMO[s]]]+=NormRespToCorrect[L2S[IndicesToPushToWMO[s]]];
                            NormRespToCorrect[L2S[IndicesToPushToWMO[s]]]=0;
                    }
                }
            }
//            Putting the final value of NormRespWMO in ResultData
            for (int s=0; s<SizeComponent; s++) {
                ResultData[IndicesToPushToWMO[s]]=NormRespWMO[L2S[IndicesToPushToWMO[s]]];
                if (ResultData[IndicesToPushToWMO[s]]>1) {
                    CountSup1Pb++;
                }
            }
        }
        else{
            CountNotAccepted++;
        }
        if(ProportionTemp!=NULL){
            delete [] ProportionTemp;
            ProportionTemp=NULL;
        }
    }
    cout<<"Pb sup 1 is "<<CountSup1Pb<<endl;
    cout<<"Not accepted is "<<CountNotAccepted<<"over "<<OpposedParLabelMax<<endl;
    delete [] HardSegCombined;
    HardSegCombined=NULL;
//    this->SaveAllClasses("/Users/Carole/Documents/PhD/ISBI/TestStrange/JuxtaCorr2.nii.gz", segment_param);
    this->RebuildNormRespFromLeaves();
    cout<<"After reshuffling "<<this->AreNormRespValid()<<endl;
    this->UpdateNormRespRoot();
//    this->SaveAllClasses("/Users/Carole/Documents/PhD/ISBI/TestStrange/JuxtaCorrectionClasses2.nii.gz", segment_param);
//    this->UpdateParameters();
//    this->UpdateNonNormResp(segment_param);
//    this->UpdateNormResp();
    
    this->UpdateHardSeg();
    HardSeg=this->GetHardSeg();

    numelmasked=this->GetNumberMaskedElements();
    HardSegFloat=TranscribeArray<int, float>(HardSeg, numelmasked);
//    SaveTmpResultMasked(HardSegFloat, "/Users/Carole/Documents/PhD/TemporaryFiles/TestHardSegCorr.nii.gz");
    delete [] HardSegFloat;
    HardSegFloat=NULL;
    delete [] Modalities;
    Modalities=NULL;
    if(ComponentOpposedParenchyma!=NULL){
        delete [] ComponentOpposedParenchyma;
        ComponentOpposedParenchyma=NULL;
    }
    if (ComponentOpposedFloat!=NULL) {
        delete [] ComponentOpposedFloat;
        ComponentOpposedFloat=NULL;
    }
    if(HardSegCombinedLong!=NULL){
        delete [] HardSegCombinedLong;
        HardSegCombinedLong=NULL;
    }
    
    delete [] ParenchymalSegBool;
    delete [] Parenchyma_long;
    delete [] OpposedParenchymal_long;
    delete [] OrderedComponentsOppPar;
    OrderedComponentsOppPar=NULL;
//    delete [] LesAlternateCSF;
//    delete [] LesAlternateGM;
// To get the final segmentation
    return ResultOpposedComponents;

}


// When NormResp coming from overall segmentation has been plugged back into TreeSkeleton, reconstruct all other NormResp at other levels of the Tree. Especially needed when all files are not available at the same time to reconstruct perfectly the tree and still needed for analysis
void TreeEM::RebuildNormRespFromLeaves(){
    // we assume the tree has been properly rebuilt with the text file at least for the leaves
    // First set to NULL all Norm Resp that do not correspond to leaves.
    this->NullAllNonLeavesNormResp();
    if (this->GetNormResp()==NULL){
        int numbchild=this->GetNumberChildren();
        for (int c=0; c<numbchild; c++) {
            this->GetChild(c)->RebuildNormRespFromLeaves();
        }
        float * NewNormRespToSet=this->SumNormRespChildren();
        this->SetNormResp(NewNormRespToSet);
        if (NewNormRespToSet!=NULL) {
            delete [] NewNormRespToSet;
            NewNormRespToSet=NULL;
        }
    }
}

// If Reconstructed tree used not good priors or pb with the files introduced, allows to reset all normResp that do not correspond to leaves and NULL priors as well
void TreeEM::NullAllNonLeavesNormResp(){
    if (this->IsLeaf() || this->GetNormResp()==NULL) {
        return;
    }
    else {
        this->SetNormResp(NULL);
        int numbchild=this->GetNumberChildren();
        for (int c=0; c<numbchild; c++) {
            this->GetChild(c)->NullAllNonLeavesNormResp();
        }
    }
}

// sum the norm resp of children to rebuild the norm resp of current node.
float * TreeEM::SumNormRespChildren(){
    float * ResultSumNormRespChildren=NULL;
    int numelmasked=this->GetNumberMaskedElements();
    if (this->IsLeaf() && this->GetNormResp()==NULL){
        return NULL;
    }
    if (this->IsLeaf() && this->GetNormResp()!=NULL) {
        ResultSumNormRespChildren=new float[numelmasked];
        float * NormRespData=this->GetNormResp();
        for (int i=0; i<numelmasked; i++) {
            ResultSumNormRespChildren[i]=NormRespData[i];
        }
        return ResultSumNormRespChildren;
    }
    else if(!this->IsLeaf()){
        ResultSumNormRespChildren=new float[numelmasked];
        for (int i=0; i<numelmasked; i++) {
            ResultSumNormRespChildren[i]=0;
        }
        int numbchild=this->GetNumberChildren();
        for (int c=0; c<numbchild; c++) {
            float * TmpNormResp=this->GetChild(c)->GetNormResp();
            if (TmpNormResp!=NULL) {
                for (int i=0; i<numelmasked; i++) {
                    ResultSumNormRespChildren[i]+=TmpNormResp[i];
                }
            }
        }
        return ResultSumNormRespChildren;
    }
    return ResultSumNormRespChildren;
}





